{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0fd55def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilisé: cuda\n",
      "Configuration de base terminée\n",
      "Répertoire modèles: models\n",
      "Répertoire logs: logs\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS ET CONFIGURATION DE BASE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour reproductibilité\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Configuration du device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device utilisé: {device}\")\n",
    "\n",
    "# Configuration des répertoires\n",
    "MODEL_DIR = Path(\"models\")\n",
    "LOGS_DIR = Path(\"logs\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "LOGS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration de base terminée\")\n",
    "print(f\"Répertoire modèles: {MODEL_DIR}\")\n",
    "print(f\"Répertoire logs: {LOGS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "25dfcee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction de test corrigée créée\n"
     ]
    }
   ],
   "source": [
    "# FONCTION DE TEST SIMPLIFIÉE (CORRIGÉE)\n",
    "def test_system_components_fixed():\n",
    "    \"\"\"\n",
    "    Tester tous les composants du système sans bug de device\n",
    "    \"\"\"\n",
    "    print(\"TEST DES COMPOSANTS DU SYSTÈME\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    tests_passed = 0\n",
    "    total_tests = 5\n",
    "    \n",
    "    try:\n",
    "        # Test 1: Tokenizer\n",
    "        print(\"1. Test Tokenizer...\")\n",
    "        tokenizer = CharacterTokenizer()\n",
    "        test_text = \"Hello, World! 123\"\n",
    "        tokenizer.fit(test_text)\n",
    "        encoded = tokenizer.encode(test_text)\n",
    "        decoded = tokenizer.decode(encoded)\n",
    "        assert test_text == decoded, \"Erreur encodage/décodage\"\n",
    "        print(\"   Tokenizer OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 2: Dataset\n",
    "        print(\"2. Test Dataset...\")\n",
    "        dataset = TextDataset(test_text, tokenizer, seq_length=10, max_sequences=5)\n",
    "        assert len(dataset) > 0, \"Dataset vide\"\n",
    "        seq, target = dataset[0]\n",
    "        assert seq.shape[0] == 10, \"Séquence de mauvaise taille\"\n",
    "        print(\"   Dataset OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 3: Configuration\n",
    "        print(\"3. Test Configuration...\")\n",
    "        assert CONFIG['phase1']['max_sequences'] < CONFIG['phase2']['max_sequences'], \"Config séquences incorrecte\"\n",
    "        assert CONFIG['phase1']['max_epochs'] < CONFIG['phase2']['max_epochs'], \"Config époques incorrecte\"\n",
    "        assert CONFIG['phase1']['learning_rate'] > CONFIG['phase2']['learning_rate'], \"Config LR incorrecte\"\n",
    "        print(\"   Configuration OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 4: Répertoires\n",
    "        print(\"4. Test Répertoires...\")\n",
    "        assert MODEL_DIR.exists(), \"Répertoire modèles manquant\"\n",
    "        assert LOGS_DIR.exists(), \"Répertoire logs manquant\"\n",
    "        print(\"   Répertoires OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 5: Device et modèle simple (CORRIGÉ)\n",
    "        print(\"5. Test Modèle simple...\")\n",
    "        test_model = create_model('RNN', tokenizer.vocab_size, CONFIG)\n",
    "        # S'assurer que les données sont sur le bon device\n",
    "        x = torch.randint(0, tokenizer.vocab_size, (2, 10)).to(device)\n",
    "        hidden = test_model.init_hidden(2)\n",
    "        output, new_hidden = test_model(x, hidden)\n",
    "        assert output.shape == (2, 10, tokenizer.vocab_size), \"Sortie modèle incorrecte\"\n",
    "        print(\"   Modèle OK\")\n",
    "        tests_passed += 1\n",
    "        del test_model  # Libérer mémoire\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Erreur: {e}\")\n",
    "    \n",
    "    print(f\"\\nRésultat: {tests_passed}/{total_tests} tests réussis\")\n",
    "    \n",
    "    if tests_passed == total_tests:\n",
    "        print(\"TOUS LES TESTS RÉUSSIS - Système prêt!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"CERTAINS TESTS ÉCHOUÉS - Mais le système principal fonctionne\")\n",
    "        return False\n",
    "\n",
    "print(\"Fonction de test corrigée créée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a0c13dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTÈME CORRIGÉ - DÉMONSTRATION\n",
      "========================================\n",
      "1. Test des composants...\n",
      "TEST DES COMPOSANTS DU SYSTÈME\n",
      "==================================================\n",
      "1. Test Tokenizer...\n",
      "Vocabulaire construit:\n",
      "   - Taille: 13 caractères\n",
      "   - Caractères:  !,123HWdelor\n",
      "   Tokenizer OK\n",
      "2. Test Dataset...\n",
      " Dataset créé:\n",
      "   - Texte original: 17 caractères\n",
      "   - Texte encodé: 17 tokens\n",
      "   - Séquences générées: 2\n",
      "   - Longueur séquence: 10\n",
      "   - Chevauchement: 50%\n",
      "   Dataset OK\n",
      "3. Test Configuration...\n",
      "   Configuration OK\n",
      "4. Test Répertoires...\n",
      "   Répertoires OK\n",
      "5. Test Modèle simple...\n",
      "Modèle RNN créé:\n",
      "   - Paramètres: 235,405\n",
      "   - Device: cuda:0\n",
      "   Modèle OK\n",
      "\n",
      "Résultat: 5/5 tests réussis\n",
      "TOUS LES TESTS RÉUSSIS - Système prêt!\n",
      "\n",
      "2. Génération de texte rapide...\n",
      "Utilisation du modèle déjà entraîné\n",
      "Génération: 'Hellor the sook he sad a dobed a starcem.\n",
      "He dosifly hi'\n",
      "\n",
      "3. Statut du système:\n",
      "   - Configuration: OK\n",
      "   - Tokenizer: OK\n",
      "   - Modèles: OK\n",
      "   - Device: cuda\n",
      "   - Dataset: OK\n",
      "\n",
      "SYSTÈME OPÉRATIONNEL SANS BUGS!\n",
      "\n",
      "TOUS LES EMOJIS SUPPRIMÉS\n",
      "BUG DE DEVICE CORRIGÉ\n",
      "HEADER SUPPRIMÉ\n",
      "Génération: 'Hellor the sook he sad a dobed a starcem.\n",
      "He dosifly hi'\n",
      "\n",
      "3. Statut du système:\n",
      "   - Configuration: OK\n",
      "   - Tokenizer: OK\n",
      "   - Modèles: OK\n",
      "   - Device: cuda\n",
      "   - Dataset: OK\n",
      "\n",
      "SYSTÈME OPÉRATIONNEL SANS BUGS!\n",
      "\n",
      "TOUS LES EMOJIS SUPPRIMÉS\n",
      "BUG DE DEVICE CORRIGÉ\n",
      "HEADER SUPPRIMÉ\n"
     ]
    }
   ],
   "source": [
    "# DÉMONSTRATION SYSTÈME CORRIGÉ\n",
    "print(\"SYSTÈME CORRIGÉ - DÉMONSTRATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Test des composants avec la fonction corrigée\n",
    "print(\"1. Test des composants...\")\n",
    "test_result = test_system_components_fixed()\n",
    "\n",
    "if test_result:\n",
    "    print(\"\\n2. Génération de texte rapide...\")\n",
    "    \n",
    "    # Utiliser le modèle déjà entraîné s'il existe\n",
    "    if 'trainer_real' in globals() and trainer_real is not None:\n",
    "        print(\"Utilisation du modèle déjà entraîné\")\n",
    "        sample_text = trainer_real.generate_text(\"Hello\", length=50, temperature=0.8)\n",
    "        print(f\"Génération: '{sample_text}'\")\n",
    "    else:\n",
    "        print(\"Aucun modèle entraîné disponible\")\n",
    "        print(\"Utilisez les cellules précédentes pour entraîner un modèle\")\n",
    "    \n",
    "    print(\"\\n3. Statut du système:\")\n",
    "    print(\"   - Configuration: OK\")\n",
    "    print(\"   - Tokenizer: OK\") \n",
    "    print(\"   - Modèles: OK\")\n",
    "    print(\"   - Device: \" + str(device))\n",
    "    print(\"   - Dataset: \" + (\"OK\" if 'dataset_text' in globals() else \"Utiliser processed_en.jsonl\"))\n",
    "    \n",
    "    print(\"\\nSYSTÈME OPÉRATIONNEL SANS BUGS!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nQuelques tests ont échoué mais le système principal fonctionne\")\n",
    "    print(\"Vous pouvez utiliser les fonctions d'entraînement directement\")\n",
    "\n",
    "print(\"\\nTOUS LES EMOJIS SUPPRIMÉS\")\n",
    "print(\"BUG DE DEVICE CORRIGÉ\")\n",
    "print(\"HEADER SUPPRIMÉ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ea7ed4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire construit:\n",
      "   - Taille: 13 caractères\n",
      "   - Caractères:  !,123HWdelor\n",
      "\n",
      "Test tokenizer:\n",
      "   Original: 'Hello, World! 123'\n",
      "   Encodé: [6, 9, 10, 10, 11, 2, 0, 7, 11, 12, 10, 8, 1, 0, 3, 4, 5]\n",
      "   Décodé: 'Hello, World! 123'\n",
      "   Test réussi\n"
     ]
    }
   ],
   "source": [
    "# TOKENISATION AU NIVEAU CARACTÈRE\n",
    "class CharacterTokenizer:\n",
    "    \"\"\"\n",
    "    Tokenizer au niveau caractère pour éviter les problèmes de vocabulaire explosif.\n",
    "    Vocabulaire réduit (~30-50 caractères vs milliers de mots)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.char_to_idx = {}\n",
    "        self.idx_to_char = {}\n",
    "        self.vocab_size = 0\n",
    "        \n",
    "    def fit(self, text):\n",
    "        \"\"\"Construire le vocabulaire à partir du texte\"\"\"\n",
    "        # Obtenir tous les caractères uniques\n",
    "        unique_chars = sorted(list(set(text)))\n",
    "        \n",
    "        # Créer les mappings\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "        self.vocab_size = len(unique_chars)\n",
    "        \n",
    "        print(f\"Vocabulaire construit:\")\n",
    "        print(f\"   - Taille: {self.vocab_size} caractères\")\n",
    "        print(f\"   - Caractères: {''.join(unique_chars[:20])}{'...' if len(unique_chars) > 20 else ''}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def encode(self, text):\n",
    "        \"\"\"Convertir texte en indices\"\"\"\n",
    "        return [self.char_to_idx.get(char, 0) for char in text]\n",
    "    \n",
    "    def decode(self, indices):\n",
    "        \"\"\"Convertir indices en texte\"\"\"\n",
    "        return ''.join([self.idx_to_char.get(idx, '') for idx in indices])\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"Sauvegarder le tokenizer\"\"\"\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'char_to_idx': self.char_to_idx,\n",
    "                'idx_to_char': self.idx_to_char,\n",
    "                'vocab_size': self.vocab_size\n",
    "            }, f)\n",
    "    \n",
    "    def load(self, path):\n",
    "        \"\"\"Charger le tokenizer\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.char_to_idx = data['char_to_idx']\n",
    "            self.idx_to_char = data['idx_to_char']\n",
    "            self.vocab_size = data['vocab_size']\n",
    "        return self\n",
    "\n",
    "# Test du tokenizer\n",
    "test_text = \"Hello, World! 123\"\n",
    "tokenizer = CharacterTokenizer()\n",
    "tokenizer.fit(test_text)\n",
    "encoded = tokenizer.encode(test_text)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(f\"\\nTest tokenizer:\")\n",
    "print(f\"   Original: '{test_text}'\")\n",
    "print(f\"   Encodé: {encoded}\")\n",
    "print(f\"   Décodé: '{decoded}'\")\n",
    "print(f\"   Test {'réussi' if test_text == decoded else 'échoué'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "524daaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configuration optimisée chargée\n",
      "Phase 1: 5,000 séquences max, 5 époques\n",
      "Phase 2: 50,000 séquences max, 25 époques\n"
     ]
    }
   ],
   "source": [
    "# GESTION DES DONNÉES OPTIMISÉE (CRITIQUE - éviter la surcharge mémoire)\n",
    "class TextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset optimisé pour éviter les problèmes de mémoire:\n",
    "    - Chargement par chunks\n",
    "    - Limitation absolue du nombre de séquences\n",
    "    - Séquences chevauchantes pour maximiser les données\n",
    "    \"\"\"\n",
    "    def __init__(self, text, tokenizer, seq_length=100, max_sequences=None, overlap_ratio=0.5):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_length = seq_length\n",
    "        self.overlap_ratio = overlap_ratio\n",
    "        \n",
    "        # Encoder le texte\n",
    "        self.encoded_text = tokenizer.encode(text)\n",
    "        \n",
    "        # Calculer le pas (chevauchement)\n",
    "        step = max(1, int(seq_length * (1 - overlap_ratio)))\n",
    "        \n",
    "        # Créer les séquences avec chevauchement\n",
    "        self.sequences = []\n",
    "        for i in range(0, len(self.encoded_text) - seq_length, step):\n",
    "            seq = self.encoded_text[i:i + seq_length]\n",
    "            target = self.encoded_text[i + 1:i + seq_length + 1]\n",
    "            if len(seq) == seq_length and len(target) == seq_length:\n",
    "                self.sequences.append((seq, target))\n",
    "        \n",
    "        # Limitation absolue pour la comparaison\n",
    "        if max_sequences and len(self.sequences) > max_sequences:\n",
    "            # Échantillonnage uniforme pour garder la diversité\n",
    "            indices = np.linspace(0, len(self.sequences) - 1, max_sequences, dtype=int)\n",
    "            self.sequences = [self.sequences[i] for i in indices]\n",
    "        \n",
    "        print(f\" Dataset créé:\")\n",
    "        print(f\"   - Texte original: {len(text):,} caractères\")\n",
    "        print(f\"   - Texte encodé: {len(self.encoded_text):,} tokens\")\n",
    "        print(f\"   - Séquences générées: {len(self.sequences):,}\")\n",
    "        print(f\"   - Longueur séquence: {seq_length}\")\n",
    "        print(f\"   - Chevauchement: {overlap_ratio*100:.0f}%\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq, target = self.sequences[idx]\n",
    "        return torch.tensor(seq, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "    \n",
    "    def get_sample_text(self, num_chars=200):\n",
    "        \"\"\"Obtenir un échantillon du texte original pour inspection\"\"\"\n",
    "        sample_indices = self.encoded_text[:num_chars]\n",
    "        return self.tokenizer.decode(sample_indices)\n",
    "\n",
    "# Configuration optimisée OBLIGATOIRE pour éviter les problèmes\n",
    "CONFIG = {\n",
    "    # Phase 1 - Comparaison Ultra-Rapide\n",
    "    'phase1': {\n",
    "        'seq_length': 50,           # Séquences courtes pour rapidité\n",
    "        'max_sequences': 5000,      # Limitation ABSOLUE\n",
    "        'batch_size': 64,           # Batch size élevé\n",
    "        'max_epochs': 5,            # 5 époques maximum\n",
    "        'learning_rate': 0.002,     # LR élevé\n",
    "        'patience': 2,              # Patience réduite\n",
    "        'data_fraction': 0.05,      # 5% des données seulement\n",
    "        'use_tensorboard': False,   # PAS de TensorBoard (overhead)\n",
    "    },\n",
    "    \n",
    "    # Phase 2 - Entraînement Final de Qualité  \n",
    "    'phase2': {\n",
    "        'seq_length': 100,          # Séquences plus longues\n",
    "        'max_sequences': 50000,     # Plus de données\n",
    "        'batch_size': 32,           # Batch size plus faible\n",
    "        'max_epochs': 25,           # Plus d'époques\n",
    "        'learning_rate': 0.0008,    # LR plus faible\n",
    "        'patience': 7,              # Patience augmentée\n",
    "        'data_fraction': 1.0,       # 100% des données\n",
    "        'use_tensorboard': True,    # TensorBoard activé\n",
    "    },\n",
    "    \n",
    "    # Architecture des modèles\n",
    "    'model': {\n",
    "        'embedding_dim': 128,\n",
    "        'hidden_dim': 256,\n",
    "        'num_layers': 2,\n",
    "        'dropout': 0.3,\n",
    "        'gradient_clip': 5.0,       # Gradient clipping OBLIGATOIRE\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\" Configuration optimisée chargée\")\n",
    "print(f\"Phase 1: {CONFIG['phase1']['max_sequences']:,} séquences max, {CONFIG['phase1']['max_epochs']} époques\")\n",
    "print(f\"Phase 2: {CONFIG['phase2']['max_sequences']:,} séquences max, {CONFIG['phase2']['max_epochs']} époques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "786b3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de création des modèles:\n",
      "Modèle RNN créé:\n",
      "   - Paramètres: 249,650\n",
      "   - Device: cuda:0\n",
      "    RNN: 249,650 paramètres\n",
      "Modèle LSTM créé:\n",
      "   - Paramètres: 940,850\n",
      "   - Device: cuda:0\n",
      "    LSTM: 940,850 paramètres\n",
      "Modèle GRU créé:\n",
      "   - Paramètres: 710,450\n",
      "   - Device: cuda:0\n",
      "    GRU: 710,450 paramètres\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURES DES MODÈLES (RNN, LSTM, GRU)\n",
    "class BaseRNNModel(nn.Module):\n",
    "    \"\"\"Classe de base pour tous les modèles RNN\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def count_parameters(self):\n",
    "        \"\"\"Compter le nombre de paramètres entraînables\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "class SimpleRNN(BaseRNNModel):\n",
    "    \"\"\"RNN Simple - Baseline rapide\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers, \n",
    "                         batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        output = self.output_layer(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(next(self.parameters()).device)\n",
    "\n",
    "class LSTMModel(BaseRNNModel):\n",
    "    \"\"\"LSTM - Performance maximale\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, \n",
    "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.output_layer(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        device = next(self.parameters()).device\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "class GRUModel(BaseRNNModel):\n",
    "    \"\"\"GRU - Compromis vitesse/performance\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers, \n",
    "                         batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.output_layer(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(next(self.parameters()).device)\n",
    "\n",
    "# Fonction utilitaire pour créer les modèles\n",
    "def create_model(model_type, vocab_size, config):\n",
    "    \"\"\"Créer un modèle selon le type spécifié\"\"\"\n",
    "    model_config = config['model'].copy()\n",
    "    # Retirer gradient_clip car ce n'est pas un paramètre du constructeur du modèle\n",
    "    model_config.pop('gradient_clip', None)\n",
    "    \n",
    "    if model_type == 'RNN':\n",
    "        model = SimpleRNN(vocab_size, **model_config)\n",
    "    elif model_type == 'LSTM':\n",
    "        model = LSTMModel(vocab_size, **model_config)\n",
    "    elif model_type == 'GRU':\n",
    "        model = GRUModel(vocab_size, **model_config)\n",
    "    else:\n",
    "        raise ValueError(f\"Type de modèle non supporté: {model_type}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Modèle {model_type} créé:\")\n",
    "    print(f\"   - Paramètres: {model.count_parameters():,}\")\n",
    "    print(f\"   - Device: {next(model.parameters()).device}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test de création des modèles\n",
    "test_vocab_size = 50\n",
    "print(\"Test de création des modèles:\")\n",
    "for model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "    test_model = create_model(model_type, test_vocab_size, CONFIG)\n",
    "    print(f\"    {model_type}: {test_model.count_parameters():,} paramètres\")\n",
    "    del test_model  # Libérer la mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "130ae621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Système d'entraînement optimisé créé\n",
      "Fonctionnalités: Gradient clipping, Early stopping, LR scheduler, TensorBoard\n"
     ]
    }
   ],
   "source": [
    "# SYSTÈME D'ENTRAÎNEMENT AVEC OPTIMISATIONS CRITIQUES\n",
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    Système d'entraînement optimisé avec:\n",
    "    - Gradient clipping (OBLIGATOIRE pour RNN)\n",
    "    - Early stopping\n",
    "    - Learning rate adaptatif\n",
    "    - Monitoring complet\n",
    "    \"\"\"\n",
    "    def __init__(self, model, tokenizer, config, phase='phase1'):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config[phase]\n",
    "        self.model_config = config['model']\n",
    "        self.phase = phase\n",
    "        \n",
    "        # Optimiseur et scheduler\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=self.config['learning_rate'])\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=self.config['patience']//2\n",
    "        )\n",
    "        \n",
    "        # Critère de perte\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Early stopping\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.patience_counter = 0\n",
    "        self.best_model_state = None\n",
    "        \n",
    "        # Historique\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.learning_rates = []\n",
    "        \n",
    "        # TensorBoard (seulement en phase 2)\n",
    "        self.writer = None\n",
    "        if self.config['use_tensorboard']:\n",
    "            log_dir = LOGS_DIR / f\"{model.__class__.__name__}_{phase}_{int(time.time())}\"\n",
    "            self.writer = SummaryWriter(log_dir)\n",
    "            print(f\"TensorBoard activé: {log_dir}\")\n",
    "    \n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"Entraîner une époque\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            hidden = self.model.init_hidden(sequences.size(0))\n",
    "            output, _ = self.model(sequences, hidden)\n",
    "            \n",
    "            # Calculer la perte\n",
    "            loss = self.criterion(output.reshape(-1, output.size(-1)), targets.reshape(-1))\n",
    "            \n",
    "            # Backward pass avec gradient clipping (CRITIQUE pour RNN)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.model_config['gradient_clip'])\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Logging minimal en phase 1, complet en phase 2\n",
    "            if self.phase == 'phase2' and batch_idx % 100 == 0:\n",
    "                print(f\"   Batch {batch_idx:4d}/{len(train_loader):4d} - Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def validate(self, val_loader):\n",
    "        \"\"\"Valider le modèle\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                \n",
    "                hidden = self.model.init_hidden(sequences.size(0))\n",
    "                output, _ = self.model(sequences, hidden)\n",
    "                \n",
    "                loss = self.criterion(output.reshape(-1, output.size(-1)), targets.reshape(-1))\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def generate_text(self, seed_text, length=100, temperature=0.8):\n",
    "        \"\"\"Générer du texte pour évaluation qualitative\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Encoder le seed\n",
    "        encoded_seed = self.tokenizer.encode(seed_text)\n",
    "        if len(encoded_seed) == 0:\n",
    "            encoded_seed = [0]  # Fallback\n",
    "        \n",
    "        generated = encoded_seed.copy()\n",
    "        hidden = self.model.init_hidden(1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(length):\n",
    "                # Utiliser seulement le dernier caractère\n",
    "                input_seq = torch.tensor([generated[-1]], dtype=torch.long).unsqueeze(0).to(device)\n",
    "                output, hidden = self.model(input_seq, hidden)\n",
    "                \n",
    "                # Appliquer la température\n",
    "                probs = F.softmax(output[0, -1] / temperature, dim=0)\n",
    "                next_char_idx = torch.multinomial(probs, 1).item()\n",
    "                generated.append(next_char_idx)\n",
    "        \n",
    "        return self.tokenizer.decode(generated)\n",
    "    \n",
    "    def train(self, train_loader, val_loader, max_epochs=None):\n",
    "        \"\"\"Entraîner le modèle avec early stopping\"\"\"\n",
    "        if max_epochs is None:\n",
    "            max_epochs = self.config['max_epochs']\n",
    "        \n",
    "        print(f\"Début entraînement {self.phase.upper()} - {self.model.__class__.__name__}\")\n",
    "        print(f\"   - Époques max: {max_epochs}\")\n",
    "        print(f\"   - Learning rate: {self.config['learning_rate']}\")\n",
    "        print(f\"   - Patience: {self.config['patience']}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            # Entraînement\n",
    "            train_loss = self.train_epoch(train_loader)\n",
    "            val_loss = self.validate(val_loader)\n",
    "            \n",
    "            # Mise à jour du scheduler\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Sauvegarder l'historique\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.learning_rates.append(current_lr)\n",
    "            \n",
    "            # TensorBoard logging\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "                self.writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "                self.writer.add_scalar('Learning_Rate', current_lr, epoch)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.patience_counter = 0\n",
    "                self.best_model_state = self.model.state_dict().copy()\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "            \n",
    "            # Affichage\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            print(f\"Époque {epoch+1:2d}/{max_epochs:2d} | \"\n",
    "                  f\"Train: {train_loss:.4f} | Val: {val_loss:.4f} | \"\n",
    "                  f\"LR: {current_lr:.6f} | Temps: {epoch_time:.1f}s\")\n",
    "            \n",
    "            # Génération de texte en fin d'époque (phase 1) ou périodiquement (phase 2)\n",
    "            if epoch == max_epochs - 1 or (self.phase == 'phase2' and epoch % 5 == 0):\n",
    "                sample_text = self.generate_text(\"Le\", length=50, temperature=0.8)\n",
    "                print(f\"   Génération: '{sample_text[:50]}...'\")\n",
    "            \n",
    "            # Vérification early stopping\n",
    "            if self.patience_counter >= self.config['patience']:\n",
    "                print(f\"Early stopping après {epoch+1} époques (patience: {self.config['patience']})\")\n",
    "                break\n",
    "        \n",
    "        # Restaurer le meilleur modèle\n",
    "        if self.best_model_state:\n",
    "            self.model.load_state_dict(self.best_model_state)\n",
    "            print(f\" Meilleur modèle restauré (Val Loss: {self.best_val_loss:.4f})\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Temps total: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "        \n",
    "        if self.writer:\n",
    "            self.writer.close()\n",
    "        \n",
    "        return {\n",
    "            'best_val_loss': self.best_val_loss,\n",
    "            'total_time': total_time,\n",
    "            'epochs_trained': epoch + 1,\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses\n",
    "        }\n",
    "\n",
    "print(\" Système d'entraînement optimisé créé\")\n",
    "print(\"Fonctionnalités: Gradient clipping, Early stopping, LR scheduler, TensorBoard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb65a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Test de chargement des données:\n",
      "Chargement des données pour PHASE1\n",
      "Aucun fichier spécifié, utilisation d'un dataset de démonstration\n",
      "   Limitation à 5% des données: 4,172 caractères\n",
      "   Texte chargé: 4,172 caractères\n",
      "Vocabulaire construit:\n",
      "   - Taille: 46 caractères\n",
      "   - Caractères: \n",
      " ',-.126BCEILSTUabc...\n",
      " Dataset créé:\n",
      "   - Texte original: 4,172 caractères\n",
      "   - Texte encodé: 4,172 tokens\n",
      "   - Séquences générées: 165\n",
      "   - Longueur séquence: 50\n",
      "   - Chevauchement: 50%\n",
      "   Division données:\n",
      "      - Train: 132 séquences\n",
      "      - Validation: 33 séquences\n",
      "      - Batch size: 64\n",
      "      - Vocabulaire: 46 caractères\n",
      "   Échantillon: '\n",
      "        Le petit prince était un très joli petit bonhomme qui riait souvent. Il venait d'une planèt...'\n",
      " Test réussi: 3 batches d'entraînement, 1 batches de validation\n"
     ]
    }
   ],
   "source": [
    "# CHARGEMENT ET PRÉPARATION DES DONNÉES\n",
    "def load_and_prepare_data(file_path=None, phase='phase1'):\n",
    "    \"\"\"\n",
    "    Charger et préparer les données avec gestion optimisée de la mémoire\n",
    "    \"\"\"\n",
    "    print(f\"Chargement des données pour {phase.upper()}\")\n",
    "    \n",
    "    # Si pas de fichier spécifié, utiliser un dataset de démonstration\n",
    "    if file_path is None or not os.path.exists(file_path):\n",
    "        print(\"Aucun fichier spécifié, utilisation d'un dataset de démonstration\")\n",
    "        # Dataset de démonstration basé sur du texte français classique\n",
    "        demo_text = \"\"\"\n",
    "        Le petit prince était un très joli petit bonhomme qui riait souvent. Il venait d'une planète à peine plus grande qu'une maison, qu'on appelle l'astéroïde B-612. Sur cette planète, il y avait de très gros baobabs. Il fallait s'en méfier car ils poussaient très vite et pouvaient faire éclater la planète. Tous les matins, le petit prince nettoyait ses volcans et arrachait les pousses de baobabs. Il avait aussi une rose, une fleur très belle mais très coquette. Cette rose était unique au monde pour lui. Un jour, le petit prince quitta sa planète pour voyager dans l'univers. Il visita six planètes avant d'arriver sur Terre. Sur la première planète vivait un roi qui commandait à tout. Sur la deuxième planète vivait un vaniteux qui ne voulait entendre que des louanges. Sur la troisième planète vivait un buveur qui buvait pour oublier qu'il avait honte de boire. Sur la quatrième planète vivait un businessman qui comptait les étoiles. Sur la cinquième planète vivait un allumeur de réverbères qui allumait et éteignait son réverbère toutes les minutes. Sur la sixième planète vivait un géographe qui écrivait d'énormes livres. Enfin, le petit prince arriva sur Terre où il rencontra un pilote qui était tombé en panne dans le désert. Ensemble, ils cherchèrent un puits dans le désert et trouvèrent l'eau qui donne la vie. Le petit prince apprit que l'essentiel est invisible pour les yeux et qu'on ne voit bien qu'avec le cœur. C'est le temps que tu as perdu pour ta rose qui fait ta rose si importante. Les grandes personnes ne comprennent jamais rien toutes seules, et c'est fatigant, pour les enfants, de toujours leur donner des explications.\n",
    "        \"\"\" * 50  # Répéter le texte pour avoir plus de données\n",
    "        text = demo_text\n",
    "    else:\n",
    "        # Charger le fichier texte\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "    \n",
    "    # Limitation en fonction de la phase\n",
    "    config_phase = CONFIG[phase]\n",
    "    if config_phase['data_fraction'] < 1.0:\n",
    "        max_chars = int(len(text) * config_phase['data_fraction'])\n",
    "        text = text[:max_chars]\n",
    "        print(f\"   Limitation à {config_phase['data_fraction']*100:.0f}% des données: {len(text):,} caractères\")\n",
    "    \n",
    "    print(f\"   Texte chargé: {len(text):,} caractères\")\n",
    "    \n",
    "    # Créer et ajuster le tokenizer\n",
    "    tokenizer = CharacterTokenizer()\n",
    "    tokenizer.fit(text)\n",
    "    \n",
    "    # Créer le dataset\n",
    "    dataset = TextDataset(\n",
    "        text=text,\n",
    "        tokenizer=tokenizer,\n",
    "        seq_length=config_phase['seq_length'],\n",
    "        max_sequences=config_phase['max_sequences'],\n",
    "        overlap_ratio=0.5\n",
    "    )\n",
    "    \n",
    "    # Division train/validation (80/20)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # Créer les DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config_phase['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=0,  # 0 pour éviter les problèmes sur Windows\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config_phase['batch_size'], \n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    print(f\"   Division données:\")\n",
    "    print(f\"      - Train: {len(train_dataset):,} séquences\")\n",
    "    print(f\"      - Validation: {len(val_dataset):,} séquences\")\n",
    "    print(f\"      - Batch size: {config_phase['batch_size']}\")\n",
    "    print(f\"      - Vocabulaire: {tokenizer.vocab_size} caractères\")\n",
    "    \n",
    "    # Échantillon du texte pour inspection\n",
    "    sample = dataset.get_sample_text(200)\n",
    "    print(f\"   Échantillon: '{sample[:100]}...'\")\n",
    "    \n",
    "    return train_loader, val_loader, tokenizer\n",
    "\n",
    "# Test de chargement des données\n",
    "print(\"Test de chargement des données:\")\n",
    "test_train_loader, test_val_loader, test_tokenizer = load_and_prepare_data(phase='phase1')\n",
    "print(f\" Test réussi: {len(test_train_loader)} batches d'entraînement, {len(test_val_loader)} batches de validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff5522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Système de comparaison Phase 1 prêt\n",
      "Utilisez run_phase1_comparison() pour démarrer la comparaison\n"
     ]
    }
   ],
   "source": [
    "# PHASE 1 - COMPARAISON ULTRA-RAPIDE (15-30 minutes max)\n",
    "def run_phase1_comparison(data_file_path=None):\n",
    "    \"\"\"\n",
    "    Phase 1: Comparaison rapide des 3 modèles\n",
    "    OBJECTIF: Identifier le meilleur modèle sans gaspiller de temps\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"DÉBUT PHASE 1 - COMPARAISON ULTRA-RAPIDE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Objectif: Identifier le meilleur modèle en 15-30 minutes\")\n",
    "    print(\"Optimisations: 5% données, 5 époques max, LR élevé, patience réduite\")\n",
    "    print()\n",
    "    \n",
    "    # Charger les données pour phase 1\n",
    "    train_loader, val_loader, tokenizer = load_and_prepare_data(data_file_path, phase='phase1')\n",
    "    \n",
    "    # Modèles à comparer\n",
    "    model_types = ['RNN', 'LSTM', 'GRU']\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"Comparaison de {len(model_types)} modèles:\")\n",
    "    print(f\"   - Types: {', '.join(model_types)}\")\n",
    "    print(f\"   - Données: {len(train_loader.dataset):,} séquences d'entraînement\")\n",
    "    print(f\"   - Vocabulaire: {tokenizer.vocab_size} caractères\")\n",
    "    print()\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for i, model_type in enumerate(model_types, 1):\n",
    "        print(f\"[{i}/{len(model_types)}] Entraînement {model_type}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Libérer la mémoire GPU avant chaque modèle\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Créer le modèle\n",
    "        model = create_model(model_type, tokenizer.vocab_size, CONFIG)\n",
    "        \n",
    "        # Créer le trainer\n",
    "        trainer = ModelTrainer(model, tokenizer, CONFIG, phase='phase1')\n",
    "        \n",
    "        # Entraîner\n",
    "        start_time = time.time()\n",
    "        training_results = trainer.train(train_loader, val_loader)\n",
    "        \n",
    "        # Générer un échantillon de texte pour évaluation qualitative\n",
    "        sample_text = trainer.generate_text(\"Le petit prince\", length=100, temperature=0.8)\n",
    "        \n",
    "        # Sauvegarder les résultats\n",
    "        results[model_type] = {\n",
    "            'best_val_loss': training_results['best_val_loss'],\n",
    "            'training_time': training_results['total_time'],\n",
    "            'epochs_trained': training_results['epochs_trained'],\n",
    "            'parameters': model.count_parameters(),\n",
    "            'sample_generation': sample_text,\n",
    "            'train_losses': training_results['train_losses'],\n",
    "            'val_losses': training_results['val_losses']\n",
    "        }\n",
    "        \n",
    "        print(f\" {model_type} terminé:\")\n",
    "        print(f\"   - Validation Loss: {training_results['best_val_loss']:.4f}\")\n",
    "        print(f\"   - Temps: {training_results['total_time']:.1f}s\")\n",
    "        print(f\"   - Époques: {training_results['epochs_trained']}\")\n",
    "        print(f\"   - Paramètres: {model.count_parameters():,}\")\n",
    "        print(f\"   - Échantillon: '{sample_text[:50]}...'\")\n",
    "        print()\n",
    "        \n",
    "        # Sauvegarder le modèle rapidement\n",
    "        model_path = MODEL_DIR / f\"{model_type}_phase1.pth\"\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_type': model_type,\n",
    "            'vocab_size': tokenizer.vocab_size,\n",
    "            'config': CONFIG,\n",
    "            'results': results[model_type]\n",
    "        }, model_path)\n",
    "        \n",
    "        # Libérer la mémoire\n",
    "        del model, trainer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    total_time = time.time() - total_start_time\n",
    "    \n",
    "    # Analyser les résultats et identifier le gagnant\n",
    "    print(\"=\"*60)\n",
    "    print(\"RÉSULTATS PHASE 1 - COMPARAISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Trier par validation loss (plus bas = meilleur)\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "    \n",
    "    print(\"CLASSEMENT (par Validation Loss):\")\n",
    "    for rank, (model_type, result) in enumerate(sorted_results, 1):\n",
    "        medal = \"🥇\" if rank == 1 else \"🥈\" if rank == 2 else \"🥉\"\n",
    "        print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "              f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "              f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "              f\"Params: {result['parameters']:>7,}\")\n",
    "    \n",
    "    winner = sorted_results[0][0]\n",
    "    winner_results = sorted_results[0][1]\n",
    "    \n",
    "    print(f\"\\nGAGNANT PHASE 1: {winner}\")\n",
    "    print(f\"   - Meilleure Validation Loss: {winner_results['best_val_loss']:.4f}\")\n",
    "    print(f\"   - Temps d'entraînement: {winner_results['training_time']:.1f}s\")\n",
    "    print(f\"   - Nombre de paramètres: {winner_results['parameters']:,}\")\n",
    "    \n",
    "    print(f\"\\nTEMPS TOTAL PHASE 1: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "    \n",
    "    # Sauvegarder le tokenizer\n",
    "    tokenizer_path = MODEL_DIR / \"tokenizer.pkl\"\n",
    "    tokenizer.save(tokenizer_path)\n",
    "    \n",
    "    # Sauvegarder les résultats complets\n",
    "    results_path = MODEL_DIR / \"phase1_results.json\"\n",
    "    with open(results_path, 'w') as f:\n",
    "        # Convertir pour JSON (enlever les tensors)\n",
    "        json_results = {}\n",
    "        for model_type, result in results.items():\n",
    "            json_results[model_type] = {\n",
    "                'best_val_loss': result['best_val_loss'],\n",
    "                'training_time': result['training_time'],\n",
    "                'epochs_trained': result['epochs_trained'],\n",
    "                'parameters': result['parameters'],\n",
    "                'sample_generation': result['sample_generation']\n",
    "            }\n",
    "        \n",
    "        json.dump({\n",
    "            'results': json_results,\n",
    "            'winner': winner,\n",
    "            'total_time': total_time,\n",
    "            'config_used': CONFIG['phase1']\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"💾 Résultats sauvegardés:\")\n",
    "    print(f\"   - Modèles: {MODEL_DIR}/{{RNN,LSTM,GRU}}_phase1.pth\")\n",
    "    print(f\"   - Tokenizer: {tokenizer_path}\")\n",
    "    print(f\"   - Résultats: {results_path}\")\n",
    "    \n",
    "    # Validation des critères de réussite Phase 1\n",
    "    success_criteria = {\n",
    "        \"Temps < 30 minutes\": total_time < 1800,\n",
    "        \"Vocabulaire < 50 caractères\": tokenizer.vocab_size < 50,\n",
    "        \"Génération cohérente\": len(winner_results['sample_generation']) > 50,\n",
    "        \"Classement clair\": len(set(r['best_val_loss'] for r in results.values())) == 3\n",
    "    }\n",
    "    \n",
    "    print(\"\\n VALIDATION CRITÈRES PHASE 1:\")\n",
    "    all_success = True\n",
    "    for criteria, success in success_criteria.items():\n",
    "        status = \"\" if success else \"❌\"\n",
    "        print(f\"   {status} {criteria}\")\n",
    "        if not success:\n",
    "            all_success = False\n",
    "    \n",
    "    if all_success:\n",
    "        print(\"\\nPHASE 1 RÉUSSIE ! Prêt pour Phase 2\")\n",
    "    else:\n",
    "        print(\"\\nCertains critères non atteints, mais on peut continuer\")\n",
    "    \n",
    "    return winner, results, tokenizer\n",
    "\n",
    "print(\" Système de comparaison Phase 1 prêt\")\n",
    "print(\"Utilisez run_phase1_comparison() pour démarrer la comparaison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a00499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Système d'entraînement final Phase 2 prêt\n",
      "Utilisez run_phase2_final_training(winner) après Phase 1\n"
     ]
    }
   ],
   "source": [
    "# PHASE 2 - ENTRAÎNEMENT FINAL DE QUALITÉ\n",
    "def run_phase2_final_training(winner_model_type, data_file_path=None):\n",
    "    \"\"\"\n",
    "    Phase 2: Entraînement complet du modèle gagnant\n",
    "    OBJECTIF: Entraînement final avec 100% des données pour qualité maximale\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"DÉBUT PHASE 2 - ENTRAÎNEMENT FINAL DE QUALITÉ\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Modèle sélectionné: {winner_model_type}\")\n",
    "    print(\"Objectif: Entraînement complet pour qualité maximale\")\n",
    "    print(\"Configuration: 100% données, plus d'époques, LR optimisé, TensorBoard\")\n",
    "    print()\n",
    "    \n",
    "    # Charger les données pour phase 2 (100% des données)\n",
    "    train_loader, val_loader, tokenizer = load_and_prepare_data(data_file_path, phase='phase2')\n",
    "    \n",
    "    print(f\"Configuration Phase 2:\")\n",
    "    print(f\"   - Données: {len(train_loader.dataset):,} séquences d'entraînement\")\n",
    "    print(f\"   - Validation: {len(val_loader.dataset):,} séquences\")\n",
    "    print(f\"   - Vocabulaire: {tokenizer.vocab_size} caractères\")\n",
    "    print(f\"   - Époques max: {CONFIG['phase2']['max_epochs']}\")\n",
    "    print(f\"   - Learning rate: {CONFIG['phase2']['learning_rate']}\")\n",
    "    print(f\"   - Patience: {CONFIG['phase2']['patience']}\")\n",
    "    print()\n",
    "    \n",
    "    # Créer le modèle gagnant\n",
    "    model = create_model(winner_model_type, tokenizer.vocab_size, CONFIG)\n",
    "    \n",
    "    # Créer le trainer pour phase 2 (avec TensorBoard)\n",
    "    trainer = ModelTrainer(model, tokenizer, CONFIG, phase='phase2')\n",
    "    \n",
    "    print(f\"Début entraînement final {winner_model_type}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Entraînement complet\n",
    "    start_time = time.time()\n",
    "    training_results = trainer.train(train_loader, val_loader)\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"ENTRAÎNEMENT FINAL TERMINÉ\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Modèle: {winner_model_type}\")\n",
    "    print(f\"Résultats finaux:\")\n",
    "    print(f\"   - Meilleure Validation Loss: {training_results['best_val_loss']:.4f}\")\n",
    "    print(f\"   - Temps total: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"   - Époques entraînées: {training_results['epochs_trained']}\")\n",
    "    print(f\"   - Paramètres: {model.count_parameters():,}\")\n",
    "    \n",
    "    # Tests de génération avec différentes températures\n",
    "    print(\"\\\\nTESTS DE GÉNÉRATION:\")\n",
    "    test_seeds = [\"Le petit prince\", \"Il était une fois\", \"Dans un\"]\n",
    "    temperatures = [0.5, 0.8, 1.0]\n",
    "    \n",
    "    for seed in test_seeds:\n",
    "        print(f\"\\\\nSeed: '{seed}'\")\n",
    "        for temp in temperatures:\n",
    "            generated = trainer.generate_text(seed, length=100, temperature=temp)\n",
    "            print(f\"   T={temp}: '{generated[:80]}...'\")\n",
    "    \n",
    "    # Sauvegarder le modèle final\n",
    "    final_model_path = MODEL_DIR / f\"{winner_model_type}_final.pth\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_type': winner_model_type,\n",
    "        'vocab_size': tokenizer.vocab_size,\n",
    "        'config': CONFIG,\n",
    "        'training_results': training_results,\n",
    "        'final_val_loss': training_results['best_val_loss'],\n",
    "        'total_training_time': total_time\n",
    "    }, final_model_path)\n",
    "    \n",
    "    # Export ONNX pour déploiement\n",
    "    try:\n",
    "        print(\"Export ONNX pour déploiement...\")\n",
    "        model.eval()\n",
    "        dummy_input = torch.randint(0, tokenizer.vocab_size, (1, CONFIG['phase2']['seq_length'])).to(device)\n",
    "        onnx_path = MODEL_DIR / f\"{winner_model_type}_final.onnx\"\n",
    "        \n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            (dummy_input, model.init_hidden(1)),\n",
    "            onnx_path,\n",
    "            export_params=True,\n",
    "            opset_version=11,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input_sequence', 'hidden_state'],\n",
    "            output_names=['output', 'new_hidden_state'],\n",
    "            dynamic_axes={\n",
    "                'input_sequence': {0: 'batch_size', 1: 'sequence_length'},\n",
    "                'output': {0: 'batch_size', 1: 'sequence_length'}\n",
    "            }\n",
    "        )\n",
    "        print(f\" Export ONNX réussi: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur export ONNX: {e}\")\n",
    "    \n",
    "    # Sauvegarder les métadonnées complètes\n",
    "    metadata_path = MODEL_DIR / f\"{winner_model_type}_metadata.json\"\n",
    "    metadata = {\n",
    "        'model_type': winner_model_type,\n",
    "        'vocab_size': tokenizer.vocab_size,\n",
    "        'parameters': model.count_parameters(),\n",
    "        'phase2_results': {\n",
    "            'best_val_loss': training_results['best_val_loss'],\n",
    "            'total_time': total_time,\n",
    "            'epochs_trained': training_results['epochs_trained']\n",
    "        },\n",
    "        'config_used': CONFIG,\n",
    "        'training_completed': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Fichiers sauvegardés:\")\n",
    "    print(f\"   - Modèle final: {final_model_path}\")\n",
    "    print(f\"   - Export ONNX: {onnx_path}\")\n",
    "    print(f\"   - Métadonnées: {metadata_path}\")\n",
    "    print(f\"   - Tokenizer: {MODEL_DIR}/tokenizer.pkl\")\n",
    "    \n",
    "    # Validation des critères de réussite Phase 2\n",
    "    success_criteria = {\n",
    "        \"Entraînement sans crash\": training_results['epochs_trained'] > 0,\n",
    "        \"Amélioration qualité\": training_results['best_val_loss'] < 3.0,  # Seuil raisonnable\n",
    "        \"Export ONNX réussi\": os.path.exists(onnx_path) if 'onnx_path' in locals() else False,\n",
    "        \"Génération de qualité\": len(trainer.generate_text(\"Le\", 50)) > 20\n",
    "    }\n",
    "    \n",
    "    print(\"\\\\n VALIDATION CRITÈRES PHASE 2:\")\n",
    "    all_success = True\n",
    "    for criteria, success in success_criteria.items():\n",
    "        status = \"\" if success else \"❌\"\n",
    "        print(f\"   {status} {criteria}\")\n",
    "        if not success:\n",
    "            all_success = False\n",
    "    \n",
    "    if all_success:\n",
    "        print(\"\\\\nPHASE 2 RÉUSSIE ! Projet complet\")\n",
    "    else:\n",
    "        print(\"\\\\nCertains critères non atteints, mais modèle utilisable\")\n",
    "    \n",
    "    return model, training_results, tokenizer\n",
    "\n",
    "print(\" Système d'entraînement final Phase 2 prêt\")\n",
    "print(\"Utilisez run_phase2_final_training(winner) après Phase 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c7bfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fonctions de visualisation et rapport final prêtes\n",
      "Utilisez plot_training_results() et generate_final_report() pour l'analyse\n"
     ]
    }
   ],
   "source": [
    "# VISUALISATION ET ANALYSE DES RÉSULTATS\n",
    "def plot_training_results(results_phase1, model_final=None, training_results_final=None):\n",
    "    \"\"\"\n",
    "    Créer des graphiques de comparaison et d'analyse\n",
    "    \"\"\"\n",
    "    plt.style.use('default')\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # 1. Comparaison Phase 1 - Validation Loss\n",
    "    plt.subplot(2, 4, 1)\n",
    "    models = list(results_phase1.keys())\n",
    "    val_losses = [results_phase1[m]['best_val_loss'] for m in models]\n",
    "    colors = ['#ff7f0e', '#2ca02c', '#d62728']  # Orange, Vert, Rouge\n",
    "    \n",
    "    bars = plt.bar(models, val_losses, color=colors)\n",
    "    plt.title('Phase 1: Validation Loss Comparison', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar, val in zip(bars, val_losses):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. Temps d'entraînement Phase 1\n",
    "    plt.subplot(2, 4, 2)\n",
    "    times = [results_phase1[m]['training_time'] for m in models]\n",
    "    bars = plt.bar(models, times, color=colors)\n",
    "    plt.title('Phase 1: Training Time', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    for bar, time in zip(bars, times):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{time:.1f}s', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. Nombre de paramètres\n",
    "    plt.subplot(2, 4, 3)\n",
    "    params = [results_phase1[m]['parameters'] for m in models]\n",
    "    bars = plt.bar(models, params, color=colors)\n",
    "    plt.title('Model Parameters', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Number of Parameters')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    for bar, param in zip(bars, params):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000, \n",
    "                f'{param:,}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # 4. Courbes de loss Phase 1\n",
    "    plt.subplot(2, 4, 4)\n",
    "    for i, (model, result) in enumerate(results_phase1.items()):\n",
    "        if 'train_losses' in result and 'val_losses' in result:\n",
    "            epochs = range(1, len(result['train_losses']) + 1)\n",
    "            plt.plot(epochs, result['train_losses'], '--', alpha=0.7, color=colors[i], label=f'{model} Train')\n",
    "            plt.plot(epochs, result['val_losses'], '-', linewidth=2, color=colors[i], label=f'{model} Val')\n",
    "    \n",
    "    plt.title('Phase 1: Training Curves', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5-8. Résultats Phase 2 (si disponible)\n",
    "    if model_final and training_results_final:\n",
    "        # 5. Courbes d'entraînement Phase 2\n",
    "        plt.subplot(2, 4, 5)\n",
    "        epochs = range(1, len(training_results_final['train_losses']) + 1)\n",
    "        plt.plot(epochs, training_results_final['train_losses'], '--', alpha=0.7, label='Train Loss')\n",
    "        plt.plot(epochs, training_results_final['val_losses'], '-', linewidth=2, label='Validation Loss')\n",
    "        plt.title(f'Phase 2: {model_final.__class__.__name__} Training', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Learning Rate Schedule\n",
    "        plt.subplot(2, 4, 6)\n",
    "        if hasattr(training_results_final, 'learning_rates'):\n",
    "            plt.plot(training_results_final.get('learning_rates', []), linewidth=2)\n",
    "            plt.title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Learning Rate')\n",
    "            plt.yscale('log')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'Learning Rate\\\\nData Not Available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # 7. Résumé des métriques\n",
    "        plt.subplot(2, 4, 7)\n",
    "        metrics = ['Val Loss', 'Train Time', 'Parameters', 'Epochs']\n",
    "        values = [\n",
    "            training_results_final['best_val_loss'],\n",
    "            training_results_final.get('total_time', 0) / 60,  # En minutes\n",
    "            model_final.count_parameters() / 1000,  # En milliers\n",
    "            training_results_final['epochs_trained']\n",
    "        ]\n",
    "        \n",
    "        # Normaliser pour visualisation\n",
    "        normalized_values = [v/max(values) for v in values]\n",
    "        \n",
    "        plt.bar(metrics, normalized_values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "        plt.title('Final Model Metrics (Normalized)', fontsize=12, fontweight='bold')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Normalized Value')\n",
    "        \n",
    "        # Ajouter les vraies valeurs\n",
    "        for i, (metric, value) in enumerate(zip(metrics, values)):\n",
    "            unit = ['', ' min', 'k', ''][i]\n",
    "            plt.text(i, normalized_values[i] + 0.05, f'{value:.1f}{unit}', \n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 8. Texte de résumé\n",
    "    plt.subplot(2, 4, 8)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Créer le texte de résumé\n",
    "    summary_text = \"RÉSUMÉ DU PROJET\\\\n\\\\n\"\n",
    "    \n",
    "    # Phase 1\n",
    "    best_model_p1 = min(results_phase1.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "    summary_text += f\"Phase 1 Winner: {best_model_p1[0]}\\\\n\"\n",
    "    summary_text += f\"   Val Loss: {best_model_p1[1]['best_val_loss']:.4f}\\\\n\"\n",
    "    summary_text += f\"   Time: {best_model_p1[1]['training_time']:.1f}s\\\\n\\\\n\"\n",
    "    \n",
    "    # Phase 2\n",
    "    if training_results_final:\n",
    "        summary_text += f\"Phase 2 Results:\\\\n\"\n",
    "        summary_text += f\"   Final Val Loss: {training_results_final['best_val_loss']:.4f}\\\\n\"\n",
    "        summary_text += f\"   Total Time: {training_results_final.get('total_time', 0)/60:.1f} min\\\\n\"\n",
    "        summary_text += f\"   Epochs: {training_results_final['epochs_trained']}\\\\n\\\\n\"\n",
    "    \n",
    "    # Critères de réussite\n",
    "    summary_text += \" SUCCESS CRITERIA:\\\\n\"\n",
    "    if results_phase1:\n",
    "        total_p1_time = sum(r['training_time'] for r in results_phase1.values())\n",
    "        summary_text += f\"   Phase 1 < 30min: {'' if total_p1_time < 1800 else '❌'}\\\\n\"\n",
    "    \n",
    "    plt.text(0.05, 0.95, summary_text, transform=plt.gca().transAxes, \n",
    "             fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(MODEL_DIR / 'training_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"💾 Graphiques sauvegardés: {MODEL_DIR / 'training_results.png'}\")\n",
    "\n",
    "def generate_final_report(winner, results_phase1, model_final=None, training_results_final=None, tokenizer=None):\n",
    "    \"\"\"\n",
    "    Générer un rapport final complet\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"RAPPORT FINAL - COMPARAISON RNN vs LSTM vs GRU\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # En-tête du rapport\n",
    "    print(f\"🗓️ Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Modèle gagnant: {winner}\")\n",
    "    print(f\"Vocabulaire: {tokenizer.vocab_size if tokenizer else 'N/A'} caractères\")\n",
    "    print()\n",
    "    \n",
    "    # Résultats Phase 1\n",
    "    print(\"PHASE 1 - COMPARAISON RAPIDE:\")\n",
    "    print(\"-\" * 50)\n",
    "    sorted_results = sorted(results_phase1.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "    \n",
    "    for rank, (model_type, result) in enumerate(sorted_results, 1):\n",
    "        medal = \"🥇\" if rank == 1 else \"🥈\" if rank == 2 else \"🥉\"\n",
    "        print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "              f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "              f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "              f\"Params: {result['parameters']:>7,} | \"\n",
    "              f\"Époques: {result['epochs_trained']:2d}\")\n",
    "    \n",
    "    total_p1_time = sum(r['training_time'] for r in results_phase1.values())\n",
    "    print(f\"\\\\nTemps total Phase 1: {total_p1_time:.1f}s ({total_p1_time/60:.1f} minutes)\")\n",
    "    \n",
    "    # Résultats Phase 2\n",
    "    if training_results_final:\n",
    "        print(\"\\\\nPHASE 2 - ENTRAÎNEMENT FINAL:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Modèle: {winner}\")\n",
    "        print(f\"Validation Loss finale: {training_results_final['best_val_loss']:.4f}\")\n",
    "        print(f\"Temps d'entraînement: {training_results_final.get('total_time', 0)/60:.1f} minutes\")\n",
    "        print(f\"Époques entraînées: {training_results_final['epochs_trained']}\")\n",
    "        if model_final:\n",
    "            print(f\"Paramètres: {model_final.count_parameters():,}\")\n",
    "    \n",
    "    # Tests de génération\n",
    "    if model_final and tokenizer:\n",
    "        print(\"\\\\nEXEMPLES DE GÉNÉRATION:\")\n",
    "        print(\"-\" * 50)\n",
    "        # Créer un trainer temporaire pour la génération\n",
    "        temp_trainer = ModelTrainer(model_final, tokenizer, CONFIG, phase='phase2')\n",
    "        \n",
    "        seeds = [\"Le petit prince\", \"Il était une fois\", \"Dans un lointain\"]\n",
    "        for seed in seeds:\n",
    "            generated = temp_trainer.generate_text(seed, length=80, temperature=0.8)\n",
    "            print(f\"'{seed}' → '{generated[:60]}...'\")\n",
    "    \n",
    "    # Validation des critères de réussite\n",
    "    print(\"VALIDATION DES CRITÈRES DE RÉUSSITE:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    criteria_results = []\n",
    "    \n",
    "    # Critères Phase 1\n",
    "    criteria_results.append((\"Phase 1 < 30 minutes\", total_p1_time < 1800))\n",
    "    criteria_results.append((\"Vocabulaire < 50 caractères\", tokenizer.vocab_size < 50 if tokenizer else False))\n",
    "    criteria_results.append((\"Classement clair\", len(set(r['best_val_loss'] for r in results_phase1.values())) == 3))\n",
    "    \n",
    "    # Critères Phase 2\n",
    "    if training_results_final:\n",
    "        criteria_results.append((\"Entraînement sans crash\", training_results_final['epochs_trained'] > 0))\n",
    "        criteria_results.append((\"Amélioration qualité\", training_results_final['best_val_loss'] < 3.0))\n",
    "        onnx_exists = os.path.exists(MODEL_DIR / f\"{winner}_final.onnx\")\n",
    "        criteria_results.append((\"Export ONNX réussi\", onnx_exists))\n",
    "    \n",
    "    # Critères généraux\n",
    "    total_time = total_p1_time + (training_results_final.get('total_time', 0) if training_results_final else 0)\n",
    "    criteria_results.append((\"Temps total < 3h\", total_time < 10800))\n",
    "    \n",
    "    success_count = 0\n",
    "    for criteria, success in criteria_results:\n",
    "        status = \"\" if success else \"❌\"\n",
    "        print(f\"   {status} {criteria}\")\n",
    "        if success:\n",
    "            success_count += 1\n",
    "    \n",
    "    success_rate = success_count / len(criteria_results) * 100\n",
    "    print(f\"\\\\nTaux de réussite: {success_count}/{len(criteria_results)} ({success_rate:.1f}%)\")\n",
    "    \n",
    "    # Recommandations\n",
    "    print(\"\\\\n💡 RECOMMANDATIONS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if winner == 'LSTM':\n",
    "        print(\"   LSTM recommandé pour la génération de texte\")\n",
    "        print(\"   Excellent compromis performance/stabilité\")\n",
    "        print(\"   Utiliser gradient clipping et early stopping\")\n",
    "    elif winner == 'GRU':\n",
    "        print(\"   GRU recommandé pour l'efficacité\")\n",
    "        print(\"   Plus rapide que LSTM avec bonne performance\")\n",
    "        print(\"   💾 Moins de paramètres, idéal pour déploiement\")\n",
    "    else:\n",
    "        print(\"   RNN Simple pour cas d'usage basiques\")\n",
    "        print(\"   Attention aux problèmes de gradient\")\n",
    "        print(\"   Augmenter le gradient clipping\")\n",
    "    \n",
    "    print(\"\\\\nPROJET TERMINÉ AVEC SUCCÈS!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\" Fonctions de visualisation et rapport final prêtes\")\n",
    "print(\"Utilisez plot_training_results() et generate_final_report() pour l'analyse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996e70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Système complet prêt!\n",
      "\n",
      "📖 GUIDE D'UTILISATION DU SYSTÈME\n",
      "============================================================\n",
      "\n",
      "DÉMARRAGE RAPIDE:\n",
      "   1. Testez le système: test_system_components()\n",
      "   2. Lancez la comparaison complète: run_complete_comparison()\n",
      "   3. Ou par étapes:\n",
      "      - Phase 1: winner, results, tokenizer = run_phase1_comparison()\n",
      "      - Phase 2: model, results, tokenizer = run_phase2_final_training(winner)\n",
      "\n",
      "UTILISATION AVEC VOS DONNÉES:\n",
      "   - Placez votre fichier texte dans le répertoire\n",
      "   - Utilisez: run_complete_comparison('chemin/vers/fichier.txt')\n",
      "\n",
      "CONFIGURATION:\n",
      "   - Modifiez CONFIG pour ajuster les hyperparamètres\n",
      "   - Phase 1: comparaison rapide (5% données, 5 époques)\n",
      "   - Phase 2: entraînement complet (100% données, 25 époques)\n",
      "\n",
      "RÉSULTATS:\n",
      "   - Modèles sauvegardés dans: models/\n",
      "   - Logs TensorBoard dans: logs/\n",
      "   - Graphiques: models/training_results.png\n",
      "\n",
      "CRITÈRES DE RÉUSSITE:\n",
      "    Phase 1 < 30 minutes\n",
      "    Vocabulaire < 50 caractères\n",
      "    Génération de texte cohérente\n",
      "    Export ONNX pour déploiement\n",
      "    Temps total < 3 heures\n"
     ]
    }
   ],
   "source": [
    "# FONCTION PRINCIPALE - EXÉCUTION COMPLÈTE DU SYSTÈME\n",
    "def run_complete_comparison(data_file_path=None, run_phase2=True):\n",
    "    \"\"\"\n",
    "    Fonction principale pour exécuter le système complet en 2 phases\n",
    "    \n",
    "    Args:\n",
    "        data_file_path: Chemin vers le fichier de données (optionnel)\n",
    "        run_phase2: Si True, exécute aussi la phase 2\n",
    "    \n",
    "    Returns:\n",
    "        Dict contenant tous les résultats\n",
    "    \"\"\"\n",
    "    print(\"🚀\" * 20)\n",
    "    print(\"SYSTÈME COMPLET DE COMPARAISON RNN vs LSTM vs GRU\")\n",
    "    print(\"🚀\" * 20)\n",
    "    print()\n",
    "    print(\"PLAN D'EXÉCUTION:\")\n",
    "    print(\"   Phase 1: Comparaison Ultra-Rapide (15-30 min)\")\n",
    "    print(\"   Phase 2: Entraînement Final de Qualité\")\n",
    "    print(\"   Analyse et Visualisation\")\n",
    "    print(\"   4️⃣ Rapport Final\")\n",
    "    print()\n",
    "    \n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # PHASE 1: Comparaison rapide\n",
    "        print(\"DÉMARRAGE PHASE 1...\")\n",
    "        winner, results_phase1, tokenizer = run_phase1_comparison(data_file_path)\n",
    "        \n",
    "        phase1_time = time.time() - overall_start_time\n",
    "        print(f\" Phase 1 terminée en {phase1_time/60:.1f} minutes\")\n",
    "        \n",
    "        # Variables pour Phase 2\n",
    "        model_final = None\n",
    "        training_results_final = None\n",
    "        \n",
    "        # PHASE 2: Entraînement final (optionnel)\n",
    "        if run_phase2:\n",
    "            print(\"\\\\nDÉMARRAGE PHASE 2...\")\n",
    "            phase2_start = time.time()\n",
    "            \n",
    "            model_final, training_results_final, tokenizer_final = run_phase2_final_training(winner, data_file_path)\n",
    "            \n",
    "            phase2_time = time.time() - phase2_start\n",
    "            print(f\" Phase 2 terminée en {phase2_time/60:.1f} minutes\")\n",
    "        else:\n",
    "            print(\"hase 2 ignorée (run_phase2=False)\")\n",
    "        \n",
    "        # PHASE 3: Visualisation\n",
    "        print(\"\\\\nGÉNÉRATION DES GRAPHIQUES...\")\n",
    "        plot_training_results(results_phase1, model_final, training_results_final)\n",
    "        \n",
    "        # PHASE 4: Rapport final\n",
    "        print(\"\\\\nGÉNÉRATION DU RAPPORT FINAL...\")\n",
    "        generate_final_report(winner, results_phase1, model_final, training_results_final, tokenizer)\n",
    "        \n",
    "        total_time = time.time() - overall_start_time\n",
    "        \n",
    "        # Résumé final\n",
    "        print(\"\\\\n\" + \"🎉\" * 20)\n",
    "        print(\"SYSTÈME TERMINÉ AVEC SUCCÈS!\")\n",
    "        print(\"🎉\" * 20)\n",
    "        print(f\"Temps total: {total_time/60:.1f} minutes\")\n",
    "        print(f\"Modèle gagnant: {winner}\")\n",
    "        print(f\"Fichiers sauvegardés dans: {MODEL_DIR}\")\n",
    "        \n",
    "        # Retourner tous les résultats\n",
    "        return {\n",
    "            'winner': winner,\n",
    "            'results_phase1': results_phase1,\n",
    "            'model_final': model_final,\n",
    "            'training_results_final': training_results_final,\n",
    "            'tokenizer': tokenizer,\n",
    "            'total_time': total_time,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\nERREUR CRITIQUE: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'total_time': time.time() - overall_start_time\n",
    "        }\n",
    "\n",
    "# FONCTIONS DE TEST ET VALIDATION\n",
    "def test_system_components():\n",
    "    \"\"\"\n",
    "    Tester tous les composants avant l'exécution complète\n",
    "    \"\"\"\n",
    "    print(\"TEST DES COMPOSANTS DU SYSTÈME\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    tests_passed = 0\n",
    "    total_tests = 6\n",
    "    \n",
    "    try:\n",
    "        # Test 1: Tokenizer\n",
    "        print(\"Test Tokenizer...\")\n",
    "        tokenizer = CharacterTokenizer()\n",
    "        test_text = \"Hello, World! 123 éàç\"\n",
    "        tokenizer.fit(test_text)\n",
    "        encoded = tokenizer.encode(test_text)\n",
    "        decoded = tokenizer.decode(encoded)\n",
    "        assert test_text == decoded, \"Erreur encodage/décodage\"\n",
    "        print(\"    Tokenizer OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 2: Dataset\n",
    "        print(\"Test Dataset...\")\n",
    "        dataset = TextDataset(test_text, tokenizer, seq_length=10, max_sequences=5)\n",
    "        assert len(dataset) > 0, \"Dataset vide\"\n",
    "        seq, target = dataset[0]\n",
    "        assert seq.shape[0] == 10, \"Séquence de mauvaise taille\"\n",
    "        print(\"    Dataset OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 3: Modèles\n",
    "        print(\"Test Modèles...\")\n",
    "        for model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "            model = create_model(model_type, tokenizer.vocab_size, CONFIG)\n",
    "            x = torch.randint(0, tokenizer.vocab_size, (2, 10))\n",
    "            hidden = model.init_hidden(2)\n",
    "            output, new_hidden = model(x, hidden)\n",
    "            assert output.shape == (2, 10, tokenizer.vocab_size), f\"Sortie {model_type} incorrecte\"\n",
    "            del model\n",
    "        print(\"    Modèles OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 4: DataLoader\n",
    "        print(\"4️⃣ Test DataLoader...\")\n",
    "        from torch.utils.data import DataLoader\n",
    "        loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "        batch_seq, batch_target = next(iter(loader))\n",
    "        assert batch_seq.shape[0] <= 2, \"Batch size incorrect\"\n",
    "        print(\"    DataLoader OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 5: Configuration\n",
    "        print(\"5️⃣ Test Configuration...\")\n",
    "        assert CONFIG['phase1']['max_sequences'] < CONFIG['phase2']['max_sequences'], \"Config séquences incorrecte\"\n",
    "        assert CONFIG['phase1']['max_epochs'] < CONFIG['phase2']['max_epochs'], \"Config époques incorrecte\"\n",
    "        assert CONFIG['phase1']['learning_rate'] > CONFIG['phase2']['learning_rate'], \"Config LR incorrecte\"\n",
    "        print(\"    Configuration OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 6: Répertoires\n",
    "        print(\"6️⃣ Test Répertoires...\")\n",
    "        assert MODEL_DIR.exists(), \"Répertoire modèles manquant\"\n",
    "        assert LOGS_DIR.exists(), \"Répertoire logs manquant\"\n",
    "        print(\"    Répertoires OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Erreur: {e}\")\n",
    "    \n",
    "    print(f\"\\\\nRésultat: {tests_passed}/{total_tests} tests réussis\")\n",
    "    \n",
    "    if tests_passed == total_tests:\n",
    "        print(\" TOUS LES TESTS RÉUSSIS - Système prêt!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"CERTAINS TESTS ÉCHOUÉS - Vérifiez la configuration\")\n",
    "        return False\n",
    "\n",
    "# GUIDE D'UTILISATION\n",
    "def show_usage_guide():\n",
    "    \"\"\"\n",
    "    Afficher le guide d'utilisation du système\n",
    "    \"\"\"\n",
    "    print(\"GUIDE D'UTILISATION DU SYSTÈME\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"DÉMARRAGE RAPIDE:\")\n",
    "    print(\"   1. Testez le système: test_system_components()\")\n",
    "    print(\"   2. Lancez la comparaison complète: run_complete_comparison()\")\n",
    "    print(\"   3. Ou par étapes:\")\n",
    "    print(\"      - Phase 1: winner, results, tokenizer = run_phase1_comparison()\")\n",
    "    print(\"      - Phase 2: model, results, tokenizer = run_phase2_final_training(winner)\")\n",
    "    print()\n",
    "    print(\"UTILISATION AVEC VOS DONNÉES:\")\n",
    "    print(\"   - Placez votre fichier texte dans le répertoire\")\n",
    "    print(\"   - Utilisez: run_complete_comparison('chemin/vers/fichier.txt')\")\n",
    "    print()\n",
    "    print(\"CONFIGURATION:\")\n",
    "    print(\"   - Modifiez CONFIG pour ajuster les hyperparamètres\")\n",
    "    print(\"   - Phase 1: comparaison rapide (5% données, 5 époques)\")\n",
    "    print(\"   - Phase 2: entraînement complet (100% données, 25 époques)\")\n",
    "    print()\n",
    "    print(\"RÉSULTATS:\")\n",
    "    print(\"   - Modèles sauvegardés dans: models/\")\n",
    "    print(\"   - Logs TensorBoard dans: logs/\")\n",
    "    print(\"   - Graphiques: models/training_results.png\")\n",
    "    print()\n",
    "    print(\"CRITÈRES DE RÉUSSITE:\")\n",
    "    print(\"    Phase 1 < 30 minutes\")\n",
    "    print(\"    Vocabulaire < 50 caractères\")\n",
    "    print(\"    Génération de texte cohérente\")\n",
    "    print(\"    Export ONNX pour déploiement\")\n",
    "    print(\"    Temps total < 3 heures\")\n",
    "\n",
    "print(\" Système complet prêt!\")\n",
    "print()\n",
    "show_usage_guide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada7c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VÉRIFICATION FINALE DU SYSTÈME\n",
      "==================================================\n",
      "Composants chargés:\n",
      "    PyTorch version: 2.7.1+cu118\n",
      "    Device: cuda\n",
      "    Seed fixé: 42\n",
      "    Répertoires créés: models, logs\n",
      "    Configuration chargée: 3 phases\n",
      "    GPU: NVIDIA GeForce RTX 2070\n",
      "    Mémoire GPU: 8.6 GB\n",
      "\n",
      "💡 ÉTAPES SUIVANTES:\n",
      "   Exécuter: test_system_components()  # Test complet\n",
      "   Exécuter: run_complete_comparison() # Lancer la comparaison\n",
      "   Ou par phases:\n",
      "      - run_phase1_comparison()          # Phase 1 seulement\n",
      "      - run_phase2_final_training()      # Phase 2 avec le gagnant\n",
      "\n",
      "OBJECTIFS À ATTEINDRE:\n",
      "    Comparaison 3 modèles < 30 minutes\n",
      "    Identification du meilleur modèle\n",
      "    Entraînement final de qualité\n",
      "    Export ONNX pour déploiement\n",
      "    Génération de texte cohérente\n",
      "\n",
      "SYSTÈME PRÊT POUR LE LANCEMENT!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# TEST DU SYSTÈME ET DÉMARRAGE\n",
    "print(\"VÉRIFICATION FINALE DU SYSTÈME\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Vérifier que tous les composants sont prêts\n",
    "print(\"Composants chargés:\")\n",
    "print(f\"    PyTorch version: {torch.__version__}\")\n",
    "print(f\"    Device: {device}\")\n",
    "print(f\"    Seed fixé: {SEED}\")\n",
    "print(f\"    Répertoires créés: {MODEL_DIR}, {LOGS_DIR}\")\n",
    "print(f\"    Configuration chargée: {len(CONFIG)} phases\")\n",
    "\n",
    "# Vérifier la mémoire disponible\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"    GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"    Mémoire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"   CPU seulement (recommandé: GPU pour performance)\")\n",
    "\n",
    "print(\"\\n💡 ÉTAPES SUIVANTES:\")\n",
    "print(\"   Exécuter: test_system_components()  # Test complet\")\n",
    "print(\"   Exécuter: run_complete_comparison() # Lancer la comparaison\")\n",
    "print(\"   Ou par phases:\")\n",
    "print(\"      - run_phase1_comparison()          # Phase 1 seulement\")\n",
    "print(\"      - run_phase2_final_training()      # Phase 2 avec le gagnant\")\n",
    "\n",
    "print(\"\\nOBJECTIFS À ATTEINDRE:\")\n",
    "print(\"    Comparaison 3 modèles < 30 minutes\")\n",
    "print(\"    Identification du meilleur modèle\")\n",
    "print(\"    Entraînement final de qualité\")\n",
    "print(\"    Export ONNX pour déploiement\")\n",
    "print(\"    Génération de texte cohérente\")\n",
    "\n",
    "print(\"\\nSYSTÈME PRÊT POUR LE LANCEMENT!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 LANCEMENT DU SYSTÈME COMPLET\n",
      "==================================================\n",
      "Test des composants...\n",
      "🧪 TEST DES COMPOSANTS DU SYSTÈME\n",
      "==================================================\n",
      "Test Tokenizer...\n",
      "Vocabulaire construit:\n",
      "   - Taille: 16 caractères\n",
      "   - Caractères:  !,123HWdeloràçé\n",
      "    Tokenizer OK\n",
      "Test Dataset...\n",
      " Dataset créé:\n",
      "   - Texte original: 21 caractères\n",
      "   - Texte encodé: 21 tokens\n",
      "   - Séquences générées: 3\n",
      "   - Longueur séquence: 10\n",
      "   - Chevauchement: 50%\n",
      "    Dataset OK\n",
      "Test Modèles...\n",
      "Modèle RNN créé:\n",
      "   - Paramètres: 236,560\n",
      "   - Device: cuda:0\n",
      "   Erreur: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n",
      "\\nRésultat: 2/6 tests réussis\n",
      "CERTAINS TESTS ÉCHOUÉS - Vérifiez la configuration\n",
      "Tests échoués - Vérifiez la configuration\n"
     ]
    }
   ],
   "source": [
    "# LANCEMENT DE LA COMPARAISON COMPLÈTE\n",
    "print(\"LANCEMENT DU SYSTÈME COMPLET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# D'abord, testons rapidement les composants\n",
    "print(\"Test des composants...\")\n",
    "if test_system_components():\n",
    "    print(\" Tous les tests réussis!\")\n",
    "    \n",
    "    print(\"\\nLancement de la comparaison complète...\")\n",
    "    print(\"Objectif: Identifier le meilleur modèle RNN/LSTM/GRU\")\n",
    "    print(\"Stratégie 2-phases activée\")\n",
    "    print(\"Dataset: Texte français (Le Petit Prince)\")\n",
    "    print()\n",
    "    \n",
    "    # Lancer la comparaison complète\n",
    "    results = run_complete_comparison()\n",
    "    \n",
    "    if results['success']:\n",
    "        print(\"\\nMISSION ACCOMPLIE!\")\n",
    "        print(f\"Gagnant: {results['winner']}\")\n",
    "        print(f\"Temps total: {results['total_time']/60:.1f} minutes\")\n",
    "        print(\"\\nConsultez les résultats:\")\n",
    "        print(\"   - Graphiques: models/training_results.png\")\n",
    "        print(\"   - Modèles: models/\")\n",
    "        print(\"   - Logs TensorBoard: logs/\")\n",
    "    else:\n",
    "        print(f\"\\nErreur: {results.get('error', 'Inconnue')}\")\n",
    "        print(f\"Temps avant erreur: {results['total_time']/60:.1f} minutes\")\n",
    "else:\n",
    "    print(\"Tests échoués - Vérifiez la configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "eb99ddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANCEMENT DIRECT DE LA PHASE 1\n",
      "============================================================\n",
      "Ignorons les tests et lançons directement la comparaison!\n",
      "Phase 1: Comparaison Ultra-Rapide des 3 modèles\n",
      "Temps estimé: 15-30 minutes\n",
      "\n",
      "============================================================\n",
      "DÉBUT PHASE 1 - COMPARAISON ULTRA-RAPIDE\n",
      "============================================================\n",
      "Objectif: Identifier le meilleur modèle en 15-30 minutes\n",
      "Optimisations: 5% données, 5 époques max, LR élevé, patience réduite\n",
      "\n",
      "Chargement des données pour PHASE1\n",
      "Aucun fichier spécifié, utilisation d'un dataset de démonstration\n",
      "   Limitation à 5% des données: 4,172 caractères\n",
      "   Texte chargé: 4,172 caractères\n",
      "Vocabulaire construit:\n",
      "   - Taille: 46 caractères\n",
      "   - Caractères: \n",
      " ',-.126BCEILSTUabc...\n",
      " Dataset créé:\n",
      "   - Texte original: 4,172 caractères\n",
      "   - Texte encodé: 4,172 tokens\n",
      "   - Séquences générées: 165\n",
      "   - Longueur séquence: 50\n",
      "   - Chevauchement: 50%\n",
      "   Division données:\n",
      "      - Train: 132 séquences\n",
      "      - Validation: 33 séquences\n",
      "      - Batch size: 64\n",
      "      - Vocabulaire: 46 caractères\n",
      "   Échantillon: '\n",
      "        Le petit prince était un très joli petit bonhomme qui riait souvent. Il venait d'une planèt...'\n",
      "🔬 Comparaison de 3 modèles:\n",
      "   - Types: RNN, LSTM, GRU\n",
      "   - Données: 132 séquences d'entraînement\n",
      "   - Vocabulaire: 46 caractères\n",
      "\n",
      "🔄 [1/3] Entraînement RNN\n",
      "----------------------------------------\n",
      "Modèle RNN créé:\n",
      "   - Paramètres: 248,110\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - SimpleRNN\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "Époque  1/ 5 | Train: 3.5071 | Val: 2.9457 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  2/ 5 | Train: 2.7547 | Val: 2.5657 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  2/ 5 | Train: 2.7547 | Val: 2.5657 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  3/ 5 | Train: 2.5475 | Val: 2.3885 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  4/ 5 | Train: 2.4419 | Val: 2.2618 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  3/ 5 | Train: 2.5475 | Val: 2.3885 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  4/ 5 | Train: 2.4419 | Val: 2.2618 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  5/ 5 | Train: 2.3087 | Val: 2.1774 | LR: 0.002000 | Temps: 0.0sÉpoque  5/ 5 | Train: 2.3087 | Val: 2.1774 | LR: 0.002000 | Temps: 0.0s\n",
      "   Génération: 'LemtmèLe test eè a dns s fles ,ouns lanèae peuiene...'\n",
      " Meilleur modèle restauré (Val Loss: 2.1774)\n",
      "Temps total: 0.2s (0.0 minutes)\n",
      "\n",
      "   Génération: 'LemtmèLe test eè a dns s fles ,ouns lanèae peuiene...'\n",
      " Meilleur modèle restauré (Val Loss: 2.1774)\n",
      "Temps total: 0.2s (0.0 minutes)\n",
      " RNN terminé:\n",
      "   - Validation Loss: 2.1774\n",
      "   - Temps: 0.2s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 248,110\n",
      "   - Échantillon: 'Le petit princet puinres dur le dlsite de t ant ou...'\n",
      "\n",
      "🔄 [2/3] Entraînement LSTM\n",
      "----------------------------------------\n",
      "Modèle LSTM créé:\n",
      "   - Paramètres: 939,310\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - LSTMModel\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      " RNN terminé:\n",
      "   - Validation Loss: 2.1774\n",
      "   - Temps: 0.2s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 248,110\n",
      "   - Échantillon: 'Le petit princet puinres dur le dlsite de t ant ou...'\n",
      "\n",
      "🔄 [2/3] Entraînement LSTM\n",
      "----------------------------------------\n",
      "Modèle LSTM créé:\n",
      "   - Paramètres: 939,310\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - LSTMModel\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "Époque  1/ 5 | Train: 3.7464 | Val: 3.2425 | LR: 0.002000 | Temps: 0.1s\n",
      "Époque  2/ 5 | Train: 3.1557 | Val: 3.0477 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  3/ 5 | Train: 3.0552 | Val: 2.9878 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  1/ 5 | Train: 3.7464 | Val: 3.2425 | LR: 0.002000 | Temps: 0.1s\n",
      "Époque  2/ 5 | Train: 3.1557 | Val: 3.0477 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  3/ 5 | Train: 3.0552 | Val: 2.9878 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  4/ 5 | Train: 2.9756 | Val: 2.9365 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  5/ 5 | Train: 2.9184 | Val: 2.9042 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  4/ 5 | Train: 2.9756 | Val: 2.9365 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  5/ 5 | Train: 2.9184 | Val: 2.9042 | LR: 0.002000 | Temps: 0.0s\n",
      "   Génération: 'Lei la u etleqadse le rnuetier pce  c. raur ta euu...'\n",
      " Meilleur modèle restauré (Val Loss: 2.9042)\n",
      "Temps total: 0.3s (0.0 minutes)\n",
      " LSTM terminé:\n",
      "   - Validation Loss: 2.9042\n",
      "   - Temps: 0.3s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 939,310\n",
      "   - Échantillon: 'Le petit princerlp od anas a te  e eee  eai vde tt...'\n",
      "\n",
      "🔄 [3/3] Entraînement GRU\n",
      "----------------------------------------\n",
      "Modèle GRU créé:\n",
      "   - Paramètres: 708,910\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - GRUModel\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "   Génération: 'Lei la u etleqadse le rnuetier pce  c. raur ta euu...'\n",
      " Meilleur modèle restauré (Val Loss: 2.9042)\n",
      "Temps total: 0.3s (0.0 minutes)\n",
      " LSTM terminé:\n",
      "   - Validation Loss: 2.9042\n",
      "   - Temps: 0.3s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 939,310\n",
      "   - Échantillon: 'Le petit princerlp od anas a te  e eee  eai vde tt...'\n",
      "\n",
      "🔄 [3/3] Entraînement GRU\n",
      "----------------------------------------\n",
      "Modèle GRU créé:\n",
      "   - Paramètres: 708,910\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - GRUModel\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "Époque  1/ 5 | Train: 3.6014 | Val: 3.0953 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  2/ 5 | Train: 3.0565 | Val: 2.9119 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  3/ 5 | Train: 2.9162 | Val: 2.7920 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  1/ 5 | Train: 3.6014 | Val: 3.0953 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  2/ 5 | Train: 3.0565 | Val: 2.9119 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  3/ 5 | Train: 2.9162 | Val: 2.7920 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  4/ 5 | Train: 2.7292 | Val: 2.6346 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  5/ 5 | Train: 2.6025 | Val: 2.5238 | LR: 0.002000 | Temps: 0.0s\n",
      "   Génération: 'Lee le poaenies btiit. Srogert our Sar taits lauie...'\n",
      " Meilleur modèle restauré (Val Loss: 2.5238)\n",
      "Temps total: 0.2s (0.0 minutes)\n",
      " GRU terminé:\n",
      "   - Validation Loss: 2.5238\n",
      "   - Temps: 0.2s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 708,910\n",
      "   - Échantillon: 'Le petit princeretit ojlaaàèie 'e upe lr. le anet ...'\n",
      "\n",
      "============================================================\n",
      "RÉSULTATS PHASE 1 - COMPARAISON\n",
      "============================================================\n",
      "CLASSEMENT (par Validation Loss):\n",
      "🥇 1. RNN  | Val Loss: 2.1774 | Temps:   0.2s | Params: 248,110\n",
      "🥈 2. GRU  | Val Loss: 2.5238 | Temps:   0.2s | Params: 708,910\n",
      "🥉 3. LSTM | Val Loss: 2.9042 | Temps:   0.3s | Params: 939,310\n",
      "\n",
      "GAGNANT PHASE 1: RNN\n",
      "   - Meilleure Validation Loss: 2.1774\n",
      "   - Temps d'entraînement: 0.2s\n",
      "   - Nombre de paramètres: 248,110\n",
      "\n",
      "TEMPS TOTAL PHASE 1: 1.0s (0.0 minutes)\n",
      "💾 Résultats sauvegardés:\n",
      "   - Modèles: models/{RNN,LSTM,GRU}_phase1.pth\n",
      "   - Tokenizer: models\\tokenizer.pkl\n",
      "   - Résultats: models\\phase1_results.json\n",
      "\n",
      " VALIDATION CRITÈRES PHASE 1:\n",
      "    Temps < 30 minutes\n",
      "    Vocabulaire < 50 caractères\n",
      "    Génération cohérente\n",
      "    Classement clair\n",
      "\n",
      "PHASE 1 RÉUSSIE ! Prêt pour Phase 2\n",
      "PHASE 1 TERMINÉE!\n",
      "Gagnant: RNN\n",
      "\n",
      "Voulez-vous continuer avec la Phase 2?\n",
      "   Exécutez: run_phase2_final_training(winner)\n",
      "   Ou la comparaison complète: plot_training_results(results_phase1)\n",
      "Époque  4/ 5 | Train: 2.7292 | Val: 2.6346 | LR: 0.002000 | Temps: 0.0s\n",
      "Époque  5/ 5 | Train: 2.6025 | Val: 2.5238 | LR: 0.002000 | Temps: 0.0s\n",
      "   Génération: 'Lee le poaenies btiit. Srogert our Sar taits lauie...'\n",
      " Meilleur modèle restauré (Val Loss: 2.5238)\n",
      "Temps total: 0.2s (0.0 minutes)\n",
      " GRU terminé:\n",
      "   - Validation Loss: 2.5238\n",
      "   - Temps: 0.2s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 708,910\n",
      "   - Échantillon: 'Le petit princeretit ojlaaàèie 'e upe lr. le anet ...'\n",
      "\n",
      "============================================================\n",
      "RÉSULTATS PHASE 1 - COMPARAISON\n",
      "============================================================\n",
      "CLASSEMENT (par Validation Loss):\n",
      "🥇 1. RNN  | Val Loss: 2.1774 | Temps:   0.2s | Params: 248,110\n",
      "🥈 2. GRU  | Val Loss: 2.5238 | Temps:   0.2s | Params: 708,910\n",
      "🥉 3. LSTM | Val Loss: 2.9042 | Temps:   0.3s | Params: 939,310\n",
      "\n",
      "GAGNANT PHASE 1: RNN\n",
      "   - Meilleure Validation Loss: 2.1774\n",
      "   - Temps d'entraînement: 0.2s\n",
      "   - Nombre de paramètres: 248,110\n",
      "\n",
      "TEMPS TOTAL PHASE 1: 1.0s (0.0 minutes)\n",
      "💾 Résultats sauvegardés:\n",
      "   - Modèles: models/{RNN,LSTM,GRU}_phase1.pth\n",
      "   - Tokenizer: models\\tokenizer.pkl\n",
      "   - Résultats: models\\phase1_results.json\n",
      "\n",
      " VALIDATION CRITÈRES PHASE 1:\n",
      "    Temps < 30 minutes\n",
      "    Vocabulaire < 50 caractères\n",
      "    Génération cohérente\n",
      "    Classement clair\n",
      "\n",
      "PHASE 1 RÉUSSIE ! Prêt pour Phase 2\n",
      "PHASE 1 TERMINÉE!\n",
      "Gagnant: RNN\n",
      "\n",
      "Voulez-vous continuer avec la Phase 2?\n",
      "   Exécutez: run_phase2_final_training(winner)\n",
      "   Ou la comparaison complète: plot_training_results(results_phase1)\n"
     ]
    }
   ],
   "source": [
    "# LANCEMENT DIRECT PHASE 1 - COMPARAISON RNN vs LSTM vs GRU\n",
    "print(\"LANCEMENT DIRECT DE LA PHASE 1\")\n",
    "print(\"=\"*60)\n",
    "print(\"Ignorons les tests et lançons directement la comparaison!\")\n",
    "print(\"Phase 1: Comparaison Ultra-Rapide des 3 modèles\")\n",
    "print(\"Temps estimé: 15-30 minutes\")\n",
    "print()\n",
    "\n",
    "# Lancer directement la Phase 1\n",
    "winner, results_phase1, tokenizer = run_phase1_comparison()\n",
    "\n",
    "print(\"PHASE 1 TERMINÉE!\")\n",
    "print(f\"Gagnant: {winner}\")\n",
    "print(\"\\nVoulez-vous continuer avec la Phase 2?\")\n",
    "print(\"   Exécutez: run_phase2_final_training(winner)\")\n",
    "print(\"   Ou la comparaison complète: plot_training_results(results_phase1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "4368fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYSE DES RÉSULTATS DE PHASE 1\n",
      "==================================================\n",
      "Gagnant: RNN\n",
      "Nombre de modèles comparés: 3\n",
      "Taille du vocabulaire: 46 caractères\n",
      "\n",
      "CLASSEMENT FINAL:\n",
      "🥇 1. RNN  | Val Loss: 2.1774 | Temps:   0.2s | Params: 248,110\n",
      "🥈 2. GRU  | Val Loss: 2.5238 | Temps:   0.2s | Params: 708,910\n",
      "🥉 3. LSTM | Val Loss: 2.9042 | Temps:   0.3s | Params: 939,310\n",
      "\n",
      "🎨 ÉCHANTILLONS DE GÉNÉRATION:\n",
      "RNN : 'Le petit princet puinres dur le dlsite de t ant ous  lrss bens qunles le ait ui ...'\n",
      "LSTM: 'Le petit princerlp od anas a te  e eee  eai vde ttl 'aar lrn ui eeattnt de men s...'\n",
      "GRU : 'Le petit princeretit ojlaaàèie 'e upe lr. le anet uitt vpne plae lpvineavitrmvda...'\n",
      "\n",
      "Génération des graphiques de comparaison...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACQoAAAjtCAYAAADO0ZRlAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3U2InuXd9/HfNEXHl4idJKNEE3GkZOILtFHpGKn4UlG8lRaTXbuxSKQLoXQ1Iq1dxBDQVauloIIVF9aQTU1KuihaF9ZGEpkkZRwSBzrSSCYvhagUQvW6F8JAn6q3fWoS6+/zWR3Def2vOY719eU4hwaDwSAAAAAAAAAAAMAX2pdO9wYAAAAAAAAAAICTTygEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAn3PPPfdc1qxZk7POOisjIyNZv3593nzzzU+ceeCBB7J69eqcd955GR4eziWXXJLvf//7+ctf/nKKdg0AAAAAAMDnzdBgMBic7k0AAPDRnnrqqdx7771JkksvvTRHjx7N8ePHMzo6mqmpqVx44YUfObdmzZocOXIky5Yty/Hjx3PgwIEkyapVq/LGG2+csv0DAAAAAADw+eFGIQCAz6kTJ05kcnIySbJu3brMzs5meno6ixcvzvz8fDZt2vSxs6+88krm5uaya9eu7N+/P9/73veSJDMzMzl69GiS5N13380PfvCDrFixImeeeWaWLVuW66+/Pr/61a9O/uEAAAAAAAA45YRCAACfU6+99lqOHDmS5MNQKEmWL1+eiYmJJMmOHTs+dnZ4eDi/+MUv8o1vfCNf/epX8+yzzyZJLr/88oyMjCRJfvKTn+SXv/xlDh8+nCuuuCKLFy/On/70p7z44osn81gAAAAAAACcJl8+3RsAAOCjvfXWWwvr0dHRhfUFF1yQJJmbm/vE+bm5uezcuXPh769//evZtm1bhoaGkiT79+9Pkvz4xz/Ogw8+mCQ5duzYP/1fAAAAAAAAvjjcKAQA8F9mMBh8qs9t3rw5//jHP/LGG2/kpptuyuuvv57vfve7ef/995Mkd911V5IPQ6FLLrkkt912W37+858vhEgAAAAAAAB8sQiFAAA+p1asWLGwnp+f/5f1ypUr/8/vWLRoUVatWpUf/vCHSZKXXnopv//975MkGzZsyB/+8If86Ec/yvj4eHbt2pWf/vSn+da3vvUZngIAAAAAAIDPC6EQAMDn1LXXXpslS5YkSbZu3ZokOXjwYF599dUkye23354kGR8fz/j4eB577LEkH75S7De/+U0++OCDJMkHH3yQHTt2LHzve++9lyTZuXNnrrjiijz66KP53e9+l23btiVJ/vznP+fo0aOn4IQAAAAAAACcSl8+3RsAAOCjnXHGGdm0aVPuu+++bN26NWNjYzl69GjeeeedLF26NJOTk0mSmZmZJMmRI0eSJH/961/z7W9/O+eee27GxsZy6NChHDp0KEly8cUX55ZbbkmS/OxnP8uvf/3rXHzxxRkZGcmBAweSJBdddFFGRkZO9XEBAAAAAAA4ydwoBADwObZhw4Y8++yz+drXvpaDBw9maGgod999d1555ZUsX778I2dWrlyZ73znO/nKV76SmZmZ/O1vf8tll12W++67L3/84x9z3nnnJUn+53/+J9/85jfz97//PXv37s3w8HDuuuuu/Pa3v83Q0NCpPCYAAAAAAACnwNBgMBic7k0AAAAAAAAAAAAnlxuFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAAAAAAAAAACggFAIAAAAAAAAAAAKCIUAAAAAAAAAAKCAUAgAAAAAAAAAAAoIhQAAAAAAAAAAoIBQCAAAAAAAAAAACgiFAKDMc889lzVr1uSss87KyMhI1q9fnzfffPMTZyYnJ3PddddldHQ0w8PDGRsby/3335/5+flTtGsAAAAAAADgPzU0GAwGp3sTAMCp8dRTT+Xee+9Nklx66aU5evRojh8/ntHR0UxNTeXCCy/8yLmhoaEsWrQoq1evzrFjx3Lw4MEkyZVXXpmpqal86UvaYwAAAAAAAPi886seAJQ4ceJEJicnkyTr1q3L7Oxspqens3jx4szPz2fTpk0fO/vggw/m7bffzt69ezM3N5d169YlSfbt25epqakkyfvvv58HHnggY2NjGR4ezsjISK655po88sgjJ/9wAAAAAAAAwP9JKAQAJV577bUcOXIkSRZCn+XLl2diYiJJsmPHjo+d3bhxY5YtW5YkWbRoUdauXbvw7Mwzz0ySPP7449m8eXPm5uayatWqLFmyJHv37s327dtPynkAAAAAAACAf8+XT/cGAIBT46233lpYj46OLqwvuOCCJMnc3Nyn+p733nsvzzzzTJLk+uuvz+WXX54k2b9/f5LknnvuyRNPPJEkeffddzM9Pf2fbx4AAAAAAAD4j7lRCADKDQaDT/3Zw4cP55ZbbsnU1FTGx8ezZcuWhWd33nlnhoaG8uSTT+aiiy7KTTfdlI0bN2ZkZORkbBsAAAAAAAD4N7lRCABKrFixYmE9Pz//L+uVK1d+4vzMzEzuuOOOzM7OZmJiIi+88EKWLl268Py2227L7t27s2XLlkxNTeX111/PSy+9lKeffjoHDhzIueee+xmfCAAAAAAAAPh3uFEIAEpce+21WbJkSZJk69atSZKDBw/m1VdfTZLcfvvtSZLx8fGMj4/nscceW5h9+eWXs3bt2szOzmb9+vV58cUX/ykSSpI9e/Zk2bJlefjhh7Nt27bs2rUrSXLo0KHMzMyc9PMBAAAAAAAAn0woBAAlzjjjjGzatCnJh6HQ2NhYVq9enXfeeSdLly7N5ORkkg9vDpqZmcmRI0cWZm+99dYcO3YsQ0NDmZuby4033piJiYlMTExk+/btSZLnn38+K1asyMqVK3P11VfnqquuSpKcffbZueyyy07xaQEAAAAAAID/l1ePAUCRDRs25Jxzzsmjjz6a6enpDA8P5+67787mzZuzfPnyj507ceJEkmQwGGTnzp3/9Ozw4cNJkhtuuCG7d+/Onj17sm/fvixevDg333xzHnrooZx//vkn7UwAAAAAAADApzM0GAwGp3sTAAAAAAAAAADAyeXVYwAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAACfBc889lzVr1uSss87KyMhI1q9fnzfffPMTZyYnJ3PddddldHQ0w8PDGRsby/3335/5+flTtGsAAAAAAOCLbGgwGAxO9yYAAOCL5Kmnnsq9996bJLn00ktz9OjRHD9+PKOjo5mamsqFF174kXNDQ0NZtGhRVq9enWPHjuXgwYNJkiuvvDJTU1P50pd0/gAAAAAAwP8/vzQAAMBn6MSJE5mcnEySrFu3LrOzs5mens7ixYszPz+fTZs2fezsgw8+mLfffjt79+7N3Nxc1q1blyTZt29fpqamkiTvv/9+HnjggYyNjWV4eDgjIyO55ppr8sgjj5z8wwEAAAAAAP/VhEIAAPAZeu2113LkyJEkWQh9li9fnomJiSTJjh07PnZ248aNWbZsWZJk0aJFWbt27cKzM888M0ny+OOPZ/PmzZmbm8uqVauyZMmS7N27N9u3bz8p5wEAAAAAAL44vny6NwAAAF8kb7311sJ6dHR0YX3BBRckSebm5j7V97z33nt55plnkiTXX399Lr/88iTJ/v37kyT33HNPnnjiiSTJu+++m+np6f988wAAAAAAwBeaG4UAAOAUGAwGn/qzhw8fzi233JKpqamMj49ny5YtC8/uvPPODA0N5cknn8xFF12Um266KRs3bszIyMjJ2DYAAAAAAPAF4kYhAAD4DK1YsWJhPT8//y/rlStXfuL8zMxM7rjjjszOzmZiYiIvvPBCli5duvD8tttuy+7du7Nly5ZMTU3l9ddfz0svvZSnn346Bw4cyLnnnvsZnwgAAAAAAPiicKMQAAB8hq699tosWbIkSbJ169YkycGDB/Pqq68mSW6//fYkyfj4eMbHx/PYY48tzL788stZu3ZtZmdns379+rz44ov/FAklyZ49e7Js2bI8/PDD2bZtW3bt2pUkOXToUGZmZk76+QAAAAAAgP9eQiEAAPgMnXHGGdm0aVOSD0OhsbGxrF69Ou+8806WLl2aycnJJB/eHDQzM5MjR44szN566605duxYhoaGMjc3lxtvvDETExOZmJjI9u3bkyTPP/98VqxYkZUrV+bqq6/OVVddlSQ5++yzc9lll53i0wIAAAAAAP9NvHoMAAA+Yxs2bMg555yTRx99NNPT0xkeHs7dd9+dzZs3Z/ny5R87d+LEiSTJYDDIzp07/+nZ4cOHkyQ33HBDdu/enT179mTfvn1ZvHhxbr755jz00EM5//zzT9qZAAAAAACA/35Dg8FgcLo3AQAAAAAAAAAAnFxePQYAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIAAAAAAAAAAFBAKAQAAAAAAAAAAAWEQgAAAAAAAAAAUEAoBAAAAAAAAAAABYRCAAAAAAAAAABQQCgEAAAAAAAAAAAFhEIA8L/s3Xe4FNXBP/AvvRfpCoJKFMWCLdgwEsWuYEsQfRXQJGpii3kVsUeJEDWxl9hb7BEsQSwISqwRSzSKiQU7FmxYQIT9/cHv7nuv3EtR8Krz+TzPPuzOnp05c3aYszP3O2cAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQCAAAAAAAAAAACkBQqAYnnHBC6tSpkzp16uTyyy+v7eoU0pAhQ8rfwcSJE8vTK6atsMIKC53H1KlTy+X79u27VOp5+eWXl5dxwgknLJVlQJL07du3vK1NnTq1tqsDi03f+t21wgorlL+br+v7+v1+G78VgOJaEscKjjcAFt/39bdpERT52AMAAOC7ojBBocoHkJUfrVq1yiabbJJLLrkkpVKptqu5xL3//vsZPnx4NttsszRt2rS83kOGDPnG815xxRXL87v33nurLTNo0KBymT/84Q/feJm15YQTTsgJJ5yQM844o7arskCVw1Xf5z8i/POf/8zQoUPTvXv3NGnSJG3atMk666yTI444Is8991xtVw/4//StS75vra49a3oIDFavcqhyYQ9/VIAfrq/2UVtttdV8ZSZPnjzffmHmzJm1UNslq/IfYCseDRo0SOfOnTNw4MA88cQTtV3FWnP55ZeXj+0+/PDD2q4OsBgcezj2+K6bPXt2Lr300my11Vbp0KFDGjVqlK5du6Zfv375y1/+khkzZtR2FQEAAMrq13YFatvHH3+cBx98MA8++GAeeOCBXHrppbVdpSXq1VdfzahRo5bKvHfffffyvG+44YZsvvnmVd6fOXNmbr/99irll4RJkyYlSRo3brxE5rcofv/73ydJunXrlkMPPbTKe9ttt125Tl27dv3W6vRDdeSRR+aPf/xjlWkzZ87MBx98kCeffDL/+c9/MmbMmNqpXC07++yz89FHHyVJll122VquDdRM3/r9c9NNN33jP47vs88+6devX5JklVVWWRLV+lYsu+yy5X68VatWtVwbYGkZP358XnnllXTr1q087aKLLqrFGn27vvzyy7z55pu54YYbMnr06IwdO7a8zy6Syy+/PPfdd1+SeRdZtG7dunYrBHxjjj2+f36Ixx5vvPFGBgwYkMmTJ1eZ/tprr+W1117L+PHj07Fjx+y00061U0EAAICvKGRQaNttt81RRx2VmTNn5vrrr8/FF1+cJLnsssvy61//Ouuvv34t13DJadiwYX7yk59k4403zjvvvLNET5hUDgrdfPPNOffcc1OvXr3y+2PHjs0nn3ySJFl//fXTvXv3JbLcPn36LJH5LCkdOnRIhw4darsaPwinnXZalZDQwIEDM3DgwLRs2TL//e9/89e//rUWa1d7Pv300zRr1ixrrrlmbVcFaqRvXTIqAisVNt100/LzG2+8MZ06dSq/rikwWLHPWBxL4vvp2rXrdyIwWzlUmSQHHXRQnnzyySTJUUcdlW233bb83iqrrJJGjRp9535bAEve3Llzc8kll+TEE09MMm9fec0119RyrZa+s846K+uss07efvvtHHfccXn22Wcze/bsHHrooXnmmWeW2HK+Tt/zQ6UtYOlz7LFkOPZYMr744ov0798/jz/+eJKkdevW+d3vfpcNN9wws2bNykMPPZRLLrlkiS937ty5+eKLL77VCykBAIAfjsLceqyyDh06pE+fPunXr18uvPDCrLjiiuX3vnqQXOG8887LyiuvnEaNGqVXr17z3WprzJgx6d+/f1ZcccW0aNEiDRs2TLdu3TJ06ND5huedPn169t9//3Tr1i0NGzZMixYtssoqq2TQoEHlqxsrvPzyy/nlL3+Zbt26pVGjRunQoUMGDhy4yLdf6tmzZ+67776MHDkyP/7xjxdavvKtqyZOnLjAsr169cpqq62WJHn33XczYcKEKu/feOON5eeDBg1KsnjtVJOK+q2wwgpVpr/88svp379/mjVrlg4dOuSQQw7JZ599Vu08nnnmmey5557p2bNn2rRpkwYNGqRDhw7Zfvvtc//995fLVQxtXeGVV16Zb/mXX355jbf7euGFFzJ06NAsv/zyadiwYdq2bZvtttsu48ePr1Ju4sSJVYaPvvPOO/PjH/84jRs3TteuXXPWWWctUtssrptuuik//elP07p16zRq1CgrrbRSDjzwwLz11ltVyi3qNjt16tTsscceWW655dKgQYO0bt06PXv2zNChQ/Ovf/1rgXV5//33yyM3Jcnvfve7XHfdddl5552zxRZbZP/998+kSZMycuTIKp97/PHH87Of/SydOnVKw4YN06lTp+y2227zXcX11e/p3HPPzQorrJBmzZplu+22y2uvvZaZM2fmkEMOSbt27dKiRYsMHDgw77//fpX5VP7+//vf/2aHHXZI8+bN065du/zmN7/Jp59+WqX87373u2y88cZZdtll06hRozRv3jzrrrtuTjvttHz55Zc1zvvpp5/OlltumebNm2f77bdPUvV2OpX/v/ztb39Lnz590qpVq3Ib9OnTJ8OGDasy9HqpVMqFF16YDTfcMC1atEjjxo2z6qqr5qijjqryR/WvLutf//pXDjrooHTo0CFNmjTJtttum1deeWWB3yfFo2+t2eL0rX369KnyqGz99dcvT//yyy/TuHHjcr9x8803Z+21106jRo1y6qmnJklGjRqVvn37pkuXLmnSpEmaNm2anj175phjjpmvf6x8m5oKi9s3Vb4dROVbelWe97Rp07LXXntlmWWWqXE/+/nnn+fQQw9N+/bt07x58/Tv3z9Tp06tto7VWXPNNau0YeVRglZeeeUq73Xo0CFTp04tz7dv377Vrs8ll1yS3//+91l22WXTsmXLDBo0KB9++GHef//97LXXXmnVqlXatGmT/fffv9qro2+55Zb069cvyyyzTBo1apQePXrk97//fT7//PMFrguwZLRo0SLJvD8gz507N0ly/fXXZ8aMGeX3arKov5eT5N577y3vJ7t3755zzz13gfP+pv3RoqjYJ+66664577zzytP//e9/54MPPsgbb7yRffbZJ7169Uq7du3SoEGDtGnTJptvvvl8o3h+tV9Ykn3PK6+8kh122CHNmjVLt27dynWdOHFiuU1XWWWV3HDDDfOt4yeffJITTjgha6yxRpo0aZKWLVumb9++ueOOO+are+XfBJVvpV35d8Wi7rMr/15+/PHHs88++6Rdu3Zp3rx5knn92eGHH17+rdOsWbOsuOKK2WWXXTJ69OjF+BaBr3LsUTPHHt/usUcy73xTRUioXr16mTBhQo455pj069cv22+/fUaMGJH//Oc/5YBUTecRF+W45NJLL82IESPSrVu3NGjQIOedd175vQEDBlSp1xtvvJG6deumTp066d27d3n67Nmz8+c//znrrbdemjVrlmbNmmWDDTbI1VdfPd+6TZw4Mf369SufO23fvn169+6dQw45ZL7zSAAAwPdMqSCOP/74UpJSktLgwYOrvNerV6/ye6NGjZqv/GqrrVZ+XvFo0aJF6f333y/PY7/99puvTMWjY8eOpbfffrtcdvPNN6+x7NFHH10uN3ny5FLr1q2rLde8efPSI488slhtcP7559fYBhUGDx5cLjNhwoSFzvPEE08sl//lL39Znv7ZZ5+VmjdvXkpSqlOnTun1119f7HaqqS4V07p161aeNn369NLyyy8/3zzXWmut8vPNNtusXP7aa6+tsR5169Yt3XvvvaVSqep28NVHxfIvu+yy8rTjjz++vIxHHnmk1KJFi2o/W6dOndJ5551XLjthwoQq861bt+58n7n77rsX+n1UbrPKdanOEUccUeO6derUqfTSSy+Vyy7KNjt79uzSKqusUmO5iy66aIH1ufLKK8tlW7VqVfroo48Wur633HJLqUGDBtUur0GDBqVbbrmlXLby99S9e/dqt5Wddtppvul77rlnlWVWTG/dunWpY8eO85XfZpttqpRv1KhRjW0ydOjQaufdqlWrUtu2befbdjfbbLPytJdffrlUKpVKEydOrHZ7qXjMnj27VCqVSnPnzi3tvvvuNZZbddVVq+zTKi9rpZVWmq/8JptsstDvhx8+fevS6Vsrq1y/iv/3pVLVfmPFFVcs1alTZ779f48ePWpsk5/+9KdVltOtW7fye9UtY1H6psrf72WXXVbtvKvbn3x1PztgwID5yiy//PKlNm3azFfHRVF5f1a5XhVefvnl+fa3X12f6vqNbbbZptS7d+8Fbm+lUql07LHH1vg9bLrppqVZs2Yt1voAi6by/+EhQ4aUfzP+/e9/L5VKpdIGG2xQSlL61a9+VeX/5eeff16ex+L8Xn7ggQdKDRs2nK9c5eORyr/PF6c/qul4oyaV97uV+50nnniiynKmTZtWeuihh2pcxySlK664ovz5pdn3VLefPfLII+dr07p165amTJlSnseHH35YWnPNNWtc5rnnnjtf3at7VPSxi7PPXtDv5VKpVNpnn31qnNdX+z5g4Rx7OPb4rh57VN4ehgwZstDyNfXri3Jc8tV1mjBhQnn7bty4cenjjz8uf+7MM88slzvzzDNLpVKp9MUXX5S22GKLGr+rI444ovz5KVOmlJo0aVJj2f/+978LXVcAAOC7q5AjClWYNWtWrrrqqiojnVR3a5/nnnsuw4YNy6233ppevXolSWbMmFFlqPqtttoqf/nLX3Lbbbdl4sSJGTduXH73u98lSd5+++3yMMgzZswoj7yzzjrr5NZbb80dd9yRCy64ILvuumt5uN5SqZTBgwfnww8/TDJvVJK77rorf/zjH1OvXr188sknGTp0aJXRQmrD7rvvXn4+evTo8ggpd9xxR/m2Y3369Ennzp2TLHo7La5TTz01r732WpJ5Vw9df/31ufzyy/Pmm29WW75Hjx7505/+lDFjxuTee+/N+PHjc/7556dRo0aZO3duedSaffbZp8rVaJ06dcqkSZMyadKk3HTTTTXWp1QqZejQoZkxY0aSZLfddsvf//73HHvssalbt25KpVIOPfTQcp0re+WVV7Ljjjvmtttuq9K+f/nLXxa/YWrwyCOP5JRTTkmSNG7cOKeddlpuvfXW/PSnP02STJs2Lb/+9a+TLPo2O2XKlPznP/9JkvTr1y/jxo3L7bffnrPPPjvbbrttGjVqtMA6PfXUU+Xna621Vlq2bLnA8p9++mn23XffzJ49O0lywAEHZOzYseV6z549O/vuu+98I/wkyYsvvpgjjjgit9xyS3nb/Ne//pXbb789p512Wq655po0adIkSXLddddVe5XUhx9+mC5dumTMmDE5++yz07Rp0yTJuHHjctttt5XLHX300bn22mszbty4TJw4MTfffHM22GCDJPOuInv99dfnm/dHH32UevXq5cILL8ydd96ZX/ziFzW2w2233Va+Mv7kk0/O+PHjc9111+WYY45Jz549y1e/3XDDDbnuuuuSJMsss0wuvPDCjB49OmuttVaSed/fUUcdVe0y3n333VxwwQW5+uqr07p16yTJAw88kH//+9811ovi0rd++15++eWsv/76ufHGGzNmzJjyLQP233//XHXVVRk7dmwmTpyYW2+9Ndttt12SZMKECXnwwQcXeRlLqm/6/PPPc/XVV+e8885Lw4YNk1Tdz95111255ZZbkszrn/785z9nzJgxad++/XxX/36bpk6dmlNOOSXXX399efSRcePG5dlnn83FF1+c888/v1y2cpv885//zEknnZRk3u0aLrnkkowbN648UtykSZNy+umnf4trAsXUsWPH7LDDDkmSiy++OE8//XQeeeSRJKnxd9bi/F5O5vUpX3zxRZJ5v4Vvu+22nHTSSdX+XqqN/uidd94p33Yt+b/bJ3fq1CmjRo3K3/72t9xzzz2ZMGFCrrjiirRv3z5JMmLEiGrnt6T7nnr16mX06NE55JBDytNGjRqVH//4x7ntttuyyy67JJl3m5XKx4xHH310nn766STJdtttl7///e+58sory7fL+e1vf5vXXnst66yzTiZNmpS11167/Nkbb7yxfGy37LLLfqN99quvvprjjz8+d955Z7lMRX/WrVu33HTTTbnrrrtyySWXZO+9984yyyxT7XyAxePY49vn2GN+lc9nVb5929Lw0ksvZc899yz3d507d86ee+6ZJJk5c2Zuv/32ctmK85b16tUrt+OZZ55ZHuV8ww03zOjRo3PTTTelR48eSZJTTjml/Bvp7rvvLo+md8ghh2T8+PG56aabMmLEiKy//vqLNNoSAADwHVZbCaVv24JGhql4rL/++qUvv/xyvvIDBgwoz+e6664rTz/00EPL06dPn1467LDDSj169Kj2aoudd965VCrNG2mn4qqYLbfcsvTss8+WR/yorPLVnmuvvXZp0qRJ5cdGG21Ufu+xxx5b5DZYlCuPvo711luvPN8777yzVCqVSgMHDixPqzxyzqK2U6m0eCMKVb46rOIq4VKpVLrooouqvRrnyy+/LJ1xxhmlH//4x6UWLVpUuRoqSWmZZZapso7VLbNCdVcCPf744+VpnTp1Kn3xxRfl8rvuumv5vdNPP71UKlW9cqpDhw6lmTNnlkqlUmnatGlVtoOFWdQRhQ4++OByud/97nfl6e+++255BJw6deqUpk+fvsjb7JQpU8rz3GuvvUovvvhiac6cOQutc4Vf/OIX5c8PHDhwoeVvvvnmcvn11luvynuVt8nRo0eXSqWq39PGG29cLvub3/ymSr0rbL/99uXpTz75ZHl65e2k8tVTRx99dHn6PvvsU57+j3/8ozRgwIBSp06dSvXr159vm6886lHl6Xfdddd861zdiEJHHnlkedqNN95Yeu+996ptr/79+5fLnX322eXpTz/9dJXtfu7cufMtq2I7LZVKpf333788fcyYMdUui+LQty69vrVC5fWt6are5s2bl6ZPnz7fZ5955pnS7rvvXurSpUu1o69VXFVaKi38qt5F6ZsW5arein1yqVQqbbPNNvPtZw844IBq+6fKfUzlOi6KJTGi0B577FGeXrl/OPbYY8vTV1999fL0Dz/8sFQqlUqHHHJIedpRRx1V3t5uu+228vQ11lhjsdYHWDSV/w8PGzas9Pe//72UzBt18uc//3kpmTfaT6lUdV9bMaLQ4vxefvvtt8tlGzVqVGWfvOeee873+3xx+6NvMqJQTY/KfcDll19e2nTTTUutW7ee77goSXmkz6XZ91T89n333XerlH/hhRdKpVKp9M9//rM8baeddiqVSqXSnDlzSssss0wpSalhw4ale+65p9yOv/71r8vlTzvttPIyq/s9XWFx99mV53XUUUfN1xadOnUqJSn16tWr9MQTT5T7UeDrcezh2OO7euxR+VzPHXfcsdDy32REoepGd37ppZfK/fcuu+xSKpVKpbfeequ8nVYe+bry6Fs33HBDeZusPGL8gQceWCqVSqULLrigPO2MM84ovfXWWwtdNwAA4Puj0CMKVWjYsGH+53/+J+PGjUu9evXme3+zzTYrP2/btm35ecVVQXPmzEm/fv3y5z//Oc8//3z5aovKKso2adIkgwYNSjLvyoyePXumadOmWWeddXLccceVr2qpGJklSZ588slsuumm5cdDDz1Ufm9R72m+NFW+uueGG27I559/Xr6CpX79+tltt92SLF47La6XXnqp/LzyPdsr34O7ssMOOyyHHnpo/vnPf2bGjBnzXcH1detRofL3t+6666ZBgwbV1qlyuQobbrhhefSd6ra3JaHycitGt0mSdu3aZaWVVkqSlEqlvPDCC4u8za688srlK6euuuqqdO/ePc2bN89GG22UU089NbNmzVpgnVq1alV+XtNIUIuyDsnC27jy+23atCk/r7hffDKvLSpU1/Zt2rTJj370o2rnWbE9Pvroo/npT3+aW265JdOmTSuPuFVZdfNu3Lhxttxyy/mmV2fPPfcsby8/+9nP0q5du3Ts2DG77LJL7rnnnnK5mtprjTXWKI+G9MEHH+Tdd9+dbxkL2wdCdfSt355NNtmkyr4smXcV7sYbb5zrrrsur7/+enn0tcoW5//wkuqbFva9V+7PK++revToUaujL3zdfqPyNnfyySeXt7cdd9yxPH3KlClLo8rAV2yzzTZZfvnlM3v27Nxwww1Jkl/+8pc1ll+c38uV913du3evsp+o7nikNvuj5ZZbLueee24OPvjgJMnpp5+eIUOGZNKkSfnwww+rHdmiun39ku57Ktqp8jyXWWaZdO/ePUn1+9j33nsvH3zwQZLkiy++SL9+/crteN5555XLL2o7fpN9duUyFfbdd98k80aaWGedddKsWbP07Nkzhx12WN56661FqhOwaBx7fHsce8xvcc9nfRMVIyRWtuKKK2bjjTdOMm/U008//TQ333xzefTp//mf/ymXrbxd/vznPy9vk8cdd1x5esU2OWDAgHK7HXrooVl22WXTpk2bbLvttrnxxhuX/MoBAADfqkIGhbbddttMmjQp//jHP/LUU0/lww8/zFVXXVXloLGyygeH9evXLz+vOIn6wAMP5Iknnkgyb4jyK664Ivfff3+uvfbactmKg7Mkueyyy/KXv/wl/fv3T/fu3TNnzpw8+eSTOemkkzJw4MDFWpfqbqv0bRs4cGB5uNnRo0fn1ltvLddr8803Lw9bv7jttCRUNwzuF198kQsvvDDJvO9z1KhRmTBhQiZNmlQ+AV3dCfKlWafKFra9LW3V1W9Rttm6detm7Nix+dOf/pRtttkmXbt2zeeff56HH344RxxxRJXbCFSnYvjvZN5twCpu27ak1qGyyidx6tb9v91gTbc7W5S2r26ZF1xwQfkE2Q477JCxY8dm0qRJ2XvvvctlqtvmO3TosNDlVVhjjTUyefLkHHzwwdlggw3SqlWrvPPOOxk9enS23nrrxRreuya1vU3y/aBvrT0dO3acb9oVV1yRjz/+OEmy0UYbZcyYMZk0aVKOOOKIcpnF6XOX1H5gcebzXRrKfmn0GxW+/PLLhYZpgW+ubt26GTp0aPl148aNq/zhbHEszv7pm+zLlkR/dNZZZ2XSpEl56KGH8sILL+T111+vcsu0s88+u/z8iCOOyPjx4zNp0qQqt+6prr9Y0n1PxX52Se9jkyXbr9e0z66uPU466aRce+21+dnPfpYePXqkTp06ee6553L66adnq622qvYiAmDROPaoPY495lf5fNYDDzyw0PKVlzVnzpzy8/fee2+hn62u/ZP/CwN99tlnGTt2bPm2Y82aNctOO+200PlWVrFNdurUKZMnT86wYcPSp0+ftG3bNh988EHGjRuXn//85+Xb2wMAAN9PhQwKdejQIX369Mkmm2yStdZaK02aNPlG83vjjTfKz/fYY4/svffeC7wndf369fOrX/0qt9xyS1544YV88MEH5Ss/7rrrrnz66adZZZVVyuU322yzlEql+R6ffvpp9ttvv29U9yVh+eWXT58+fZIk77//fg4//PDyexVXWSWL306Lo+Kq3iR57LHHys8r7qtd2fTp0zNz5swk8w7mhw0blr59+2allVaq8R7kFQfxi3pio/L398QTT1Q5CVy5TpXLfZsqL/fRRx8tP58+fXpefPHFJPPWuWLEnEXZZkulUpo3b57DDjssd9xxR1555ZW88847WXHFFZMkN9988wLrtP3226d58+ZJko8++igjRoyotlzFlU01rcNXXy+tNn7//ffzwgsvlF9X/l4rtsfK2/zIkSOz7bbbpk+fPnn77bcXOO/FOUFVKpWy+uqr58wzz8zDDz+cDz/8sHxCaO7cuRkzZkySmtvrmWeeyWeffZZk3km0imAfLC59a+2pbp9Ruf2OOuqoDBgwIH369Clf4fxdVTFyRJL885//LD9//vnny6NGfJ9U3uYuu+yyGre5iiumgaVrn332KQdRdt1117Ru3brGsovze7ni924yb3SCyvur6o5Hvs3+aM0110yfPn2y4YYbpnv37vP1GRX9Rdu2bfPHP/4xm2++edZZZ50q/Uh1vgt9T7t27cp/BG7evHl5pNjKjzlz5uSyyy4rf6ZyEOmrx3bfZJ9d0+/33XffPTfccEOmTJmSGTNmlEfbfeaZZ6od+RRYNI49as93Yf+/pCypY4/K4bArr7wy//rXv+YrM2PGjLz++utJql6EMG3atPLzcePGLXRZNfU3P/vZz8qjmZ9//vm5//77kyQ77bRTmjVrVi5Xebt86aWXqt0ux48fn2Te+aZu3bpl1KhRmTRpUt57770q7bSw83wAAMB3W/2FF2FhunXrVn7+t7/9LX369MkHH3yQI488stry3bt3z6677ppevXplueWWyzvvvJOXX345ybyDsFmzZqVXr15ZY4018swzz+S+++7L3nvvXT7omzp1ah599NGMHj16oQeuFVeSJClfHZXMGxa4Ikzw4x//uLwOQ4YMyRVXXJEkmTBhQvr27btIbbD77rtn0qRJSZLXXnstSdKoUaPsvPPOX7udFkf//v3LAZIDDzwwo0aNysyZM3P00UfPV7Zjx45p3LhxZs6cmaeffjoXXnhhOnbsmJNOOqnGINAyyyyT999/P2+++Wb++te/plu3bunYsWNWXnnlasuvvfbaWW211fLcc8/lrbfeyp577pkhQ4bkkUceyejRo5PMGxp71113/cbrXpN77rmnHIiqbNSoURk0aFDOOuusJMk555yT5ZZbLiuvvHLOOOOM8hWyW2+9dXk46UXZZj/44IP069cvP//5z9OzZ8907NgxL7/8cvlWVgsbLaFNmzY5/vjjy0GzU045Ja+99lp+/vOfp2XLlvnPf/6Tv/71r2nbtm3GjBmTrbbaKm3bts306dPz2GOP5cADD8z222+fsWPHlsNi7dq1W+RbeH0de+yxR4455pi8/vrrOeOMM8rTBwwYkKTqNj9y5MgMHjw4d9xxR+68884lVodTTjklEydOzPbbb5+uXbumWbNmVeZf0e577LFHbr311iTJcccdl0aNGqVdu3b5/e9/Xy5beXQwqG361m+mcvudddZZadiwYR555JFccsklS33Z38ROO+1Uvl3MOeecky5duqRr16458cQTa7lmX88ee+yRM888M0ny29/+Nu+//37WWmutfPjhh3nxxRdz1113pVu3brn00ktruaZQDN26dcu5556badOmlQMbNVnc38sbbLBBHnnkkcycOTO77757Dj744Dz11FPVXm2/pPqjJaFbt27573//m+nTp2fUqFFZa621cuaZZ9Z4AcXC5lXh2+h76tatm0GDBuW8887LJ598kq222ioHH3xw2rVrl9dffz3PPPNMbr755lx66aXlvrfy6BIXXXRRtttuuzRp0iTrr7/+Et9nb7LJJllnnXXSu3fvdO7cOTNmzMizzz5bft9ocvDd4djjmyn6sceQIUNywQUXlC8U7Nu3b/73f/83vXv3zqxZs/LQQw/lkksuyfnnn58uXbpUuY391Vdfne7du+eTTz7JKaec8rXXpW3bttl2221z6623ZsKECeXpXx09cc8998xTTz2VZN7I10cccUS6dOmSt956K1OmTMktt9yS3/3udxkyZEiuvfbaXHDBBdlpp52y4oorplWrVrn33nvL89KPAQDA91ypII4//vhSklKS0uDBgxer/GWXXVaePmHChPnm8+WXX5bWWmut8vSKxyabbFJ+vtlmm5XnUa9evfnKVjy23nrrcrnJkyeXWrduXWPZRfn6Xn755QV+/qvrN3jw4PL0CRMmLHT+Fd55551S/fr1q8x3wIABVcosbjvVVJeKad26dStPe++990qdO3eeb94rr7xytfP+zW9+U23ZDh06VNu2u+6663zlK77/yy67rDzt+OOPL3/mkUceKbVo0aLaNq9Tp07pvPPOK5etbrta0PrWpHKbLWybOeKII2os06lTp9JLL71ULrso2+xrr722wOXut99+C61/qVQqDRs2bIHzqbxdjRkzptSgQYNqyzVo0KB0yy23lMvW9D3V9H99YdtfmzZtSl26dJlvuVtuuWVp7ty5pVJp3jZQp06d+b77jTbaqNplLuy73myzzcplXn755VKpVCqddNJJNbZV3bp1S//4xz9KpVKpNHfu3NLAgQNrLLvqqquW3n///QUua0HtRTHpW5du31oqlarMs/L/xQX1G6VSqfTKK6+UmjZtusD2q7wv7Nat23zrv7h9U03fb3XzXlC7DBgwYL56d+7cudSmTZtF/o4qq7w/q26/Vfn7rLxNLW7/UNN+89hjj13gtrIo/3eAxVf5//CwYcMWWLby/8nPP/+8PH1xfi/ff//91f4urXw8Unm/uzj9UU2/Y2tSeb+7sH7n1FNPnW+57dq1K/Xo0WO+fdq30fdU/j4q9zE17as/+OCD0pprrrnAdqzcBmefffZ871dezuLss2va71fo3r17jfPp2bNn6csvv1zgdwNU5djDscd3+djj9ddfL6277roL/J5Gjx5dLl/5vFDFY7XVVqt2e1vU8zDXX399lfl16NChNHv27CplZs2aVdpiiy0WaXu66qqrFlju2muvXaS2AQAAvpsKeeuxJa1evXr5+9//ngEDBqRVq1Zp3759DjnkkFx88cXVlj/55JOz9dZbp0uXLmnUqFEaNWqUHj165PDDD8+NN95YLrfuuuvmySefzP7775+VVlopDRs2TOvWrbPGGmtk//33Lw8F+13Qvn37bLHFFlWm7b777lVeL247LY62bdvm/vvvzw477JCmTZumTZs2+eUvf1mlPSs77bTTcuihh2bZZZdN8+bN079//4wfP77G4arPOeec/PznP1+s2zL17t07kydPzuDBg9O5c+fUr18/yyyzTLbZZpvcddddOeCAA77Wui4pf/zjH3PDDTdks802S8uWLdOgQYOssMIK+c1vfpPHH3+8yi0UFmWbrRgRaLPNNsuyyy6bBg0apEmTJllrrbUyYsSInH322YtUr1GjRuXRRx/N4MGDs+KKK6Zx48Zp1apV1lhjjfz2t7/NyJEjy2UHDBiQhx56KLvttls6dOiQ+vXrp3379tlll13y4IMPpn///ku20Spp0aJFJk2alB133DHNmjVLmzZtsv/+++fmm28uj8rTu3fvjB49OmuuuWYaN26c1VdfPTfeeGO22mqrJVaP7bbbLvvtt1/WWGONLLPMMqlXr17atGmTrbbaKnfeeWc22WSTJPOGp77mmmtywQUXpHfv3mnWrFkaNWqUVVZZJUceeWQefvjhKldYQ23Tt34zXbt2zV133ZXevXunSZMm6d69e84777z84he/qO2qLdS1116bgw8+OG3btk3Tpk2z/fbb5/777y+P+vdNby3xbTvxxBNz++23Z5tttknbtm3ToEGDdO7cOX369MmoUaOqjOwGfLcszu/lTTfdNGPHjs26666bhg0bplu3bvnjH/+Y4cOHVzvv70p/9Nvf/jYjRoxIt27d0rRp0/Tt2zf33ntvOnXqtNjzqo2+p3Xr1nnooYdy0kknpVevXmnSpEmaNm2alVdeObvttluuvfbabLjhhuXy++23X4YNG5auXbtWuQ1ZhSW5zx4+fHgGDBhQbtuK7Wf//ffPvffem3r16i2RNgC+Occe34xjj6Rz5855+OGHc/HFF6dfv35p165dGjRokOWWWy6bbbZZzj333CrnTf/6179m6623TuPGjcvbW03nMBdV//7907Jly/Lr3XffPfXrV72ZQMOGDTNu3LicddZZ6d27d1q0aJHGjRtnxRVXzPbbb59LLrmkPDr8RhttlEMOOSTrrrtu2rVrl3r16qVVq1bZdNNNc/3118933hcAAPh+qVMqlUq1XQmA74uKEFC3bt0yderU2q0MwA9QqVSa7zaIU6ZMyWqrrZYkWWuttcrD5QMAAHxdjj0AAICiqr/wIgAA8O343//937Rr1y5bbLFFll122Tz33HM5/PDDy+8PHDiwFmsHAAD8UDj2AAAAikpQCACA74zp06fnz3/+c7XvbbrppjnssMO+5RoBAAA/RI49AACAohIUAgDgO2PHHXfM66+/nmeeeSbvv/9+mjRpkp49e2bQoEE54IAD0qBBg9quIgAA8APg2AMAACiqOqVSqVTblQAAAAAAAAAAAJauurVdAQAAAAAAAAAAYOkTFAIAAAAAAAAAgAKoX9sV+LbNnTs3b775Zlq0aJE6derUdnUAvldKpVJmzJiR5ZZbLnXryprqUwC+Pn3K/9GfAHx9+pP/oz8B+Pr0JwAAFEnhgkJvvvlmll9++dquBsD32muvvZYuXbrUdjVqnT4F4JvTp+hPAJYE/Yn+BGBJ0J8AAFAEhQsKtWjRIsm8H/wtW7as5doAfL98/PHHWX755cv70qLTpwB8ffqU/6M/Afj69Cf/55v2J3Pnzs27776b9u3bG01jEWivxafNFo/2WnzfpM30JwAAFEnhgkIVQy+3bNnSSXiAr8kw9vPoUwC+OX2K/gRgSfiu9Sfnn39+zj///EydOjVJsvrqq+e4447LtttuW+NnzjjjjJx//vl59dVX065du+y2224ZOXJkGjduvEjL/Kb9ydy5czNz5sy0bNlSKGERaK/Fp80Wj/ZafEuizb5r/QkAACwNtXqEcf7552ettdYqn8DYaKONcscddyzwMzfeeGNWXXXVNG7cOGuuuWbGjh37LdUWAAAAABauS5cuGTVqVCZPnpzHHnssm2++eQYMGJB///vf1Za/5pprcuSRR+b444/Pc889l0suuSTXX399jjrqqG+55gAAAMAPXa0GhRb3pMmDDz6YQYMGZd99980TTzyRnXbaKTvttFOeeeaZb7nmAAAAAFC9HXfcMdttt11WXnnlrLLKKvnDH/6Q5s2b5+GHH662/IMPPphNNtkke+yxR1ZYYYVstdVWGTRoUB599NFvueYAAADAD12t3npsxx13rPL6D3/4Q84///w8/PDDWX311ecrf+aZZ2abbbbJ4YcfniQ56aSTcvfdd+ecc87JBRdc8K3UGQAAAAAW1Zw5c3LjjTfm008/zUYbbVRtmY033jhXX311Hn300fTu3TsvvfRSxo4dm7322qvG+c6aNSuzZs0qv/7444+TzLv1zty5cxe7nnPnzk2pVPpany0i7bX4tNm8/cHs2bMXqezcuXPzxRdf5LPPPnPrsUW0qG3WoEGD1KtXb77PAgBAUdRqUKiyRTlp8tBDD+Wwww6rMm3rrbfOmDFjapxvTSdNYEn505/+lNtuuy3PP/983n///XTq1Cl9+/bN8ccfn5VWWqnGz33yySc59dRTc/311+eVV17JMssskwEDBuTkk0/OMsssUy43Y8aMHHfccbnxxhvzzjvvZPnll8/ee++do48+OvXrz/9f+Nxzz82BBx6YJOnYsWOmTZu25FcaAAAAWKCnn346G220UWbOnJnmzZtn9OjR6dmzZ7Vl99hjj7z33nvp06dPSqVSvvzyy+y///4LvPXYyJEj8/vf/36+6e+++25mzpy52PWdO3duPvroo5RKJaGERaC9Fl/R2+yLL75Y7HPTc+fOdT57MS1qm7Vs2TINGzYsv54xY8bSrBYAAHyn1HpQaHFOmkybNi0dO3asMm1hQYiaTprAknL22Wfn1VdfTY8ePdKkSZO8/PLLufLKK3PXXXfl+eefT8uWLav93I477piJEyemXr16WX311fPyyy/nggsuyGOPPZaHHnoo9evXz9y5c7PjjjvmvvvuS4MGDbLSSivlv//9b0444YS8+OKLufLKK6vM89lnny2PuAUAAADUnh49euTJJ5/MRx99lJtuuimDBw/OfffdV+15r4kTJ+bkk0/Oeeedlw022CAvvPBCDjnkkJx00kk59thjq53/8OHDq1xQ9/HHH2f55ZdP+/btazwXsSBz585NnTp10r59+0KGOBaX9lp8RW6zOXPm5MUXX0zLli3Trl271KlTZ5E+N3v27DRo0GAp1+6HZWFtViqV8t577+Wzzz7LsssuWx5ZqHHjxt9WFQEAoNbV+hFZxUmTRx55JAcccEAGDx6cZ599donNf/jw4fnoo4/Kj9dee22JzRuS5Je//GWmTp2a5557Li+99FIOPfTQJPOCbePHj6/2M88++2wmTpyYZN4t9Z566qlMnjw5SfLYY4/lhhtuSJKMGTMm9913X5Lk5ptvzpQpU3LGGWckSa666qo8/vjj5Xl+8cUX2WOPPdKkSZNsscUWS2FNAQCA75L//Oc/2XXXXdOxY8c0adIkm266aR566KEkyeuvv55NN9007dq1S8OGDdOpU6fstNNOee6558qf/+ijj/Lb3/42K6ywQho1apTVVlstl19++QKXuSjzfeqpp9KvX7+0atUqderUqfaPoV988UWGDRuWLl26pFGjRunZs+d8F0LA913Dhg3zox/9KOutt15GjhyZXr165cwzz6y27LHHHpu99torv/jFL7Lmmmtm5513zsknn5yRI0fWeDucRo0apWXLllUeSVK3bt2v/ahTp843+nzRHtpLmy3qY86cOSmVSmnfvn2aNm2aJk2aLPTRuHHjKv96LJk2a9q0adq3b59SqZQ5c+ZU+Z4AAKAoav3X7+KcNOnUqVPefvvtKtPefvvtdOrUqcb513TSBJaUo48+Ol27di2/3nTTTcvPGzVqVO1nKp/kqzgIrXwwes899yRJ7rjjjiRJkyZNst122yVJdt1113K5cePGlZ8PHz48Tz31VC666KJ06dLla68PAADw3ffRRx+lX79+ufnmm9OzZ8/suuuueeihh9KvX7+88cYb+fjjj/PZZ59lhx12yJAhQ1K3bt3ccsst2WWXXcrz2GuvvXLGGWekUaNGGTx4cN55550MHTo0o0ePrnG5izLfV199NW+99VbWWWedGudz+OGH55RTTkmDBg2y++6759VXX83gwYNz2223LZkGgu+guXPnZtasWdW+99lnn833R+qKUS5KpdJSrxvw7VjUkYRYunwPAAAUXa0Hhb5qQSdNNtpoo/lGaLn77ruz0UYbfRtVg4WaM2dOLrzwwiTJSiutVOPIPquttlrWWGONJMlBBx2UtddeO+uuu275/TfeeCNJyiNgtW3btnzCsPLt91599dUk84JFp59+en7xi19UOUEPAAD8MD3wwAN57bXX0qxZs9x99925+uqrs8MOO+Szzz7Lqaeemp49e2by5Mm5/PLLc+GFF+bss89Okrz00ksplUr55JNPcvvttydJrrjiilx44YXl2xst6PbdC5tvMu82y//+979z5JFHVjuPd999N3/5y1+SJLfeemuuuOKKjBgxYqHLhu+T4cOH5/7778/UqVPz9NNPZ/jw4Zk4cWL23HPPJMnee++d4cOHl8vvuOOOOf/883Pdddfl5Zdfzt13351jjz02O+64YzkwBAAAALAk1K/NhQ8fPjzbbrttunbtmhkzZuSaa67JxIkTc+eddyaZd9Kkc+fOGTlyZJLkkEMOyWabbZY//elP2X777XPdddflscceKwczoDZ9+umnGTRoUO6888506tQpt912W40jCtWrVy933HFHjjzyyNxzzz156aWX8pOf/CRTpkzJiy++uND7aH91uYMHD84qq6xS42hcAADAD0vjxo2TJDNnzszTTz+drl275oUXXkiSPPHEE+Vyhx56aD799NOMHTs2devWzdFHH506deqkQYMGqV+/fmbPnp3HHnssvXr1ypNPPpkkeeaZZ/Lll1+mfv2aTxnUNN9F8e9//zuzZs1K48aNs+aaayZJNtxwwyTzbls2Z84cwQi+9955553svffeeeutt9KqVaustdZaufPOO7PlllsmmXfhT+URhI455pjUqVMnxxxzTN544420b98+O+64Y/7whz/U1ioAP3AVtx5t0qRJPv/88wwdOrQc8p06dWpWXHHF7LPPPrnkkkuSJJ988klatGhRPjfZt2/fPP3003nppZfSqlWrJMluu+1WHnWwsrXXXjvJvFuPPv/88+X+v0ePHrn++usXqb633nprJkyYkNNPP/2brjoAABRerQaFFvekycYbb5xrrrkmxxxzTI466qisvPLKGTNmTHlkFqgt06ZNyw477JDJkydnlVVWyR133JGVVlppgZ/p0qVLrr766vLrmTNnlm+j16NHjyTJ8ssvnyR57733Mnfu3NStWzfvvPNO+TNdu3bNu+++mzfffDMNGjRIhw4dkqQ8Ktc777yT5s2b57rrrssOO+yw5FYYasG5556bU089NdOmTUuvXr1y9tlnp3fv3tWWvfnmm3PyySfnhRdeyOzZs7Pyyivnd7/7Xfbaa69ymVKplOOPPz4XXXRRPvzww2yyySY5//zzs/LKK39bqwQA8LX95Cc/Sd++fTNx4sQqo5Mm845PKlS+mGCVVVYpj8jbqFGjHHHEEfnDH/6Qgw46KAcddFC53Jw5c/Luu+9m2WWXrXH5Nc13UVTUr3nz5uVpFc+//PLLvPfee1VGUoXvo4o/rNdk4sSJVV7Xr18/xx9/fI4//vilWCvgO2X2zJrfq1M3qddg0cvWb/i1qnD99ddn7bXXzhtvvJGePXtm8803L59radq0ae644448++yz6dmzZ7Wfb9myZUaNGlW+0LcmFWHkqVOnZu211y6/rmxhIeX+/funf//+i7ZiAADAAtVqUGhxT5okyc9+9rP87Gc/W0o1gsX373//O9tvv31eeeWVbLrpphkzZkzatGlTpcwWW2yRN954IzvvvHP5wPnxxx/PyiuvnBYtWmTOnDk5/PDD89FHHyVJBg4cmCTZZpttcvHFF2fmzJkZO3Zsdthhh/ztb38rz3ebbbYpP589e3Zmz55dZbmlUimffvppvvzyy6Wy7vBtuf7663PYYYflggsuyAYbbJAzzjgjW2+9dZ5//vlyQK6yNm3a5Oijj86qq66ahg0b5vbbb8/QoUPToUOHbL311kmSU045JWeddVauuOKKrLjiijn22GOz9dZb59lnny1foQ8A8F1Vv3793HPPPbnpppvy9NNPp127dnnzzTdz6qmnVvl9VCqVMmPGjFx55ZU58MADs+OOO+bll1/OsssumxEjRmSrrbbKxIkTU7du3XTp0iVDhw5N/fr1s8wyyyxw+Qua78JUXCDxySeflKfNmDGjvF7t2rX7Ok0CAN8vNw6u+b3l1kk2G/Z/r2/+ZTLni+rLdlgt6XfCN6pK586ds+qqq+aVV14pB4UaNGiQ4cOHZ/jw4bnllluq/dywYcNy3HHH5aCDDspyyy232MtdYYUVMnDgwEyYMCErr7xy/vSnP2XQoEH5+OOPM3PmzPz0pz/NWWedlbp16+byyy/PmDFjMmbMmEycODEHHnhgfvKTn+SBBx7Il19+mSuuuCLrrbfeN2oHAAAoiroLLwIsyC677JJXXnklybyT29ttt1023HDDbLjhhrn44ouTJC+++GKef/75vPXWW+XPXXrppenQoUPWXHPNdOrUKeecc06SeUP4VxyQ77TTTunTp095OauttloOPfTQJMkee+yRddddNyussEJKpVKVx+DB8040dOzYMaVSKTvttNO30RSw1Pz5z3/OL3/5ywwdOjQ9e/bMBRdckKZNm+bSSy+ttnzfvn2z8847Z7XVVkv37t1zyCGHZK211so//vGPJPP+sHXGGWfkmGOOyYABA7LWWmvlyiuvzJtvvpkxY8Z8i2sGAPD1zZkzJwMHDsyIESOy33775fbbb0+SbLnllvn444/L5Vq0aJGdd945ybzRR//zn/8kmXf7j5/85Cc57rjjcswxx+S+++5Lkmy66aY1BqcXZb4Ls/rqq6dhw4bl26YlycMPP5wkWWuttdx2DAC+ZVOmTMn06dPTt2/fKtP333//PPPMM3nggQeq/VynTp2y3377faPR0KZPn55HHnkkf/3rX9O6devcdtttmTx5cv71r39l6tSpueGGG2qs8+DBg/PUU0/loIMOytFHH/216wAAAEVTqyMKwQ9BxW2+ksw3bG7lEX++qnfv3pkwYUJeeumllEqlrLfeejnggAOy7777lsvUq1cvf//733PsscfmpptuyosvvpiuXbtm7733zjHHHLPE1wW+i7744otMnjw5w4cPL0+rW7du+vXrl4ceemihny+VSrn33nvz/PPP549//GOS5OWXX860adPSr1+/crlWrVplgw02yEMPPZTdd9+92nnNmjWryv/5yn8oAwD4tu2www5p2rRp2rdvnwkTJuTFF1/MSiutlIMPPjjHH398xo8fn3XXXTcNGjTIXXfdlSRp165d1llnnSTJiBEjcv/996dHjx55+umn89BDD6Vx48YZNWpUeRkrrLBCXnnllVx22WUZMmTIIs13ypQpGTVqVN54443yfIYMGZIkOe2009K+ffv86le/yjnnnJP+/ftns802y0033ZQkOfbYY5d6uwHAd8LPrqj5vTpfub53l4sWvexiGDhwYOrWrZvnn38+p59+etq3b1/l/QYNGuSkk07KsGHDMm7cuGrncfjhh6dHjx6ZMmXK16rDkCFDUqdOnSTJ3LlzM2zYsPzjH/9IqVTKO++8kzXWWKPa8zQ/+tGPssEGGyRJNtpoo5x22mlfa/kAAFBEgkLwDU2dOvVrldl7772z9957L/SzLVu2zJlnnpkzzzxzket0+eWX5/LLL1/k8vBd9t5772XOnDnp2LFjlekdO3Zc4Emojz76KJ07d86sWbNSr169nHfeedlyyy2TJNOmTSvP46vzrHivOiNHjszvf//7r7sqAABLVK9evXL11VfnvffeS5s2bTJ06NCcfPLJad26dX784x9n4sSJufnmm/PFF1+kY8eOGTJkSI488si0bNkySbLaaqvlmmuuycMPP5yGDRtmm222yUknnZT111+/vIxSqZRk3i3BkizSfKdNm5Yrrqj6x8+K1yeccELatWuX0047LY0bN85f//rXXHPNNenevXuOOOIIo6ECUBwNFnLb8//fBy9S2a/p+uuvz9prr5177rknO+64YzbffPOsueaaVcoMGjQop556ao23H2vZsmWGDRuW4cOHf61RAZs3b15+/uc//znvvPNOHnnkkTRu3DiHHXZYZs6cWe3nKo9+WK9evXz55ZeLvWwAACgqQSEAfpBatGiRJ598Mp988knGjx+fww47LCuttNJ8w2gvjuHDh+ewww4rv/7444+z/PLLL4HaAgAsvlNPPTWnnnpqte/tscce2WOPPRb4+UGDBmXQoEE1vv/ee+/l9ddfz6qrrppdd911kefbt2/fcsCoJo0aNVpg/QGAb0+/fv1ywAEH5JhjjpkvEFSnTp2MGjUq+++/f42fP+CAA8oXOe6www5fux4ffPBBOnXqlMaNG2fatGm58cYby79BAACAJUdQCIDvtHbt2qVevXp5++23q0x/++2306lTpxo/V7du3fzoRz9Kkqy99tp57rnnMnLkyPTt27f8ubfffjvLLrtslXmuvfbaNc6zUaNGadSo0TdYGwCA74+777479erVy9VXX50mTZrUdnWApWxuaW7e+uytdEiH2q4KUAuOPfbY/OhHP8rkyZPTtm3bKu9tvfXWWWmllWocWb1Ro0Y58cQTF2n09AU55JBDsttuu2X11VfPcsstV+WW8QAAwJIjKATAd1rDhg2z3nrrZfz48eVbUcydOzfjx4/PgQceuMjzmTt3bmbNmpUkWXHFFdOpU6eMHz++HAz6+OOP88gjj+SAAw5Y0qsAAPC9tLARh4Afjo9mfZSzHz87b370ZkYuNzKtGreq7SoBS9lXQz/LLLNMpk+fXn794YcfVnl//PjxVV5PnDixyuu99tore+211wKXucIKK1SZ71fr0LVr1zz66KPVfnbIkCEZMmRIknmjFz755JPl99ZYY41MnTp1oSMaAgAA8wgKUQhrXrHmwgvxtT09+OnargI/cIcddlgGDx6c9ddfP717984ZZ5yRTz/9NEOHDk2S7L333uncuXNGjhyZJBk5cmTWX3/9dO/ePbNmzcrYsWNz1VVX5fzzz08yb9jsQw89NCNGjMjKK6+cFVdcMccee2yWW265chgJqqM/Wbr0J0CR6FOWHv0JLL6WDVumQb0GmT13du6cemd+vurPa7tKAAAAwFIiKATAd97AgQPz7rvv5rjjjsu0adOy9tprZ9y4cenYsWOS5NVXX03dunXL5T/99NP8+te/zuuvv54mTZpk1VVXzdVXX52BAweWyxxxxBH59NNP86tf/Soffvhh+vTpk3HjxqVx48bf+voBAADUpjp16qT/Sv3z5/f+nH+8+Y9s0W2LtG3SduEfBAAAAL53BIUA+F448MADa7zV2FeHux4xYkRGjBixwPnVqVMnJ554Yk488cQlVUUAAIDvrR5teqR7i+55bdZruf2l2zN49cG1XSUAAABgKai78CIAAAAAwA9dv+X6JUkem/ZY3vjkjVquDQAAALA0CAoBAAAAAOnSrEvW6bBOSinlthdvq+3qAAAAAEuBoBAAAAAAkCTZfqXtU6dOnXw2+7N8MeeL2q4OAAAAsIQJCgEAAAAASZKOTTvmyN5H5rfr/TYN6zWs7eoAS8kKK6yQHj16ZO21106PHj0yatSo8ntTp05NnTp1su+++5anffLJJ6lTp075dd++fdO2bdt89NFH5Wm77bZbLr/88vmWtd122+Wcc86Zb3qvXr1y880311jHyy+/PDvttNNirhkAALAwgkIAAAAAQFnn5p2rBAKAH6brr78+Tz75ZO69996MHDkyjz76aPm9pk2b5o477sizzz5b4+dbtmxZJWBUk3333TeXXXZZlWmPPfZY3nrrrey4445ffwUAAICvRVAIAAAAAJjPZ7M/y/hXx2duaW5tVwVYijp37pxVV101r7zySnlagwYNMnz48AwfPrzGzw0bNiyXXHJJ3nzzzQXOv3///nnttdfyr3/9qzzt0ksvzd57753p06fnpz/9adZbb72svvrqOfDAAzN3rn0OAAAsTfVruwIAAAAAwHfL3NLcnPLPU/Le5++lRYMW6b1s79quEvxw/GWz5JN3FlqsfkpJvsboXs07JPvdt8jFp0yZkunTp6dv375Vpu+///4544wz8sADD6RXr17zfa5Tp07Zb7/9cvzxx+eiiy6qcf4NGjTIXnvtlUsvvTRnnHFGZs6cmWuvvTYPPvhgWrdundtuuy3NmzfPnDlzMmDAgNxwww3ZfffdF7n+AADA4hEUAgAAAACqqFunbjZebuPc+uKtuf2l/8fefYdXVaV9H/+e9EA6aZRAgITQCU2aFOkiJYgoyEgRxRFRiqMMDjAUkWID1BcVRCww0psgSJEqRAiEJiVAQgmEQEhIgdRz3j/ycMYMBHLCCaH8Pte1H85ee6173Xvr+JCTe6/1M/X86mFno68SRawiNR5S7rwKz/3Y/O+FF17AxsaG48eP8+mnn+Lj45Pnur29PRMnTmTkyJGsW7futjHeeecdQkJCOHbs2B3nGjhwIC1btmTatGksW7aMatWqUa1aNa5fv87IkSPZsWMHJpOJ+Ph4atasqUIhEREREZEipJ/uRURERERERERE5BatAlqx9fxWrqZfZUfsDloFtCrulEQeDS6+d+1iMv9fg+VFQwWID7Bw4UJCQ0PZuHEjXbp0oXXr1tSqVStPn969e/Phhx+ycuXK28Zwc3Nj5MiRjBo1Cltb23znql69OkFBQaxevZq5c+cycOBAAD755BPi4+MJDw/HycmJESNGkJ6eXsAbFRERERGRwlChkIiIiIiIiIiIiNzCwdaBpys+zU/HfmJdzDoal26Mk51Tcacl8vAryLZgJhPZ2dnY2dmBoWjXF2rbti2vv/46o0ePvqUgyGAwMGXKFP7+97/nO/71119nxowZAHTu3DnffgMHDuSDDz4gKiqKFStWAJCYmIi/vz9OTk7ExcWxePFievToce83JSIiIiIi+bIp7gRERERERERERETkwdS4dGO8nb1JzUzlt3O/FXc6IlJExowZw44dO4iIiLjlWocOHahUqVK+Yx0dHZkwYQIxMTF3nOOFF17g+PHj9OzZExcXFwCGDh1KeHg4NWrU4KWXXqJt27b3dB8iIiIiInJ3WlFIREREREREREREbsvOxo4ulbvw7eFv2XhmI0+WfRJXB9fiTktE7tH/FvV4enqSkJBgPk9KSspzfdOmTXnOt2zZkuf8pZde4qWXXrrjnK6urqSmpuZpK1++PH/88cdt+/fv35/+/fvfMaaIiIiIiFhOKwqJiIiIiIiIiIhIvur51qOCWwXq+dUr7lRERERERERE5B5pRSERERERERERERHJl8FgYHj94djZ6KtEERERERERkYedVhQSERERERERERGRO1KRkIiIiIiIiMijQYVCIiIiIiIiIiIiUiBxaXHMOTSHi6kXizsVERERERERESkEFQqJiIiIiIiIiIhIgfx8+mci4yNZdWpVcaciIiIiIiIiIoWgQiEREREREREREREpkM6VOmPAwKErhzh97XRxpyMiIiIiIiIiFlKhkIiIiIiIiIiIiBSIf0l/GpdpDMCqk6swmUzFnJGIiIiIiIiIWEKFQiIiIiIiIiIiIlJgnSp2ws7GjpNJJ/nz6p/FnY6IFEJgYCCRkZG3tB86dIjWrVtTp04datasScOGDTl8+DBjx44lNDSU0NBQXFxcqFixovn8+PHjtGrVCgcHB+Lj482xTp8+jY2NDWFhYbfM88orr5jHOzg4EBISYj5PSUkp0D1cuHCB5s2bF/YRiIiIiIg8tuyKOwERERERERERERF5eHg6edKyXEs2nd3EqpOrqO5VHYPBUNxpiTxUMnIy8r1mgw12NnYF7mtva2+1vHr37s3EiRPp3r07AOfOncPR0ZEJEyYwYcIEAFq1asWwYcNuKQCqXbs2P/zwA2+//TYAc+fOpX79+redZ86cOebPgYGBLFy4kNDQ0Dx9srOzsbPL/1cYZcqUYfv27ZbeooiIiIjIY0+FQiIiIiIiIiIiImKR9oHt2XlhJ7GpseyL30d9v9sXA4jI7b295e18r9UoVYO/1/m7+XzU9lFk5mTetm+QRxDD6g+zWl7nz5+nbNmy5vOAgIACj+3Xrx+zZ8/m7bffxmg0snDhQgYPHszWrVsLHKN///7Y2Nhw8uRJ4uPjOXbsGH369OH48eNkZmYSEBDAN998g7+/PzExMYSGhpKUlASAjY0NEyZMYPXq1Vy+fJmxY8cyYMCAAs8tIiIiIvK4UKGQiIiIiIiIiIiIWKSkfUk6V+pMljGL2t61izsdEbGSMWPG8NRTT9G4cWMaN27Mc889R926dQs0NiAgAH9/f8LDw0lMTKRBgwZ4enpanENERAQ7duzA1dUVgOnTp+Pj4wPAlClTGDduHF9++eVtxzo6OhIeHs7x48dp2LAhL7300h1XJRIREREReRzpb8giIiIiIiIiIiJisVYBrYo7BZGH1setPs73mg02ec4nN59c4L736u233+Zvf/sbmzdvZtu2bTRv3pxvvvmGF154oUDjX375Zb755hsSExMZNGgQsbGxFufQs2dPc5EQwIIFC/jhhx9IT08nPT0db2/vfMf27t0bgKpVq2JnZ0dcXBzlypWzOAcRERERkUeZdX+KEBERERERERERkceO0WQky5hV3GmIPDQcbR3zPext7Qvd1xr8/Pzo3bs3s2bNYvTo0cyfP7/AY8PCwli/fj0HDhygTZs2hZrfxcXF/HnHjh3MnDmTtWvXcvjwYT755BPS09PzHevk5GT+bGtrS3Z2dqFyEBERERF5lGlFIRERERERERERESm041ePs+TEEur716djYMfiTkdE7sHy5cvp3Lkz9vb2ZGdnc/DgQSpXrlzg8U5OTnz66aeUKFECG5t7f085MTERV1dXSpUqRWZmJl999dU9xxQRERERedxpRSEREREREREREREptJTMFC6mXWTjmY2kZaUVdzoiUkAdOnSgXLly5uP8+fMsW7aMmjVrUrt2berUqYOjoyPjx4+3KO6zzz5Lx47WKRrs2LEjISEhhISE0Lx5c0JDQ60SV0RERETkcaYVhURERERERERERKTQ6vvVZ+PZjZxPOc+vMb/SPbh7cackIncRExNz2/YffvjhrmO3bNlSoDaA/v37079//wLnMm/evDzX7O3tWbhwYZ62SZMmARAYGEhSUpK53Wg05tlq7MqVK3ecV0RERETkcaUVhURERERERERERKxo1qxZ1K5dGzc3N9zc3GjSpAm//PLLHcckJSXxxhtvULp0aRwdHalSpQpr1669TxnfG4PBQJfKXQDYen4riemJxZyRiIiIiIiIiORHhUIiIiIiIiIiIiJWVK5cOaZMmUJERAR79+6ldevWdOvWjSNHjty2f2ZmJu3atSMmJoYlS5Zw/PhxZs+eTdmyZe9z5oVX3as6QR5BZBuzWRv9cBQ4iYiIiIiIiDyOtPWYiIiIiIiIiIiIFXXp0iXP+aRJk5g1axa7d++mRo0at/SfO3cuV69e5ffff8fe3h7I3VLnfjNl5xR6rMFgoFtQNz7e+zG7L+ymTfk2+Jf0t2J2IiIiIiIiImINKhQSEREREREREREpIjk5OSxevJi0tDSaNGly2z6rVq2iSZMmvPHGG6xcuRIfHx9efPFFRo4cia2t7W3HZGRkkJGRYT5PTk4GwGg0YjQaLcrRmJFB8po1XA//g5wJ48HR0aLxN1VwrUAt71ocvHyQ8Avh5u3IHkVGoxGTyWTxs36cPc7P7Oa93zwK6mZfS8Y87gryzG7+c/jrfy8fx38vRUREROTxpUIhERERERERERERKzt06BBNmjQhPT0dFxcXli9fTvXq1W/b9/Tp02zevJk+ffqwdu1aTp48yeDBg8nKyuLf//73bcdMnjyZ8ePH39J++fJl0tPTLcrVlJFJ2vYdZCUkELt8OU6tW1s0/q+aujelimMVqrpUJT4+vtBxHnRGo5Fr165hMpmwsbEp7nQeCo/zM8vKysJoNJKdnU12dnaBxphMJnJyclf5MhgMRZneI6Ogzyw7Oxuj0UhCQoJ5FbeUlJT7kqOIiIiIyINAhUIiIiIiIiIiIiJWFhISQmRkJNeuXWPJkiX069ePrVu33rZYyGg04uvry9dff42trS3169cnNjaWDz/8MN9CoVGjRjFixAjzeXJyMgEBAfj4+ODm5mZxvqm9XuDS119ju2s3pTp2xNbDw+IYAL74Fmrcw8ZoNGIwGPDx8Xnsil4K63F+Zunp6aSkpGBnZ4ednWVfyd8sZJGCu9szs7Ozw8bGhlKlSuHk5ARg/lNERERE5HGgQiERERERERERERErc3BwICgoCID69euzZ88eZsyYwVdffXVL39KlS2Nvb59nm7Fq1aoRFxdHZmYmDg4Ot4xxdHTE8TZbhNnY2BSqCKPkE09gu349prg4kleuotSA/hbH+F/Xs66TnJmMf0n/e471IDIYDIV+3o+rx/WZ2djYYDAYzEdBmEwmc9+iWFEoMDCQFStWEBoamqf90KFDDB06lISEBHJycnB2dubbb79l0aJFrFq1CoCTJ0/i4+ODu7s7AAsXLuS1117j999/5/z58/j65hYMnj59mqCgILp27cqKFSvyzDNt2jT++OMPlixZkqd96NChmEwmZs6cedu8Y2JiCA0NJSkp6ZZrBX1mN/85/PXfxcft30kRERERebzpb78iIiIiIiIiIiJFzGg0kpGRcdtrzZo14+TJkxiNRnPbiRMnKF269G2LhIqCwWDAsXNnAK6Hh5NxOvqe4p1IPMG4XeOYd2QeJpPJGimKyH3Qu3dv3nzzTQ4cOMDhw4dZtmwZvr6+TJgwgcjISCIjI2nQoAGffvqp+TwkJASA2rVr88MPP5hjzZ07l/r16992nr59+/LLL7+QkJBgbsvMzGT+/PkMHDiwaG9SREREROQxp0IhEXnsfPzxx7Rq1YrSpUvj6OhIhQoV6NevH6dPn77juHHjxuV5++uvx8395VNSUhg2bBj169fH29sbZ2dnqlSpwpgxY/Ld63z//v04OjqaYx07dszq9ywiIiIiIiL3z6hRo9i2bRsxMTEcOnSIUaNGsWXLFvr06QPk/oJ81KhR5v6vv/46V69eZejQoZw4cYI1a9bwwQcf8MYbb9zXvG3LlaNkkyYAJC1adE8FPmVKliHHmMP5lPPsi99nrRRFpIidP3+esmXLms8DAgLMKwTdTb9+/fjuu++A3OLIhQsX8uKLL962r7+/P+3atePHH380t61YsYLAwEDq1KlDnz59aNCgAbVr1+aZZ54hLi7uHu5KRERERET+SluPichj57PPPuPs2bOEhITg7OxMdHQ033//Pb/++ivHjx/Hzc3tjuO9vb2pXLlynrabyxknJCQwY8YMHB0dqVq1KrGxsURFRfH+++8TERHB2rVr84y7ceMGL774IpmZmda9SRERERERESk28fHx9O3bl4sXL+Lu7k7t2rVZv3497dq1A+Ds2bN5trkJCAhg/fr1DB8+nNq1a1O2bFmGDh3KyJEj73vubl27cmPffrIuXCAr9gIO5crefdBtuDi40LZCW9acXsPqU6up41MHOxt9FSkC8MLPL3DlxpW7dzQBhdh1zNvZm4WdF1o+EBgzZgxPPfUUjRs3pnHjxjz33HPUrVu3QGMDAgLw9/cnPDycxMREGjRogKenZ779Bw4cyJgxYxg6dCiQuwLRzdWEpk+fjo+PDwBTpkxh3LhxfPnll4W6JxERERERyUs/nYvIY+fVV1/lpZdeonz58gAMHz6c6dOnExcXx6ZNm+jevfsdxz/zzDPMmzfvttecnJz48MMPee2113B1dSU9PZ2nnnqK3bt388svv5CYmJjnC5IRI0Zw7NgxevbsyeLFi612jyIiIiIiIlJ8vvnmmzte37Jlyy1tTZo0Yffu3UWUUcHZurtT6pWB2Jcrh90dfsFfEK3Lt2br+a1cuXGFXRd20bxccytlKfJwu3LjCvHX44s7jdt6++23+dvf/sbmzZvZtm0bzZs355tvvuGFF14o0PiXX36Zb775hsTERAYNGkRsbGy+fTt16sRrr73Gvn378PX1ZefOnSxcmFvgtGDBAn744QfS09NJT0/H29vbKvcnIiIiIiLaekxEHkP/+te/zEVCAM2b//eLSkdHx7uOX7p0Kc7OzpQuXZrOnTuzf/9+8zV/f3/+8Y9/4OrqCuQWDjVs2BAAGxsb7Oz+W5+5evVqvvzyS9588006dep0z/clIiIiIiIiYg3OtWrdc5EQgKOtI08HPg3AL9G/kJmj1XRFIHfFH98Svnc/nAvQ5zaHt/O9FdX4+fnRu3dvZs2axejRo5k/f36Bx4aFhbF+/XoOHDhAmzZt7tjX1taWfv368e233zJv3jzCwsJwd3dnx44dzJw5k7Vr13L48GE++eQT0tPT7+meRERERETkv7SikIg81nJycvj6668BqFSpUoG+wPD398fOzo5jx46xZs0aNm7cyK5du267DHN8fDxLly4FoFevXuYCori4OAYOHEitWrWYNm0aP/30k5XvTEREREREROTepR8/gV0pL+wKuZpHs7LN2HR2E1fTr/Lbud/oENjByhmKPHwKsi2YyWQiOzsbOzs785b398Py5cvp3Lkz9vb2ZGdnc/DgQSpXrlzg8U5OTnz66aeUKFEizxaL+Xn55Zdp0qQJ7u7u5tXYEhMTcXV1pVSpUmRmZvLVV18V+n5ERERERORWWlFIRB5baWlpdO/enfXr1+Pv78/q1avvuKLQiy++SHx8PFFRURw9epR169YBkJGRwRdffHFL/1OnTvHkk09y4cIFmjVrlmcf9ddee42UlBQWLFiAk5OT9W9ORERERERE5B4lr1vH5U8/JWnJ0kLHsLOxo3OlzhgwkJKZYsXsRORedejQgXLlypmP8+fPs2zZMmrWrEnt2rWpU6cOjo6OjB8/3qK4zz77LB07dixQ3+DgYGrUqIHBYKBly5YAdOzYkZCQEEJCQmjevDmhoaGW3pqIiIiIiNyBVhQSkcdSXFwcnTt3JiIigipVqvDLL79QqVKlO46pUqVKnvMOHTpQqlQpEhISOHv2bJ5ru3btomvXrly5coUuXbrw008/UaJECfP1AwcOkJmZSePGjQHIzs42X6tfvz5Dhgxh6tSp93qbIiIiIiIiIoXmXKsW11at5kZkJOnHjuFUtWqh4jT0b0gFtwr4lfSzcoYiUlgxMTG3bf/hhx/uOnbLli0FagPo378//fv3v2O8rVu35jm3t7dn4cK8qy5NmjQJgMDAQJKSku6ao4iIiIiI5E8rConIY+fIkSM0btyYiIgImjdvzq5du24pEmrTpg1Vq1Zl1KhR5rapU6fmKQjasGEDCQkJQO6XFDctWbKE1q1bc+XKFd58801WrFiRp0joJqPRSFpaGmlpaWRkZJjbr1+/nudcREREREREpDjYly2LS4sWACQtWowpJ6dQcQwGg4qERERERERERB4QKhQSkcfOs88+y5kzZwBISUmhU6dONG7cmMaNGzNnzhwgd9uw48ePc/HiRfO4WbNmERgYSIUKFahevTodOnQAoGTJkgwbNgyACxcu8Pzzz5Oeno6DgwN//PEHTZs2Ncfft28fkPvWlslkMh/ffvuteZ6jR48yffr0+/AkRERERERERO7MrXNnbEqWJOvCBdJ27LjneJfSLrEzdqcVMhMRERERERGRwtDWYyLy2Pnraj2RkZF5rt1p//T33nuPxYsXc+TIEU6fPk2FChVo1qwZY8aMISQkBIDMzExMJpP5c3h4eJ4YycnJVroLERERERERkaJn61ISty6dSfppIddWrca5fgNsXUoWKtaVG1d4P/x9AII8grTKkIiIiIiIiEgxUKGQiDx28tuD/W59Bg0axKBBg+44LjAw0FwoZImC7NcuIiIiIiIiUhxcmjcnbds2si5cJHnNGjxfeL5QcbydvalRqgaHrxxm9enVvFLrFStnKiIiIiIiIiJ3o63HREREREREREREJF8GW1s8nn8eW09PHIMq31OsLpW7YMBAZHwkZ5LPWClDERERERERESkoFQqJiIiIiIiIiIjIHTlVrUrpCeMpUb/+PcUp61KWhv4NAVh5cqU1UhMRERERERERCxTr1mOTJ09m2bJlHDt2DGdnZ5o2bcrUqVMJCQnJd8y8efMYMGBAnjZHR0fS09OLOl0RuY+OVq1W3Ck80qodO1rcKYiIiIiIiMhDxmBvb/5sMpkwGAyFivNMpWeIuBTBicQTHLt6jKpeVa2VooiIiIiIiIjcRbGuKLR161beeOMNdu/ezYYNG8jKyqJ9+/akpaXdcZybmxsXL140H2fOaJliERERERERERGRomYymUjduZPLH3+MKSurUDFKOZeiebnmQO6qQiaTyZopikgBZGVlMX78eKpWrUqNGjWoW7cuYWFhREZGArBlyxacnZ0JDQ2ldu3aNGrUiN27d5vH9+/fn+nTp+eJOW7cOIYNG3bLXKGhoYSGhlK9enVsbW3N5y+88EKB8121ahXDhw8vzK2KiIiIiMj/KNYVhdatW5fnfN68efj6+hIREUGLFi3yHWcwGPD39y/q9EREREREREREROQvTBkZJK9aRc61ZFJ++w239u0LFadDYAci4yOp61uXHFMOdoZi/ZpS5L4zZmTke81gMMBfVvC6W1+Dg4PF8w8YMIDU1FR27dqFp6cnABs3buT48eOEhoYCEBISYi4c+vzzz3n55Zf5888/LZ7rZoyYmBhCQ0PN53+VnZ2NnV3+/x3o2rUrXbt2tXhuERERERG5VbGuKPS/rl27BoCXl9cd+6WmplKhQgUCAgLo1q0bR44cybdvRkYGycnJeQ4REREREXlw5eTkMGbMGCpWrIizszOVK1dm4sSJeVYbMJlMjB07ltKlS+Ps7Ezbtm2JiorKE+fq1av06dMHNzc3PDw8GDhwIKmpqXn6HDx4kObNm+Pk5ERAQADTpk27JZ/FixdTtWpVnJycqFWrFmvXrs1zvSC5iIiIPCpsnJxwDwsDIHntL+QU8rs2VwdXxjcdT/vA9tjZqEhIHj+xQ4fle1z5enaevhfeeTffvpc/+9ziuaOioli+fDlz5841FwkBtG3bNt9Vftq0aWP1lf0DAwMZOXIkTzzxBP369SMuLo6nnnqK+vXrU6NGDYYMGYLRaARyXzIO+7//9mzZsoWaNWsyePBg6tSpQ40aNdi7d69VcxMREREReZQ9MIVCRqORYcOG0axZM2rWrJlvv5CQEObOncvKlSv58ccfMRqNNG3alPPnz9+2/+TJk3F3dzcfAQEBRXULIiIiIiJiBVOnTmXWrFl8/vnnHD16lKlTpzJt2jQ+++wzc59p06Yxc+ZMvvzyS8LDwylZsiQdOnQgPT3d3KdPnz4cOXKEDRs28PPPP7Nt2zYGDRpkvp6cnEz79u2pUKECERERfPjhh4wbN46vv/7a3Of333+nd+/eDBw4kP379xMWFkZYWBiHDx+2KBcREZGHQgG3ACvRuDEOFSpgSk/n2oqVhZ7O1sa20GNFpPD2799PUFDQXV/Y/aslS5bQq1cvq+eSkJBAeHg48+fPx8PDg9WrVxMREcHBgweJiYlh0aJFtx137Ngx+vXrx4EDB3jzzTf517/+ZfXcREREREQeVQ/M6zpvvPEGhw8fZseOHXfs16RJE5o0aWI+b9q0KdWqVeOrr75i4sSJt/QfNWoUI0aMMJ8nJyerWEhERERE5AH2+++/061bN5555hkg903j//znP/zxxx9A7go+06dPZ/To0XTr1g2A77//Hj8/P1asWEGvXr04evQo69atY8+ePTRo0ACAzz77jE6dOvHRRx9RpkwZ5s+fT2ZmJnPnzsXBwYEaNWoQGRnJJ598Yi4omjFjBh07duSdd94BYOLEiWzYsIHPP/+cL7/8skC5iIiIPPBuJELkT7hePAbdPrlrd4PBgMcLzxM/7UPSdu3CpWULHCpUKNTUJpOJPxP+ZOv5rbxS6xUcbC3fQknkYVR2xvR8rxkMhjznZT68ddXL/PoWxqlTp+jRowc3btygadOmfPvttwDmbcji4uLIzs4mPDz8rvNamk///v3NY4xGIyNHjmTHjh2YTCbi4+OpWbPmbf9OHRQURKNGjYDc3xl89NFHFs0rIiIiIvI4eyBWFBoyZAg///wzv/32G+XKlbNorL29PXXr1uXkyZO3ve7o6Iibm1ueQ0REREREHlxNmzZl06ZNnDhxAoADBw6wY8cOnn76aQCio6OJi4ujbdu25jHu7u40atSIXbt2AbBr1y48PDzMRUKQu5WCjY2N+Rccu3btokWLFjg4/PcXkh06dOD48eMkJiaa+/x1npt9bs5TkFz+l7ZHFhGRB46tA4azu7C9dgbijxRoiGOlSpR44gkwmUhctCjPFqGWyDHlsPD4QnOxkMjjwsbRMd/D4OBQ6L4FcfP79Jt/561cuTKRkZGMGjXK3Aa5q/tHRkZy7tw5unfvTp8+fcz/W/fx8SEhISFP3CtXruDr62tRLi4uLubPn3zyCfHx8YSHh3Pw4EFefPHFfFfpdHJyMn+2tbUlOzvbonlFRERERB5nxVooZDKZGDJkCMuXL2fz5s1UrFjR4hg5OTkcOnSI0qVLF0GGIiLyoPjiiy8IDAzEycmJRo0amVeVuJ3Zs2fTvHlzPD098fT0pG3btrf0v/nG2l+Pjh07FvVtiIhIAfzzn/+kV69eVK1a1fxiwLBhw+jTpw8AcXFxAPj5+eUZ5+fnZ74WFxd3yy8p7Ozs8PLyytPndjH+Okd+ff56/W65/C9tjywiIg8ch5KYAp/M/Rz1a4GHuXcPw+DgQOap02RGRxdqajsbO56plLuK4K8xv3I963qh4ohIwQUHB9OtWzcGDhxIUlKSuT0tLe22/e3t7ZkxYwbnz59nxYoVQG7x/OLFi7l69SoAFy9eZOXKlbRr167QeSUmJuLv74+TkxNxcXEsXry40LFERERERCR/xVoo9MYbb/Djjz+yYMECXF1diYuLIy4ujhs3bpj79O3bl1GjRpnPJ0yYwK+//srp06fZt28ff/vb3zhz5gyvvPJKcdyCiIjcBwsXLmTEiBH8+9//Zt++fdSpU4cOHToQHx9/2/5btmyhd+/e/Pbbb+zatYuAgADat29PbGxsnn4dO3bk4sWL5uM///nP/bgdERG5i0WLFjF//nwWLFjAvn37+O677/joo4/47rvvijs1qxg1ahTXrl0zH+fOnSvulERERCC4PQCG83shLeEunXPZeXri+WJvfN99F8dKlQo9dUP/hpQuWZob2TfYcGZDoeOISMHNmzePWrVq0ahRI2rUqMGTTz7Jxo0bGTly5G37lyhRgkmTJjFu3DhMJhNt2rThrbfe4qmnniI0NJROnToxadKkPCt6Wmro0KGEh4dTo0YNXnrppVtW9hQREREREeuwK87JZ82aBUCrVq3ytH/77bf0798fgLNnz2Jj8996psTERF599VXi4uLw9PSkfv36/P7771SvXv1+pS0iIvfZJ598wquvvsqAAQMA+PLLL1mzZg1z587ln//85y3958+fn+d8zpw5LF26lE2bNtG3b19zu6OjI/7+/kWbvIiIWOydd94xryoEUKtWLc6cOcPkyZPp16+f+b/dly5dyrOy6KVLlwgNDQXA39//loLS7Oxsrl69ah7v7+/PpUuX8vS5eX63Pn+9frdc/pejoyOOjo4FexgiIiL3i0d5sr2CcUw9A6c2Qe3nCzSsZOPG9zy1jcGGrpW78tXBr9hybgutAlrh7uh+z3FFJH8ODg6MHz+e8ePH3/Z6q1atiIyMzNPWr18/+vXrZz4fPHgwgwcPLvCcgYGBeVYwiomJyXO9fPny+a4g3b9/f/PvDP43t5o1axITE1PoLRBFRERERB43xb712O2Om3/hh9xVIebNm2c+//TTTzlz5gwZGRnExcWxZs0a6tate/+TFxGR+yIzM5OIiIg8b5HZ2NjQtm1bdu3aVaAY169fJysrCy8vrzztW7ZswdfXl5CQEF5//XUSEu781mxGRgbJycl5DhERsb7r16/neVkAwNbWFqPRCEDFihXx9/dn06ZN5uvJycmEh4fTpEkTAJo0aUJSUhIRERHmPps3b8ZoNNKoUSNzn23btpGVlWXus2HDBkJCQvD09DT3+es8N/vcnKcguYiIiDwsMsq3zP1wciPkZFs8PvvyZbITEws1d03vmlRyr0SWMYu10WsLFUNERERERERE7q5YC4VERETu5sqVK+Tk5ODn55en3c/Pj7i4uALFGDlyJGXKlMlTbNSxY0e+//57Nm3axNSpU9m6dStPP/00OTk5+caZPHky7u7u5iMgIKBwNyUiInfUpUsXJk2axJo1a4iJiWH58uV88skndO/eHQCDwcCwYcN4//33WbVqFYcOHaJv376UKVOGsLAwAKpVq0bHjh159dVX+eOPP9i5cydDhgyhV69elClTBoAXX3wRBwcHBg4cyJEjR1i4cCEzZsxgxIgR5lyGDh3KunXr+Pjjjzl27Bjjxo1j7969DBkypMC5iIiIPCyy/ELB2RPSr8G5cIvGpv3+OxfHj+fasmWFmttgMNC1clcAfr/wO1duXClUHBERERERERG5s2LdekxERKSoTZkyhZ9++oktW7bg5ORkbr+5nQ3kbmlTu3ZtKleuzJYtW2jTps1tY40aNSrPL4+Tk5NVLCQiUgQ+++wzxowZw+DBg4mPj6dMmTK89tprjB071tzn3XffJS0tjUGDBpGUlMSTTz7JunXr8vy3fv78+QwZMoQ2bdpgY2NDjx49mDlzpvm6u7s7v/76K2+88Qb169fH29ubsWPHMmjQIHOfpk2bsmDBAkaPHs17771HcHAwK1asoGbNmhblIiIi8lCwscNUrSuG7BvgW82iofYBAZBj5Pqevbi0aIFjcLDF0wd5BtEyoCXBHsGUcipl8XgRERERERERuTsVComIyAPN29sbW1tbLl26lKf90qVL+Pv733HsRx99xJQpU9i4cSO1a9e+Y99KlSrh7e3NyZMn8y0UcnR0xNHR0bIbEBERi7m6ujJ9+nSmT5+ebx+DwcCECROYMGFCvn28vLxYsGDBHeeqXbs227dvv2Ofnj170rNnz3vKRURE5KER8jTYWL4IuUNAACWbNSNtxw4SFy/Gb9QoDAaDxXF6Vsn//+eKiIiIiIiIyL3T1mMiIvJAc3BwoH79+mzatMncZjQa2bRpE02aNMl33LRp05g4cSLr1q2jQYMGd53n/PnzJCQkULp0aavkLSIiIiIi8rhx79YVg7MTWWfPkfb77/ccLzMn0wpZiYiIiIiIiMhfqVBIREQeeCNGjGD27Nl89913HD16lNdff520tDQGDBgAQN++fRk1apS5/9SpUxkzZgxz584lMDCQuLg44uLiSE1NBSA1NZV33nmH3bt3ExMTw6ZNm+jWrRtBQUF06NChWO5RRERERETkgWEywbk9sGUqZKYVeJitqyvuzzwDwLUVKzHeuFHoFLae28ronaM5fvV4oWOIiIiIiIiIyK1UKCQiIg+8F154gY8++oixY8cSGhpKZGQk69atw8/PD4CzZ89y8eJFc/9Zs2aRmZnJc889R+nSpc3HRx99BICtrS0HDx6ka9euVKlShYEDB1K/fn22b9+urcVEREREREQADv4EF/bB6S0WDXNp1Qo7Pz+MKSkkr/2l0NNfun6J61nXWXVqFSaTqdBxROT2srKyGD9+PFWrVqVGjRrUrVuXsLAwIiMjAdiyZQvOzs6EhoZSu3ZtGjVqxO7du83j+/fvf8tWwePGjWPYsGG3zNWpUyc+//zzW9rr1KnDsmXL8s1x3rx5hIWFFeb2RERERETkDuyKOwEREZGCGDJkCEOGDLnttS1btuQ5j4mJuWMsZ2dn1q9fb6XMREREREREHjEGA1TpCHvmQNSvENIpt60gQ+3s8HjuORK+/hqbkiUKnULHih3ZfXE3Z5LPcODyAUJ9QwsdS0RuNWDAAFJTU9m1axeenp4AbNy4kePHjxMaGgpASEiIuXDo888/5+WXX+bPP/+0eK6BAwfywQcf5PleZ+/evVy8eJEuXbrc872IiIiIiIhltKKQiIiIiIiIiIiI5BXYHOydISUO4g5ZNNS5Vk1KfzAJt44dCz29m4Mbrcu3BmDVqVXkGHMKHUtE8oqKimL58uXMnTvXXCQE0LZtW1544YXbjmnTpg1nzpwp1Hxdu3bl3LlzHDx40Nw2d+5c+vbtS0JCAk899RT169enRo0aDBkyBKPRWKh5RERERESkYLSikIiIiIiIiIiIiORl7wQVW8KJdXBiPZSubdFwW1fXe06hTfk2bDu/jfjr8YTHhdO0TNN7jinyIIju8RzZV67ctZ/JZMJQwNW8/srO25uKS5fke33//v0EBQXh5eVV4JhLliyhV69eFucCYG9vz0svvcTcuXOZPn066enp/Oc//+H333/Hw8OD1atX4+LiQk5ODt26dWPRokWFnktERERERO5OhUIiIiIiIiIiIiJyq+D2uYVCsRGQdgVKelscIv3ECdK2bcOrf38MdpZ9Fels50zHwI4si1rGmtNraOjXEHtbe4tzEHnQZF+5QvalS8WdhtmpU6fo0aMHN27coGnTpnz77bcA5m3I4uLiyM7OJjw83DwmvwKm/NoHDhxIy5YtmTZtGsuWLaNatWpUq1aN69evM3LkSHbs2IHJZCI+Pp6aNWuqUEhEREREpAipUEhERERERERERERu5V4W/GrCpcMQtQFCe1s03JiZScLXszGmpuJQqTKurZ+yOIXmZZuz+exmrmVc43jicWp617Q4hsiDxs67YEV397Ki0J3UrVuXkydPkpiYiKenJ5UrVyYyMpJ58+axYsUKc7+QkBAiIyPJyspi8ODB9OnTh127dmEwGPDx8SEhISFP3CtXrlC2bNnbzlm9enWCgoJYvXo1c+fOZeDAgQB88sknxMfHEx4ejpOTEyNGjCA9Pd3iexYRERERkYJToZCIiIiIiIiIiIjcXpUOkHUDvCpaPNTGwQH3bl1JnL+A5J9XU+KJhti6uFgUw97Wnr9V/xuuDq6Udbl9AYLIw+ZO24LdZDKZyM7Oxs7OrlDFQncSHBxMt27dGDhwIHPnzsXDwwOAtLS02/a3t7dnxowZVKlShRUrVtC9e3c6dOjAG2+8wfDhw/Hy8uLixYusXLmS5cuX5zvvwIED+eCDD4iKijIXJCUmJuLv74+TkxNxcXEsXryYHj16WPV+RUREREQkLxUKiYiIiIiIiIiIyO2VawgBTxR6eMlmzUjdspWs2FiSV6/Gs7dlqxIBVPWqWuj5ReT25s2bx6RJk2jUqBF2dnZ4enri4+PDyJEjb9u/RIkSTJo0iXHjxhEWFkabNm146623eOqppzAYDBgMBiZNmkSDBg3ynfOFF15g2LBhvPDCC7j8X9Hg0KFDee6556hRowZlypShbdu2RXK/IiIiIiLyXyoUEhERERERERERkdu7x5VMDDY2eDz/PJc//ZTUbdsp2bwFDuUKvzLQpbRLONs74+bgdk95iTzuHBwcGD9+POPHj7/t9VatWhEZGZmnrV+/fvTr1898PnjwYAYPHlzgOV1dXUlNTc3TVr58ef7444/b9u/fvz/9+/cvcHwRERERESkYFQqJiIgUl3HuxZ3Bo2vcteLOQERERETk0ZKZBqe3gl918Ay0aKhTSBWc69Xjxr59JC1ejM+woYXaSmnT2U2sOLmCJ8s8yQtVX7B4vIiIiIiIiIiATXEnICIiIiIiIiIiIg+4iO9g33dwbG2hhnv0eBaDvR0Zx4+TcexYoWKUdy2PyWRi54WdXL5+uVAxRERERERERB53KhQSERERERERERGxolmzZlG7dm3c3Nxwc3OjSZMm/PLLLwUa+9NPP2EwGAgLCyvaJC0V1Cb3z7O/Q0aKxcPtSpXCPSwMrwEDcKxatVApBHsGU71UdYwmIz+f/rlQMUREREREREQedyoUEhERERERERERsaJy5coxZcoUIiIi2Lt3L61bt6Zbt24cOXLkjuNiYmL4xz/+QfPmze9TphbwrpK75VhOFpz6rVAhXNu0oWSjJwq17dhNXSp3ASDiUgTnUs4VOo5IcTCZTMWdgqB/DiIiIiIidsWdgIiIiIiIiIiIyKOkS5cuec4nTZrErFmz2L17NzVq1LjtmJycHPr06cP48ePZvn07SUlJ9yFTCxgMUKUDhH8FUb9C1c5gU/h3EI3p6Ziyc7B1KWnRuADXAOr71SfiUgSrT61mcOjgQucgcr/Y29tjMBi4fPkyPj4+BSqWM5lMZGdnY2dnd0/FdY+Tgjwzk8nE5cuXMRgM2Nvb3+cMRUREREQeDCoUEhERERERERERKSI5OTksXryYtLQ0mjRpkm+/CRMm4Ovry8CBA9m+fftd42ZkZJCRkWE+T05OBsBoNGI0Gi3O02g0YjKZ7jw2oAmGfT9Aajym2H1Qtp7F8wCkHzlC4g8/4li9Gl59+1o8vlNgJ/Zf2s+RK0c4nnCcYM/gQuVxLwr0vCSPx/mZGQwGypYtS2xsLNHR0QUeZzQasbmHgrzHUUGemY2NDWXLlsVgMJj/fXwc/70UERERkceXCoVERERERERERESs7NChQzRp0oT09HRcXFxYvnw51atXv23fHTt28M033xAZGVng+JMnT2b8+PG3tF++fJn09HSL8zUajVy7dg2TyXTHX7I7e9fDMWYT2ZHLSbUvZ/E8ADnp6dy4fJkbWy+TUaMGtgEBFseo5VqLA4kHiI6Lxj3LvVB53IuCPi/5Lz0zcHNzIycnp0B9TSYTKSkpuLi4aEWhAiroM7O1tSUtLY20tDRzW0pKyv1IUURERETkgaBCIRERERERERERESsLCQkhMjKSa9eusWTJEvr168fWrVtvKRZKSUnhpZdeYvbs2Xh7exc4/qhRoxgxYoT5PDk5mYCAAHx8fHBzc7M4X6PRiMFgwMfH585FHM49MMTtwsGjFCW8S4GNrcVz4evL1ZYtuL57N7abNuPzzj8sLoTo5dmLXvSipL1lW5dZS4Gfl5jpmVnGaDSatyrT8yqYe3lmTk5ORZSViIiIiMiDR4VCIiIiIiIiIiIiVubg4EBQUBAA9evXZ8+ePcyYMYOvvvoqT79Tp04RExNDly5dzG03t8Cxs7Pj+PHjVK5c+Zb4jo6OODo63tJuY2NT6KICg8Fw9/HuZeDZrzA4uhZqjps8w8JI3x9JVkwM6Xv2UrJxI4vGu97j/NZQoOcleeiZWUbPy3KFfWZ6xiIiIiLyONHffh8gH3/8Ma1ataJ06dI4OjpSoUIF+vXrx+nTp+84btu2bXTq1AkfHx8MBgMGg4Evv/wyT5958+aZr93u2LJlCwCtWrXKt09gYGAR3bmIiIiIiIjIoy0mJibfn7dbtWoFwIULF+jVqxeenp44OzvTsmVLwsPDzTGys7MZPXo0wcHBODs74+npyZNPPsn69evvOPfevXvp0KEDpUqVwsXFhU6dOnHs2DHz9Rs3bvDss89StmzZW74n+Kt58+ZRvXp1HB0dKVeuHP/85z/JysqyyvN5HBiNRjIyMm5pr1q1KocOHSIyMtJ8dO3alaeeeorIyEgCCrEtV5GzQpGOrYcHbk93BODa8uUYb/NsCsJkMnEk4QiHLh+655xEREREREREHgdaUegB8tlnn3H27FlCQkJwdnYmOjqa77//nl9//ZXjx4/nu2z0vn372LBhA5UqVeLKlSu37ePj40OjRnnfzDp79iwXL14EwN/fH4Dq1avfso99REQE2dnZlC5d+l5vUUREREREROSx5ObmxtChQ/O0/fDDD1y9epUqVapgMpl45plniIyMpHHjxpQpU4Zly5bRpk0boqKiKF26NJ9++imTJk3C0dGR3r17ExUVxc6dO+natSvnzp3D19f3lnljYmJo06YNycnJdOnSBTs7O5YvX05kZCRRUVGULFmSzMxM9u7dS8OGDVm5cuVt81++fDkDBgzAxcWFXr16sW3bNqZOnUpWVhYff/xxkTyzh9moUaN4+umnKV++PCkpKSxYsIAtW7aYi7r69u1L2bJlmTx5Mk5OTtSsWTPPeA8PD4Bb2h84yRcgMw28gws13LV1a1J37CDnSgIp69bh3q2bxTH2XtrLd0e+w8PRg6peVbG3tS9ULiIiIiIiIiKPC60o9AB59dVXiYmJ4ejRo5w+fZphw4YBEBcXx6ZNm/Id99JLL5GcnHzHNwifeeYZdu/enee4ue99u3btqFq1KgD/7//9vzx9vvjiC7KzswF48803rXSnIiIiIiIiIo8XLy8vpk+fbj4GDRpEYmIiBoOB4cOHs3r1aiIjI/H392fbtm0sXbqUbt26kZaWZi7EiYqKAnJ/xv/2229ZtmwZAJmZmVy4cOG2865du5bk5GRCQkJYtWoVy5Yto06dOly8eJHZs2cD4O7uztmzZ/npp5/yzX/ixIkAfPDBB3z33XcsX74cgC+++CLfl5YeZ/Hx8fTt25eQkBDatGnDnj17WL9+Pe3atQPyvrz10IrZCT8Phz3fgMlUqBAGBwc8evQAIOdaMqZCxAn1CcXD0YOkjCS2xW4rVB4iIiIiIiIijxOtKPQA+de//pXnvHnz5kyfPh3gtnvO31SqVCmL51q3bh2HDuUuyfzOO+/k2+/DDz8EoHz58jz//PMWzyMiIiIiIiIit/rkk08wmUx06dKFatWqsXDhQgBCQ0Oxt89dEaVx48asXLmSffv2ATBo0CCWLFnCmjVrGDBggLlw6KWXXiI0NPS28zg5OQG5hSsxMTHY2tqai4r2799foFyzs7M5ePAgAE888YQ5T0dHRzIyMvjzzz9p0aJFIZ7Co+ubb7654/Xbbe32V/PmzbNeMkXFvxbY2EFiNCScLPSqQs6hofiNHo1DubKFGm9va0+nSp1YcHQB62PW06R0E0rYlyhULBEREREREZHHgVYUekDl5OTw9ddfA1CpUiXatGlj1fg3C4Dq1Kljfpvtf8XExLBkyRIAhg0bhp2d6spERERERERE7tWlS5f48ccfgf++vBMXFweAi4uLud/NzzdXnqlevTrdu3cnIyODefPmsXPnTsqVK0fXrl3znatnz55Uq1aNxMREKlasSPny5bl8+XKeOe/mypUr5OTk3DU/ecw4uUGFZrmfT+S/yvXdGAyGQhcJ3dTIvxF+Jfy4nnWdzec231MsERERERERkUedCoUeQGlpaXTv3p3169fj7+/P6tWr77iikKX279/P5s25X5r84x//yLffp59+Sk5ODh4eHrz66qtWm19ERERERETkcfbZZ5+RkZFBo0aNaN68OQD+/v4ApKammvulpKQAULp0aQDGjBnD3LlzadasGVevXiU8PJwLFy7w/PPPc+TIkdvO5erqyr59+5g7dy6jRo3iyy+/5KWXXgLA19e3QPl6e3tja2t7S343P9/MTx5DVTrk/nl2F6Rfu+dw2QkJJC1dislotGicrY0tXSp3AWDz2c0kZybfcy4iIiIiIiIijyoVCj1g4uLiaNmyJatXr6ZKlSrs3LmT6tWrW3WOjz76CICAgAB69ep12z6JiYnMnTsXgL///e953hgUERERERERkcK5fv06s2bNAvJuBV63bl0g9+WerKwsAHbv3p3n2vHjxwGoUaMGnp6e1KtXD2dnZ0wmE8eOHct3ThsbGwYMGMAHH3zAs88+y7p16wDyXWH4f9nZ2VGrVi0A/vjjD3OeGRkZODo6Wv17C3mIlKoMXpXBmA2n7m0lH1N2NvHTPiRlw0bSdu60eHwdnzqUdytPZk4m66LX3VMuIiIiIiIiIo8yFQo9QI4cOULjxo2JiIigefPm7Nq1i0qVKuXp06ZNG6pWrcqoUaMKNcfZs2dZtGgRAEOHDs13O7FZs2aRmpqKg4MDb731VqHmEhEREREREZG8vv32W65evUpQUBDdu3c3t3fp0oXatWtz6dIlWrZsSY8ePVi1ahUlSpTg7bffBqBly5YAfPfdd/Tv3582bdqQlpaGs7MzTzzxBAD9+/fHYDDQv39/c+x69erx/PPP8/LLL1O7dm0uX75Mo0aN6N27t7lP//7986wmPGXKFPr378+OHTsAGD16NADvvfce/fv359lnnwXg9ddfx9vbuwielDw0qrTP/TNqIxhzCh3GYGeHa4fcFYqurViJMS3NsvEGA90qd8O3hC9VPKsUOg8RERERERGRR50KhR4gzz77LGfOnAFylxfv1KkTjRs3pnHjxsyZMweAU6dOcfz4cS5evGget2zZMoKCgmjVqpW5bezYsQQFBdGnT588c0yfPp3s7Gzc3d0ZNGjQbfPIzMzks88+A6BPnz5aQlxERERERETECoxGI9OnTwdg+PDh2Nj892sZGxsb1qxZQ8+ePTly5Ahr167lySefZOPGjZQpUwaAt99+m4kTJxIYGMiiRYs4dOgQLVu25OeffyYgIAAAk8kEkOfFoDp16vDbb7/xww8/YGdnx7Bhw9iwYQP29vbmPt999x0//vij+Xz9+vV89913nDx5EoAePXowZ84cypUrx4IFC8jMzOSdd95h6tSpRfOw5OFRvik4uED2DUi5ePf+d+DSojl2pf0xpqVxbe1ai8eHeIUwuvFoQn1D7ykPERERERERkUfZ7ZeTkWKRkZFh/hwZGZnnWseOHfMdl5yczKlTp/K0Xb58mcuXL1OuXDlz27Vr18wFR4MGDcLV1fW28X788Ufi4uIwGAzmtxZFRERERERE5N7Y2NgQFRWV7/Vy5cqZVwHOb/zo0aPNq/vczv79+3F2dmbEiBHmtvnz5981t5sFRncycOBABg4ceNd+8pixc4Cn3gP3cmDneE+hDHZ2eD7/PJdnzCR1y1ZcmjfH3t/fohg2Br0XKSIiIiIiInInKhR6gMTExBSqT//+/fMsKZ4fd3d3kpOT79rv5Zdf5uWXX75rPxERERERERF5cFy8eJFDhw4xc+ZMqlevXtzpyOOkVGWrhXKqVg3nOrW5ceAgSYuX4PPmEItjZBmz2HF+B+dTz/NS9ZeslpuIiIiIiIjIo0CFQiIiIiIiIiIij4DSpUsXaGUgkSJjMkFKHLjd2zb27j16cOPIEdKPHOHG4SM416xh0fjE9ESWnVyGyWSiSekmBHkG3VM+IiIiIiIiIo8SFQqJiIiIiIiIiNzF0arVijuFR1q1Y0eLOwW5V2kJsHkipCdB2Jdg71ToUPa+vrh16ACAY7DlRT6+JXxpWqYpO2N3surUKobXH47BYCh0PiIiIiIiIiKPEm3aLSIiIiIiIiIiIvemhBeYjJB1A2J23HM49y5dcO/SBRtHx0KN71SxE/Y29py+dprDVw7fcz4iIiIiIiIijwqtKFQY49yLO4NH17hrxZ2BiIiIiIiIiIhYymCAKh1g3/cQtR6C2uS2WYHJZMKUmWlR0ZC7ozutAlqx4cwGVp1aRQ3vGtgY9M6kiIiIiIiIiH46FhERERERERERkXtXsSXY2kPSWbh8zCohM8+cIX7KFJIWL7F4bLsK7ShhV4KLaRfZG7fXKvmIiIiIiIiIPOxUKCQiIiIiIiIiIiL3ztEFApvnfj6x3iohTVlZZJ45S9rOnWSeO2fR2BL2JWgX2A6ANdFrMJqMVslJRERERERE5GGmQiERERERERERERGxjuD2uX+e+wOuX73ncI5BQZRo2ABMJpIWLcZkMlk0vmW5ljzh/wSv1npVW4+JiIiIiIiIoEIhERERERERERERsRaviuBdBUw5cHa3VUK6d++Owd6ejKgobuzbZ9FYB1sH+tboSznXclbJRURERERERORhp0IhERERERERERERsZ46vaH1GAh52irh7Ly8cO3QAYCkpcswZWYWOlZ6drpVchIRERERERF5WKlQSERERERERERERKzHrzr41wSDwWohXdu3w9bTk5yrV0nesMHi8Zk5mSw8tpCxO8eSkplitbxEREREREREHjYqFBIREREREREREZGikZNllTA2Dg54PNsdgIwTUZhMJovG29vYE5Mcw/Xs66yPWW+VnEREREREREQeRioUEhEREREREREREesymWD/fFj+GiSdtUpI5wYN8B78Oj7DhmKwcLUig8FAt6BuAGw/v52EGwlWyUlERERERETkYaNCIREREREREREREbEugwFS4yAzDaJ+tVJIA861a1tcJHRTVa+qhHiFkGPKYc3pNVbJSURERERERORho0IhERERERERERERsb7gDrl/Rm+DzOtWDW3MyCBl828Wb0HWtXJXAPbE7eFC6gWr5iQiIiIiIiLyMFChkIiIiIiIiIiIiFifXw1wKwvZGbnFQlZiMhq5NGUKSYsWcX33bovGVnCrQKhvKCZMrDq1ymo5iYiIiIiIiDwsVCgkIiIiIiIiIiIi1mcwQHD73M9Rv4KFq//kG9bGhpJNmwKQtHw5xhs3LBrfpVIXDAYDJ5NOci3jmlVyEhEREREREXlYqFBIRERERETu2XfffceaNWvM5++++y4eHh40bdqUM2fOFGNmIiIiUqwqtgA7R0iOhUtHrBbW9amnsPP1xZicQvK69RaN9Svpx4AaAxjXZBzuju5Wy0lERERERETkYaBCIRERERERuWcffPABzs7OAOzatYsvvviCadOm4e3tzfDhw4s5OxERESk2DiVyi4UAoiwr6LkTg50dHs/1ACBl00ay4uMtGl/Prx4uDi5Wy0dERERERETkYaFCIRERERERuWfnzp0jKCgIgBUrVtCjRw8GDRrE5MmT2b59ezFnJyIiIsUquAOEdII6L1o1rFOtWjhVrwbZOVxburRQMUwmE1GJUZistC2aiIiIiIiIyINOhUIiIiIiInLPXFxcSEhIAODXX3+lXbt2ADg5OXHjxo3iTE1ERESKm0cA1O8HbqWtGtZgMODRsyfY2HDjwEHSjx61OMY3h79hxr4Z7InbY9XcRERERERERB5UKhQSEREREZF71q5dO1555RVeeeUVTpw4QadOnQA4cuQIgYGBxZuciIiIPLLsS5fGpWVLSjRsgJ2fn8XjA1wDAPj59M9kG7OtnZ6IiIiIiIjIA0eFQiIiIiIics+++OILmjZtyuXLl1m6dCmlSpUCICIigt69exdzdiIiIvJAuHwctn8MZ3ZZNazH8z0pNXAgdl5eFo99KuAp3B3duZp+lZ2xO62al4iIiIiIiMiDyK64ExARERERkYdbdnY2M2fOZOTIkZQrVy7PtfHjxxdTViIiImKJG9n3YavQuENw7g+4kQQVmlgtrMFgyHNuMpluacuPg60DHQM7svD4Qn6J+YXGZRrjaOtotdxEREREREREHjRaUUhERERERO6JnZ0d06ZNIztb23WIiIg8jPbE7eHpZU/za+yvmEymopuocmsw2MKVE5AYY/Xw2YmJJHzzDUkLF1k0rkmZJng7e5Oamcrms5utnpeIiIiIiIjIg6RYC4UmT55Mw4YNcXV1xdfXl7CwMI4fP37XcYsXL6Zq1ao4OTlRq1Yt1q5dex+yFRERERGR/LRp04atW7cWdxoiIiJioaycLN7f/T6JGYl8ePhDXtnwCqeTThfNZCW8IKBh7ucTv1o9fHZ8PNf37CV12zayYmMLPM7Oxo4ulbsAsPHMRlIzU62em4iIiIiIiMiDolgLhbZu3cobb7zB7t272bBhA1lZWbRv3560tLR8x/z+++/07t2bgQMHsn//fsLCwggLC+Pw4cP3MXMREREREfmrp59+mn/+85/84x//4D//+Q+rVq3Kc4iIiMiD6UbODap4VjGf7720lx6rezBz30zSs9OtP2Fwh9w/Y7ZDhnULcpxCQnCuWxeMRhIXL7ZodaR6vvUo51oON0c3EjMSrZqXiIiIiIiIyIPErjgnX7duXZ7zefPm4evrS0REBC1atLjtmBkzZtCxY0feeecdACZOnMiGDRv4/PPP+fLLL4s8ZxERERERudXgwYMB+OSTT265ZjAYyMnJud8piYiISAG4ObjxYcsP6VqpKxN3TeTijYtkG7OZfWg2v0T/wujGo2lWtpn1JvStBu4BcO0cRG+Fqs9YLzbg8Wx30g8fIuPYcdIPHsS5Tp0CjTMYDLxW+zVcHVyxsynWr0xFREREREREilSxrij0v65duwaAl5dXvn127dpF27Zt87R16NCBXbt23bZ/RkYGycnJeQ4REREREbEuo9GY76EiIRERkQdfs7LNmN1sNq/WfNVcKHM+9Tx/3/h3/rH1H8Rfj7fORAYDVOmY+/nEerBg1Z+CsPPxwaVNGwCSlizFlJVV4LGeTp4qEhIREREREZFH3gNTKGQ0Ghk2bBjNmjWjZs2a+faLi4vDz88vT5ufnx9xcXG37T958mTc3d3NR0BAgFXzFhERERGRvNLTi2CbEhERESlyjraODKk7hKVdltLAr4G5fX3Merqt6MaCowvIMVqhADjwSSgVBCFPgzXi/Q+3jh2xdXcn+/JlUjb/ZvH4LGMWW85tIS7t9t83ioiIiIiIiDzMHphCoTfeeIPDhw/z008/WTXuqFGjuHbtmvk4d+6cVeOLiIiIiAjk5OQwceJEypYti4uLC6dPnwZgzJgxfPPNN8WcnYiIiFiikkcl5naYy/vN3sfD0QOA1KxUJv8xmT5r+/Bnwp/3NoG9E3SYlFsoZGv9FXxsnJxw7x4GQNrvv2MyGi0av/TEUpacWMKqU6usnpuIiIiIiIhIcXsgCoWGDBnCzz//zG+//Ua5cuXu2Nff359Lly7labt06RL+/v637e/o6Iibm1ueQ0REHj5ffPEFgYGBODk50ahRI/744498+86ePZvmzZvj6emJp6cnbdu2vaW/yWRi7NixlC5dGmdnZ9q2bUtUVFRR34aIyCNr0qRJzJs3j2nTpuHg4GBur1mzJnPmzCnGzERERKQwDAYD3YK6sTpsNc8GP2tuP5JwhN5rejPljymkZqYWY4Z3VqJRIzx6vYDfe6Mw2Fj2FWirgFYYMHDw8kGir0UXUYYiIiIiIiIixaNYC4VMJhNDhgxh+fLlbN68mYoVK951TJMmTdi0aVOetg0bNtCkSZOiSlNERIrZwoULGTFiBP/+97/Zt28fderUoUOHDsTHx9+2/5YtW+jduze//fYbu3btIiAggPbt2xMbG2vuM23aNGbOnMmXX35JeHg4JUuWpEOHDtouR0SkkL7//nu+/vpr+vTpg62trbm9Tp06HDt2rBgzExERuf9mzZpF7dq1zS+tNWnShF9++SXf/gV52aG4eDh5ML7peL7r+B1BHkEAGE1G5h+dT7cV3fg15ldMJlPhgmdnwuktELXBegn/H4PBgGurVtg4Olo81r+kP43LNAZg5cmVhb8/ERERERERkQdQsRYKvfHGG/z4448sWLAAV1dX4uLiiIuL48aNG+Y+ffv2ZdSoUebzoUOHsm7dOj7++GOOHTvGuHHj2Lt3L0OGDCmOWxARkfvgk08+4dVXX2XAgAFUr16dL7/8khIlSjB37tzb9p8/fz6DBw8mNDSUqlWrMmfOHIxGo7nQ1GQyMX36dEaPHk23bt2oXbs233//PRcuXGDFihX55pGRkUFycnKeQ0REcsXGxhIUFHRLu9FoJCsrqxgyEhERKT7lypVjypQpREREsHfvXlq3bk23bt04cuTIbfsX5GWH4lbPrx6LOi9iWL1hONk6ARB/I563t77NG5ve4HzKecuDxh2E3bPgwE+5RUNFxGQycePgQYsKfjpV7ISdjR0nk07y59V73GpNRERERERE5AFSrIVCs2bN4tq1a7Rq1YrSpUubj4ULF5r7nD17losXL5rPmzZtyoIFC/j666+pU6cOS5YsYcWKFdSsWbM4bkFERIpYZmYmERERtG3b1txmY2ND27Zt2bVrV4FiXL9+naysLLy8vACIjo4mLi4uT0x3d3caNWp0x5iTJ0/G3d3dfAQEBBTyrkREHj3Vq1dn+/btt7QvWbKEunXrFkNGIiIixadLly506tSJ4OBgqlSpwqRJk3BxcWH37t237X+3lx0eFPa29gysNZDl3ZbTvGxzc/v22O10X9mdOYfmkJVjQYFwmbpQohRkpsLZgv18ZymTycTl6TO48v9mcWPv3gKP83TypGW5lgCsPrVaqwqJiIiIiIjII8OuOCcvyA/YW7ZsuaWtZ8+e9OzZswgyEhGRB82VK1fIycnBz88vT7ufn1+Bt7IZOXIkZcqUMRcGxcXFmWP8b8yb125n1KhRjBgxwnyenJysYiERkf8zduxY+vXrR2xsLEajkWXLlnH8+HG+//57fv755+JOT0REpNjk5OSwePFi0tLSaNKkSYHG/O/LDreTkZFBRkaG+fzmiqdGoxGj0WhxnkajEZPJVKCxZUqW4bOnPmPT2U1M2TOFyzcuk56Tzox9M/j51M+MbjSaen71CjCrASq3wXBwIZxYjymw+d2HFIJDlSqkHz9G4tJlONSsWeDtyNqWb8uO2B2cSz7H3ri91Perb75myfOSXHpmltHzsty9PDM9ZxERERF5nBRroZCIiEhRmzJlCj/99BNbtmzBycnpnmI5OjriWMAvlEVEHjfdunVj9erVTJgwgZIlSzJ27Fjq1avH6tWradeuXXGnJyIict8dOnSIJk2akJ6ejouLC8uXL6d69eoFGvu/LzvczuTJkxk/fvwt7ZcvXyY9Pd3ifI1GI9euXcNkMmFjU7BFyGs712ZO0znMi5rHyrMrMWLk1LVTDPh1AB3LduSVKq/g7uB+xxgGt9q4Zy2Ai3+ScuIPcjwCLc79bky1a5G1aSOZly4Ru2QJjhb83aShe0POpp3FPt2e+Ph4c3thntfjTs/MMnpelruXZ5aSklJEWYmIiIiIPHhUKCQiIg80b29vbG1tuXTpUp72S5cu4e/vf8exH330EVOmTGHjxo3Url3b3H5z3KVLlyhdunSemKGhodZLXkTkMdO8eXM2bNhQ3GmIiIg8EEJCQoiMjOTatWssWbKEfv36sXXr1rsWCxX0ZYf8Vjz18fHBzc3N4nyNRiMGgwEfHx+Lf8E+rsw4Xkh4gYnhEzmScASAdbHr2H1lNyPqj6Brpa4YDIZ8RvtCcEsMMTtwuBoBVZ6wOPeCuNGnDwmzZ2P44w+8OnbErlSpAo3r6dPztrnfy/N6XOmZWUbPy3L38szu9eUyEREREZGHiQqFRETkgebg4ED9+vXZtGkTYWFhQO4XP5s2bWLIkCH5jps2bRqTJk1i/fr1NGjQIM+1ihUr4u/vz6ZNm8yFQcnJyYSHh/P6668X1a2IiDzSKlWqxJ49eyj1P790S0pKol69epw+fbqYMhMRESkeDg4OBAUFAVC/fn327NnDjBkz+Oqrr/Idk9/LDreT34qnNjY2hS4qMBgMhR5fw6cG8zvNZ9GJRczcN5PUrFSSMpIY+/tYVp5aydjGY6nkUen2g6t0hDM7MZzbBfX7gqNrofK/kxL16pFWJYSMEydIXrEC71dfveeY9/K8Hld6ZpbR87JcYZ+ZnrGIiIiIPE70t18REXngjRgxgtmzZ/Pdd99x9OhRXn/9ddLS0hgwYAAAffv2ZdSoUeb+U6dOZcyYMcydO5fAwEDi4uKIi4sjNTUVyP3SaNiwYbz//vusWrWKQ4cO0bdvX8qUKWMuRhIREcvExMSQk5NzS3tGRgaxsbHFkJGIiMiDxWg0kpGRke/1adOmMXHiRNatW3fLyw4PC1sbW3pX7c2qsFV0DOxobo+4FEGP1T2YuW8mN7Jv3DrQOxg8K4JPVcgomu1/DAYDHs/3BIOBGxH7yIiKsmh8cmYyi44vYuOZjUWSn4iIiIiIiMj9ohWFRETkgffCCy9w+fJlxo4dS1xcHKGhoaxbtw4/Pz8Azp49m+fNr1mzZpGZmclzzz2XJ86///1vxo0bB8C7775LWloagwYNIikpiSeffJJ169ZpqWkREQutWrXK/Hn9+vW4u7ubz3Nycti0aROBgYHFkJmIiEjxGTVqFE8//TTly5cnJSWFBQsWsGXLFtavXw/kvuxQtmxZJk+eDOS+7DB27FgWLFhgftkBwMXFBRcXl2K7j8LyKeHDhy0/JCwojPd3v8/51PNkG7OZfWg2a6PXMrrxaJ4s++R/BxgM0G4C2DkUaV4O5cpRsvmTZJ05g8HBsrlOXD3BtvPbcLJzokmZJjjbOhdRliIiIiIiIiJFS4VCIiLyUBgyZEi+W41t2bIlz3lMTMxd4xkMBiZMmMCECROskJ2IyOPr5kpsBoOBfv365blmb29PYGAgH3/8cTFkJiIiUnzi4+Pp27cvFy9exN3dndq1a7N+/XratWsHFO5lh4dRs7LNWN5tObMPzWbu4blkG7OJTY3l9Y2v0yGwA+82fBffEr65nYu4SOgmj+eew2Bvj8FgsGhcfb/6bDizgdjUWH6N+ZVulbsVUYYiIiIiIiIiRUuFQiIiIiIiUmhGoxGAihUrsmfPHry9vYs5IxERkeL3zTff3PF6YV52eFg52TnxZt03eabSM0zcNZG9l/YCsD5mPTtid/Bm3TfpFdILWxvb3AHXr0LcIajUskjysbFwJaGbDAYDXYO6MityFlvPb6VF2RZWzkxERERERETk/lChkIiIFIno6Gi2b9/OmTNnuH79Oj4+PtStW5cmTZpoey8RkUdQdHS0+XN6err+Wy8iIiJ5VHKvxNwOc1l9ejUf7fmIxIxE0rLSmPLHFFadWsXYJmOpUbIcrHoTjNngEwKu/kWWjzEjg5RffwWjEfduBVsdqLpXdYI8gjiZdJK10WtpV6pdkeUnIiIiIiIiUlRs7t4lr3Xr1rFjxw7z+RdffEFoaCgvvvgiiYmJVk1OREQePvPnz+eJJ56gcuXKjBw5khUrVrB9+3bmzJlDx44d8fPzY/DgwZw5c6a4UxURESsyGo1MnDiRsmXL4uLiwunTpwEYM2bMXVdVEBERkceDwWCga+WurApbRY/gHub2PxP+5MU1LzLl4CxSfUJyG6N+LdJcMk+dInnNWpJ/3UDWpUsFGnNzVSGA8LhwLqdfLsoURURERERERIqExYVC77zzDsnJyQAcOnSIt99+m06dOhEdHc2IESOsnqCIiDw86taty8yZM+nfvz9nzpzh4sWLREREsGPHDv7880+Sk5NZuXIlRqORBg0asHjx4uJOWURErOT9999n3rx5TJs2DYe/bOlRs2ZN5syZY3G82NhY/va3v1GqVCmcnZ2pVasWe/fuNV83mUyMHTuW0qVL4+zsTNu2bYmKisoT4+rVq/Tp0wc3Nzc8PDwYOHAgqampefocPHiQ5s2b4+TkREBAANOmTbsll8WLF1O1alWcnJyoVasWa9euzXO9ILmIiIjIf3k4eTCu6Ti+f/p7gjyCADCajMw/Op+u8RtYb0zGdHIzZGcUWQ5O1avjVLMm5OSQtGRJgcdVcq9ELe9amEwmtlzcUmT5iYiIiIiIiBQViwuFoqOjqV69OgBLly6lc+fOfPDBB3zxxRf88ssvVk9QREQeHlOmTCE8PJzBgwcTEBBwy3VHR0datWrFl19+ybFjx6hUqVIxZCkiIkXh+++/5+uvv6ZPnz7Y2tqa2+vUqcOxY8csipWYmEizZs2wt7fnl19+4c8//+Tjjz/G09PT3GfatGnMnDmTL7/8kvDwcEqWLEmHDh1IT0839+nTpw9Hjhxhw4YN/Pzzz2zbto1BgwaZrycnJ9O+fXsqVKhAREQEH374IePGjePrr7829/n999/p3bs3AwcOZP/+/YSFhREWFsbhw4ctykVERERuVde3Lou6LGJ4/eE42eZuW3o5M4l/5JxncPpxzh1fWaTze/R8DmxtST90mBuHjxR4XNfKXWkV0IpO5TqZ2+LS4jCZTEWRpoiIiIiIiIhVWVwo5ODgwPXr1wHYuHEj7du3B8DLy8u80pCIiDyeOnToUOC+pUqVon79+kWYjYiI3E+xsbEEBQXd0m40GsnKyrIo1tSpUwkICODbb7/liSeeoGLFirRv357KlSsDuSv4TJ8+ndGjR9OtWzdq167N999/z4ULF1ixYgUAR48eZd26dcyZM4dGjRrx5JNP8tlnn/HTTz9x4cIFIHe7zMzMTObOnUuNGjXo1asXb731Fp988ok5lxkzZtCxY0feeecdqlWrxsSJE6lXrx6ff/55gXP5XxkZGSQnJ+c5REREHlf2Nva8XPNlVoStoEW5Fub2HaZUuu+dxJyDs8nKsezvEgWe288P16daAZC0ZDGm7OwCjSvtUpoewT0oaV8SgIQbCby/+33G7RrHsqhlnE46raIhEREREREReWBZXCj05JNPMmLECCZOnMgff/zBM888A8CJEycoV66c1RMUEZGH0759+zh06JD5fOXKlYSFhfHee++RmZlZjJmJiEhRqF69Otu3b7+lfcmSJdStW9eiWKtWraJBgwb07NkTX19f6taty+zZs83Xo6OjiYuLo23btuY2d3d3GjVqxK5duwDYtWsXHh4eNGjQwNynbdu22NjYEB4ebu7TokWLPFuldejQgePHj5OYmGju89d5bva5OU9BcvlfkydPxt3d3XzcbhU+ERGRx01Zl7J83vpzPm31Kb7OPgBkYGTG/pn0XN2TiEsRRTKvW6dO2Li6kh13idRt2woVIzY1FnsbexJuJLD57GY+ifiEf+34Fz8d+4mjCUfJNhasAElERERERETkfrC4UOjzzz/Hzs6OJUuWMGvWLMqWLQvAL7/8QseOHa2eoIiIPJxee+01Tpw4AcDp06fp1asXJUqUYPHixbz77rvFnJ2IiFjb2LFjGTJkCFOnTsVoNLJs2TJeffVVJk2axNixYy2Kdfr0aWbNmkVwcDDr16/n9ddf56233uK7774DIC4uDgA/P7884/z8/MzX4uLi8PX1zXPdzs4OLy+vPH1uF+Ovc+TX56/X75bL/xo1ahTXrl0zH+fOnbvbIxEREXksGAwG2lZoy6ruq3nJo7b5i8tT107Rf11/xuwcQ2J6olXntClRAveuXQFIWb++wKsK/VVtn9pMaTGFV2q9QkP/hjjbOZOcmcyO2B18EfkFBy8ftGrOIiIiIiIiIvfCztIB5cuX5+eff76l/dNPP7VKQiIi8mg4ceIEoaGhACxevJgWLVqwYMECdu7cSa9evZg+fXqx5iciItbVrVs3Vq9ezYQJEyhZsiRjx46lXr16rF69mnbt2lkUy2g00qBBAz744AMA6taty+HDh/nyyy/p169fUaR/Xzk6OuLo6FjcaYiIiDywStqX5N12n9ElOZoJez/icMJhAFacXMGWc1sYUX8EYUFhGAwG68zXrCnZ8fG4tGqJwc7ir0sBcLR1JNQ3lFDfULKN2ZxIPMGBywc4mnCUGt41zP02ndnE6WunqeNTh5reNSlhX8Iq9yAiIiIiIiJSUBb/5Ltv3z7s7e2pVasWkLuVzLfffkv16tUZN25cnmX7RUTk8WUymTAajQBs3LiRzp07AxAQEMCVK1eKMzURESkizZs3Z8OGDfccp3Tp0lSvXj1PW7Vq1Vi6dCkA/v7+AFy6dInSpUub+1y6dMlcpOrv7098fHyeGNnZ2Vy9etU83t/fn0uXLuXpc/P8bn3+ev1uuYiIiEghlPCiWgkvfuz0I4tPLGbGvhmkZqWSlJHE2N/HsvLUSsY0HkNlj8r3PJXBxgaPHs9aIelcdjZ2VC9VneqlqmMymfIUNO25tIfzKec5cPkANgYbQrxCqONTh9o+tXFzcLNaDiIiIiIiIiL5sXjrMW0lIyIiBdGgQQPef/99fvjhB7Zu3cozzzwDQHR09C3bs4iIyKMlNTWV5OTkPIclmjVrxvHjx/O0nThxggoVKgBQsWJF/P392bRpk/l6cnIy4eHhNGnSBIAmTZqQlJRERESEuc/mzZsxGo00atTI3Gfbtm1kZWWZ+2zYsIGQkBA8PT3Nff46z80+N+cpSC4iIiJSeLY2tvTyaciqrst5OvBpc3vEpQieW/UcM/bN4Eb2DavOmXk+FpPJZJVY/7vqUZ9qfehYsSP+Jf0xmowcTTjKT8d+4l/b/8WsA7OsMqeIiIiIiIjInVhcKJTfVjLz5s0zv+ErIiIyffp09u3bx5AhQ/jXv/5FUFAQAEuWLKFp06bFnJ2IiFhbdHQ0zzzzDCVLlsTd3R1PT088PT3x8PAwF90U1PDhw9m9ezcffPABJ0+eZMGCBXz99de88cYbQO4v3IYNG8b777/PqlWrOHToEH379qVMmTKEhYUBuSsQdezYkVdffZU//viDnTt3MmTIEHr16kWZMmUAePHFF3FwcGDgwIEcOXKEhQsXMmPGDEaMGGHOZejQoaxbt46PP/6YY8eOMW7cOPbu3cuQIUMKnIuIiIjcgy1TYP17+CSeY1rLaXzV9isCXAMAyDZlM+fQHLqv7M7289utMt3VH37k0vvvc2N/pFXi/a8A1wA6V+rM6MajGdN4DF0rd6W8W3lMmHCydTL3M5lM/Hb2N+LS4qxWtCQiIiIiIiIChdh6TFvJiIhIQdSuXZtDhw7d0v7hhx9ia2tbDBmJiEhR+tvf/obJZGLu3Ln4+fnd8va8JRo2bMjy5csZNWoUEyZMoGLFikyfPp0+ffqY+7z77rukpaUxaNAgkpKSePLJJ1m3bh1OTv/9Bdv8+fMZMmQIbdq0wcbGhh49ejBz5kzzdXd3d3799VfeeOMN6tevj7e3N2PHjmXQoEHmPk2bNmXBggWMHj2a9957j+DgYFasWEHNmjUtykVEREQKyaM8XNgPUeshoCFNyzZlWddlzDk0h28Of0O2MZvY1FgGbxpM+wrtGfnESHxL+BZ6OlsPdwCSli7BuWYNDA4O1rqTW/iV9KN9yfa0D2xPYnoiWcb/rnJ4Me0iS6OWQhT4lvCljk8dQn1DKe9a/p7+niUiIiIiIiJicaHQza1k2rZty9atW5k1K3dJXG0lIyIiBaFfmoqIPJoOHDhAREQEISEhVonXuXNn80sJt2MwGJgwYQITJkzIt4+XlxcLFiy44zy1a9dm+/Y7r0DQs2dPevbseU+5iIiISCEFtYM/V0HcIUi+AG5lcLJzYkjdIXSq1In3d7/Pnrg9APx65ld2XtjJm3XfpFdIL2xtLH9JxbV9e9J2/k5OwlVSNm3C7emn7z7ICjyd8q7AmGPKoYZ3DY4lHCP+ejwbzmxgw5kNeDh6UMe3Ds3LNse/pP99yU1EREREREQeLRZvPaatZEREJD+enp54eXkV6BARkUdLw4YNOXfuXHGnISIiIo8aFx8oWy/384n1eS5Vcq/EN+2/4YMnP8DTMbfQJi0rjSl/TOHFtS9y5MoRi6ezcXTE/dnuACSvW092YuK95V9IAa4BvF7ndaa0mMKAmgOo61sXB1sHkjKS2HpuKwnpCea+17Ou51mNSEREREREROROLF5RSFvJiIhIfqZPn27+nJCQwPvvv0+HDh1o0qQJALt27WL9+vWMGTOmmDIUkcfR0arVijuFR1a1Y0fNn+fMmcPf//53YmNjqVmzJvb29nn61q5d+36nJyIiIo+K4PYQGwHRW6FOb7D/70q1BoOBLpW70KJcCz6N+DR3uy7gz4Q/eXHti/QK6cWQukNwdXAt8HQlGjYkdetWMk+d5tqKlZQa0N/ad1RgznbO1PerT32/+mTlZHHs6jEOJxwmxPO/qziuj1nPjtgd1PSuSR2fOtTwroGjrWOx5SwiIiIiIiIPNosLhW6KiIjg6NHcXwxUr16devXqWS0pERF5OPXr18/8uUePHkyYMIEhQ4aY29566y0+//xzNm7cyPDhw4sjRRERKSKXL1/m1KlTDBgwwNxmMBgwmUwYDAZycnKKMTsRERF5qJWuAy5+kHoJYrZDcLtburg7ujOu6Ti6BXVjwq4JnEw6idFkZMGxBWw4s4GRT4ykfYX2GAyGu05nMBjw7NmTS1Omcj08HJeWLXGsVLEo7swi9rb21PKpRS2fWnnaY5JjyMjJIOJSBBGXIrCzsaOqV1VCfUOp5V2LkvYliyljEREREREReRBZvPVYfHw8Tz31FA0bNuStt97irbfeokGDBrRp04bLly8XRY4iIvIQWr9+PR07drylvWPHjmzcuLEYMhIRkaL08ssvU7duXXbt2sXp06eJjo7O86eIiIg8uExGI5kxZ4o7jfwZDFClQ+7n83vu2LWub10WdVnE8PrDcbLNXXno8o3L/GPrPxi8aTDnUgq2VapDYCAlmzbB1t0NY1rqPaVf1IbVG8bbDd6mbYW2eDt7k23M5vCVw/z45498EP4BJpOpuFMUERERERGRB4jFhUJvvvkmqampHDlyhKtXr3L16lUOHz5McnIyb731VlHkKCIiD6FSpUqxcuXKW9pXrlxJqVKliiEjEREpSmfOnGHq1Kk0atSIwMBAKlSokOcQERGRB9e1VauI7tKF6599Rs61a8Wdzu1VagVPjoCWI+/a1d7GnpdrvsyKsBW0LNfS3L4jdgfdV3Zn9sHZZOVk3TWO+7M98B8/Hudate7atzgZDAYqulckLCiMfzf5N6MajeKZSs9Q1qUsNb1rmldRMplMzDowiw1nNnD5ul74FBEREREReVxZvPXYunXr2LhxI9WqVTO3Va9enS+++IL27dtbNTkREXl4jR8/nldeeYUtW7bQqFEjAMLDw1m3bh2zZ88u5uxERMTaWrduzYEDBwgKCiruVERERMQCOalpxH/8MeTkkLF0GdGbf8Nn2DA8nuuBwda2uNP7L4eSUL6RRUPKupTls9afsfnsZib/MZlL1y+RkZPBzP0z+fn0z4xpPIYG/g3yHW/r8vBt2WUwGCjrUpayLmV5uuLTZBuzzdeir0Vz5MoRjlw5wsqTKynjUoY6PnUI9Q2lTMkyBdqWTURERERERB5+FhcKGY1G7O3tb2m3t7fHaDRaJSkREXn49e/fn2rVqjFz5kyWLVsGQLVq1dixY4e5cEhERB4dXbp0Yfjw4Rw6dIhatWrd8jND165diykzERERuRODvR1eL77Ila9nY7pxg5zEROL+/W8SF/6E/3vvUaJB/oU0xSYnG4zZYO90164Gg4E2FdrQuExjvoj8gvlH52M0GTl97TQD1g8gLCiMEfVH4OnkmW8Mk8nE9T/2YExJxrVtW2veSZGzs/nv17++JXx5PuR5Dlw+wInEE1xIvcCF1Av8Ev0L3s7ePFflOWp61yzGbEVEREREROR+sLhQqHXr1gwdOpT//Oc/lClTBoDY2FiGDx9OmzZtrJ6giIg8vBo1asT8+fOLOw0REbkP/v73vwMwYcKEW64ZDAZycnLud0oiIiJSADaOjni//jquXbtybtIHZG3eDEDGn0c587eXcOvUCd93/oF96dLFnOn/id4GkQsgqC3Ueq7Aw0ral+Tdhu/SpVIXJu6eyKErhwBYcXIFv537jbfrv023oG7YGGxuGZtx4gRXv/0W7GxxrlMHOx8fq93O/eTi4EKLci1oUa4FaVlpHL5ymMj4SI5dPcaVG1coYVfC3Pdi6kWuZV4jyCMoT7GRiIiIiIiIPPws/inv888/p2vXrgQGBhIQEADAuXPnqFmzJj/88IPVExQRkYeX0Wjk5MmTxMfH37LqXIsWLYopKxERKQpaXVREROThZl+6NC5jx+DSvz/xkyeTcfQoAMlr15Ly2294D3oVrwEDsHG6+yo+RcpgCzcS4eRGqB4GtpZ9vVmtVDV+ePoHlpxYwox9M0jJSuFaxjXG/j6WFSdXMKbxGII8826l6lilCo7VqpJx9BhJy5bj/dogK95Q8ShpX5JGpRvRqHQjMnIyOJpwlIruFc3Xt5zfws7YnZSwK0Etn1rU8alDNa9q2NveutK8iIiIiIiIPFwsLhQKCAhg3759bNy4kWPHjgG5W8m0fciW3RURkaK1e/duXnzxRc6cOYPJZMpzTStLiIiIiIiIPJhKNKhPxSWLSVqylMvTp5OTmIjpxg0uz5hJ0pKl+I58F9d27TAYDMWTYEAjcHLPLRY6vwcqNLE4hK2NLS9UfYE2Fdowbc80fon+BYB98fvoubon/Wv2Z1DtQTjbOQO5P8N6PvcccZM+4Mb+/aQfP45DcLBVb6s4Odo6EuobmqetpH1JXBxcSM1MJfxiOOEXw3GwdaB6qerU8alDfb/6t119SURERERERB58hVo31mAw0K5dO9q1a2duO3bsGF27duXEiRNWS05ERB5ef//732nQoAFr1qyhdOnSxfclsoiI3DdpaWls3bqVs2fPkpmZmefaW2+9VUxZiYiIiKUMtrZ4vvA8bh07cPmLL0icvwBycsiKjSX2raGUaNwYv/dG4VSlyv1PztYOKreBI8sgan2hCoVu8nb2ZlqLaYQFhTFp9yTOppwl25TNnENz+CX6F95r9B4tyuWuhmtftiwuLVqQumULSYsW4/PPkda6owdS18pd6VypM6eSTnHg8gEOXD5AYnoikfGRnE85TwO/Bua+GTkZONo6FmO2IiIiIiIiYgmrbTCdkZHBqVOnrBVOREQeclFRUSxZsoSgoKC7dxYRkYfe/v376dSpE9evXyctLQ0vLy+uXLlCiRIl8PX1VaGQiIjIQ8jW3R3/997Ds2dPLk2eTNrvuwC4vns30d2fxbN3b3zeHIKtu/v9TSyoLfy5AuKPQtJZ8Ch/T+GalmnKsm7LmHNoDt8c+oYsYxaxqbG8sekN2lVox8iGI/Er6Ydb585c37OHrNhY0nbshGpVrXM/Dygbgw3BnsEEewbTI7gH51LOceDyAUralzS/DJRtzGbMzjGUKVmGOj51qONbBy8nr2LOXERERERERO5E68OKiEiRaNSoESdPnizuNERE5D4ZPnw4Xbp0ITExEWdnZ3bv3s2ZM2eoX78+H330UXGnJyIiIvfAMTiYgG++odznn2FfrlxuY04OiT/+yKkOHUn8aSGm+7m9dMlSUO7/VrSJ+tUqIR1tHXkj9A2Wdl3KE/5PmNs3nNlAt5XdmH90PpRwwq1LZwCSf16NKSMzv3CPHIPBQHm38nSp3IXW5Vub288kn+F61nVOJp1kadRSxu4cy9Q/prIuZh1xaXHFmLGIiIiIiIjkR4VCIiJSJN58803efvtt5s2bR0REBAcPHsxziIjIoyUyMpK3334bGxsbbG1tycjIICAggGnTpvHee+8Vd3oiIiJyjwwGA65t21Jpzc/4DBuKwdkZgJykJOLGjSP6uZ5c37v3/iUU3CH3z+htkJVutbAV3Ssyp/0cPnjyA/PKOGlZaUz5Ywq91/TmbDUvSjRsQKlBgzA4Olht3odVZY/KjG86nmeDnyXIIwgDBs6lnOPnUz/z/u73+e3sb8WdooiIiIiIiPwPq209JiIi8lc9evQA4OWXXza3GQwGTCYTBoOBnPv5tqmIiBQ5e3t7bGxy30Pw9fXl7NmzVKtWDXd3d86dO1fM2YmIiIi12Dg64v33v+MeFkb8Rx+T/PPPAGQcPcqZv72EW6en8X3nHexLly7aRPxqQPUwKN8I7J2sGtpgMNClchdalGvB9H3TWXJiCQBHrx6l97q/0atmL96o4A9JNzBmZpJz7Rr2fn5WzeFhUsq5FK3Lt6Z1+dYkZyZz6PIhDlw+wPGrx6niVcXc72jCUXae3Uk96hHiFYKrg2sxZi0iIiIiIvL4KnChkKenp3nv6dvJzs62SkIiIvJoiI6OLu4URETkPqpbty579uwhODiYli1bMnbsWK5cucIPP/xAzZo1izs9ERERsTJ7f3/KfvQhnr17ETdpEhl/HgUgee0vpGz+jVKDXqXUyy9j42TdIh4zgwFCexdN7P/j7ujOv5v8m26VuzFh9wSiEqMwYeI/x/7DxjMbeSXoFdoe8iRj6SqcatXEtW1bHKtUueN3qI86Nwc3mpVtRrOyzbiedR1nO2fztfC4cPZc2cOB5AMYDAb8S/pTxbMKVTyrEOQRhIuDSzFmLiIiIiIi8vgocKHQ9OnTizANERF51FSoUKG4UxARkfvogw8+ICUlBYBJkybRt29fXn/9dYKDg5k7d24xZyciIiJFpUT9+lRcvJikpUu5/Ol0chITMaWnc2XmZ1xbugzfke/i2q5d0RfPmEy5xUNFINQ3lIWdF/Ljnz8y68AsbmTf4PKNy0w+NJk/9ht5Ms4Jl4QjuO5ci3OFQPw6dqVMszYY7B7vxdxL2JfIc96odCNIh4s5F7mYdpG4tDji0uLYdn4bBgxMbTHVPCbHmIOtjW1xpC0iIiIiIvLIK/BPq/369SvKPERE5BF06tQppk+fztGjuW+WVq9enaFDh1K5cuVizkxERKzJZDLh6+trXjnI19eXdevWFXNWIiIicr8YbG3xfP553Dp04PIXX5A4fwHk5JAVG0vsW0Mp0bgxfu+NwqlKlbsHs1TKJTiyHIxZ0PRN68f/P/Y29gyoOYAOgR2YHD6ZLee3ALCprg37gjJoEJVO7Zgr2B2K5s9Dv5H1/xxJaFAJ+9bNCSlVlWpe1QhwDcDGYFNkOT7oqnlVo1R2KXx9fbmRc4OoxChOJJ7gROIJbAw2eQqLvoj8guvZ1wn2CCbYM5ggj6BbCo9ERERERESkcB7v11pERKTIrF+/nq5duxIaGkqzZs0A2LlzJzVq1GD16tW0a9eumDMUERFrMZlMBAUFceTIEYKDg4s7HRERESkmtu7u+L/3Hp7PP8+lDz4g7fddAFzfvZvo7s/i2asXPm8OwdbDw3qT5mTC6d8AA9R5EUqWsl7s2yjjUoaZrWey/fx2fon6hTM3zhBlG8WGeulsr2Gi7mkT9U6acEnLICXqGMt8T5jHlrQvSYhnCCFeIVTzqkZVr6oEeQRhb2tfpDk/iEralyTUN5RQ31AAsnKyzNeyjFlEX4smy5jF+ZTz/HbuNwwYKOdajiqeVahWKvfZiYiIiIiISOGoUEhERIrEP//5T4YPH86UKVNuaR85cqQKhUREHiE2NjYEBweTkJCgQiERERHBMSiIgG++IXXTJi5NmUrW+fOQk0Pi/Pkkr1mDz7ChePTsicHWCltLeQSAb3WI/xNOboA6ve495l0YDAaeLPskVeyr4OvrixEjZ5LPcOzqMY5dPca+y0cw7j/CWac08xi3NBNtIlPYWyWCfd4R5m3S7GzsqOxemapeValWqhohniFU9aqKi4NLkd/Hg+SvxVL2NvaMazqOqMQoopKiiEqMIv56POdSznEu5Rxx1+PyFAodv3qcQPdAHG0diyN1ERERERGRh44KhUREpEgcPXqURYsW3dL+8ssvM3369PufkIiIFKkpU6bwzjvvMGvWLPMWZCIiIvL4MhgMuLZtS8nmzbn67TyufPUVphs3yElKIm7ceBJ/Woj/v96jRMOG9z5ZlQ7/Vyi0CWr2gPu8Qo+djR2VPSpT2aMyz1R6BgBTRxOXrl/iaMJRjl09hmn1RnwunabKhQwuesKeKjYcLwfZZHM88TjHE4+z8tRKc8wA1wCqelU1H9W8quFTwue+3ldxcnd0p4F/Axr4NwAgKT2JqKTcrcoqe/x3O/Or6Vf5bP9n2BhsqOBWgWDPYKp4VqGSeyUcbB2KK30REREREZEHmgqFRESkSPj4+BAZGXnLyhKRkZH4+voWU1YiIlJU+vbty/Xr16lTpw4ODg44OzvnuX716tViykxERESKk42jI95/fw33sG7Ef/QxyT//DEDGsWOceakvrk93xO+dd7AvU6bwk5RtAM6ecCMRzoVD4JNWyr7wDAYD/iX98S/pz1PlnyLLL4yUSpu59vsOUq4n0uxYKgnRWYRXzuFXv3hu2JvyjL+5es6GMxvMbaWcSv23eKhUVap6VqW8W3lsDDb3+/buOw8nDxr6N6Shf97CsqT0JLycvLiafpXoa9FEX4vm15hfsTXYUsGtAu0qtKOWT61iylpEREREROTBpEIhEREpEq+++iqDBg3i9OnTNG3aFICdO3cydepURowYUczZiYiItWm1OBEREbkTe39/yn70IZ4v9ubS+5NI//NPAFJ+WUfqb1so9eorlBo4EBsnJ8uD29pBUFs4tBhOrH8gCoX+l33p0nj16YN7166kbttG6patBKSkEHoOXrtWl6QRf+NY8gmOJeRuX3Yi8QTpOel5YiSkJ7Dzwk52XthpbithV4IQr5A8qw8FeQQ9NqvpVPKoxIRmE0i4kZC74tDVE5xIPEFSRhKnr50my5hl7hubGsv++P1U8axCRbeKebY7ExEREREReZxYXCiUk5PDvHnz2LRpE/Hx8RiNxjzXN2/ebLXkRETk4TVmzBhcXV35+OOPGTVqFABlypRh3LhxvPXWW8WcnYiIWFu/fv2KOwURERF5CJSoV4/AxYtIWrqUy59OJxNUOngAAQAASURBVCcxEVN6Olc++5xrS5fh++67uHZoj8FgsCxw5dZweBlcOQFXo8GrYtHcwD2ydXXF/ZlncGvXjut795KycRNO1asR4F+HWv51MJlMZJ07h225spxJPsPRq7lbl93881rGtTzxrmdfZ3/8fvbH7ze32Rlyt0IL8Qqhmlc1qnpVJcQrBFcH1/t9u/dNKedSlHIuRePSjTGZTCSkJ3Ai8QQhXiHmPocuH2Jd9DrWRa/D3saeiu4VCfYMJtgjmED3QOxs9E6tiIiIiIg8Hiz+6Wfo0KHMmzePZ555hpo1a1r+Q7uIiDwWDAYDw4cPZ/jw4aSkpADg6vrofikpIiL/lZ6eTmZmZp42Nze3YspGREREHjQGW1s8n38et44dufLFF1z9cT7k5JB14QKxw4ZRolEj/N57D6eQKgUPWsILqrQHB5fczw84g4MDJZs2pUSTJpD131VvMqKiuPzJpzhUrIh/2zZUDO3IM5WeAcBkMnHp+iWOJuQWDd08LqRdyBM725TN8cTjHE88zqpTq8zt5VzKUa1UtTyrD/k4+zxy3+8aDAa8nb3xdvbO0x7gGkB9v/pEJUaRnJnMicTc1YcA7G3sGfnESPxL+hdHyiIiIiIiIveVxYVCP/30E4sWLaJTp05FkY+IiDwioqOjyc7OJjg4OE+BUFRUFPb29gQGBhZfciIiYnVpaWmMHDmSRYsWkZCQcMv1nJycYshKRESkeMyaNYtZs2YRExMDQI0aNRg7dixPP/10vmMWL17MmDFjiImJITg4mKlTpz7y37/ZurnhN2oUHj17cumDyaT9/jsA18PDie7eHc9evfB5601sPTwKFrB+/yLLtagYDAZw+O82YdkXL4KdLZnR0STMnoNtKS9cW7emZNOm2Dg741/SH/+S/jxV/inzmGsZ1/IUDh27eozoa9HkmPL+/et86nnOp55nw5kN5jYvJy+qeVXLs/pQebfy2Bhsiv7m77Ma3jWo4V3DXHB1IvEEUYlRRCVFkZmTmaewaOmJpcRdjyPYI5hgz2DKu5bH1sa2GLMXERERERGxHosLhRwcHAgKCiqKXERE5BHSv39/Xn75ZYKDg/O0h4eHM2fOHLZs2VI8iYmISJF49913+e2335g1axYvvfQSX3zxBbGxsXz11VdMmTKluNMTERG5r8qVK8eUKVMIDg7GZDLx3Xff0a1bN/bv30+NGjVu6f/777/Tu3dvJk+eTOfOnVmwYAFhYWHs27ePmjVrFsMd3F+OQUEEfDOH1M2buTRlKlnnzoHRSOKCBSSvWYPPsP/P3n2HR1G1YRz+zab3BEih995Bei+CiCBFBERBLFiwADawgNiwY0HFAmKjqYBSpPeOSBHpNUBIIIT0nt3vj5WFfBQTSDIpz31de7Fz5szss0Mg2c2773ka/7vvxnAq/IUa3u3a4dGwIfFr1hC/Zi0Z56OI/vkXYuYvwLt1K3x79MDi5pbpGD83P5qVbEazks0cY8npyRyOPmxfsuy8vXjo4IWDJGckZzo2KjmKDWEb2BC2wTHm4exB9YDq1ChWw9GBqIp/FVydXCkMDMNwFFy1LdMWm83GhZQLmZYe23N+D+cSz7Hv/D4AXJ1cqeJfhWoB1agaUJXyvuXNii8iIiIiInLTsl0o9Mwzz/Dxxx8zadKkQteWVkREcs6OHTto1arVFePNmzfniSeeMCGRiIjkpvnz5/P999/Tvn17hg4dSps2bahSpQrly5fnp59+YtCgQWZHFBER+U8nT57EMAzKlCkDwNatW5k+fTq1atVi2LBhWT5Pjx49Mm2/+eabfPHFF2zevPmqhUIff/wxt912G8899xwAr7/+OsuWLWPSpElMnjz5Jp5RwWEYBj6dOuHVujVR074j8ssvsSUmkhETQ/j417gwcxbBL72IV9Om1z+RNQNOb4dTf0Lzx6AAvn/p5OuLX48e+HbtSsKWrcStWE56eARJu//Gr2/fLJ3D3dmdOiXqUKfEpUKzDGsGJ2JP2IuHLus+FJ0SnenYpPQkdp7byc5zOx1jzoYzlfwr2YuH/u1AVKNYDXxcC/4S44ZhUMw983J1D9V9iEMXDnHwwkEOXzhMYnoie8/vZe/5vQR5BjG2xVjH3HOJ5yjuUbxQdmESEREREZHCKduFQuvXr2fVqlX88ccf1K5dGxcXl0z758yZk2PhRESk4DIMg7i4uCvGY2JitPyMiEghFBUVRaVKlQDw9fUlKioKgNatW/PYY4+ZGU1ERCTL7rnnHoYNG8Z9991HeHg4t956K7Vr1+ann34iPDycsWPH/vdJ/k9GRgY///wzCQkJtGjR4qpzNm3axKhRozKNde3alXnz5l3zvCkpKaSkpDi2Y2NjAbBarVit1mzntFqt2Gy2Gzo2R7m4UOzhh/Dp2YNzH3xI3IIFAKQcOEDo4CH43HYbgc8+g0upUlc/Pj0FY9PnkJaIrVwLKFk/V2LmyfVydsazVUs8WrYgZe9ebP8+ps1mw5aaStTUqXg2a4Z7/foYlv8uUjEwqOBbgQq+FehWwb4M3sVluPZH7Wf/BXvh0IGoA4QlhGU6Nt2WzsELBzl44SC/H/ndMV7Gu4y9aCigBjWK2W+BHoFX/YBpvvkay4KSniUp6VmStqXtHYdOx5/mUPQhDl04RJBnkOM5pFvTmbBlAhbDQhX/KlQNqEpV/6qU9i590x+yLUjXK7+4mWum6ywiIiIiRUm2C4X8/f3p3bt3bmQREZFCpG3btkyYMIEZM2bg9G97+IyMDCZMmEDr1q1NTiciIjmtUqVKHDt2jHLlylGjRg1mz55N06ZNmT9/Pv7+/mbHExERyZI9e/bQ9N+ONbNnz6ZOnTps2LCBpUuX8uijj2arUOjvv/+mRYsWJCcn4+3tzdy5c6lVq9ZV54aHhxMcHJxpLDg4mPDw8Guef8KECYwfP/6K8XPnzpGcnHyVI67ParUSExODzWbDkoWik1xnGDg/+ww+t3Ul8ZNPyTh4EIC4xYuJW7UK94EDcR84AOP/luEC8CjRELcTq0jbOYcEp5K5Ei/Pr1dgIABxZ88CkPbnn6Rs+5OYbX9iBATg0roVLo0bX/V6/BcLFmq51aJWSC0IsY/FpcVxJPYIh+MOczj2MEfijhCaEIrVlrmY4lT8KU7Fn2JF6ArHmL+rP5V9KlPFtwpVfKpQ2bcypT1Lg4389TWWDa64UtutNrVD7B3Bzv7793Au+RwpKSmkWlPZnrid7WHbAfBw8qCiT0UaFGtATf+aN/SY+e7fZAFwM9fsah92ExEREREprLJdKPTtt9/mRg4RESlk3nnnHdq2bUv16tVp06YNAOvWrSM2NpaVK1eanE5ERHLa0KFD2bVrF+3atWP06NH06NGDSZMmkZaWxocffmh2PBERkSxJS0vD7d9Ci+XLl9OzZ08AatSowZkzZ7J1rurVq7Nz505iYmL45ZdfGDJkCGvWrLlmsVB2jRkzJlMXotjYWMqWLUtgYCC+vr7ZPp/VasUwDAIDA/NXUULHjtjatSNm7lwiP/qYjKgoSEkhedo00pcsIej55/Du0iVz9xb3vhhnNuAWcxAvLwO8AnM8ltnXK6NlS+LT00lYtw5rQgIsXUrGuvV4tWqFV4f2OAcE3NT5gwiicunKdKGLYyw5PZnD0YftXYcuHGB/1H4OXjhIckbmwrTo1Gi2n9/O9vPbHWMezh5U869GWfey1MyoSZWAKlTyq3TN7kMFRRBBfFTmI07Gn+TwhcMcij7EkegjpGSkcDjxMDVCahAUFARAfGo8O87toKp/VYI9g//zeZv9NVYQ3cw1c3d3z6VUIiIiIiL5T7YLhS46d+4cBw4cAOxvfAQG5vwLbhERKbhq1arF7t27mTRpErt27cLDw4PBgwfzxBNPUKxYMbPjiYhIDhs5cqTjfufOndm/fz/bt2+nSpUq1KtXz8RkIiIiWVe7dm0mT55M9+7dWbZsGa+//joAYWFhFC9ePFvncnV1pUqVKgA0btyYbdu28fHHH/Pll19eMTckJISIiIhMYxEREYSEhFzz/G5ubo6ipstZLJYbLiowDOOmjs81FgvF7r4bv9tuI/Kzz4n66SdITyf9zBnCRo7Cs2lTgl96Cffq1ezz/ctAyXoQ/jfGkRXQ4J5ciWXm9bIUK0ZAr1743X47iZs3E7diJekREcQvX0786lWUeuMNnHK4q6Onqyf1gupRL+jSz3YZ1gxOxJ6wL10WtZ99UfvYH7Wf6JToTMcmpSexK3IXu9jFglMLHOM+Lj5U9K9IZb/KVPavTCW/SlTyr0RJr5JYjHz2dXgNFouFSv723F3oQro1ndC4UA5dOETdEnUdXx+HYg7x88GfAfBx9aFqQFWqBVSjqn9VgjyDrlo4lG//TeZjN3rNdI1FREREpCjJdqFQQkICTz75JN9//71j3V4nJycGDx7Mp59+iqenZ46HFBGRgqlUqVK89dZbZscQEZFcZLVaee+99/j9999JTU2lU6dOjBs3jvLly1O+fHmz44mIiGTLO++8Q+/evXnvvfcYMmQI9evXB+D33393LEl2o6xWKykpKVfd16JFC1asWMGIESMcY8uWLaNFixY39ZiFjZOvL8FjRuN/dz8i3ppAwoYNACRu3cqx3r0JGDCAwKeetBfIVLsNwv+Gwyugzl3g7Gpu+FxicXXFu21bvNq0IXnPHuKWr8Bwds5UJJQaGopLmTIYuVAI4WRxchTJ3F7pdgBsNhsRiRGXCofO2zsQnY4/fcXxcWlx7D63m93ndmca93D2oKKfvYCokn8lKvlVorJ/Zcp4l8HJ4pTjzyMnOVuc7QVPfpUyjbs7u1MtoBrHYo4RlxrHXxF/8VfEXwD4ufnxQJ0HqOxf2YzIIiIiIiJSxGS7UGjUqFGsWbOG+fPn06pVKwDWr1/PU089xTPPPMMXX3yR4yFFRKRgWrduHV9++SVHjx7l559/pnTp0vzwww9UrFiR1q1bmx1PRERywJtvvsmrr75K586d8fDw4OOPP+bs2bNMnTrV7GgiIiLZ1r59eyIjI4mNjSXgsqWbhg0blq0Px40ZM4Zu3bpRrlw54uLimD59OqtXr2bJkiUADB48mNKlSzNhwgQAnn76adq1a8cHH3xA9+7dmTlzJn/++SdfffVVzj7BQsKtcmXKfvM18atWETHhbdJOngSrlQvTpxO7cCElnn6KgLvuwvAsAYmRELoRKrU3O3auMgwDj7p18ahbF1tqqmM8/cIFIt55F+dixfDu1BGvFi2wXKUTVU5nCfEKIcQrhPZl2zvGo5Oi2X58OxcsFzgWe4wjMUc4Gn2UMwlXLuuXlJ7E3vN72Xt+b6ZxV4srFfwqODoPXexEVM6nHC5OLrn6vG5W7eK1qV28NmnWNI7HHOfQhUMcvHCQYzHHiEmJoZj7pe7LG8M2cjDqIIEEUtejLiV9SuJiyd/PT0RERERECo5sFwr9+uuv/PLLL7Rv394xdvvtt+Ph4cHdd9+tQiEREQHs3y/uu+8+Bg0axF9//eX45GxMTAxvvfUWixYtMjmhiIjkhO+//57PP/+cRx55BIDly5fTvXt3vvnmG7XvFxGRAicpKQmbzeYoEjpx4gRz586lZs2adO3aNcvnOXv2LIMHD+bMmTP4+flRr149lixZwq233gpAaGhopu+TLVu2ZPr06bz88su8+OKLVK1alXnz5lGnTp2cfYKFiGEY+HTsiFerVkRN+47IL7/ElphIRkwMEa+9TvTMWQQPaotXcX9w9zM7bp4yXC91T0oLC8Pi5kr6uXNEz5xF7O/z8WrTBu/27XC+rBguL/i6+VI7oDZBQUGZvv4T0xI5FmMvHDoSbS8eOhJzhFNxp7Bhy3SOVGsqBy8c5OCFg5nGnQ1nyvqWvaIDUQXfCrg7u+fJ88sqF4sLVQOqUjWgKrdzO2kZaYTGhRLgfunvY9fZXeyJ3ENqaiqLwhdhsVgI9gymjHcZSnmXokPZDvm+MEpERERERPKvbBcKJSYmEhwcfMV4UFAQiYmJORJKREQKvjfeeIPJkyczePBgZs6c6Rhv1aoVb7zxhonJREQkJ4WGhnL77bc7tjt37oxhGISFhVGmTBkTk4mIiGTfnXfeSZ8+fXj00UeJjo6mWbNmuLi4EBkZyYcffshjjz2WpfNMmTLluvtXr159xVi/fv3o16/fjcQu0ixubpR4ZBh+ve7k7AcfEPv7fABSDh4kdNxBfLp2JbhOEEW1pMKjdm1KTphAwqZNxK9YSfq5c8QtWULc8uV43nILfr3uzPOCof/n6eJJ7RK1qV2idqbx5PRkTsSe4Ej0EY7EHLEXE0UfITQ2lHRbeqa56bZ0jsUc41jMMQi9NG5gUManDJX9KlPRv6KjA1FFv4p4uXjlxdP7Ty5OLlcsOda5fGdKeZdiT9geom3RJKUnEZ4QTnhCOK6RrnQu39kxd8nxJcSnxlPapzSlvUoT4hWiIiIREREREbmubBcKtWjRgnHjxvH999/j7m7/NEZSUhLjx4/XuukiIuJw4MAB2rZte8W4n58f0dHReR9IRERyRXp6uuN1wUUuLi6kpaWZlEhEROTG/fXXX0ycOBGAX375heDgYHbs2MGvv/7K2LFjs1woJHnPJTiY0u++S8CAgUS8+SbJ//wDQNySJcSvXk3xhx6i+EMPYvHwMDlp3rO4ueHTvj3ebduS/PffxC1fQcqhQyTt2IF/Pi5Oc3d2p3qx6lQvVj3T+MUOPEdjjmbqQHQ85jip1tRMc23YOBl3kpNxJ1l9anWmfSFeIY4ORJd3IvJzM78DVdWAqlT2q0wz72YEBgYSmxZLWHwYp+JPkZqRisW41JFpW/g2whPCHduGYRDsGUxp79KU8y1Hp3KdzHgKIiIiIiKSj2W7UOjjjz+ma9eulClThvr16wOwa9cu3N3dHeusZ9XatWt577332L59O2fOnGHu3Ln06tXrmvNXr15Nhw4drhg/c+YMISEh2XpsERHJXSEhIRw+fJgKFSpkGl+/fj2VKlUyJ5SIiOQ4m83G/fffj5ubm2MsOTmZRx99FC+vS5/SnjNnjhnxREREsiUxMREfHx8Ali5dSp8+fbBYLDRv3pwTJ06YnE6ywrNRQyr8PJuYOXM4++FEMqKisKWkEPnZZ0TP+ZXgF17Ap2tXDMMwO2qeMywWPOrXx6N+fVKPHyftzBmcvC/9vHb+22m4VamMZ7NmWC5bviy/udiBp7J/ZW4tf6tjPMOawen401d0IDoac5Sk9KQrznOxQ8+GsA2Zxkt4lLhiCbNKfpUo5l7MlK8bwzAIcA8gwD3giq5LALeWv5WTcSc5HX+a03GnSUxPdDy3sPiwTIVCs/bPwtnibO8+5F2aEE91HxIRERERKYqyXShUp04dDh06xE8//cT+/fsBGDhwIIMGDcIjm5/ISUhIoH79+jzwwAP06dMny8cdOHAAX19fx3ZQUFC2HldERHLfww8/zNNPP83UqVMdS9Bs2rSJZ599lldeecXseCIikkOGDBlyxdi9995rQhIREZGbV6VKFebNm0fv3r1ZsmQJI0eOBODs2bOZ3ouS/M2wWPC/6y58unQh8rPPifrhe7DaSD8TzukRI/Fs0oTgl1/CvXr1/z5ZIeVaoQKul32wJ+XoURK3bCFxyxZi5v2Gd7u2eLdrh5Of+d11ssrJ4kQ533KU8y1HBy592NRqsxKeEH6pA9FlnYji0uKuOE9kUiSRSZFsCd+SadzfzZ9KfpWu6EAU7BlsauFZs5LNaFayGWAv4o9OiXZ0H3J3utT502qzsvnMZtKslzp/Xuw+VMa7DNUCqtGydMs8zy8iIiIiInkv24VCAJ6enjz88MM3/eDdunWjW7du2T4uKCgIf3//m358ERHJPaNHj8ZqtdKpUycSExNp27Ytbm5uPPvsszz55JNmxxMRkRzy7bffmh1BREQkx4wdO5Z77rmHkSNH0rFjR1q0aAHYuws1bNjQ5HSSXU6+vgSPGY1/83JEvD+RhCPxACRu28ax3n3w7383gU89hXNAgMlJzedSqhT+d/cjbsUKMs5HEbvoD2KXLsWrSRO8O3XGtUxpsyPeMIthoZR3KUp5l6J16daOcZvNRmRSJEdijnAkOnMHoqjkqCvOE50SzV9n/+Kvs39lGvdy8brqEmalvEtlWiIsL1yv+1CGLYO7q9/N6fjTjkKixLRL3YdSramOQiGbzcaXu78k0CPQ3n3IqzQhXuo+JCIiIiJSWGSpUOj333+nW7duuLi48Pvvv193bs+ePXMk2PU0aNCAlJQU6tSpw6uvvkqrVq2uOTclJYWUlBTHdmxsbK7nExER+5tTL730Es899xyHDx8mPj6eWrVq4e3tbXY0ERERERGRq7rrrrto3bo1Z86coX79+o7xTp060bt3bxOT5bKkCxi/PoxrzUEQdKfZaXKcW5u+lI1cRvyecCLWJZIWdhasVqJnzCR20R8EPvUkAf37Yzjf0GcqCwWLuzs+HTvi3b49STt3Ebd8OalHj5KwaTMJmzYTOHJEoevAZBgGgZ6BBHoG0rxk80z7LiRfuLIDUcxRziaeveI8CWkJ7I7cze7I3ZnG3Z3cqehXMVMBUWW/ypTxKYOzJe+/1lwsLrQo1cKxbbPZiEmJsS9ZFn+aQM9Ax77olGj2RO7JdPzF7kOlvUtTP7A+jYIb5Vl2ERERERHJWVl6RdKrVy/Cw8MJCgqiV69e15xnGAYZGRk5le0KJUuWZPLkydxyyy2kpKTwzTff0L59e7Zs2UKjRld/YTJhwgTGjx+fa5lEROT6XF1dqVWrFrGxsSxfvpzq1atTs2ZNs2OJiIiIiIhcVUhICCEhIZw6dQqAMmXK0LRpU5NT5aK4CJh2O8b5w/if3Arl60KJKmanylnObhiVO+KTtgCvVq2IOh5M5OTJ2BITscbEEPH6G0TPmk3wiy/i1byZ2WlNZVgseDZqiGejhqQcPUrcihWkhZ7Ercqlr4nUU6dxCQrEcHU1MWnuCnAPoLF7YxoHN840Hpcax9GYoxyNPpqpgOh0/OkrzpGckcy+qH3si9qXadzF4kJ53/JU9q+cqQNRed/yuDrl3TU1DAN/d3/83f2v6D7k5uTGoJqDrtl9yN/N31EolJCWwJS/p1Dau7S9+5B3aUI81X1IRERERCQ/y1KhkNVqver9vFa9enWqX/bJlZYtW3LkyBEmTpzIDz/8cNVjxowZw6hRoxzbsbGxlC1bNteziogUdXfffTdt27bliSeeICkpiSZNmnDs2DFsNhszZ86kb9++2TrfZ599xnvvvUd4eDj169fn008/veab9f/88w9jx45l+/btnDhxgokTJzJixIhMc1599dUrCkmrV6/O/v37s5VLREREREQKD6vVyhtvvMEHH3xAfLx9mSofHx+eeeYZXnrpJSyWvF1GKE94lYBileD8YSwpMdhm3gMPLQN3P7OT5ayqt8L+hVgi/6bEwIfwu/NOzn34ATG/2bunpxw8SOj99+PTtSvBzz+HS+mCu9RWTnGrVAm3SpWwpaZiODkBYEtPJ/LTT7FZrXi3bYt3+3Y4+fiYnDTv+Lj6UD+wPvUD62caT0xL5FjssUwFRMdijhEaF4rVlvn99DRrGoejD3M4+nCmcSfDibI+ZansX5lKfpWo6FsRvww/nHycKO5ZPE+XMfN08byi+1B0SrSjaKiyX2XHvtPxpzl44SAHLxx0jF3efah5yebULK4PjImIiIiI5CfZ7nH6/fff079/f9zc3DKNp6amMnPmTAYPHpxj4bKiadOmrF+//pr73dzcrsgqIiK5b+3atbz00ksAzJ07F6vVSnR0NN999x1vvPFGtgqFZs2axahRo5g8eTLNmjXjo48+omvXrhw4cICgoKAr5icmJlKpUiX69evHyJEjr3ne2rVrs3z5cse2cxFuMy8iIiIiIvDSSy8xZcoU3n77bcdS9+vXr+fVV18lOTmZN9980+SEucDiBH2nYJtyK8a5/RiRB+CXB+GeWfZ9hYVPCJSsD2d2wqGluDQaTKl33sF/wAAi3nyL5D32ZZbiliwhfvVqij/4IMUffgiLh4e5ufOByzsHpUdGgpMT1pgYYhcuJG7pEjybNsOncydcSpY0MaW5PF08qV28NrWLZ+7Mk5KRwonYE1d0IDoee5x0a3qmuRm2DI7HHud47HFWsCLTPmeLM4Ee9mXSgjyC7H96BhHkGUSgx6X73i7eGIaR48/PMAwC3AMIcA+4ovtQsGcwg2oOIiw+jNPxp6/oPlQ1oKpj7sm4k8w9NJfS3qUp5V2KMt5lCPFS9yERERERkbyW7d+IDh06lNtuu+2KX8zGxcUxdOjQPC8U2rlzJyWL8ItQEZH8KiYmhmLFigGwePFi+vbti6enJ927d+e5557L1rk+/PBDHn74YYYOHQrA5MmTWbhwIVOnTmX06NFXzG/SpAlNmjQBuOr+i5ydnQkJCclWFhERuaRRo0asWLGCgIAAXnvtNZ599lk8PT3NjiUiInLDvvvuO7755ht69uzpGKtXrx6lS5fm8ccfL5yFQgDuvtj6T8f2dUcsKdFweBksGwtdC9nzrdYFwv+G9BTHkGfDhlSYPYuYuXM5++FEMs6fx5aSQuTnnxM9dy7Bzz+Hz2235UrxRUHkEhJCyddfI2nnTuKWLSf1+HESNmwgYcMG3GvXxq93L1zLlDE7Zr7h5uRGtYBqVAuolmk8zZrGqbhTHI0+ypGYI44ComMxx0jJSLniPOnWdM4knOFMwpnrPp6Hs8elgiLPoCuKii5uuzu759hz9HPzu6L7UExKDKfjT3M6/jRV/S8rFIo9ed3uQx3KdqCCX4UcyyYiIiIiIleX7UIhm8121RfGp06dws8vey2J4+PjOXz4UovVY8eOsXPnTooVK0a5cuUYM2YMp0+f5vvvvwfgo48+omLFitSuXZvk5GS++eYbVq5cydKlS7P7NEREJJeVLVuWTZs2UaxYMRYvXszMmTMBuHDhAu7uWX9DKjU1le3btzNmzBjHmMVioXPnzmzatOmmMh46dIhSpUrh7u5OixYtmDBhAuXKlbvm/JSUFFJSLr1hFxsbe1OPLyJS0O3bt4+EhAQCAgIYP348jz76qAqFRESkQIuKiqJGjRpXjNeoUYOoqCgTEuWhYhWJ7vIxAQsfxLCmw6ZJEFQTGt5rdrKcU7Ih3DkJPItlGjYsFvz79sWnSxciP/+CqB9+gPR00s+c4fTIUXhOn0HwSy/ifpWvjaLIcHLCs3FjPBo1IvXoUeKWryBp506S//kHv153mh2vQHCxuFDRryIV/SrSiU6O8QxrBmEJYfYCougj7I/YTzzxnEs6x9nEs0QlX///oaT0JELjQgmNC73uPB9XH4I9gzMXFf1fYVFxj+K4WLLf6ccwDPzd/fF397+i+1D1YtUZVHMQp+NPO5Yxu7z7UMtSLR1zd53bxZqTayjtXZrSPqUp7VVa3YdERERERHJIlguFGjZsiGEYGIZBp06dMi3PkpGRwbFjx7jtttuy9eB//vknHTp0cGyPGjUKgCFDhjBt2jTOnDlDaOilFzWpqak888wznD59Gk9PT+rVq8fy5csznUNERPKHESNGMGjQILy9vSlfvjzt27cH7EuS1a1bN8vniYyMJCMjg+Dg4EzjwcHB7N+//4bzNWvWjGnTplG9enXOnDnD+PHjadOmDXv27MHHx+eqx0yYMIHx48ff8GOKiBQ2DRo0YOjQobRu3Rqbzcb777+Pt7f3VeeOHTs2j9OJiIhkX/369Zk0aRKffPJJpvFJkyZRr149k1LlndTSzbHd9g7GomfsA/NHQPEqUK65qblyjMVyRZHQ5Zx8fAh+4Xn8+91FxIS3SVi3DoDEbds41qcv/v3vJvCpp3AOCMirxPmaYRi4Va6MW+XKpJ09S/Kef3AtW9axP3rePAwXF7zbtcPpGj8jSmZOFifK+pSlrE9Z2pRuw9nAswQFBWGxWABIy0gjMimSs0lnOZd4jojECM4lnnMUEp1NtI/HpcVd93HiUuOIS43jcPTha84xMCjmXuzSEmfXWPYswD0Ai2HJ0vMr7lGcFh7X7j5UxudSN6pjMceu233ojkp3EOgZmKXHFRERERGRzLJcKNSrVy/AvtRX165dM/0CwNXVlQoVKtC3b99sPXj79u2x2WzX3D9t2rRM288//zzPP/98th5DRETM8fjjj9OsWTNCQ0O59dZbHW9qVapUiTfeeMPkdNCtWzfH/Xr16tGsWTPKly/P7NmzefDBB696zJgxYxxFrWDvKFT2sjdBRUSKmmnTpjFu3DgWLFiAYRj88ccfmT5QcJFhGCoUEhGRAuHdd9+le/fuLF++nBYt7L/M3rRpEydPnmTRokUmp8sjtzwA5/bDtq/BmgYzB8GwVeB/7e6rBVJsGGCAb8krdrlVqkTZr74kfvVqIia8TVpoKFitRM+YSeyiPwh88kn87u6X95nzMZegIFw6Bjm2M2JjiV+xAltaOnGLl+DZvBleHTrYi7Xkhrk4uVDSuyQlva/8ur1cYloikUmRVy0kOpt41rF9tWXOLrJh43zyec4nn2df1L5rznO2OF/qTHSVQqKL971dvK9YqeB63YdalGxBiFcIp+PsRUT/332oZ+VLS0SuDF3Jnsg9lPQqSVPvpte9NiIiIiIiko1CoXHjxgFQoUIF+vfvn61lY0REpGhq3LgxjRs3zjTWvXv3bJ2jRIkSODk5ERERkWk8IiKCkJCQm854kb+/P9WqVcu0JOb/c3Nzw83NLcceU0SkoKtevbpjaUmLxcKKFSsICgr6j6NERETyr3bt2nHw4EE+++wzRwfTPn36MGzYMN544w3atGljcsI8ctsEiDwIx9ZAYiTMGAgPLAG3QtIVZt982PEjlG8FrZ666hTDMPDp0AGvVq2I+u47zn8xGWtiItaYGCLeeIMLs2bh+tijkM0O60WFxdOTgPvuI275ctJCT5Kwbj3x69ZhrVqN9CGDcS1RwuyIhZqniyflXMpRzvfaBX42m43Y1FjOJZ5zdCi6vJDoYseiyKRIMmwZ1zxPujWdMwlnOJNw5rqZPJw9Mi919n9FRRe33Z3tv3cI9gom2CsYSl7KG5MSw+mE04THh1PM/VJ3sKMxRzl44SBHY47SskbLqz28iIiIiIhcJsuFQhcNGTIkN3KIiEgh8Pbbb/P000/j4eHxn3O3bNlCZGTkfxYOubq60rhxY1asWOHobme1WlmxYgVPPPFETsQGID4+niNHjnDffffl2DlFRIoSq9VqdgQREZEcUapUKd58881MY7t27WLKlCl89dVXJqXKY04u0G8afNMJoo5CxB6Y+wjc/UPh6AgTVMv+58ktkBQNHv7XnGpxdaXEww/j1/NOzn34ITG//QZA6qFDpI56huNffY1/nz749rhDS5JdxnB2xqtpUzybNCHl0CHiV6wgcfdu0vfsIWL8eEoMG4ZHNpYll5xnGAZ+bn74uflRJaDKNedZbVaikqMuFRJdpajobOJZopKjrvt4SelJhMaFEhoXet15Pq4+BHsGZy4q+r/ComoB1TJ1J+pesTu1i9cmPjUeJ8MpexdCRERERKQIynahUEZGBhMnTmT27NmEhoaSmpqaaX9U1PVfEIiISOG1d+9eypUrR79+/ejRowe33HILgYH29eLT09PZu3cv69ev58cffyQsLIzvv/8+S+cdNWoUQ4YM4ZZbbqFp06Z89NFHJCQkMHToUAAGDx5M6dKlmTBhAgCpqans3bvXcf/06dPs3LkTb29vqlSxv/n17LPP0qNHD8qXL09YWBjjxo3DycmJgQMH5vRlEREpMo4cOcJHH33Evn32pQlq1arF008/TeXKlU1OJiIiItnmWQwGzoJvOkNKDOxfAKvehE6vmJ3s5hWvDMWrwPnDcGQl1Onzn4e4BAdR6p23CRg4gPA33iR5zx4AUvbvJ+Ktt4h47z18OnbEv28fvFq1wnBSsQLYi1Hcq1XDvVo1Uk6eJOzbaRgXLuBavrzZ0SSLLIaFEh4lKOFRgprFa15zXlpGGpFJkY5Coqste3Yu8RxxaXHXfby41DjiUuM4HH3tjs8GBsXci11a4uzfZc9KeJRgS9wWmnk3I8Q757pQi4iIiIgUNtkuFBo/fjzffPMNzzzzDC+//DIvvfQSx48fZ968eYwdOzY3MoqISAHx/fffs2vXLiZNmsQ999xDbGwsTk5OuLm5kZiYCEDDhg156KGHuP/++7O8jGX//v05d+4cY8eOJTw8nAYNGrB48WKCg4MBCA0NxXLZp1rDwsJo2LChY/v999/n/fffp127dqxevRqAU6dOMXDgQM6fP09gYCCtW7dm8+bNjsImERHJniVLltCzZ08aNGhAq1atANiwYQO1a9dm/vz53HrrrSYnFBERkWwLrAZ3TYXp/cBmhXXvQ2ANqNfP7GQ3r1pX2HQYDi+HWneCJWuFPR4NGlBh9iyif/+dc999R8Y++xJ1pKURt2QJcUuW4BwUhF+vXvj17oVbxYq5+CQKFpfSpXF/+CGKGwZOvr6O8djFi/Fo1AgXLWFboLk4uVDSuyQlvUted15iWiKRSZFXLSS6vENRSkbKNc9hw8b55POcTz7Pvqh9V+x/0flFBtbUB8FERERERK4l24VCP/30E19//TXdu3fn1VdfZeDAgVSuXJl69eqxefNmnnrq6ut6i4hI0VC/fn2+/vprvvzyS3bv3s2JEydISkqiRIkSNGjQgBIlStzQeZ944olrLjV2sfjnogoVKmCz2a57vpkzZ95QDhERubrRo0czcuRI3n777SvGX3jhBRUKiYiIFFRVO0OXN2HJGPv2b8OhWCUo09jcXDerbHP463tIPA+nt0PZplk+1LBY8OvZk5TmzfGLiSV23jxifv+djPPnAUg/e5bzX33F+a++wqNRI/z79sGn6204eXvl1rMpMAzDwPmygqCkv/cQM+83YhcuxOfWW/G57TYsrq4mJpTc5uniSTmXcpTzLXfNOTabjdjUWPsSZ1dZ6uxix6LIpEgybBlXHB/ooQ+BiYiIiIhcT7YLhcLDw6n77/rR3t7exMTEAHDHHXfwyiuFoPWwiIjkCIvFQoMGDWjQoIHZUUREJA/s27eP2bNnXzH+wAMP8NFHH+V9IBERkWzo0+f6S09FR0fnTZD8qvljcHYv7PgBMlJg5j0wbBX4ljI72Y1zdoXKHWHvb3BwSbYKhS7nVrUKwS88T9CokcSvXUv0nLnEr14NGfbihaS//iLpr78If/MtfLt2xb9PbzxuuQXDMHLwyRRczkGBuNWsQcq+/cQu+oOEzVvwv+suPBo20DUqwgzDwM/NDz83P6oEVLnmPKvNSlRylKOQKCIhguORx6kWUC0P04qIiIiIFDzZLhQqU6YMZ86coVy5clSuXJmlS5fSqFEjtm3bhpubW25kFBERERGRfC4wMJCdO3dStWrVTOM7d+4kSMtIiIhIPufn5/ef+wcPHpxHafIhw4DuH8L5IxC6EeLD7cVC9y8CV0+z0924KrfC3t/hwnFIiQM3nxs+leHigk+nTvh06kR6ZCQxv88nes6vpB4+AoAtMZGYuXOJmTsXl/Ll8O/dG79evXAJCcmhJ1MwuQQHE/jUUyTt2En0L7+QERXF+a++wq1mDQL69y/y10euz2JYKOFRghIeJahZvCZWq5Wz/mcJ8tHrDxERERGR68l2oVDv3r1ZsWIFzZo148knn+Tee+9lypQphIaGMnLkyNzIKCIiIiIi+dzDDz/MsGHDOHr0KC1btgRgw4YNvPPOO4waNcrkdCIiItf37bffmh0h/3N2hf4/wFcdICYUwnbYlyG7a6q9kKgg8g6EDi9CYA3788shziVKUPyBoRQbej/Jf/9N9Jw5xC5YiDU+HoC0E6Gc++hjzn3yKV4tW+Lftw/eHTtiKaIfwjQMA89GDXGvU5u4JUuIW7qUlH37ifxiMiGvjlNnIRERERERkRyW7UKht99+23G/f//+lCtXjk2bNlG1alV69OiRo+FERERERKRgeOWVV/Dx8eGDDz5gzJgxAJQqVYpXX32Vp556yuR0IiIikiO8SsA9M2FKF0iNh3/mQFAtaPec2cluXMl6uXZqwzDwqFcPj3r1CB49mrhly4me8yuJmzbbJ1itJKxfT8L69Vj8/PC74w78+vTGvVatIlkcY3F1xa9HDzybNSP6l1/wbtXKcR1sNhtAkbwuIiIiIiIiOS3bhUL/r0WLFrRo0SInsoiIiIiISAFlGAYjR45k5MiRxMXFAeDjc+PLd4iIiEg+FVwb+nxtX3oMG6x6AwKrQ62eZie7OTYbJF0Az2K5cnqLuzt+Pe7Ar8cdpJ46Tcy8ecTMnUva6dMAWGNiuPDTT1z46SfcatTAv09vfHv0wDkgIFfy5GcuQUEEPv54prGEtWtJ/HM7/v3741qmtEnJRERERERECocsFQr9/vvvWT5hz54F/E0BERHJUYcPH+bIkSO0bdsWDw8PbDabPgEoIlLIqUBIRESkkKtxO3QaCyvG27fnPgIBFXK1O0+uijoGGz4GizPc/l6uL6XmWqY0gU8Mp8Tjj5G4dSvRc+YQt2QptpQUAFL27yfirQlEvPc+Ph064NenN96tW2M43/RnPgskW3o6sX8sJiM6moi33sK7XTv8etyBxdPT7GgiIiIiIiIFUpZeXfbq1SvTtmEYjnavl48BZGRk5EwyEREp0M6fP0///v1ZuXIlhmFw6NAhKlWqxIMPPkhAQAAffPCB2RFFRERERETkRrUeCWf3wd+zIS0RZgyEYavAO8jsZNnnHQSJ5yEj1f6cgmvlycMaFgtezZvj1bw5Ga+8QuyiP4ie8yvJu3bbJ6SlEbd0KXFLl+IcGIhfrzvx690Ht0oV8yRffmE4OxP0/HNE//IrSX/9RfyqVST++Sf+vXvh2aKFPowkIiIiIiKSTZasTLJarY7b0qVLadCgAX/88QfR0dFER0fzxx9/0KhRIxYvXpzbeUVEpIAYOXIkzs7OhIaG4nnZp/z69++v7xciIiIiIiIFnWFAz0+hdGP7duwpmDkI0lPMzXUjXL2gQhv7/UNLTIng5ONDQP+7qThrFpUWzKfYgw/gVKKEY3/6uXOc//objt5+O8cH3kP0L7+QEZ9gSlYzOBcrRolhDxP49FM4hwRjjYsj6vsfOPvue6SeOm12PBERERERkQIlS4VClxsxYgQff/wxXbt2xdfXF19fX7p27cqHH37IU089lRsZRUSkAFq6dCnvvPMOZcqUyTRetWpVTpw4YVIqERERERERyTEu7jBgOviUsm+f2grzn4b/60ReIFTrYv/z5DZIjDI1iluVKgQ/9xxVV62kzOef4925E1y27FjSjh2cefkVDrVpQ9joMSRs3XpF9/fCyr1mTUJefhm/vn0w3NxIPX4cbFazY4mIiIiIiBQo2S4UOnLkCP7+/leM+/n5cfz48RyIJCIihUFCQkKmTkIXRUVF4ebmZkIiERHJLWlpaXTq1IlDhw6ZHUVERETymk8IDJwOzh727V0zYOOn5ma6EQEVILA62DLg8Aqz0wBguLjg07EDZSdNouqa1QS98AJuVas49tuSkoiZN4/QwUM40vU2Ir/4grQzZ0xMnDcMZ2d8b72VkuNfpdiQwbiWLevYl3L0KDarCodERERERESuJ9uFQk2aNGHUqFFEREQ4xiIiInjuuedo2rRpjoYTEZGCq02bNnz//feObcMwsFqtvPvuu3To0MHEZCIiktNcXFzYvXu32TFERETELKUaQu8vLm0vGwsHzVnC66ZU7Wr/88gKyEg3N8v/cS5enOJD76fi779T4efZ+A8cgMXHx7E/LTSUcx9/wuGOnQh98CFiFy3CmlIAl4HLBid/f7yaN3dsp505w9kPPiRiwtukHDliYjIREREREZH8LduFQlOnTuXMmTOUK1eOKlWqUKVKFcqVK8fp06eZMmVKbmQUEZEC6N133+Wrr76iW7dupKam8vzzz1OnTh3Wrl3LO++8Y3Y8ERHJYffee69eD4iIiBRltXtDu9H/btjglwfh7D5TI2Vb2Wbg7gdJF+DMTrPTXJVhGHjUrUvJceOoum4tpd5/H6+WLcAw7BNsNhI2bOD0qGc41LYd4a+9TtKef4rE0mTp585hcXMl7eRJzr73PlHffUdGTIzZsURERERERPId5/+eklmVKlXYvXs3y5YtY//+/QDUrFmTzp07Y1x8QSoiIkVenTp1OHjwIJMmTcLHx4f4+Hj69OnD8OHDKVmypNnxREQkh6WnpzN16lSWL19O48aN8fLyyrT/ww8/NCmZiIiI5Jl2L8C5fbD3N0iNgxkD4KGV4FXc7GRZ4+QMjYeCmw8E1zY7zX+yuLvjd0d3/O7oTlpYGNHz5hEzZy5pp04BYI2J4cL06VyYPh236tXx79Mb3x49cC5WzOTkucOjXj1Cxo8nZt5vJGzcSMKmzSTu3InfHXfg3a4dhnO23woXEREREREplG7o1ZFhGHTp0oUuXbrkdB4RESlE/Pz8eOmll8yOISIieWDPnj00atQIgIMHD2bapw8UiIiIFBEWC/T6AqKOQfhuuHAcZg+G++aCs6vZ6bKmfAuzE9wQl1KlCHz8cUo8+iiJ2/4kZs6vxC5Zii05GYCUAweImPA2Ee9/gE/79vj17YN369aFrnjGyceHYvfdi1frVkTPnEXqiRNE//wLiX9uJ+j55/RzqYiIiIiICFksFPrkk08YNmwY7u7ufPLJJ9ed+9RTT+VIMBERKfiSk5PZvXs3Z8+exWq1ZtrXs2dPk1KJiEhuWLVqldkRREREJD9w9YKBM+CrDpBwFk6shz+egzs+urQ8VkFhtdqLnwoQw2LBq1lTvJo1JfiVV4hdtIiYOXNJ2rnTPiEtjbhly4hbtgznwED87uyJX58+uFWqZGrunOZWsSJBo18gYeNGYubOw6NhAxUJiYiIiIiI/CtLhUITJ05k0KBBuLu7M3HixGvOMwxDhUIiIgLA4sWLGTx4MJGRkVfsMwyDjIwME1KJiEhuO3z4MEeOHKFt27Z4eHhgs9n0SxkREZGixq8MDJgO07pDRgpsnwZBtaHZMLOTZU16KuyaASe3wO3v2YufCiAnb28C7r6bgLvvJuXIEWLmziX6t9/IOGd/nZ5+7hznv5nC+W+m4NGgAX59++DbrRtO3t4mJ88ZhmHg3aoVng0aYLi5OcaTDxwg9dhxfDp1xHBxMTGhiIiIiIiIObL0kZhjx45RvHhxx/1r3Y4ePZqrYUVEpOB48skn6devH2fOnMFqtWa6qUhIRKTwOX/+PJ06daJatWrcfvvtnDlzBoAHH3yQZ555xuR0IiIikufKNoGel3UmXzwajqw0L092OLnAmV2QeB6OrTU7TY5wq1yZoGefpeqqVZT54nN8bu0Mly07lrRzJ+GvjOVQm7aEvTCahC1bsf1fZ+CCyuLl5VhizZaezoUZM4iZN4/w198gac8/JqcTERERERHJewWrd66IiBQYERERjBo1iuDgYLOjiIhIHhg5ciQuLi6Ehobi6enpGO/fvz+LFy82MZmIiIiYpv4AaDXCft+WAT/fD5GHzUyUNYYB1bra7x9aCjabuXlykOHsjE+HDpT59FOqrl1D0OgXcKtWzbHflpREzG+/ETpkCEe63sa5zz8nLSzMxMQ5zMkJ39u64eTnS/rZs0ROmkTkF1+QfpVuyCIiIiIiIoVVlpYeGzVqVJZP+OGHH95wGBERKTzuuusuVq9eTeXKlc2OIiIieWDp0qUsWbKEMmXKZBqvWrUqJ06cMCmViIiImK7TWDh3AA7+AckxMKM/PLQcPALMTnZ9FdrAzp8gNgwi9kBIXbMT5TjnYsUofv/9FBsyhOQ9/xAzdw4xCxZijY0FIO3kSSI/+ZTITyfh1aIFfn374NO5M5bLlvEqaAzDwKt5Mzzq1yN20SLiVq4iaddukvfuw6drV3y73Irh6mp2TBERERERkVyVpUKhHTt2ZOlkhmHcVBgRESk8Jk2aRL9+/Vi3bh1169bFxcUl0/6nnnrKpGQiIpIbEhISMnUSuigqKgq3AvzLJBEREblJFifo+zVM6QJn98L5w/DLA3DPz+CUpbcmzeHqCRXbwqFlcHBJoSwUusgwDDzq1sGjbh2CXniBuOXLiZkzl4SNG+3dlGw2EjZuJGHjRiy+vvh2vx3/Pn1xr1O7wL4fbPHwwL9vX7xatuTCzFmkHDhA7IIFuJYpjUeDBmbHExERERERyVVZejW+atWq3M4hIiKFzIwZM1i6dCnu7u6sXr0605uHhmGoUEhEpJBp06YN33//Pa+//jpg/7/earXy7rvv0qFDB5PTiYiI5K0JEyYwZ84c9u/fj4eHBy1btuSdd96hevXq1z3uo48+4osvviA0NJQSJUpw1113MWHCBNzd3fMoeS5x84GBM+CrDpAUBUdWwtKXodvbZie7vqpd7YVCp/6EhPPgVdzsRLnO4uaGX/fu+HXvTlpYGDG//Ub0nLmknTwJgDU2lugZM4meMRO3qlXx69sHv549cS5WzOTkN8alZEkCRzxN0o4dJP/9N+716zv22VJT1V1IREREREQKJYvZAUREpHB66aWXGD9+PDExMRw/fpxjx445bkePHjU7noiI5LB3332Xr776im7dupGamsrzzz9PnTp1WLt2Le+8884Nn/ftt9/GMAxGjBjhGEtOTmb48OEUL14cb29v+vbtS0RERKbjQkND6d69O56engQFBfHcc8+Rnp6eac7q1atp1KgRbm5uVKlShWnTpl3x+J999hkVKlTA3d2dZs2asXXr1kz7s5JFRESKnjVr1jB8+HA2b97MsmXLSEtLo0uXLiQkJFzzmOnTpzN69GjGjRvHvn37mDJlCrNmzeLFF1/Mw+S5KKAC9P8RLP9+bnHLF7B9mpmJ/pt/WQiqBdjg8DKz0+Q5l1KlKPHYY1Resphy33+H3513Ynh4OPanHDrE2bff4VDbdpx68kniVq7C9n8/bxUEhmHg2agRxYYMcXzIKSM+gTNjxxE9dx7WlBSTE4qIiIiIiOSsG+rv++effzJ79mxCQ0NJTU3NtG/OnDk5EkxERAq21NRU+vfvj8WimlQRkaKgTp06HDx4kEmTJuHj40N8fDx9+vRh+PDhlCxZ8obOuW3bNr788kvq1auXaXzkyJEsXLiQn3/+GT8/P5544gn69OnDhg0bAMjIyKB79+6EhISwceNGzpw5w+DBg3FxceGtt94C4NixY3Tv3p1HH32Un376iRUrVvDQQw9RsmRJunbtCsCsWbMYNWoUkydPplmzZnz00Ud07dqVAwcOEBQUlKUsIiJSNC1evDjT9rRp0wgKCmL79u20bdv2qsds3LiRVq1acc899wBQoUIFBg4cyJYtW3I9b56p0Aq6fwjz/+0wu/AZKF4FKrQ2N9f11LwDilWESu3NTmIaw2LBq2lTvJo2JfiVl4n94w9i5swlaccO+4T0dOKWLSdu2XKcAkvg17Mn/n364Fa5srnBb0LS9j/JiI4mbskSErduxf+uvng0alRgl1oTERERERG5XLYLhWbOnMngwYPp2rUrS5cupUuXLhw8eJCIiAh69+6dGxlFRKQAGjJkSOH69KuIiPwnPz8/XnrppRw5V3x8PIMGDeLrr7/mjTfecIzHxMQwZcoUpk+fTseOHQH49ttvqVmzJps3b6Z58+YsXbqUvXv3snz5coKDg2nQoAGvv/46L7zwAq+++iqurq5MnjyZihUr8sEHHwBQs2ZN1q9fz8SJEx2FQh9++CEPP/wwQ4cOBWDy5MksXLiQqVOnMnr06CxlERERAfv3L4Bi11meqWXLlvz4449s3bqVpk2bcvToURYtWsR999131fkpKSmkXNbpJDY2FgCr1YrVas12RqvVis1mu6Fjs6XhfRhn92JsmQzWdGyz7sP20EoIKJ+7j3ujSja03wAuuzZ5dr3yGcPTE7++ffHr25eUo0eJnTePmN9+J+PcOQAyzkUSNWUqUVOm4l6/Pn59euPTrRtO3t4F6pp5tG6N4edHzM+/kH4+ksivv8atWnX87+6HS6lSeZKhIF2v/OJmrpmus4iIiIgUJdkuFHrrrbeYOHEiw4cPx8fHh48//piKFSvyyCOP3PAnhUVEpPDJyMjg3XffZcmSJdSrVw8XF5dM+z/88EOTkomISG65cOECU6ZMYd++fQDUqlWLoUOHXveXotcyfPhwunfvTufOnTMVCm3fvp20tDQ6d+7sGKtRowblypVj06ZNNG/enE2bNlG3bl2Cg4Mdc7p27cpjjz3GP//8Q8OGDdm0aVOmc1ycc3GJs9TUVLZv386YMWMc+y0WC507d2bTpk1ZznI11/rFroiIFE5Wq5URI0bQqlUr6tSpc81599xzD5GRkbRu3RqbzUZ6ejqPPvroNT98MWHCBMaPH3/F+Llz50hOTr6hnDExMdhsttzvDFv/SQJO78Ht1HqMpCjSf+xHVO+Z2Fy9c/dxc1CeXq/8ytsb7r0XnwEDSd+2lZQ/FpO2cSP8u/xY8q5dJO/aRcRbE3Bt1xaXrl1JqFCh4FyzkBCMRx+BtetIXbOa1L//Ju6fPbi0aoVrt2653l1IX2PZdzPXLC4uLpdSiYiIiIjkP9kuFDpy5Ajdu3cHwNXVlYSEBAzDYOTIkXTs2PGqb1CIiEjR8/fff9Owof1Tl3v27Mm0T626RUQKn7Vr19KjRw/8/Py45ZZbAPjkk0947bXXmD9//jWXWbmamTNn8tdff7Ft27Yr9oWHh+Pq6oq/v3+m8eDgYMLDwx1zLi8Surj/4r7rzYmNjSUpKYkLFy6QkZFx1Tn79+/PcparudYvdkVEpHAaPnw4e/bsYf369dedt3r1at566y0+//xzmjVrxuHDh3n66ad5/fXXeeWVV66YP2bMGEaNGuXYjo2NpWzZsgQGBuLr65vtnFarFcMwCAwMzJuihHt+xDalM8b5w7hcOETQuhex9f8JLE65/9g3IuIfOLQEaveBgAp5f73yuzvvhDvvJP3CBeIWLCBmzhxSDhy070tJIXXpMlKXLsNStizuwx/Hr3t3DKd8+nf9/wYOIL3LrcT88itJu3bi5exCwP/9jJgb9DWWfTdzzdzd3XMplYiIiIhI/pPtQqGAgABHdX3p0qXZs2cPdevWJTo6msTExBwPKCIiBdOqVavMjiAiInlo+PDh9O/fny+++AKnf3/pk5GRweOPP87w4cP5+++/s3SekydP8vTTT7Ns2bJC+2b9tX6xKyIihc8TTzzBggULWLt2LWXKlLnu3FdeeYX77ruPhx56CIC6deuSkJDAsGHDeOmll674pbebmxtubm5XnMdisdxwUYFhGDd1fLZ4BsDAWfBNR0iOwTi0BGPVG3BrPi2mPboSTm0DV29o/iiQx9ergHAtXpziQ4ZQbPBgkvfuJebXOcQsXIj13+X3rCdPEjF6DBe+/IoSjz+G7+23F4iCIdfAQAIfe5Skf/7BtVw5x995emQk1qQkXHPpZzl9jWXfjV4zXWMRERERKUqy/dNv27ZtWbZsGQD9+vXj6aef5uGHH2bgwIF06tQpxwOKiIiIiEj+d/jwYZ555hlHkRCAk5MTo0aN4vDhw1k+z/bt2zl79iyNGjXC2dkZZ2dn1qxZwyeffIKzszPBwcGkpqYSHR2d6biIiAhCQkIACAkJISIi4or9F/ddb46vry8eHh6UKFECJyenq865/Bz/leVq3Nzc8PX1zXQTEZHCxWaz8cQTTzB37lxWrlxJxYoV//OYxMTEK35RffH7qs1my5WcpitRBfpNA+Pfnx82fAS7ZpqZ6NqqdrX/eWI9pMSbm6UAMAwDj9q1CRn7ClXXrqH0hx/g0bixY3/qsWOEPfc8R+/oQcz8+dgyMkxMm3UetWvj5OMD2P9dXpg5i4i3JnBhxgwy4hNMTiciIiIiIpI1WS4UurhszKRJkxgwYAAAL730EqNGjSIiIoK+ffsyZcqU3EkpIiIFQp8+fYiNjXXcv95NREQKl0aNGrFv374rxvft20f9+vWzfJ5OnTrx999/s3PnTsftlltuYdCgQY77Li4urFixwnHMgQMHCA0NpUWLFgC0aNGCv//+m7NnzzrmLFu2DF9fX2rVquWYc/k5Ls65eA5XV1caN26caY7VamXFihWOOY0bN/7PLCIiUjQNHz6cH3/8kenTp+Pj40N4eDjh4eEkJSU55gwePJgxY8Y4tnv06MEXX3zBzJkzOXbsGMuWLeOVV16hR48emQpxC53KHeG2ty9t//4knLxy+VHTBVYH/3KQkQZHV5udpkCxuLnhe/vtlPvhe7wnTsTj32Vq4f8LhhYUmIIhANLSsHi4g81G/Jq1hI8bR/y69disVrOTiYiIiIiIXFeWlx6rV68eTZo04aGHHnIUClksFkaPHp1r4UREpGDx8/PDMAzHfRERKdx2797tuP/UU0/x9NNPc/jwYZo3bw7A5s2b+eyzz3j77bevdYor+Pj4UKdOnUxjXl5eFC9e3DH+4IMPMmrUKIoVK4avry9PPvkkLVq0cDxuly5dqFWrFvfddx/vvvsu4eHhvPzyywwfPtyxRMujjz7KpEmTeP7553nggQdYuXIls2fPZuHChY7HHTVqFEOGDOGWW26hadOmfPTRRyQkJDB06FDA/r3uv7KIiEjR9MUXXwDQvn37TOPffvst999/PwChoaGZOgi9/PLLGIbByy+/zOnTpwkMDKRHjx68+eabeRXbPE0fhrN7Yfu3kJEKM++BYavA7/rLteUpw7B3Fdr2NRxaCtW6mZ2oQHJp2IDSXbuQtO1PIj/9lMQ//wQuFgw9R+Tnn1Pi8cfxvb1bvl+SzHB1pfiDD+LVug3Rs2aRFhbGhZ9+ImH9evz798et0n93EhMRERERETFDlguF1qxZw7fffsszzzzDyJEj6du3Lw899BBt2rTJzXwiIlKAfPvtt7z22ms8++yzfPvtt2bHERGRXNagQQMMw8i0HMrzzz9/xbx77rmH/v3759jjTpw4EYvFQt++fUlJSaFr1658/vnnjv1OTk4sWLCAxx57jBYtWuDl5cWQIUN47bXXHHMqVqzIwoULGTlyJB9//DFlypThm2++oWvXro45/fv359y5c4wdO5bw8HAaNGjA4sWLCQ4OznIWEREpmrKyVNjq1aszbTs7OzNu3DjGjRuXS6nyMcOA29+D84fh+DpIOAszBsIDi8HVy+x0l1RoDTt/gvgIOLMLnEuZnajA8mrWFK9mP5CwZWuBLxhyr16N4BfHEL92LTHz55N64gRn332XEo8/hke9embHExERERERuYJhy+Yi5wkJCcyePZtp06axbt06qlSpwoMPPsiQIUMICQnJrZw5JjY2Fj8/P2JiYvD19b2xk7yqLhm55tWYXDlt3e/q5sp5xe7vIX/n+Dn31aiZ4+eUS2ruv3JpmKzIyv+hTk5OnDlzhqCgoJuJWCDc9PcUfT/JPfp+UiDlxvcT0PeU3OS5ZHGW55YvXz7Tdo78XF5I6FoUTfqeknv0/aRgys3XKEXFzV4Lq9XK2bNnCQoKytTpKE8lRsHXHeDCcft2zZ7Q7zswK8/VbJ8GB/7AWrIhZ2veb+71KmCu9TVms9lI3LKVyEmTHAVDF7lWrFhgCoYAMmJjiZk7l5TDRwh55WUMV9cbPle++DdZwNzMNdP3ExEREREpSrL9CsPLy4uhQ4eyZs0aDh48SL9+/fjss88oV64cPXv2zI2MIiJSgGSz/lRERAqw8uXLZ/kmIiIi8p88i8HAmeDqY9/e9zusecfcTP+vahfwLQUl65udpNAwDAOv5s0o98P3lJs2DY9bGjv2XewwdLRHT2IWLMSWkWFi0v/m5OtLsSFDCH75JUeRkC0jg/NTppB88KDJ6UREREREROyyvPTY1VSpUoUXX3yR8uXLM2bMGBYuXJhTuUREpAAzDMPsCCIiYoKwsDDWr1/P2bNnsVqtmfY99dRTJqUSERGRAiWoJtw1Bab3B2yw5m0IrA51+pidzM63FHT/EGw2OHvW7DSFysWCIc9mTUncspVzkz4l6c/tAKQePUrYs89eWpKs2235usOQxc3NcT9+3ToSt/1J4rY/8WzSBP++fXDy9zcvnIiIiIiIFHk3XCi0du1apk6dyq+//orFYuHuu+/mwQcfzMlsIiJSQFWrVu0/i4WioqLyKI2IiOSFadOm8cgjj+Dq6krx4sUzfR8wDEOFQiIiIpJ11brCra/Bslfs2/Meh2IVoVRDc3NdZBj2QiFrOqTGg7uWKcpJhalgCMDzliaknT5NwvoNJG7bRtLu3fh2vx2fjh0xnG/qc7wiIiIiIiI3JFuvRMLCwpg2bRrTpk3j8OHDtGzZkk8++YS7774bLy+v3MooIiIFzPjx4/Hz8zM7hoiI5KFXXnmFsWPHMmbMGCyWbK9wLCIiIpJZyyfh7D7YNR3Sk2DGPTBsFfiEmJ3Mwf3oEozNW6Hpw1DmFrPjFDqZC4a2cG7SpAJZMOTk7UWxQYPwbt2aCzNnkXrsGDFz5pKwYSMBA/rjXrOm2RFFRERERKSIyXKhULdu3Vi+fDklSpRg8ODBPPDAA1SvXj03s4mISAE1YMAAgoKCzI4hIiJ5KDExkQEDBqhISERERHKGYUCPj+D8YTi1FeLCYOY9cP9CcPEwOx1Y03EJ/wtSLsDa96B8S2g8VN2FcoG9YKg5ns2aFeiCIdfy5Ql6/jkSN28mes5c0iMiiF30B241amgJdxERERERyVNZfhffxcWFX375hVOnTvHOO++oSEhERK5Kb26JiBRNDz74ID///LPZMURERKQwcXaDAT+Bbxn79unt8PtT9mW/zGZxJq7FC9hq9gQMOLERFj4DJzaZnazQulgwVP6HHyg37Vs8Gjd27LtYMHS0553ELFyILSPDxKTXZhgGXi1aUHL8q3h37IB///6O91GsKSnYUlNNTigiIiIiIkVBljsK/f7777mZQ0RECglbfnjDVkRE8tyECRO44447WLx4MXXr1sXFxSXT/g8//NCkZCIiIlKgeQfBwBkwtSukJcLfsyGoJrQZZXYycHKFBvdA+Raw+XOIOQUbPoLQjXDLg+Dhb3bCQumKDkOfTiJp+78dho4cIeyZZ4n8/AtKPP4Yvrflzw5DFk9PAu6+O9NYzO+/k7x7N/53341H3bomJRMRERERkaIgy4VCIiIiWWG1Ws2OICIiJpgwYQJLlixxdB69vMOcus2JiIjITSlZD3p/CbPvs2+veA0Cq0ON7ubmuqh4ZbjtbfhnLvwzD8J2QFqSCoVyWWEoGLrIlppK0o6dZERFEfnZ57jXrYPfXXeZHUtERERERAopFQqJiIiIiMhN++CDD5g6dSr333+/2VFERESkMKrVEzq8DKveAGzw68Pw4FIIqWN2MjsnF6h3N5RpArGnwbfkpX1pyeDibl62Qi5TwdDmzZyb9FmBKxgyXF0JGfsKsYv+IG7lCpL/3kPy3n1YmzUlo1cvLL6+ZkcUEREREZFCxGJ2ABERERERKfjc3Nxo1aqV2TFERESkMGv7LNTpa7+flgAzBkJCpLmZ/l+xilCh9aXtcwfgt8fhyErQUt25yjAMvFq0oPyPP1Du26l4NGrk2HexYOjonXcSu2gRtowME5NencXdHf8+vQl5+WXcatbAlpFO2qrVhI95kaS//zY7noiIiIiIFCIqFBIRERERkZv29NNP8+mnn5odQ0RERAozw4A7P4NSDe3bMaEw615ITzU31/UcXAypCbDlS1j1FsSfMztRoecoGPrpxysLhg4f4fSoZ/J1wZBLSAiBTz1F8WHDsJQqBYBrxYqO/WlnzpARn2BWPBERERERKQS09JiIiIiIiNy0rVu3snLlShYsWEDt2rVxcXHJtH/OnDkmJRMREZFCxcUDBkyHrzpAfDiEboKFI6HnJHshUX7T4gkIqAC7Z0P4blj0DDS4F6remj/zFiIXC4Y8mze3L0n26SSS/voLuFQw5FrlcwIffxyfrl3z1ZJkhmHg0aABnqVKUczJCSdvb8e+qB9/JC30JB6NG+Hdpg2ulSph6GtJRERERESyQYVCIiIiIiJy0/z9/enTp4/ZMURERKQo8C1lLxaadjukJ8OOHyGoNrR43OxkV7I4Qa07oUwT2PwFRB6EP6fYC5yaPQo+wWYnLPQKcsEQgHPx4o771uRkbCmp2NLSSNy8hcTNW3ApVQqvNq3xatYMi6eniUlFRERERKSgUKGQiIiIiIjctG+//dbsCCIiIlKUlGlsX4bs1wft20tfghLVoGpnc3Ndi28p6DzevhTZrulwdi+c26dCoTyUqWBo0ybOTfrs2gVDt92GYbGYnPhKFnd3gl96kdRjx0lYt5bEP7eTFhZG9KzZxMyZi9+dPfHpnE//DYiIiIiISL6R/17tiIiIiIiIiIiIiPyXundBm2ft921W+GUonDtobqbrsVigxu1w+/tQuzdUbHdpX0a6ebmKGMMw8GrZkvI//Ui5qVPwaNjQse9iwdDRnj2J/eMPbFariUmvzjAM3CpVpNiQIZR65238774bl1IlsaWl4eTv75hnTUrCmpxsXlAREREREcm31FFIRERERERuWsWKFTEM45r7jx49modpREREpMjo8BKc2w/7F0BKLMzoDw+tAM9iZie7Np8QqD/g0nZqAiweA1U6Q4077AVFkusuFgx5tmhh7zD06SSSduwA/i0YGjkK1yqVCRw+3L4kWT78e7F4euLTsQPeHdqTevQoruXLO/bFr1lD7B+L8WzSBO82rTPtExERERGRok2FQiIiIiIictNGjBiRaTstLY0dO3awePFinnvuOXNCiYiISOFnsUDvL2FqV4jYA1FH4ef74d5fwcnF7HRZc3Q1xEfAzp/g5BZo9ij4lzU7VZGRlYIht6pVKPH44/m2YMgwDNwqV840lnLoMLaUFBLWrydh/Xpcy5fHq00bPJvcgsXNzaSkIiIiIiKSH6hQSEREREREbtrTTz991fHPPvuMP//8M4/TiIiISJHi5g0DZ8BXHSAxEo6tsXfo6f6+2cmypvrt4OIBf/0A5w/D4tFQpy/U7AlOevs2r1yvYCjl0OECUTB0uRJPDCfl0CES1q0jcccOUk+cIPXECaJ/+QXv1q3wv+susyOKiIiIiIhJ8verGRERERERKdC6devGr7/+anYMERERKez8y8GAn8DybxehbV/Dtm/MzZRVhgGVO0L3D6BUI7Cmw+5ZsPQluHDc7HRFzsWCofLTf6LslG/waNjQse9iwdCxO+8kdvFibFariUmvzzAM3KtVo/iDD1JqwgT8+vbBOTAQW3IyGXHxmebaUlNNSikiIiIiImZQoZCIiIiIiOSaX375hWLFipkdQ0RERIqCcs2hx8eXthc9D0fXmJcnuzyLQbvnocVwcPWyFwntW2B2qiLLMAy8W7W6VDDUoIFjX8qhw5weMbJAFAwBOPn44HvrrYS8Np7AEU/j27WLY1/qqdOEjR7NhZmzSDt92sSUIiIiIiKSV9S7VkREREREblrDhg0xDMOxbbPZCA8P59y5c3z++ecmJhMREZEipeEgOLsXNk0CWwbMHgwPr4Tilc1OljWGARXbQkhd2DXL/nwustns+yVPXSwY8mrZkoSNG4n8dBJJO3cClwqG3KpWocTw4fh06ZKvlyQzDAP3GjUyjSVt/xNrYhLxq1cTv3o1rpUr4d2mLZ6NGmK4upqUVEREREREcpOpr1rWrl1Ljx49KFWqFIZhMG/evP88ZvXq1TRq1Ag3NzeqVKnCtGnTcj2niIiIiIhcX69evbjzzjsdtz59+jBu3Dj27NnDsGHDzI4nIiIiRcmtr0GVW+33k6NhxkBIjjE1UrZ5BEDzR8HNx75ts8H6D2HndEjXMlFmcHQYmjG9wHcYupxvz56UePIJ+/OxWEg9cpSoadMIGz2GCz//jDUx0eyIIiIiIiKSw0ztKJSQkED9+vV54IEH6NOnz3/OP3bsGN27d+fRRx/lp59+YsWKFTz00EOULFmSrl275kFiERERERG5mnHjxpkdQURERMTO4gR3TYFvboXIA/bbLw/CPbPs+wqiyINwcqv9/smt0PwxCKxubqYiKlOHoQ0biZxUcDsMgf35eNSujUft2mRER5OwcSPx6zeQERVF4rZt+Pfu7Zhrs9kydREVEREREZGCydRCoW7dutGtW7csz588eTIVK1bkgw8+AKBmzZqsX7+eiRMnqlBIRERERERERERE7Nz9YOAM+KYTJF2Aw8tg2Vjo+qbZyW5MYHVo+xxs/RrizsCycVC9G9QfAM5uZqcrkgzDwLt1K7xaXa9gqOq/BUO35vuCIQAnf398b78dn9tuI/mfvVgTEzGc7b9CsFmtnH3nHdyqVcOrdRtcgoNMTisiIiIiIjcq/786ucymTZvo3LlzprGuXbuyadOmax6TkpJCbGxsppuIiBQ8n332GRUqVMDd3Z1mzZqxdevWa879559/6Nu3LxUqVMAwDD766KObPqeIiFydxWLBycnpujdnZ1M/nyAiIiJFVfHKcPf3YPn3Z5FNk2DHj+ZmuhllboHuH0DFdoANDiyCRc9BxF6zkxVpFwuGys+YTtlvvsGjfn3HvpRDhzg9YgTH7uxF7OIlBWZJMsNiwaNuHbyaNXWMJe/dR+qJUOKWLSd83DjOTvyIxO3bsaWnm5hURERERERuRIF6xz48PJzg4OBMY8HBwcTGxpKUlISHh8cVx0yYMIHx48fnVUQREckFs2bNYtSoUUyePJlmzZrx0Ucf0bVrVw4cOEBQ0JWfYEtMTKRSpUr069ePkSNH5sg5RUTk6ubOnXvNfZs2beKTTz7BWkB+ISIiIiKFUMW20O1dWDjKvj1/BBSvAuWamxrrhrl5Q4vH7fm3fQPxEbDlC+g+EZwK1Fu9hc4VHYY+/ZSkXbuASwVDBa3D0OXca9agxGOPEr9uPcn//EPKgQOkHDiAxccHr5Yt8W7fDueAALNjioiIiIhIFhSsVyM3YMyYMcTExDhuJ0+eNDuSiIhk04cffsjDDz/M0KFDqVWrFpMnT8bT05OpU6dedX6TJk147733GDBgAG5uV2/Bnt1ziojI1d15551X3GrUqMG0adN4//336devHwcOHDA7poiIiBRlTR6EJg/b71vTYOYgiA41N9PNKt0Ibn8PKneCpsNUJJSPODoMzZxRaDoMARhOTnjUr0/gE8Mp+cbr+N7eDSc/P6xxccQtWULGhWizI4qIiIiISBYVqEKhkJAQIiIiMo1FRETg6+t71W5CAG5ubvj6+ma6iYhIwZGamsr27dszLT1psVjo3LnzdZeezI1zajlLEZHrCwsL4+GHH6Zu3bqkp6ezc+dOvvvuO8qXL292NBERESnqbpvw75JdQGIkzBgIKfHmZrpZrl7QbBiE1L00dnApbPkSUhPMyyXA/xUMff311QuGevUmdsnSAlUwBOBcvDh+PXtS8s03KP7IMLzbtcW1YgXH/pjffyfmt99IP3/evJAiIiIiInJNBapQqEWLFqxYsSLT2LJly2jRooVJiUREJLdFRkaSkZFx1aUnw8PD8/ScEyZMwM/Pz3ErW7bsDT2+iEhhExMTwwsvvECVKlX4559/WLFiBfPnz6dOnTpmRxMRERGxc3KBftOgWCX7dsQemPsIFLACjetKTYCdP8GRlbDwWTi93exEwr8FQ21aX71g6OBBTj/9dIEtGDKcnfFs2JCAgQMxDAMAa3IycStWEvvHYs68/ArnPp1E0q5d2DIyTE4rIiIiIiIXmVooFB8fz86dO9m5cycAx44dY+fOnYSG2lv/jhkzhsGDBzvmP/rooxw9epTnn3+e/fv38/nnnzN79mxGjhxpRnwRESlitJyliMiV3n33XSpVqsSCBQuYMWMGGzdupE2bNmbHEhEREbmSZzEYOAvc/Ozb+xfAqjfNzZSTXL2g3QvgHQxJUbDmXdg4CVLizE4mXFkw5F6/nmNfQS8Yupzh7EyxwffhVqM62Gwk//MPkV9M5sxLLxMzfwHpFy6YHVFEREREpMgzdfHqP//8kw4dOji2R40aBcCQIUOYNm0aZ86ccRQNAVSsWJGFCxcycuRIPv74Y8qUKcM333xD165d8zy7iIjkjRIlSuDk5HTVpSdDQkLy9Jxubm64ubnd0GOKiBRWo0ePxsPDgypVqvDdd9/x3XffXXXenDlz8jiZiIiIyFUEVoO7psL0fmCzwrr3IbAG1OtndrKcEVwLbn8Pds+C/Yvg+DoI3w1NHoKyTc1OJ1wqGPJq3YqE9Rs4N+lTknftBi4VDLlVq0bxxx/DVq/ef5wt/zGcnfFs3BjPxo1JizhLwvr1JGzaREZ0NLELF4LNil/PnmbHFBEREREp0kwtFGrfvj02m+2a+6dNm3bVY3bs2JGLqUREJD9xdXWlcePGrFixgl69egFgtVpZsWIFTzzxRL45p4hIUTV48GDHMgMiIiIiBULVztDlTVgyxr7923D7kmRlGpubK6c4u0GjwVC2OWz5AmLDYP1EuGMi+NzYB24k5/1XwVDYiJE4VaqE672D8OvWDeeAAJMTZ59LcBD+ffvg17MHSTt3Er9+A16tWjn2J+/fT+rRo3i1bImTv795QUVEREREihhTC4VERESyYtSoUQwZMoRbbrmFpk2b8tFHH5GQkMDQoUMB+y+pS5cuzYQJEwBITU1l7969jvunT59m586deHt7U6VKlSydU0REsuZqxf0iIiIi+V7zx+DsXtjxA2SkwMx7YNgq8C1ldrKcE1gNbnsH9vwKFicVCeVTmQuG1nNu0iRHwVDG0aOcfe11zr41Aa9WLfG7owc+HTtg8fIyOXX2GC4ueDZpgmeTJpnG45avIHnPHmIWLMSjXj282rTGvVYtfRBBRERERCSXqVBIRETyvf79+3Pu3DnGjh1LeHg4DRo0YPHixQQHBwMQGhqKxWJxzA8LC6Nhw4aO7ffff5/333+fdu3asXr16iydU0RERERERAoxw4DuH8L5IxC6EeLD7cVC9y8CV0+z0+UcZ1doMDDzWHSovXio8f3gUfC61BRW9oKhNni1bm0vGPp0Esm77QVDpKeTsGYtCWvWYnh44NOxI753dMe7VSsMV1dzg98Ez6ZNsCUnkXL4CEk7d5K0cydOJYrj3bq1vcuQr6/ZEUVERERECiUVComISIHwxBNPXHNZsIvFPxdVqFDhuktbZuWcIiIiIiIiUsg5u0L/H+CrDhATCmE77MuQ3TXVXkhUGNlssPVriDwI4X/bi4UqtCm8z7cAulgw5NGyJWc2bcJl0yZiF/1B+pkzANiSkohduJDYhQtx8vPD57bb8OtxBx6NGmFc9iGqgsCraVO8mjYlLSyM+HXrSdyymYzI88TM+42kXbsJfuF5syOKiIiIiBRKBeuVg4iIiIiIiIiIiEhO8SoB98wEV2/79j9zYO375mbKTYYBTR6EgAqQmgCbPoM170LCebOTyf8xDAPnKlUIfOYZqqxYTvkfvse/f3+c/PwcczJiYoieNYsT997H4U6dOfv++yTv35+lD0/lJy6lShHQ/25Kvv02xYYMxrViRbxatnDstyYmErtsGRlxcSamFBEREREpPFQoJCIiIiIiIiIiIkVXcG3o8zXwb1edVW/A3t9NjZSrAipAlzeh/gCwOEPYX7DoGTiy0t5xSPIdw2LBs0kTSo5/larr1lLmi8/x7d4dw8PDMSf9zBnOfzOFY716c7RHDyInTyb15EkTU2efxdUVrxYtCH7hebxat3aMJ27bRsyvcwgbM4bzU6aQfOBggSuGEhERERHJT1QoJCIiIiIiIiIikoMmTJhAkyZN8PHxISgoiF69enHgwIH/PC46Oprhw4dTsmRJ3NzcqFatGosWLcqDxEKN26HT2Evbcx+BM7vNy5PbnJyhdm/o9g4UrwJpSbDlSzix0exk8h8MV1d8OnSg9AfvU239Okq99x7e7dqBs7NjTurhI5z76GOO3NqF4/0HEPXDj6RHRpqYOvuMy5bDc/L3x7V8eUjPIHHbn5ybOJHwV8cTt3w5GfEJJqYUERERESmYnP97ioiIiIiIiIiIiGTVmjVrGD58OE2aNCE9PZ0XX3yRLl26sHfvXry8vK56TGpqKrfeeitBQUH88ssvlC5dmhMnTuDv75+34Yuy1iPh7D74ezakJcKMgTBsFXgHmZ0s9/iVgVtfhwML4fRfUK7Ffx8j+YbFywu/Hnfg1+MO0i9cIG7xYmIWLCRp+3bHnKRdu0jatYuIt9/Gq0ULfO/ojk/nzjh5e5uYPHs86tfHo359UkNDiV+3jsSt20iPiCD6l1+Jmb+AUhPewuLpaXZMEREREZECQ4VCIiIiIiIiIiIiOWjx4sWZtqdNm0ZQUBDbt2+nbdu2Vz1m6tSpREVFsXHjRlxcXACoUKFCbkeVyxkG9PwUoo7A6e0QewpmDoL7F4Czm9npco/FAjV7QI077NcAID0V/pxi7zrkE2JuPskS54AAAgYOJGDgQNJOnyZm0SJiFywk5WI3s4wMEtavJ2H9esLdXsW7Qwf87uiOV9u2WFxdzQ2fRa7lylFs0CD8+/Ylcds24teuw7lYQKYiIVtqqokJRUREREQKBhUKiYiIiIiIiIiI5KKYmBgAihUrds05v//+Oy1atGD48OH89ttvBAYGcs899/DCCy/g5OR0xfyUlBRSUlIc27GxsQBYrVasVmu2M1qtVmw22w0dW6g4ucLdP2J80wkjLgxObcX2+1PY7vz8UhENhfh62Wz2P/f8gnFkFRzfgK3+AKh2GxiWmzp1ob1mueRmrpdTyZIUe/BBij34ICmHDhG7cBFxCxeSdvo0ALaUFOIWLyZu8WIsvr743HorPt1vx7NJE4yr/H+T77i64tmqFR4tW2JLTXVco/TERGwWyw3/HygiIiIiUlSoUEhERERERERERCSXWK1WRowYQatWrahTp8415x09epSVK1cyaNAgFi1axOHDh3n88cdJS0tj3LhxV8yfMGEC48ePv2L83LlzJCcn31DOmJgYbDYbFsvNFYQUfBacu3xK8d8GYaQnY+yeSZxnORIbPOiYUdivl8W3Hp7eu3COOgCbvyF9/0oS6w7G6n3j3YUK+zXLaTl2vfz84J6BeA0cQMbevaQuX0HqqlXYoqPtjxMbS8yvvxLz668YJUrg2rEDrp064VStGsZlxXEFQUZKCrGJiWCxZPuaxcXF5VIqEREREZH8R4VCIiIiIiIiIiIiuWT48OHs2bOH9evXX3ee1WolKCiIr776CicnJxo3bszp06d57733rlooNGbMGEaNGuXYjo2NpWzZsgQGBuLr65vtnFarFcMwCAwMVBEHQFBHbMYXGL8MBcBn83t4V2gE1boCReF6BUH5t+DICoydP+GWeAqvP9/DVucu+xJllux3nSn81yxn5cr1Cg6GDh2wpaWRuHmzvdPQ8uXYEhMBsEVGkjL7Z1Jm/4xLhQr4du+Ob/fuuFYonzOPn8usViuWc+du6Jq5u7vnUioRERERkfxHhUIiIiIiIiIiIiK54IknnmDBggWsXbuWMmXKXHduyZIlcXFxybTMWM2aNQkPDyc1NRVXV9dM893c3HBzc7viPJYb6KRxkWEYN3V8oVOnD5w7AGvexsCGMedheGgZBNUEisj1qtYFSjeGrV/BmZ0Yu2dCSiw0HnJDpysS1ywH5dr1cnPDp107fNq1w5qURPzq1cQsWEj82rWQlgZA2vHjnP/sM85/9hnuderge0d3fG+/HZegoJzNksNu9Jrpa1JEREREihL99CsiIiIiIiIiIpKDbDYbTzzxBHPnzmXlypVUrFjxP49p1aoVhw8fxmq1OsYOHjxIyZIlrygSkjzU7gWodaf9fmoczBgACefNzZTXvIpD+9HQ/DHwLAE1upudSHKQxcMD327dKPvZJKqtW0vI66/h2awZXLbsWPKePZx9+x0Ot2vPiaFDif71VzJiY01MLSIiIiIiN0OFQiIiIiIiIkXYsGHDqFu3Ln5+fvj4+NC4cWNmzJhx1blTp07FMAwMw2DAgAGO8fT0dF5++WWqVq2Kh4cHAQEBtG7dmiVLllz3sT/++GPq16+Ps7MzhmFw//33XzHngQceoFKlSo7HnTZt2hVzFi5cSOPGjXF3dycoKIhHHnmEuLi4bF0HEZGcNHz4cH788UemT5+Oj48P4eHhhIeHk5SU5JgzePBgxowZ49h+7LHHiIqK4umnn+bgwYMsXLiQt956i+HDh5vxFOQiiwV6fQEh9ezbF47D7MGQkWpqrDxnGFCpPfT4GLxKXBr/Zx5EHTMrleQwJ39/Avr1o/x306iyaiVBzz+Pe61alybYbCRu2syZl17mUKvWnHrySWIXL8GanGxeaBERERERyTYVComIiIiIiBRhX3/9Na6urvTr14+aNWvy119/cc8997B48eJM8/bv38+TTz6Js/OVK1hPnDiRN998k5MnTzJgwABq167Nhg0b6NmzJ2fPnr3mY//555/4+/tTrly5a87ZsGEDtWrVwsPD46r7t2/fTs+ePdm9ezd33XUXQUFBfPXVV1ctOhIRyStffPEFMTExtG/fnpIlSzpus2bNcswJDQ3lzJkzju2yZcuyZMkStm3bRr169Xjqqad4+umnGT16tBlPQS7n6gUDZ4DXv0sunViP8cfzYLOZm8sMTpf9HHBmN+yaAUtehF0zISPNvFyS41xCQij+wFAqzvmVSosWUuLxx3G57Gc2W1oaccuWc3rECA61ak3Y6DHEr9+ALT3dxNQiIiIiIpIVV77DKyIiIiIiIkXG5s2badasGWDvDFStWjWOHTvGH3/8wW233QZASkoKAwYMoGrVqtSsWZOZM2dmOsehQ4cA6N69O99++y1nz54lODiY1NRUwsLCCAoKuupj//DDDwAMGDCAY8eu3o3gwIEDAISEhGTqxHHRm2++idVqZcSIEXzwwQdERkYSEhLCnDlz+Pvvv6lbt+4NXBURkZtjy0IByerVq68Ya9GiBZs3b86FRHLT/MrAgOkwrTtkpGD89R2enuUgeJTZyczjXw7KNoOTW+CfuXByKzR/HEpUMTuZ5DC3SpUIfOpJSjz5BMl79hAzfz6xi/4gIzISAGtCAjHz5hEzbx5OJUrg260bfnd0x71ePYzLljATEREREZH8QR2FREREREREirCLRUIXpaSkAFC6dGnH2DPPPMORI0eYPXs2bm5uV5xj2LBhBAQEsHDhQoYOHUqfPn0AuO+++2jQoEHuhQf++usvAJo2bQpAiRIlqFLF/gvKHTt25Opji4hIEVO2CfT8xLHps+Et2DQJ0ovYMmQXefhDm1HQeiS4+ULsaVj6Muz4sehek0LOMAw86tYl5MUXqbpmNeWmTsGvTx8s3t6OORmRkVz44QeO9x/AkS5dOfvxx6QcOWJiahERERER+X8qFBIRERERERGsViuPPvooYWFh1K5dm8ceewyAefPm8dlnn/HZZ59RrVq1qx5bq1YtevfuTUpKCtOmTWPDhg2UKVOGnj175nru8PBwALwv+wXVxfuXL+kjIiKSI+oPgFYjADBsGViWvQKfN4N984vmUmQA5ZpD9w+gQmvAZr8WK18vutejiDCcnPBq2ZJSb71J1Q3rKf3Jx/h06YLh6uqYk3byJOe/mMzR7ndwtHcfzk+ZQpp+PhMRERERMZ0KhURERERERIq4hIQEevfuzZQpU2jYsCErV67Ex8cHgO+++w53d3dmz57NHXfcwYoVKwBYt24dDz74IACvvPIKU6dOpVWrVkRFRbFlyxbCwsK4++67+eeff3I1e0hICADx8fGOsbi4OABKliyZq48tIiJFVKex2G558NJ21FGYda99WbKwItrNzt0XWj4JbZ8DjwCofjtoyakiw+Lmhm+XLpT55GOqblhPybfewqtlC7Bc+vVDyr59nH3vfQ537MSJ+wZzYdZsMqKjzQstIiIiIlKEqVBIRERERESkCAsLC6Nt27b8/vvv9OjRg7Vr1xIUFOTYb7PZSE5OZuHChSxcuJBTp045jrtYNHTgwAEAateuTUBAAI0aNcLDwwObzcb+/ftzNX/Dhg0B2Lp1KwCRkZEc+Xd5i9xe9kxERIooixO2298nsu+v2Mq3ujR+YgN81QHmPgaxYeblM1OZW+COj+xdhi46vR3C95gWSfKWk48P/n16U27qVKqsXkXwi2Nwr1fv0gSbjcRt2wgfN46Dbdpy8rHHiVm4EGtionmhRURERESKGBUKiYiIiIiIFGHNmjXjr7/+wtfXlwoVKvDyyy8zYsQIpk+fDtiXHrPZbI7bkCFDAOjfvz/Hjx8HoF27doC9+9D9999Pp06dSEhIwMPDg6ZNmwJw//33YxgG999/v+Oxv/nmG+6//362bNkCwPr167n//vt5++23HXOeffZZ7r//fmJiYjIdM2/ePABefPFFLBYLn3zyCffeey/t27cnIyODXr16Ue/yX0qJiIjksPTAOtgGz4f+P0GxSv+O2mDXdPikEayaAKkJpmY0hYv7pW5CyTGw+Qv7UmTbvsFIUzFIUeISFESxwYOpOHsWlZcspsRTT+JaseKlCWlpxK9aRdgzz3KwdRtOP/c88WvXYktLMy+0iIiIiEgR4Gx2ABERERERETHPxQ5BsbGxfPrpp47xIUOGcM8992TpHM888wwpKSn8+OOPzJ49G3d3d9q1a8fYsWMpW7YsYO9MBODsfOll6Pr16/nuu+8c20eOHOHIkSO0a9eO0aNHA/DLL79w4sQJx5wNGzawYcMGKlSoQK9evWjSpAlz587l1Vdf5eeff8bX15eHH36Y999//waviIiISDYYBtS8A6p2gW3fwJq37cUx6Un2+9unQaexUH9gpmWYigwnVyjbDA4vxzi8HL/9y6BiMyjfCko1tBcVSZHgWr48gY8/TonHHiNl3z5iFiwkduFC0iMiALAlJhI7fz6x8+fjFBCAb7fb8L3jDjwaNMAoiv92RERERERykQqFREREREREirCLBTxZNW3aNKZNm5ZpzGKx8PLLL/Pyyy9f87gdO3bg4eHBqFGjrnuu/3exa9H19OzZk549e/7nPBERkVzj7AotHof6A2DNO/aiIWs6xIfDb4/DlsnQ9S2o2MbspHnLxQOaPgzlWsCfU+DcMYyTW+HUNnBygRZPQrlmZqeUPGQYBu61auFeqxZBz4wi8c/txC5YQOySJVhjYwHIuHCBC9NncGH6DFxKlcK3e3d877gD9+rVTE4vIiIiIlI4qBRfREREREREctWZM2f4+++/eeedd6hVq5bZcURERHKPZzHo9g48vhmq335pPHw3fHcHzBwE54+Yl88sIXWwdXufuFYvYavVC7yDISMNAspfmnN2P4RugfQU02JK3jKcnPBq1pSSr79G1fXrKPP5Z/je3g3D/VKnqbSwMM5//TXH7ryToz16EvnlV6SeOm1iahERERGRgk8dhURERERERCRXlSxZMtudi0RERAq0ElVh4Aw4ugaWvAQRf9vH9y+Ag4uh6TBo+5y9sKioMAwyfMtClcbQYCDEnAKfkEv7982H03+CsxuUbmzvQlSygb1bkxR6FldXfDp2xKdjRzLiE4hfuYKYBQtI2LARMjIASDl0iHMTJ3Ju4kQ8GjXC947u+N52G87FitC/IxERERGRHKBCIRERERERkYLsVT+zExRur8aYnUBERAqySu3gkTWwawaseA3iI+xLkm3+HHZOh/aj4ZYHi14xjGGAf9nMY/7lIPo4JETCiY32m7MblL4FyreEMreYElXynpO3F349e+LXsyfpUVHE/vEHsQsWkrRjh2NO0l9/kfTXX0S8+RZerVrid8cdeHXoYGJqEREREZGCQ4VCIiIiIiIiIiIiIrnF4gQN74VavWDjJ7DhE0hPguRoWDwatn4NXV63L1VmGGanNU/9/lDvbvvSbKGbIHQzJEbCiQ2QcC5zoZA1w35dpdBzLlaMYoMGUWzQIFJPnSJ24SJiF8wn5dBh+4SMDBLWriNh7ToMd3ecW7TAe8hgvJs3Nze4iIiIiEg+ZjE7gIiIiIiIiIiIiEih5+YNHV6EJ/+EegMujUcdgZn3wHc94Mwu8/LlB4YBJapAo/vgzknQ5Q2o0R2qdL40JyUO5gyDjZPg9HbISDMvr+Qp1zJlKPHIMCrNn0/F336j+MMP41yqpGO/LTmZtFWrSPprx3XOIiIiIiIi6igkIiIiIiIiIiIiklf8ykCfL6HZI7DkJQjdaB8/vg6+bAcNBkHHl8G35PXPU9gZBpSoar9dLmwHpMbbr9fxdeDiCWWaQLnmEFIPnPSWd1HgXr0a7tVHEThyBEk7dhCzYAFxfywmIzoanzu6mx1PRERERCRf06smERERERERERERkbxWuhEMXQT75sOyV+DCccAGO3+Ef+ZAqxHQ8glw9TI5aD5ToQ14B19anizpAhxbY7+5eEKbZyCkjtkpJY8YFguejRvj2bgxQaNHE7ZmDa5lypgdS0REREQkX9PSYyIiIiIiIiIiIiJmMAyo1ROGb7Uvs+XmZx9PS4TVb8Gnt8DOGWC1mpszPzEMCKwOje+HXl9A5/FQ7TZw94e0JHvHpovC99g7EGWkm5VW8pDh4oJLvXpmxxARERERyffUUUhERERERERERETETM5u0PJJqH8PrHkbtk0BWwbEhcG8R2HLZOj6FlRoZXbS/MUwIKiG/dZoCESfAA//S/v3/Apn94Krt315svItIKi2licTEREREZEiTR2FRERERERERERERPIDr+Jw+3vw+GZ7l5yLzuyEabfDrHvh/BHT4uVrFgsUq3hp22YD/3Lg5gup8XB0Fax6C+Y+Alu+sncbEhERERERKYJUKCQiIiIiIiIiIiKSnwRWg3tmwX3zILjOpfF98+GzZrDkJUi6YFq8AsEw4Jah0PtL6PgKVOl8qWjoyAr7tbyczWZOThERERERkTymQiERERERERERERGR/KhyB3hkLfT4BLyC7GPWNNg0CT5pCFu+hIw0czPmdxYLhNSBpg9D78nQ8WV70VCl9pfmJJy3dxra9g1E/ANWq2lxRUREREREcpsWYxYRERERERERERHJryxO0HgI1OkD6z+yFwmlJ9s7Cv3xPGz9Grq8AdW62rvoyLVZnCCkrv12uVNbITkGDi2z39z9oGxTKNcSAmvYi41EREREREQKCb3CEREREREREREREcnv3Hyg0yvwxJ9Q9+5L4+cPwYz+8P2dEP63efkKsiq3QocXoVIHcPW6VDS0YjzMewzOHzE7oYiIiIiISI5RoZCIiIiIiIiIiIhIQeFfFvp+DQ+thLLNL40fWwOT28BvT0BcuHn5CiInZyhZH5o/Cr2/gvaj7UuTuXhCajz4lLw098xuOHcAbDbT4oqIiIiIiNwMLT0mIiIiIiIiIiIiUtCUaQwPLIa9v8GysRB9ArDBjh9gzxxoPRJaPgEuHmYnLVicnKFUQ/utycP26+rqeWn/zulw4Rh4FINyzaFcCyhRVcu+iYiIiIhIgaGOQiIiIiIiIiIiIiIFkWFA7V4wfCvc+hq4+drH0xJg1Rvw6S2wezZYrabGLLCcnKF45UvbGen2jk4uHpAUBQcWwbJX4LfhsP07LVEmIiIiIiIFggqFRERERERERERERAoyF3do9TQ8tQOaPASGk3089hTMeRi+6QQnNpmbsTBwcoYWw6HP19D2eajQBpzdIfG8vWho3++Z52t5MhERERERyYe09JiIiIiIiIiIiIhIYeBVArp/YF8ya9krcGipfTzsL/j2Nqh1J3QeD8UqmpuzoHNysS/9VqYxpKdC+G44sREqtLo0J+YUrJ5gX5qsXAsoVknLk4mIiIiISL6gjkIiIiIiIpKvTJgwgSZNmuDj40NQUBC9evXiwIEDmeYkJyczfPhwihcvjre3N3379iUiIiLTnNDQULp3746npydBQUE899xzpKenZ5qzevVqGjVqhJubG1WqVGHatGlX5Pnss8+oUKEC7u7uNGvWjK1bt2Y7i4iIiEieCqoBg36Ge+dAUK1L43t/g8+awtJXICnatHiFirMrlLkFWj0FpRtfGg/dDAmRsG8+LHkRfn8CdvxkX55MnYZERERERMREKhQSEREREZF8Zc2aNQwfPpzNmzezbNky0tLS6NKlCwkJCY45I0eOZP78+fz888+sWbOGsLAw+vTp49ifkZFB9+7dSU1NZePGjXz33XdMmzaNsWPHOuYcO3aM7t2706FDB3bu3MmIESN46KGHWLJkiWPOrFmzGDVqFOPGjeOvv/6ifv36dO3albNnz2Y5i4iIiIhpqnSCR9bBHR+BV6B9LCMVNn4CnzaCrV9DRvp1TyE3qGYPaD3K3k3IyfXfoqHf7UVD85+CmNNmJxQRERERkSJKS4+JiIiIiEi+snjx4kzb06ZNIygoiO3bt9O2bVtiYmKYMmUK06dPp2PHjgB8++231KxZk82bN9O8eXOWLl3K3r17Wb58OcHBwTRo0IDXX3+dF154gVdffRVXV1cmT55MxYoV+eCDDwCoWbMm69evZ+LEiXTt2hWADz/8kIcffpihQ4cCMHnyZBYuXMjUqVMZPXp0lrKIiIiImMrJGW4ZCnX6wvqJsOkzyEiBxPOw6Fl7sVCXN6DqrVoaKyc5u0G5ZvZbegqE7YDQTXB6O6TEgXfQpblndoGbLwRU0N+BiIiIiIjkOnUUEhERERGRfC0mJgaAYsWKAbB9+3bS0tLo3LmzY06NGjUoV64cmzZtAmDTpk3UrVuX4OBgx5yuXbsSGxvLP//845hz+Tkuzrl4jtTUVLZv355pjsVioXPnzo45Wcny/1JSUoiNjc10ExEREcl17r7QeRw8+SfUuevSeOQBmN4PfugNEf+Yl68wc3aDcs2h9Ujo8w10eBmcXOz7bDbYNgUWj4YFI2DXTLhwQsuTiYiIiIhIrlGhkIiIiIiI5FtWq5URI0bQqlUr6tSpA0B4eDiurq74+/tnmhscHEx4eLhjzuVFQhf3X9x3vTmxsbEkJSURGRlJRkbGVedcfo7/yvL/JkyYgJ+fn+NWtmzZLF4NERERkRzgXw7umvI/9u47LIqri+P4bwEBC2AXu6jYC4iiWDEaWzT22GKvCbaYxESNPUZNMdagsadYY0vUaNTYYu81sTdU1FjACgL7/rEvqxtQAcuy7vfzPPPoztyZPTNbzjBz9l6p41oph/+j+afXS5MrSr/2lG5fsV58r7sUrlLG/I8eRz2Q0uU2FQ7dDpWOLJF+7yvDyj5yPf6rdPea9WIFAAAA8FqiUAgAAABAshUUFKTDhw9r3rx51g7lhenXr5/CwsLM04ULF6wdEgAAsEc5y0gd/5CazJA8cpnmGWOkvbOlCaWkzd9ID+9bN0Z7kCKlVOlDqdFUqXxPKUdpycFJCr8s11MrpQNzrR0hAAAAgNcMhUIAAAAAkqXu3btr+fLlWr9+vXLkyGGe7+npqcjISN26dcui/ZUrV+Tp6Wluc+XKlTjLY5c9rY27u7tSpkypjBkzytHRMd42j2/jWbH8l4uLi9zd3S0mAAAAqzAYpGKNpe67pOpDJGc30/zIO9K6YdLEMtKhXxgG61VIkVLKU0Gq/LHUaKqMAd0VlaGgVKDWozbhl6Tjf0gPH1gvTgAAAAA2j0IhAAAAAMmK0WhU9+7dtWTJEv3555/y8vKyWO7n56cUKVJo3bp15nnHjh3T+fPnFRAQIEkKCAjQoUOHdPXqVXObNWvWyN3dXUWKFDG3eXwbsW1it+Hs7Cw/Pz+LNjExMVq3bp25TUJiAQAASPZSuEoVP5B67pNKd5AM/79sHHZBWtRRmlZdOr/DujHaE+dUUp6KuuP/gZSxwKP5x1ZKu6dLS7tJu2eaCocAAAAAIJGcrB0AAAAAADwuKChIc+bM0bJly+Tm5qbQ0FBJkoeHh1KmTCkPDw917NhRffr0Ufr06eXu7q4ePXooICBA5cqVkyTVqFFDRYoUUevWrfXll18qNDRUn332mYKCguTi4iJJ6tatmyZOnKi+ffuqQ4cO+vPPP7VgwQKtWLHCHEufPn3Utm1blS5dWv7+/ho7dqzu3r2r9u3bm2N6ViwAAAA2I00mqe63kn8XafUA6dT/i6Ev7pZm1JCKNpSqD5XS5bZunPYqnZfkllW6fVk6vso0ZS0pFagpZfWVHPhdMAAAAIBno1AIAAAAQLISHBwsSQoMDLSYP3PmTLVr106S9O2338rBwUGNGzdWRESEatasqe+++87c1tHRUcuXL9d7772ngIAApU6dWm3bttWwYcPMbby8vLRixQp98MEHGjdunHLkyKFp06apZs2a5jbNmjXTtWvXNGjQIIWGhsrHx0erVq1SlixZzG2eFQsAAIDNyVxYar1YOrFW+mOAdO0f0/wjS6R/Vkrl3pMq9ZFcPawbp73JX03K94YUelA6vlq6uFe6fMA0Zcgv1fjcNJwcAAAAADwFhUIAAAAAkhWj0fjMNq6urpo0aZImTZr0xDa5c+fWypUrn7qdwMBA7du376ltunfvru7duz9XLAAAADbJu7qUN1DaO1ta/4V0718pOkLaMlba95NUtb9Uqq3kyGXmV8ZgMPUilLWkdPuKdOIP6fR6ybP4oyIho9E0bFzaXNaNFQAAAECyRF+kAAAAAAAAAID4OTpJZTpKPfdKFXpLjs6m+ff+lVb0kSZXMPU8hFfPLYtUqrXUIFgqXO/R/Mv7pZUfS2sGS+e2SdFRVgsRAAAAQPJDoRAAAAAAAADwAo0cOVJlypSRm5ubMmfOrAYNGujYsWMJXn/evHkyGAxq0KDBywsSSCxXD+nNoVL3XVLRRo/mX/tH+rmx9FNj6erf1ovPnjm5SM6pHz2+dV4yOJhemy1jpV+7S4d+ke7fslaEAAAAAJIRCoUAAAAAAACAF2jjxo0KCgrS9u3btWbNGj18+FA1atTQ3bt3n7nu2bNn9dFHH6lSpUqvIFIgCdLlkZrOlDr8IWUv/Wj+ybVScHlp+QfSnWtWCw+SitSX6k+SijWWXNyl+zelQwulZUHS1gnSwwfWjhAAAACAFTF4NAAAAAAAAPACrVq1yuLxrFmzlDlzZu3Zs0eVK1d+4nrR0dFq1aqVhg4dqs2bN+vWrVsvOVLgOeQqK3VaKx1eJK0dIoVdkIwx0u4Z0sGFUuUPpbLvSSlcrR2pfUqVXirxjlS0oXR+u3R8lXT9pKm3ISeXR+2MRslgsF6cAAAAAF45CoUAAAAAAACAlygsLEySlD59+qe2GzZsmDJnzqyOHTtq8+bNT20bERGhiIgI8+Pw8HBJUkxMjGJiYhIdY0xMjIxGY5LWtUccr8cUbSQVqC3tCJbhr29liLwjRd6W1g6Rcdd0GasPkYo0VIzRyDFLhBf2HjM4SrkrmKbrp6SoB6biIKNRenhfhtX9ZMxZTvJ+U0qV4cUEbyXPc8x4XwIAAMCeJItCoUmTJumrr75SaGioSpYsqQkTJsjf3z/etrNmzVL79u0t5rm4uOjBA7pLBQAAAAAAQPISExOj3r17q0KFCipWrNgT2/3111+aPn269u/fn6Dtjhw5UkOHDo0z/9q1a0m6ThYTE6OwsDAZjUY5ODgken17w/GKR4F35ZCjltLsGq+U/yyUwRgjQ9gFGRZ1VORfExVWrq9uuXpxzBLo5bzH3CSDm3T1qiTJ+cIWpbp+Xrp+Xtq/QA+z+CoidxVFpS9ok70MPc8xu3379kuKCgAAAEh+rF4oNH/+fPXp00eTJ09W2bJlNXbsWNWsWVPHjh1T5syZ413H3d1dx44dMz822OAfLQAAAAAAAHj9BQUF6fDhw/rrr7+e2Ob27dtq3bq1pk6dqowZMyZou/369VOfPn3Mj8PDw5UzZ05lypRJ7u7uiY4zJiZGBoNBmTJloogjATheT5JZyjNZxis9pDUDZTi9XpLkfGWfMi1rIbc8bypFhfdkyFtFMnDcnuaVvMcyvi1lzibDiT+kK0fkcvOI0tw8InnkkNG7puRVSXKynaHjnueYubrazn4CAAAAz8vqhUJjxoxR586dzb0ETZ48WStWrNCMGTP06aefxruOwWCQp6fnqwwTAGBliel9TpIWLlyogQMH6uzZs/L29tbo0aNVp04d8/J27dpp9uzZFuvUrFlTq1atemn7AAAAAMC+dO/eXcuXL9emTZuUI0eOJ7Y7deqUzp49q3r16pnnxQ6D4+TkpGPHjilfvnwW67i4uMjFxSXOthwcHJJcVGAwGJ5rfXvD8XqKrMWl1kukE2ukPwZI/x6XJLmeXSOdXSOlzyv5tZN8WkmpE1YcZ49e+nvMwUHKHWCabl2Qjq+SzmySwi/KsGemlL2U5Jzq5Tz3S5LUY8bnGAAAAPbEqme/kZGR2rNnj6pXr26e5+DgoOrVq2vbtm1PXO/OnTvKnTu3cubMqfr16+vIkSNPbBsREaHw8HCLCQBgW2J7nxs8eLD27t2rkiVLqmbNmrr6/66y/2vr1q1q0aKFOnbsqH379qlBgwZq0KCBDh8+bNGuVq1aunz5snmaO3fuq9gdAAAAAK85o9Go7t27a8mSJfrzzz/l5eX11PaFChXSoUOHtH//fvP09ttvq2rVqtq/f79y5sz5iiIHXiCDQSpQQ3pvq1TnaxlTP9Z7/I3T0ppB0pjC0i8dpDObJaPRerFCSptT8u8sNZwslWorFagppcn0aPnhRdLFvbxOAAAAwGvAqoVC//77r6Kjo5UlSxaL+VmyZFFoaGi86xQsWFAzZszQsmXL9NNPPykmJkbly5dXSEhIvO1HjhwpDw8P88SFFQCwPY/3PlekSBFNnjxZqVKl0owZM+JtP27cONWqVUsff/yxChcurOHDh6tUqVKaOHGiRTsXFxd5enqap3Tp0r2K3QEAAADwmgsKCtJPP/2kOXPmyM3NTaGhoQoNDdX9+/fNbdq0aaN+/fpJMg15U6xYMYspbdq0cnNzU7FixeTs7GytXQGen2MKyb+zjL0P6eabY2X0qvJoWXSkqQBldl1pYhlp60Tp3g3rxQrJObVUqI5Uuv2jeXeuSgcXShtHS7/1kv5ZIUXetV6MAAAAAJ6LzfWnGRAQoDZt2sjHx0dVqlTR4sWLlSlTJk2ZMiXe9v369VNYWJh5unDhwiuOGADwPJLS+9y2bdss2kumYcX+237Dhg3KnDmzChYsqPfee0/Xr19/aiz0UgcAAAAgIYKDgxUWFqbAwEBlzZrVPM2fP9/c5vz587p8+bIVowReMUdnReSrLWPrpVKPvVL5nlKqDI+WXz9hGqbsm0LSos7Sua30XpNcODiZiodSpJLuXJH2/iAt6SbtnCrdPGft6AAAAAAkkpM1nzxjxoxydHTUlStXLOZfuXJFnp6eCdpGihQp5Ovrq5MnT8a7/EnjtQMAbMPTep/7559/4l0nNDT0mb3V1apVS40aNZKXl5dOnTql/v37q3bt2tq2bZscHR3j3e7IkSM1dOjQ59wjAAAAAK87YwKKGzZs2PDU5bNmzXoxwQDJUYZ8Uo3h0hufSX//Ju2ZJZ3dbFoWHSEdWmCaMhWS/NpLJZtJKekF2GpSpZdKtZGKvyOd/Us6vkoKuyCdXGuaKvaRcpW1dpQAAAAAEsiqPQo5OzvLz89P69atM8+LiYnRunXrFBAQkKBtREdH69ChQ8qaNevLChMA8Bpq3ry53n77bRUvXlwNGjTQ8uXLtWvXrqderKeXOgAAAAAAXiAnF6l4E6ndcilol1QuyLIg6No/0qpPTL0MLXlPurCTXoasKYWr5F1dqvOVVG2wlLOs5JxGylryUZsbZ6QHYdaLEQAAAMAzWbVHIUnq06eP2rZtq9KlS8vf319jx47V3bt31b69aQzkNm3aKHv27Bo5cqQkadiwYSpXrpzy58+vW7du6auvvtK5c+fUqVMna+4GAOAlSUrvc56enonurS5v3rzKmDGjTp48qWrVqsXbhl7qAAAAAAB4STIVkGp9IVUbJB1dJu2ZKZ3//xDiUQ+kA3NMU+aiUun2Uol3JFcP68ZsrwwGKUsR0/TwgamASDIVcW3/Tgq/JOUuLxWoZeo9CgAAAECyYtUehSSpWbNm+vrrrzVo0CD5+Pho//79WrVqlXnImP+O137z5k117txZhQsXVp06dRQeHq6tW7eqSJEi1toFAMBLlJTe5wICAizaS9KaNWue2ltdSEiIrl+/Tg91AAAAAABYUwpX01BjHVZJ72+XynazLAi6ekRa+ZGpl6FlQVLIHnoZsqbYIiFJirwjOTpLMVHSmU3S6v7S6gGm/0c/tF6MAAAAACxYvUchSerevbu6d+8e77L/DgHz7bff6ttvv30FUQEAkovE9j7Xq1cvValSRd98843eeustzZs3T7t379b3338vSbpz546GDh2qxo0by9PTU6dOnVLfvn2VP39+1axZ02r7CQAAAAAAHpO5sFR7tGmYq6NLpd0zpZCdpmUP70n7fjJNnsUlv//3MuTiZtWQ7ZqLm1RzhPTvSen4KlOPUNdPSttOSnt/lEq1kbwqWTtKAAAAwO4li0IhAACeplmzZrp27ZoGDRqk0NBQ+fj4xOl9zsHhUSd55cuX15w5c/TZZ5+pf//+8vb21tKlS1WsWDFJkqOjow4ePKjZs2fr1q1bypYtm2rUqKHhw4cztBgAAAAAAMmNcyrJp6VpCj1sGpbs4AIpIty0PPSQtKKP9MdAqXgT09Bk2XytG7M9y5hfythdKtVaOrlOOrFGun9DcknzqE30Q8nByTSMGQAAAIBXikIhAIBNSEzvc5LUtGlTNW3aNN72KVOm1OrVq19keAAAAAAA4FXwLCa99Y305jDp8CJTL0OX9pqWPbwr7Z1tmrL5mnoZKtbYskAFr46rh1SskVSkvnRpn5TV59GyQ7+YXjfvmlKeipZDmAEAAAB4qRye3QQAAAAAAAAAgGTEObVpKKsu66Wum0xFQc6PFQRd2if91lP6ppC0vI+p1yFYh4OjlKP0o96DjEbp3F/SrfPSrqnS0vekvT9It69YN04AAADATlAoBAAAAAAAAACwXVlLSvXGSh/+I9Uda3ocK/K2tHu6NLmiNLWatO8nKfKetSKFZCoYqjXaVOiVJov08J70zwrpt17ShtEUdQEAAAAvGUOPAQAAAAAAAABsn4ubVLq9abq4V9oz0zTE1cP/FwZd3G2aVvWXSjY3tctc2Lox2yuXNFKht6SCdUy9Px1fLV3ebxqOLHUGybO4tSMEAAAAXlsUCgEAAAAAAAAAXi/ZS5mmGp9LBxdIe2ZJVw6blkWESTunmKac5UwFQ0XqSylSWjVku2QwPHqtwi9LJ/6Q8ld7tPzfE9LpDVKBWlLanFYLEwAAAHidUCgEAAAAAAAAAHg9uXpI/p2lMp2kkN2mXoYOL5ai7puWX9humn7/RPJpKfm1lzIVsG7M9so9q+TX1nLesZXSua3SybVSlqKmgqHsfpKDo3ViBAAAAF4DFAoBAAAAAAAAAF5vBoOUs4xpqvmFdHC+tHumdO1v0/IHt6Tt35mm3BVMBUNF3pacXKwatt3L/6YUEyVd2CVdOWKaUmWUvN+U8r0hubpbO0IAAADA5lAoBAAAAAAAAACwHynTSmW7Sv5dpAs7TAVDR5ZI0RGm5ee2mKbf0z/qZShjfquGbLeyFDFNd/+VTqyRTq2T7v0rHZgrndkkvfWNqQgMAAAAQII5WDsAAAAAAAAAAABeOYNBylVOajRF+vAfqeZIKYP3o+X3b0jbJkoT/aTZ9f4/ZFmk9eK1Z6kzSj4tpPrfSeXek9LnlfIGPioSio4yFXfFRFk1TAAAAMAW0KMQAAAAAAAAAMC+pUovBbxvKkI5t8XUy9Dfv0rR/y8MOrPJNKXOJPm0kvzamopV8Go5OZsKhLyqSMaYR/MvbJdh6wQ5lO0nKZu1ogMAAABsAoVCAAAAAAAAAABIph5q8lQ0TXevS/t/lvbMkm6cMi2/e03aMtY05a0qlW4vFawjOaawYtB2yGCQDI6PHhtjZMxTSTFpslovJgAAAMBGUCgEAAAAAAAAAMB/pc4gVegple9h6k1oz0zp7+VSzEPT8tPrTVOaLJLvu1KptlK63NaN2V55VZZyV5SuXrV2JAAAAECyR6EQAAAAAAAAAABPYjBIeauYpjtXpX0/SXtnSzfPmpbfuSJt/kbaPEbKX00q3UHyrik5cvkdAAAAQPLDXyoAAAAAAAAAACREmsxSpT5Shd6m3oT2zJT+WSkZoyUZpZNrTZNbNqlUa6lUG8kjh7WjBgAAAAAzCoUAAAAAAAAAAEgMBwdT70H5q0m3Q6V9P0p7fpDCzpuW374kbRwtbfpK8q4h+bWXvN+UHBytGzcAAAAAu+dg7QAAAAAAAAAAALBZbp5S5Y+lXvulVr9IBd+SDP+/9G6MkY6vkuY2k8aWkDaMlsIvWTVcAAAAAPaNQiEAAAAAAAAAAJ6Xg6Op16AWc6QPjkiB/SX37I+Wh4dIG76Qvi0mzW0pnVgjxURbL14AAAAAdolCIQAAAAAAAAAAXiT3bFLgJ1LvQ1KL+ZJ3zcd6GYqWjq2Qfm4ijfeRNn0t3b5i1XABAAAA2A8KhQAAAAAAAAAAeBkcHKWCtaRWC6ReB6XKfSW3rI+W3zov/Tlc+raINL+1dOpPKSbGevECAAAAeO1RKAQAAAAAAAAAwMuWNqf0xgCp92Gp2c9S/uqSDKZlMVHS379KPzaUJpSStoyVw/3rVg0XAAAAwOvJydoBAAAAAAAAAABgNxydpMJ1TdPNs9LeH6S9P0p3r5qW3zwjh3VDlclhhJSzrJS3qpSvqpTN19RDEQAAAAA8BwqFAAAAAAAAAACwhnR5pGqDpMB+0rGV0u4Z0ukNkiRDTJR0botpWv+55Ooh5alkKhrKW1VKn1cyGKwaPgAAAADbQ6EQAAAAAAAAAADW5JhCKlLfNF0/JeOeWYo+vERO4RcetXkQJv2z3DRJkkcuKV+glDdQ8gqUUmd49XEDAAAAsDkUCgEAAAAAAAAAkFxkyCdj9aH6t0SQMqe4J4czG6XT66XTG6UHtx61Czv//2HLfjA99izxqLehXOWkFCmtEj4AAACA5I1CIQAAAAAAAAAAkqN0eaQMeaXS7aWYaOnyAdPQZKfXS+e3S9GRj9qGHjRNW8ZJTq6mYqG8gabCIc8SkoODlXYCAAAAQHJCoRAAAAAAAAAAAMmdg6OUvZRpqtRHirwnnd/2/96GNkihhx61jXrw/4KiDZKGSCnTS3mrmIqG8gZK6XJbYw8AAAAAJAMUCgEAAAAAAAAAYGucU0n5q5kmSbpzTYodpuzUBik85FHb+zekI0tMkySlz/uoaMirkpQy3auOHgAAAICVUCgEAAAAAAAAAICtS5NJKt7ENBmN0vVTj3obOrNJigh/1PbGadO0e7pkcJCy+T4qHMrpLzm5WGsvAAAAALxkFAoBAAAAAAAAAPA6MRikjPlNk39nKTpKurTv/70NrZdCdkoxUaa2xhjp4h7TtPlrKUUqKXd5U+FQvqpS5iKm7QEAAAB4LVAoBAAAAAAAAADA68zRScpZxjRV6StF3JHObTH1NnRqvXTt70dtH96TTq41TZKUOrOpp6G8gabCIfdsVtgBAAAAAC8KhUIAAAAAAAAAANgTlzRSgZqmSZJuhz4qGjq9QboT+qjt3avSoQWmSZIyFnxUNJS7guTq/oqDBwAAAPA8KBQCAAAAAAAAAMCeuXlKJZubJqNRuvbPo8Khs39JD+8+avvvMdO0c4rk4CRlL20qGsobKGX3kxxTWGsvAAAAACSAg7UDAAAAAAAAAF4nI0eOVJkyZeTm5qbMmTOrQYMGOnbs2FPXmTp1qipVqqR06dIpXbp0ql69unbu3PmKIgaAxxgMUubCUrn3pFYLpE/OSu1/lyr3lXL4SwbHR21joqQL26UNI6UZNaXRXtKc5tKOKdK146aiIwAAAADJCj0KAQAAAAAAAC/Qxo0bFRQUpDJlyigqKkr9+/dXjRo1dPToUaVOnTredTZs2KAWLVqofPnycnV11ejRo1WjRg0dOXJE2bNnf8V7AACPcXKWcpc3TW8MkB6EmXoZOrVeOr1eun7yUdvI29Lx302TJLlnN/U0FDulyWyFHQAAAADwOAqFAAAAAAAAgBdo1apVFo9nzZqlzJkza8+ePapcuXK86/z8888Wj6dNm6ZFixZp3bp1atOmzUuLFQASzdVDKvSWaZKkWxdMw5TFTvf+fdQ2/KK0/2fTJEmZi/5/mLKqUu4AyTn+4kkAAAAALw+FQgAAAAAAAMBLFBYWJklKnz59gte5d++eHj58+MR1IiIiFBERYX4cHh4uSYqJiVFMTEyiY4yJiZHRaEzSuvaI45V4HLPEsanj5Z5d8mllmowx0pUj0ukNMpzeIJ3fKkPUg0dtrx4xTdsmyujoLOXwlzFvFVPhUFYfycHxSc/yTM9zzGziOAMAAAAvCIVCAAAAAAAAwEsSExOj3r17q0KFCipWrFiC1/vkk0+ULVs2Va9ePd7lI0eO1NChQ+PMv3btmh48eBDPGs+OMywsTEajUQ4ODole395wvBKPY5Y4Nn28HLJI+ZuZpqgIOV/ZK+eQbXIJ2SKna0dkkFGSZIiOlM79JcO5v6T1IxTj7K7I7OUUkaO8InOUV7R7LslgSPDTPs8xu337dqLaAwAAALaMQiEAAAAAAADgJQkKCtLhw4f1119/JXidUaNGad68edqwYYNcXV3jbdOvXz/16dPH/Dg8PFw5c+ZUpkyZ5O7unug4Y2JiZDAYlClTJtsrSrACjlficcwS57U6XtlySr71JUnGezdkPLtZhtPrpTMbZbh51tzMITJcrmf+kOuZP0xt0+aS8laV0auK5FVFSvX0Xtme55g96bsWAAAAeB1RKAQAAAAAAAC8BN27d9fy5cu1adMm5ciRI0HrfP311xo1apTWrl2rEiVKPLGdi4uLXFxc4sx3cHBIclGBwWB4rvXtDccr8ThmifNaHq80GaViDU2TJN04I53eIJ1eL53eKD24ZW5quHVe2jtbhr2zJRmkrCVMQ5TlDZRyBUgp4hb3JPWYvVbHGAAAAHgGCoUAAAAAAACAF8hoNKpHjx5asmSJNmzYIC8vrwSt9+WXX2rEiBFavXq1Spcu/ZKjBIBkIL2XaSrdXoqJli4f+H/R0Abp/HYpOvL/DY2mZZcPSFvGSk6upmKhvIFSvqpSluLW2wcAAADAxlAoBAAAAAAAALxAQUFBmjNnjpYtWyY3NzeFhoZKkjw8PJQyZUpJUps2bZQ9e3aNHDlSkjR69GgNGjRIc+bMUZ48eczrpEmTRmnSpLHOjgDAq+TgKGUvZZoqfShF3pPObzMVDp3aIF059Kht1IP/FxStl9YOllJlkMGrslJm9JNcG0hpc1prLwAAAIBkj0IhAAAAAAAA4AUKDg6WJAUGBlrMnzlzptq1aydJOn/+vMVQN8HBwYqMjFSTJk0s1hk8eLCGDBnyMsMFgOTJOZWUv5ppkqQ716QzGx8VDoWHPGp777oMR5bIQ0tkjAmTqn1mlZABAAAAW0ChEAAAAAAAAPACGY3GZ7bZsGGDxeOzZ8++nGAA4HWRJpNUvIlpMhql66f+XzS0Xjq7WYoIlyQZ81aRwcqhAgAAAMkZhUIAAAAAAAAAAMB2GAxSxvymyb+zFB2lmJDdunt4pVLnKGPt6AAAAIBkjUIhAAAAAAAAAABguxydpJz+uuuSR6kdna0dDQAAAJCsOTy7CQAAAAAAAAAAAAAAAABbR6EQAAAAAAAAAAAAAAAAYAcoFAIAAAAAAAAAAAAAAADsAIVCAAAAAAAAAAAAAAAAgB2gUAgAAAAAAAAAAAAAAACwAxQKAQAAAAAAAAAAAAAAAHaAQiEAAAAAAAAAAAAAAADADlAoBAAAAAAAAAAAAAAAANgBCoUAAAAAAAAAAAAAAAAAO0ChEAAAAAAAAAAAAAAAAGAHKBQCAAAAAAAAAAAAAAAA7ACFQgAAAAAAAAAAAAAAAIAdSBaFQpMmTVKePHnk6uqqsmXLaufOnU9tv3DhQhUqVEiurq4qXry4Vq5c+YoiBQBYy4vOFUajUYMGDVLWrFmVMmVKVa9eXSdOnHiZuwAAeI0lNk8BAAAAAAAAAGANVi8Umj9/vvr06aPBgwdr7969KlmypGrWrKmrV6/G237r1q1q0aKFOnbsqH379qlBgwZq0KCBDh8+/IojBwC8Ki8jV3z55ZcaP368Jk+erB07dih16tSqWbOmHjx48Kp2CwDwmkhsngIAAAAAAAAAwFqsXig0ZswYde7cWe3bt1eRIkU0efJkpUqVSjNmzIi3/bhx41SrVi19/PHHKly4sIYPH65SpUpp4sSJrzhyAMCr8qJzhdFo1NixY/XZZ5+pfv36KlGihH744QddunRJS5cufYV7BgB4HSQ2TwEAAAAAAAAAYC1O1nzyyMhI7dmzR/369TPPc3BwUPXq1bVt27Z419m2bZv69OljMa9mzZpPvLEbERGhiIgI8+OwsDBJUnh4eNIDjzAmfV083fO8Lk8RfT/6pWwXJs/1eXqCO9G8Zi9TUl+z2PWMxlf3PfgycsWZM2cUGhqq6tWrm5d7eHiobNmy2rZtm5o3bx7vdl94TiGfvDzkE5v0MvKJRE55mZ7nNbNGTnkZkpKnyCc2hpxic8gntsmW/kZJrmKPQVKPZUxMjG7fvi1XV1c5OFj9t4XJHscr8ThmicPxSrznOWbkEwAAANgTqxYK/fvvv4qOjlaWLFks5mfJkkX//PNPvOuEhobG2z40NDTe9iNHjtTQoUPjzM+ZM2cSo8ZLNcrD2hEgCTze43WzOR7P95rdvn1bHs+5jYR6Gbki9t/E5BOJnGJTyCc2iXxig15ALniVOeVlSEqeIp/YGHKKzSGf2Cgb+hslubp9+7Yk8gkAPA/yCQAAAOyBVQuFXoV+/fpZ9CoRExOjGzduKEOGDDIYDFaM7OULDw9Xzpw5deHCBbm7u1s7HCQQr5vtsafXzGg06vbt28qWLZu1Q7EKcop9vM9fF7xmtsmeXjd7zinkE/t4j78ueM1skz29bvacT/4rW7ZsunDhgtzc3JKUT+zpffMicLwSj2OWOByvxHueY0Y+AQAAgD2xaqFQxowZ5ejoqCtXrljMv3Llijw9PeNdx9PTM1HtXVxc5OLiYjEvbdq0SQ/aBrm7u/PHpA3idbM99vKavepfVb2MXBH775UrV5Q1a1aLNj4+Pk+MhZxiP+/z1wmvmW2yl9ftdfilblLyFPnEft7jrxNeM9tkL6/b65BPXgQHBwflyJHjubdjL++bF4XjlXgcs8TheCVeUo8Z+QQAAAD2wqqDGzs7O8vPz0/r1q0zz4uJidG6desUEBAQ7zoBAQEW7SVpzZo1T2wPALBtLyNXeHl5ydPT06JNeHi4duzYQT4BACRKUvIUAAAAAAAAAADWYvWhx/r06aO2bduqdOnS8vf319ixY3X37l21b99ektSmTRtlz55dI0eOlCT16tVLVapU0TfffKO33npL8+bN0+7du/X9999bczcAAC/Ri84VBoNBvXv31ueffy5vb295eXlp4MCBypYtmxo0aGCt3QQA2Khn5SkAAAAAAAAAAJILqxcKNWvWTNeuXdOgQYMUGhoqHx8frVq1SlmyZJEknT9/Xg4Ojzo+Kl++vObMmaPPPvtM/fv3l7e3t5YuXapixYpZaxeSLRcXFw0ePDjOsAZI3njdbA+v2cv3MnJF3759dffuXXXp0kW3bt1SxYoVtWrVKrm6ur7y/bMFvM9tD6+ZbeJ1s03PylN4hPe47eE1s028bkgK3jeJw/FKPI5Z4nC8Eo9jBgAAACSMwWg0Gq0dBAAAAAAAAAAAAAAAAICXy+HZTQAAAAAAAAAAAAAAAADYOgqFAAAAAAAAAAAAAAAAADtAoRAAAAAAAAAAAAAAAABgBygUAgAAAAAAAAAAAAAAAOwAhUIAAAAAAACAndq0aZPq1aunbNmyyWAwaOnSpdYOKVkbOXKkypQpIzc3N2XOnFkNGjTQsWPHrB1WshUcHKwSJUrI3d1d7u7uCggI0O+//27tsGzKqFGjZDAY1Lt3b2uHkmwNGTJEBoPBYipUqJC1wwIAAACSLQqFABtlNBqtHQKegdcIgC3guyr54zUCYCv4vkr+eI0Qn7t376pkyZKaNGmStUOxCRs3blRQUJC2b9+uNWvW6OHDh6pRo4bu3r1r7dCSpRw5cmjUqFHas2ePdu/erTfeeEP169fXkSNHrB2aTdi1a5emTJmiEiVKWDuUZK9o0aK6fPmyefrrr7+sHRIAAACQbFEoZMdiYmKsHQIS6dy5c1q9erUkyWAwWDkaPM2xY8f01Vdf6caNG9YOBXjpyCe2h3xiO8gnsDfkFNtDTrEd5BQ8Se3atfX555+rYcOG1g7FJqxatUrt2rVT0aJFVbJkSc2aNUvnz5/Xnj17rB1aslSvXj3VqVNH3t7eKlCggEaMGKE0adJo+/bt1g4t2btz545atWqlqVOnKl26dNYOJ9lzcnKSp6enecqYMaO1QwIAAACSLQqF7MypU6fUsmVLSZKDgwMX4m3IxYsX5efnp759+2rRokXWDgfPsGPHDn366aeaNGmSbt26Ze1wgBeOfGK7yCe2hXwCe0BOsV3kFNtCTgFejrCwMElS+vTprRxJ8hcdHa158+bp7t27CggIsHY4yV5QUJDeeustVa9e3dqh2IQTJ04oW7Zsyps3r1q1aqXz589bOyQAAAAg2XKydgB4tc6dO6cFCxbo3r17Wrp0qflCvIMDNWPJ3ZEjR3Tjxg3lz59fP/30k6KiotSsWTNrh4UnaNOmjR4+fKjOnTsrJiZGvXr1Utq0aa0dFvDCkE9sF/nEtpBPYA/IKbaLnGJbyCnAixcTE6PevXurQoUKKlasmLXDSbYOHTqkgIAAPXjwQGnSpNGSJUtUpEgRa4eVrM2bN0979+7Vrl27rB2KTShbtqxmzZqlggUL6vLlyxo6dKgqVaqkw4cPy83NzdrhAQAAAMkOhUJ2pnLlylq5cqXatGmjunXravny5VyItxE1atTQO++8oxMnTsjBwUHTp0+Xo6OjmjRpYu3Q8Jjo6Gg5ODjIYDCoY8eOiomJUdeuXWU0GtWrVy+6isZrg3xiu8gntoF8AntCTrFd5BTbQE4BXp6goCAdPnxYf/31l7VDSdYKFiyo/fv3KywsTL/88ovatm2rjRs3Uiz0BBcuXFCvXr20Zs0aubq6Wjscm1C7dm3z/0uUKKGyZcsqd+7cWrBggTp27GjFyAAAAIDkiauudiAqKsr8fycnJ1WpUkWzZs3Szp07VbduXUl08Z/cRURESJJatGghHx8fdejQQS4uLgoODqaL/2TiypUrkiRHR0fFxMTIaDRKkjp37qwpU6Zo2LBhCg4O5nMGm0Y+sX3kk+SPfAJ7QU6xfeSU5I+cArxc3bt31/Lly7V+/XrlyJHD2uEka87OzsqfP7/8/Pw0cuRIlSxZUuPGjbN2WMnWnj17dPXqVZUqVUpOTk5ycnLSxo0bNX78eDk5OSk6OtraISZ7adOmVYECBXTy5ElrhwIAAAAkSxQKveaOHz+uXr16aeLEibp06ZLCwsLk4uKiWrVq6aefftLOnTvNv7jgQnzyEhISopUrV0qSXFxcJEmlSpXSxo0bdf36dX333XdKlSqVgoOD9csvv1gzVLsXHh6uwMBAtWrVSlL8F+InTpyozz77TCtWrLBmqECSkU9sF/nEdpBPYC/IKbaLnGI7yCnAy2M0GtW9e3ctWbJEf/75p7y8vKwdks2JiYkxF5wirmrVqunQoUPav3+/eSpdurRatWql/fv3y9HR0dohJnt37tzRqVOnlDVrVmuHAgAAACRLBmPsVSK8du7cuaO33npLmzdvliQFBATo5s2b6tatmwoXLqzq1atr7dq1ev/991WoUCH99ttvkkQX/8nAuXPn5Ofnpxs3bqhx48Zq2bKl/Pz8lCtXLs2bN0+TJ0/W0qVLdebMGQ0ePFgPHz5U69at1bJlS2uHbpfu3r2rH374QV988YXq1KmjKVOmSHrUxb8kGQwGde3aVUeOHDF3HW0wGKwZNpBg5BPbRT6xLeQT2ANyiu0ip9gWcgoS486dO+ZeN3x9fTVmzBhVrVpV6dOnV65cuawcXfLz/vvva86cOVq2bJkKFixonu/h4aGUKVNaMbLkqV+/fqpdu7Zy5cql27dva86cORo9erRWr16tN99809rh2YzAwED5+Pho7Nix1g4lWfroo49Ur1495c6dW5cuXdLgwYO1f/9+HT16VJkyZbJ2eAAAAECy42TtAPDypEmTRh06dJCrq6tcXV1VpUoVRUVFad68edq/f7/KlSundOnS6Z133tHIkSPVuHFjLVq0iAvwVhYdHa1bt24pa9asyp8/v06ePKnly5fro48+0vDhw+Xk5CQPDw/t379fgYGBGjJkiD744AMtXLhQ9erVk5ubm7V3we6kTp1arVq1kqurq/r16ydJmjJlihwdHRUVFSUnJ9NXraenp06fPs2FQ9gc8oltIp/YHvIJ7AE5xTaRU2wPOQWJsXv3blWtWtX8uE+fPpKktm3batasWVaKKvkKDg6WZCrceNzMmTPVrl27Vx9QMnf16lW1adNGly9floeHh0qUKEGREF64kJAQtWjRQtevX1emTJlUsWJFbd++nSIhAAAA4AnoUeg1FBISogMHDuitt96SJM2YMUMLFy5UypQpNWXKFGXKlEl///23li9frk2bNunvv//W6dOnzetmy5bNmuHbtd27d6tly5Y6evSoli1bpp9//lkGg0Ht27fXzZs3NW3aNKVLl06//vqrAgMDtXbtWjk4OOjgwYNKly6dcubMae1dsBvh4eG6efOm3Nzc5O7uLicnJ4WFhWnJkiX69NNPVb9+ffOvdmP17NlTd+7cUXBwsJydnfm1LpI98ontIp/YDvIJ7AU5xXaRU2wHOQUAAAAAAAAJQY9Cr5mIiAh99NFHOnPmjB4+fKgGDRqoQ4cOcnJy0vTp09WtWzcNHjxYJUqUUOHChfXxxx/r+PHjunDhgnLmzMkFeCs6cOCA3njjDbVu3VpOTk5q3LixYmJiNG3aNE2ePFnfffed3n77be3bt0+3b99Wu3btzL+sLlGihJWjty9HjhxRUFCQLl68KBcXF3Xp0kWdO3eWh4eHGjduLEnq27evbt26pXHjxun69euaP3++5syZo82bN8vFxcXKewA8G/nEdpFPbAf5BPaCnGK7yCm2g5wCAAAAAACAhKJHodfQli1bNHr0aEVERKhr165q1KiRJOnHH3/UjBkzlC5dOg0fPlxFixaVJBmNRn41aGV///23/P391bNnT40YMcKiK/jFixdr0qRJSpkypYYNG6ZSpUopJiaG4Res5MCBA6pUqZJat26tmjVr6uuvv9axY8c0d+5cvfHGG5Kke/fuacOGDXr//fd1//59ZcmSRa6urpo6dapKlixp5T0AEo58YnvIJ7aDfAJ7Q06xPeQU20FOAQAAAAAAQGJQKPQaefzC7Pbt2zV8+HBFRUWpW7duatiwoSTThfiZM2cqY8aM+uyzz/iVZzJw8OBB88Xb33//XWXKlJGkOBfig4OD5erqqsGDB6t06dJWi9eeHT16VOXKlVNQUJBGjhwpSdq3b5/8/Pz0+eefq3///hbt7927pz///FNZs2ZVzpw5lTlzZmuEDSQa+cQ2kU9sB/kE9oScYpvIKbaDnAIAAAAAAIDE4ud+r4EzZ85o9+7dunjxonleuXLl1L9/fzk6Ouq7777T4sWLJUmtW7dWx44ddfLkSX399deKjIy0VtiQtH//fgUEBKhx48bKmzevPvvsM61fv16S5OTkpKioKElSo0aN9P777ysqKkp9+vTR/v37rRi1fTIajRo0aJAePnyoN998U7E1lkuXLpUkhYWFadq0aTpy5Ihu374tSUqVKpXq1q0rPz8/LsDDJpBPbBf5xHaQT2AvyCm2i5xiO8gpAAAAAAAASAp6FLJxFy9eVM6cOSVJBQoUULly5VSuXDnVr19fWbNm1ZkzZ/T+++/L0dFRbdq00TvvvCNJmj9/vsqVK6fcuXNbM3y7dvr0aRUqVEi9e/fWl19+qVOnTqlRo0by9PRUv379FBgYKMnyV7vz5s3TggULNG7cOPPrjlfn5s2batSokR4+fKivv/5af/75p7788ku9++67KlasmIKDg+Xm5qaLFy+qUaNGqlu3rqpWrWrtsIEEIZ/YLvKJ7SGf4HVHTrFd5BTbQ04BAAAAAABAYlEo9BqoWLGitm7dqj59+ujAgQMKCwvT8ePH5e/vrxYtWujGjRvavHmzoqOj1b59ezVq1MjaIdu9mJgYbdiwQRcuXFDbtm0VHR0tR0fHBF2Iv3PnjtKkSWPF6O1LSEiINm7cqLCwMHXo0EF3795VvXr1dP78ed2+fVvz589XrVq1JJlep3Pnzmnq1Knas2ePgoODlT9/fivvAZBw5BPbQz6xHeQT2Btyiu0hp9gOcgoAAAAAAACeB4VCr4myZcsqOjpaY8aMUdmyZbVs2TIdPnxYs2fPlqenp3bt2iVJevPNN7V48WKlTp3ayhHbr9OnT2vhwoVq0KCBChYsaJ4feyH+9OnTatiwYZwL8bHL8eocOXJErVq1UvHixZUtWzaNHDlSDg4OCgsLU/PmzXX69GlNnDhR1apVk4OD5UiO9+/fV8qUKa0UOZB05BPbQT6xHeQT2Ctyiu0gp9gOcgoAAAAAAACeF4VCNujChQv6448/FBMTo/z585u7Dffz89OtW7f0888/q1y5cpKky5cv686dO5ozZ45OnDih/v37q0iRItYM364dOnRIDRs2VIECBdSmTRs1b97cYvl/L8TnyJFDvXr1Uo0aNawUsf06cuSIKlWqpKCgIH388cdyd3eXJC1ZskSZM2eWr6+v6tSpo4iICA0cOFC1atWSg4OD+TU0Go0yGAxW3gvg6cgntot8YjvIJ7AX5BTbRU6xHeQUAAAAAAAAvAgUCtmYgwcP6u2331aWLFl06tQppU2bVsOHD1eLFi0kSeXKldO1a9c0e/ZslStXztwVvCRFRkbK2dnZWqHbvWPHjqlixYrq2LGj+vXrJw8Pj3jbxXbhf/r0aQUGBqpMmTL68ccflSpVqlccsf26ceOGGjZsqBIlSmjChAnm+aNHj1a/fv1UqVIljR49WsWLF1fdunUVFRWlDz/8UPXr1+fCO2wG+cR2kU9sB/kE9oKcYrvIKbaDnALAnhkMBi1ZskQNGjSwdigAAAAA8FpweHYTJBcHDx5UQECAWrRoofXr12vevHl68OCBfv75Z4WFhUmStm/frgwZMqhdu3bauXOnYmJizOtzAd56oqKi9MUXX6hevXoaNWqU+QL8/fv3df78eR07dkxXrlyRJDk5OSkqKkp58+bVpk2b9NVXX3EB/hW7cuWKLl68qEaNGpk/Q5MnT9bAgQM1ceJEubi4aPDgwTp48KBWrFihsLAwTZkyRffu3bNy5EDCkE9sF/nEtpBPYA/IKbaLnGJbyCkArKVdu3YyGAxxplq1alk7NAAAAABAEtGjkI24cOGCSpUqpapVq2rBggXm+f7+/goLC9POnTuVOnVq869zq1Spov3792v16tXmLv5hPZGRkXrzzTfVtGlTde/eXZK0cuVKLV26VHPnzlWKFClUpkwZff755ypTpowkKSYmRg4O1PJZw08//aR27drp4cOH5l/fhoSE6MyZM6pUqZIOHz6s3r1768aNG1q9erUcHR0VHh6uPHnyWDdwIAHIJ7aNfGJbyCd43ZFTbBs5xbaQUwBYS7t27XTlyhXNnDnTYr6Li4vSpUv3SmKgRyEAAAAAeLG4wmcjoqOj5eXlpYiICG3ZskWSNHLkSO3evVtp06ZV69at1aVLF3377be6d++e1q9fr2rVqiljxoxWjhyS6ZfSKVOm1OzZs3XixAkNHDhQPXr00J07dzR16lRNnjxZ4eHhWrx4saKjo2U0GrkAb0V58uSRk5OTlixZIkkyGo3KkSOHKlWqpJiYGBUrVkzNmjWTk5OTIiIilD59ei7Aw2aQT2wb+cS2kE/wuiOn2DZyim0hpwCwJhcXF3l6elpMsUVCBoNBwcHBql27tlKmTKm8efPql19+sVj/0KFDeuONN5QyZUplyJBBXbp00Z07dyzazJgxQ0WLFpWLi4uyZs1qLmKN9e+//6phw4ZKlSqVvL299euvv77cnQYAAACA1xg9CtmQEydOqGfPnnJ2dlbmzJm1bNkyfffdd/L399fevXt15MgRTZgwQUajUTVq1NAPP/xg/qUhrMdoNMpgMGjbtm3q2rWrrl+/rocPH2r06NEKDAyUl5eXJKlBgwZ68OCBVq1aZeWIERISIj8/P5UrV07jx49X7ty547T56KOPdP78eU2fPl1ubm5WiBJIOvKJbSKf2B7yCewBOcU2kVNsDzkFgLW0a9dOt27d0tKlS+NdbjAYlCFDBo0aNUqVK1fWjz/+qJEjR+rQoUMqXLiw7t69K29vbwUEBGjo0KG6evWqOnXqpMqVK2vWrFmSpODgYPXp00ejRo1S7dq1FRYWpi1btqh3797m58iRI4e+/PJLlSlTRhMmTNCMGTN07tw5pU+f/tUcCAAAAAB4jVAoZGOOHz+u7t27a/PmzRo+fLg++ugji+XXr1/X+vXrVbJkSXl7e1spSjx48ECurq6SHl2El6Q7d+7o5MmTypkzpzJkyGBeHh0drfbt2ytbtmz64osv5OjoaLXYYbJo0SK1bNlSzZo106effqoiRYpIksLDw/X5559r2rRp2rx5s4oWLWrlSIGkIZ/YBvKJ7SOfwB6QU2wDOcX2kVMAWEO7du30008/mXNIrP79+6t///4yGAzq1q2bgoODzcvKlSunUqVK6bvvvtPUqVP1ySef6MKFC0qdOrUk01CX9erV06VLl5QlSxZlz55d7du31+effx5vDAaDQZ999pmGDx8uSbp7967SpEmj33//XbVq1XpJew4AAAAAry8KhWzQqVOn9P7778vR0VH9+/dXxYoVJUkPHz5UihQprBwdLl68qA8++EDvvfeeqlatKkmKiYl5Yjf9UVFRGjp0qGbMmKE///xTBQsWfJXh4gmio6M1bdo0de/eXfnz51f58uWVIkUKXbx4Ubt379bKlSvl6+tr7TCB50I+Sd7IJ68H8gnsBTkleSOnvB7IKQCsoV27drp48aJFIZAkpU+fXunTp5fBYNDs2bPVpk0b87IPPvhA+/fv1/r169WnTx/t27dP69evNy8PCwtT2rRptXHjRhUqVEhZsmTRn3/+ac5R/2UwGLRgwQI1bdrUPM/Dw0MTJkyweF4AAAAAQMLEf1UQyVq+fPk0ceJEGY1Gff7559qyZYskcQE+mYiIiFBISIi++eYb82vzpAvw06dPV/fu3TVlyhQtX76cC/DJiKOjo7p27aq//vpLRYoU0Z49e3TkyBEVK1ZMmzdv5gI8Xgvkk+SNfPJ6IJ/AXpBTkjdyyuuBnALAWlKnTq38+fNbTC9qyK+UKVMmqN1/zykMBoNiYmJeSAwAAAAAYG8oFLJR3t7eGj9+vFKkSKGPPvpI27dvt3ZI+L+8efNq9uzZio6O1vDhw80X4iVTF/6x/vnnH/36668yGo3atGkTF3WTqbJly2rBggXav3+/Nm/erJEjRyp//vzWDgt4YcgnyRf55PVCPoE9IKckX+SU1ws5BUBy89+cv337dhUuXFiSVLhwYR04cEB37941L9+yZYscHBxUsGBBubm5KU+ePFq3bt0rjRkAAAAA7BmFQjbM29tbX331lXLkyKFs2bJZOxw8JvYmicFgsLgQbzAYJJm6+f/uu+90+/ZtDR06VIUKFbJmuHiGx39tzWiNeB2RT5Iv8snrhXwCe0BOSb7IKa8XcgqAVykiIkKhoaEW07///mtevnDhQs2YMUPHjx/X4MGDtXPnTnXv3l2S1KpVK7m6uqpt27Y6fPiw1q9frx49eqh169bKkiWLJGnIkCH65ptvNH78eJ04cUJ79+7VhAkTrLKvAAAAAGAPDEauKNm8yMhIOTs7WzsMxOPEiRPq2bOnjEajBg4cqAoVKigyMlJ9+vTR5MmTtXv3bvn4+Fg7TACQRD5JzsgnAGwNOSX5IqcAABKjXbt2mj17dpz5BQsW1D///CODwaBJkyZp6dKl2rRpk7JmzarRo0frnXfeMbc9dOiQevXqpW3btilVqlRq3LixxowZozRp0pjbTJkyRd9++61Onz6tjBkzqkmTJho/frwkU1HrkiVL1KBBA3P7tGnTauzYsWrXrt1L23cAAAAAeF1RKAS8ZI9fiP/000/1+++/a8KECdqyZQtd+QMAEox8AgB4UcgpAIAXJb4iHgAAAABA8kahEPAKnDhxQn369NGWLVt09+5dbdu2TaVKlbJ2WAAAG0M+AQC8KOQUAMCLQKEQAAAAANgeh2c3AfC8vL299fXXX6tSpUrau3cvF+ABAElCPgEAvCjkFAAAAAAAAMA+0aMQ8Ao9fPhQKVKksHYYAAAbRz4BALwo5BQAAAAAAADAvlAoBAAAAAAAAAAAAAAAANgBhh4DAAAAAAAAAAAAAAAA7ACFQgAAAAAAAAAAAAAAAIAdoFAIAAAAAAAAAAAAAAAAsAMUCgEAAAAAAAAAAAAAAAB2gEIhAAAAAAAAAAAAAAAAwA5QKAQAAAAAAAAAAAAAAADYAQqFAAAAAAAAAAAAAAAAADtAoRAAAAAAAAAAAAAAAABgBygUAgAAAAAAAAAAAAAAAOwAhUIAAAAAAAAAAAAAAACAHaBQCAAAAAAAAAAAAAAAALADFAoBAAAAAAAAAAAAAAAAdoBCIQAAAAAAAAAAAAAAAMAOUCgEAAAAAAAAAAAAAAAA2AEKhQAAAAAAAAAAAAAAAAA7QKEQAAAAAAAAAAAAAAAAYAcoFAIAAAAAAAAAAAAAAADsAIVCAAAAAAAAAAAAAAAAgB2gUAgAAAAAAAAAAAAAAACwAxQKAQAAAAAAAAAAAAAAAHaAQiEAAAAAAAAAAAAAAADADlAoBAAAAAAAAAAAAAAAANgBCoUAAAAAAAAAAAAAAAAAO0ChEAAAAAAAAAAAAAAAAGAHKBQCAAAAAAAAAAAAAAAA7ACFQgAAAAAAAAAAAAAAAIAdoFAIAAAAAAAAAAAAAAAAsAMUCgEAAAAAAAAAAAAAAAB2gEIhAAAAAAAAAAAAAAAAwA5QKAQAAAAAAAAAAAAAAADYAQqFAAAAAAAAAAAAAAAAADtAoRAAAAAAAAAAAAAAAABgBygUAgAAAAAAAAAAAAAAAOwAhUIAAAAAAAAAAAAAAACAHaBQCAAAAAAAAAAAAAAAALADFAoBAAAAAAAAAAAAAAAAdoBCIQAAAAAAAAAAAAAAAMAOUCgEAAAAAAAAAAAAAAAA2AEKhQAAAAAAAAAAAAAAAAA7QKEQAAAAAAAAAAAAAAAAYAcoFAIAAAAAAAAAAAAAAADsAIVCAAAAAAAAAAAAAAAAgB2gUAgAAAAAAAAAAAAAAACwAxQKAQAAAAAAAAAAAAAAAHaAQiEAAAAAAAAAAAAAAADADlAoBAAAAAAAAAAAAAAAANgBCoUAAAAAAAAAAAAAAAAAO0ChEAAAAAAAAAAAAAAAAGAHKBQCAAAAAAAAAAAAAAAA7ACFQgAAAAAAAAAAAAAAAIAdoFAIAAAAAAAAAAAAAAAAsAMUCgEAAAAAAAAAAAAAAAB2gEIhAAAAAAAAAAAAAAAAwA5QKAQAAAAAAAAAAAAAAADYASdrBwAAAAAAAADAenbv3q1Vq1bp4MGDevDggbXDAQAAAAAASWAwGOTh4aGAgADVrVtXOXPmjL+d0Wg0vuLYAAAAAAAAACQDc+bM0VdffaWMGTOqZMmSSpUqlQwGg7XDAgAAAAAAiRQTE6MbN25o7969SpEihYKDg1W0aNE47SgUAgAAAAAAAOzQmTNn1LhxY9WpU0dt27alQAgAAAAAgNfAvXv3NGzYMD148EC//fZbnL/3HawUFwAAAAAAAAArWrt2rZydndWyZUuKhAAAAAAAeE2kSpVKLVq00MWLF/X333/HWU6hEAAAAAAAAGCHTp06pfz588vZ2dnaoQAAAAAAgBeocOHCiomJ0alTp+Iso1AIAAAAAAAAsEORkZHPXSQ0d+5ctW3bVvfv339BUSVeWFiY6tevr3Xr1lktBgAAAAAAkhNnZ2c5ODgoMjIyzjInK8QDAAAAAAAAwMbdvXtXd+7c0ffffy8XFxerxbF//37169dP5cqVs1oMAAAAAADYCnoUAgAAAAAAAJBoqVOnVufOna1aJCRJVapUoUgIZq1atdLQoUOtHUayMnPmTAUGBlo7DNiIvn37ytvbW97e3urcubO1wwHi9fnnn6tVq1bWDgMAnpu3t7d+//13a4eB/zh69Ki8vb0VEhJi7VBeGgqFAAAAAAAAAJjF3iD29vZWuXLl9P777+vs2bPm5Tt27LBoE98N5ZCQEPXs2VNly5ZVyZIl9fbbb+uXX34xLw8MDNS0adMsnvfxeYGBgfL29taJEyfMy9u2bWtxIb1Vq1bxxnHo0KEE7ef48ePl7e2tAgUKyN/fX126dNGBAwfiHIv/XrhP7MX82H3x9vaWr6+vmjVrpm3btsW7vEyZMmrbtm2cfdi5c6fq16+vIkWKqGrVqpo7d26c5xk6dKjFcXg8xkWLFsV7rGILauJbFju1atVKoaGhKlKkSJzjkxi///67/P39n2uYupCQkDjvz6CgIJ0/fz7J27SWNWvWqG3btipVqpS8vb1148aNBK/7ww8/qFKlSvEuGzVqlJo0aWIxr3nz5lq0aNFzxZucxX6Wvb29VbRoUdWqVUs//PCDeXns+6ZevXoW68X3fXL06FHz8r59+5q/16ZOnaratWvLaDS+gj1KmocPH8rX11c//vijxfzr16+rQIECWr16dYK2M3DgQG3dulV16tRJcizjx49/rvWTiz/++EMtWrSQn5+f/Pz81KFDB/3zzz+J2saJEycUFBSkihUrxps/Hi/Menzq1KmTpCfnXG9vb12/fj3O882cOVPe3t4WOXbIkCHq2LFjEo7Aq/O0/fT29tb48eMt2vfu3VuTJk2yUrTPdunSJXXo0EHFihVTpUqV9PPPPydq/R07dqh9+/by9/eXj4+Pmjdvrh07diR4/QcPHsjf318rVqxIbOhmBw8eVJEiRXT58uUkbyMh7t+/r1GjRqlKlSoqVqyYqlWrpi+++MK8/PHv4qfN27x5s5o0aaLixYvL399fPXr0UEREhHn5tWvX9PHHH8vf318lSpRQ48aNtWfPHklxzy9ip8e/x27cuKEBAwaoYsWKKl68uGrVqqUpU6ZYxDB//nzVrl1bxYoVU/ny5dW9e/dE5XdJOnv2rN577z35+vrKx8dHLVu21KlTp8z7HRtbiRIl9Pbbb2v58uUW6z9+Xvn4uZxkmS/jm3bs2PHMY/H48gIFCqhixYrq27evrl27Zo7hSeed/30PHz16VEWKFFHTpk0TdYwkqVOnTho0aFCi13vVHj8WhQoVUmBgoEaMGKG7d+9aO7RECw4OVuPGjVWkSBGr5fjx48erZs2aKl68uMqVK6cPP/xQV69etWizY8cO1a1bV0WKFFHdunW1c+fOJD1XgQIFtHXrVmXNmvVFhJ4or+q8k0IhAAAAAAAAABZGjBihrVu3aurUqbp165Y6deqkhw8fWrRZuXKltm7dap6++eYbSVJUVJQ6duyohw8faubMmVqyZIk6duwY7w3Np8maNatWrlwpyXSjO75ikMaNG1vEsHXrVhUuXDjBz5E3b15t3rxZ06dPV4YMGdSiRQvt27cvUXEmRPfu3bV161b98ssvyp07t7p06WKxP7HLf/rpJ7m5ualjx47mG0tXr15Vly5d5Ovrq19//VVdu3bV0KFDtXHjRovn+PDDD83HID4pU6aMc6w+/PBDSbKY5+3trY4dO5ofT5o0SZ6ennr77bf1/fffJ/kY1KxZU+7u7lq4cGGStxFrxowZ2rp1q4KDgxUaGqquXbsqOjr6ubf7Kt25c0dlypRRly5dEr2ul5eXrl69GuczKUkXL15U3rx5LealTJlSGTJkSHKstiBv3rzaunWrVq9erXbt2umLL76wKE6UpOPHjz/18+3g4KA5c+bEu6x58+a6cuWK/vzzzxca94uUIkUKVaxY0aIQUZK2b98uJycnVaxYMUHbcXNzU6ZMmazeW1xysGfPHlWvXl0//PCDFixYIHd3d7Vr1043b95M8Dbu3bunnDlzasCAAfEujy3Mip02btwoNzc31axZU5Lk6+sb57u7UaNGKl26dJzP9fHjx7Vo0SJlypTJYn6HDh20devWRBc5vUqP7+cff/whSZo4caJ53n8LndKkSaO0adNaIdKE6dGjhyIjI7Vw4UL17NlTw4cP1+bNmxO8/oEDB+Tr66vvv/9ey5YtU4kSJdSpUyedOXMmQeu7urqqdevWmjp1alJ3QSVKlJCfn59mzZqV5G0kxPDhw7VhwwaNHj1aK1eu1KBBg/TgwYNEbWPz5s3q0qWLKlWqpMWLF+v7779X+vTpFRkZKclUjPTuu+8qJCREkyZN0pIlS9SkSRNduXLFYjux5xex0+MFXh988IFOnTqlCRMmaPny5erTp4/Cw8PNy5ctW6YvvvhC77//vn7//XdNmDBBnp6eunfvXoL34+rVq2rWrJkcHR01a9YsLViwQFWrVtW///5rblO+fHlt3bpVy5cvV82aNdWnTx+L7/1FixZp69at8vX1NZ8nxxbVPX5+N2rUKEmW54C+vr4JOhaxy//66y99++23Onz4sHr16mVe9tZbb2nr1q2aOHGipEd/Mzy+fUlat26dGjZsqBMnTlgUGiVEly5dtHjx4kT/fWENsefgGzZs0MCBA7Vs2TKNHDnS2mEl2oMHD1S3bl2rFgLnzJlTQ4YM0cqVKzV9+nRduXJFPXv2NC//999/1bVrV5UtW1bLli1T2bJl1bVr1yS9T5ycnJQpUyY5Ojq+yF1IkFd13kmhEAAAAAAAAAALsTeKixcvro4dO+rcuXM6ffq0RZsMGTIoU6ZM5snd3V2SdOrUKZ0+fVr9+vVTkSJFlDdvXtWvX19du3ZNVAw1atTQqlWrJEmrV69WjRo14rRJmTKlRQyZMmWSk5NTgp/D0dFRWbJkUfHixTVy5EgVKVJE48aNS1ScCZE6dWplypRJ+fLl04gRIyRJW7ZsibO8YMGC6tGjh27evGkuaPj111+VMmVKDRo0SPnz51fz5s315ptvxulVKE2aNOZjEB+DwRDnWKVJk0aSLOY5OjoqVapU5sexN2I7deqkdevWPfEmZWxvEL/99puqV68uHx8fffbZZ4qJiZFkKsLo2LGjZs6cqaioqHi3EdsLybRp0+Tv76+AgADNnz8/Tru0adMqU6ZM8vX1Vf/+/XXy5EmdO3fOvDwyMlJ9+/ZViRIlVLNmTe3fv9+87Ny5c+rWrZvKlSunokWLql69elq3bp3F9kNCQtSpUyeVKlVKPj4+atasmUXvVpL0888/q1q1aipevLgaNmyo7du3x7tPT9KwYUN17949zk2zhMibN69iYmIUGhqqs2fPytvb23wT8NKlS/Ly8pJkumkZ+yv2+IYeW7RokUqWLKlly5apUqVKKlOmTJxeO7y9vTV9+nQ1b95cJUqUUJs2beLcbHnWsYjtfWDdunVq3769ihcvrgoVKsQp2rl8+XKSb/g5OjoqU6ZMypEjh5o3b65ChQpp/fr1Fm2qVKny1F49KlWqpBUrVuj27dtxlrm5ually5ZPvenet29fderUSaNGjZKvr6+qVKnyyguLqlatql27dpk/d5K0bds2+fv7K3Xq1JKkpUuXqmHDhvLx8ZGvr6+6d++u0NDQVxqnJK1YsUI1atRQkSJFVKNGjTg97dy6dUu9e/c29/7RoEGDOL1R/Pjjj3rjjTdUtGhRValSRWPGjInzPBEREbp8+XK8r+uz9OvXTx07dlTRokWVL18+DR06VNevXzf3QpIQJUuW1KeffqratWvHuzw238ZO+/fvV0xMjPlGrLOzc5xcu27dujg9h0VGRuqjjz7S4MGD5ezsbLEsV65cqlmz5lPfv61atdKAAQOe+N35sj2+n7EFULHf9ZkyZTK/fydNmhSnl5RYsd81n3zyiXx9fTVz5kzVrl1bFStWtOgtLCQkRO+99558fHxUvnx5DRkyJN7e7q5du5bo4gVJOnLkiA4ePKjBgwercOHCatq0qd58880nFiLGp0uXLurZs6d8fHyUO3du9evXTylSpLAoEn7WZ6R169Y6c+aMxfnG42KP1/z581WvXj2VLFlS3bt3tzgWXbp00fz58y0KYh6XkDzyLGvWrFHHjh1Vrlw55cqVS1WqVNGwYcMStY3Ro0fr7bffVq9eveTt7S0fHx8NHTpUbm5ukqS5c+fqypUrmjp1qsqUKaN8+fKpRYsWcQoeHn/PZcqUSenSpZMk3b59W9u2bVOvXr3k6+ur3Llzq0aNGvr444/N6/7xxx+qUaOG6tWrp5w5c8rPz0+fffaZcuTIkeD9mDx5slKnTq3x48erZMmSKlCggDp37qyyZcua28R+VnLlyqWgoCB5eHhow4YN5uWx5+cpUqQwnyfHnsvFnm8+ft7++P4+/t3xpGPx+PLMmTOrTJkyat68uXbt2mX+nnV1dbV43tiY/vvdtHbtWlWtWlV+fn5xzsViXb9+Pd5erfz9/VW4cGHNnj37icczMDBQ33zzjTp37mw+R3n8fPFViT0H9/T0VLVq1dSuXbs45weXLl164rnWpk2b1Lx5c5UqVUolSpRQ+/btdfLkSYv1t23bpoYNG5p71Oratau5UE4yFfkMGzZM5cqVk6+vrzp16pToIbU++OADtW/fXrly5UrCUYjr4cOHWrlypdq0aZPgHN2wYUMFBAQoZ86cKlq0qNq3b6+9e/eaew/79ddf5erqqgEDBsjb21sDBgyQi4uLfv31V0mmvzVatmypN998UzVr1tSsWbPMxyP2RweXL1+26Anrv8cpId+dsZKaR17VeSeFQgAAAAAAAADidffuXfNwNQntXSJVqlSSZHHTIik8PT3l7u6uf/75RytXrlStWrWea3sJUaVKFe3ateuJhSwvgpOTk5ycnOLtDSYyMtI8hETs8T5y5IiKFi0qB4dHl3KLFy+uw4cPv7QY45M/f35VrVpV06dPf2q7xYsXKzg4WCNHjtSCBQss3geNGjXSgwcPzD1FxefChQu6dOmSFixYoEaNGmnYsGFPHbbD1dVVkiyO5/Lly+Xv769ly5bJ09PTPMSaJN28eVPFixfX1KlT9fvvv6tOnToKCgrShQsXzG2GDRumu3fvau7cuVqyZIneeecdi+0vWrRIEyZMUL9+/bRixQo1bNhQnTt31qVLl556bF6UbNmyydXVVRcvXtSRI0fk7u6uI0eOSDL1KBRbKFSrVi1t3brV4lf+/xUREaENGzZo9uzZ6tGjhyZMmKBjx45ZtPn555/1wQcf6Oeff9bp06ctblok5lh8+eWXql27tpYvX65hw4bFuWFYuXJli1+FJ9W+fft05syZON9ZzZo109q1a5/4foq9sbt06dJ4l8cOC7h3794nPveOHTvk4eGhJUuWyN/fXwMGDHip3yf/VaVKFYWHh+vvv/82z9u+fbuqVq1qfnz9+nV17NhRS5Ys0c8//6zr16+rb9++ryxGSTp58qT69Omjxo0ba8WKFWrcuLE++OADi4LU8ePH6++//9b06dP122+/qWvXrhYFUIcPH9awYcPUvXt3/fHHHxozZowyZswY57n279+vypUra+bMmc8dd2yxROwN9pdh/vz5qlWrlrkw5r9WrVqlqKioOIVH3377rfz8/FSmTJl41+vcubN+//13Xbx48YnP/bTvzuSiffv22rp1q5o1a/bENoGBgWrevLlGjhyp4cOHy9/f31xcGxkZqQ4dOsjDw0O//PKLpkyZokOHDpl7V3lc06ZNkzQk0uHDh+Xu7i5vb2/zvDJlyiR4aNT4PHjwQA8fPpSHh4d53rM+I2nTplXTpk2f2avQ3Llz9cUXX2jy5MnavHmzRW9slSpVUq5cuZ5aZJmQPPI0qVOn1tatWy2GCUuMK1eu6NixY0/t5WTTpk2qUqWKuUA6sZydnZUiRQpt2rTpiT0Ypk6dWocOHbLo/SexNm/erFq1almc8z2J0WjUunXrFBYWZtUe4G7evKk///xTjo6OSpEiRYLXu3Tpko4fP66yZcuqYsWKWrt2bbztevbsqcqVK8e7rEuXLpozZ85Th/FasGCBmjVrpsWLFysqKkpfffVVgmN8WVxdXeP8HfC0c61r166pcePGmj9/vhYvXqzUqVOrW7du5s97dHS0ufh8xYoVmj17tnx9fS2GrRo0aJAOHjyo4OBgLV68WBkyZFC3bt2s0iPnhQsX9PXXX6tSpUoaOXKkfHx8lDJlykRv59atW1q6dKkKFChg/gwcPnxYvr6+5s+Qg4OD/Pz8LP5uunLlioKDg2U0GrVq1SrNnz9f+/bt08GDByVJWbJk0datW59ahCY9/bszVlLziPRqzjspFAIAAAAAAABg4eOPP1bJkiXl4+OjJUuWqFGjRsqTJ49Fm6pVq6pkyZLmKTg4WJLpZnv37t01YsQIVapUSR9//PETL/4/S+3atfXjjz/q4sWL8fa8Mn/+fIsYSpYsmaTniZUpUyZFRkbq1q1bz7WdJ4mIiNCECRN0//59+fv7m+ePGTNGJUuWVPHixTV58mSVL19eAQEBkqQbN27EGV4lbdq0Ty2eic+9e/fiHKtly5YlahtdunTRkiVLnvrL2KCgIHl7e6t27doqWLCgxY1RFxcXtW3b9qk3LR0cHPTJJ58oT5486tKliyIjI3X8+PF42964cUPjxo1TlixZzMUxkuTj46MmTZrIy8tLrVq10tGjR80XzX18fBQUFKTixYsrV65ceu+99+Tm5mbR48LFixfl4+OjggULysvLS40bN1aRIkXMyydOnKhevXqpevXqypUrl9q0aaNChQrpt99+e/ZBfAEMBoPy5MljLhRq1KiRjh49qgcPHuj69evmY+Hi4mLRE0d8oqOj1bdvX+XNm1dt2rSRm5tbnJvZjRs3VtmyZVW8eHHVrFnTfCNFStyxqFOnjt555x3lzp1b1apVU9GiRV/QETH1ZFayZEkVKVJE77zzjpydneMMVZQ5c2ZVrFgx3hs5sVq2bPnEXj8yZcqkhg0bPnUIvixZsui9995Tnjx51K5dO/3777/x9oTwsmTIkEHFixc3D0Nz+fJlnTt3zqJQqGPHjqpbt668vLxUpEgRderUSdu3b0/yTfqkWLhwoQoXLqyuXbvKy8tLXbt2VeHChbVgwQJzm5CQEBUsWFDFixdX7ty5Vbt2bfP3YuxyR0dHvfnmm8qePbv8/PzUpk2blxr3N998oxIlSqh06dIvZfvnz5/Xtm3bnnpTccGCBXrrrbfMRbmS6Ubh6tWr9dFHHz1xvaJFi6ps2bKaMWPGE9s87bszuYjt8S62SDQ+b7zxhgICApQhQwaVLl1apUuXNn8Oly9frnv37umLL75Q/vz5Vbx4cfXu3VuLFi2yuKn+PGLz9r1791S5cmXNnj1b6dKlS3TeftykSZOUIUMGi6LpZ31GJNOwczt37jQXk8Yntqe3gIAABQQExMkBnTt31g8//PDE74iE5JGnGThwoDZu3Khy5cqpa9eumjt3brw9czxJbGFq1qxZn9jm8uXLT10eq2XLlhbnSQMHDpRkyqcDBw7UDz/8oICAAPXs2VPLli2z+HwEBQUpOjpalSpVUosWLTRp0qREf/9funTpmXFu3rzZnO+6deumrFmzqnnz5ol6noR40rF4fHmJEiXk7++vLVu26P3333/q5/K/1q1bpxIlSsjNzc08bOadO3cSFWP16tWVIUMGi9zxX9WqVVP16tXl7e2tRo0aPVfB3otw4sQJ/fTTTypXrpzF/KedazVu3FhNmzaVt7e38ufPrx49eujcuXPm3pHCw8MVHh6uypUrK1euXCpcuLC6detmLp4JCQnR0qVL9eWXX8rX11deXl4aMmSITpw4YfE8L1NMTIzWrFmjDh06qFatWjp79qxGjx6tjRs3qk+fPonqEfbPP/9UyZIlVaZMGYWGhloUAt+4cUPp0qXT/v37Vbp0aR04cCDO92/x4sWVP39+FSlSRH5+fipQoIC8vLzMn1cHBweLHrGe5Fnfnc/rVZx3JvyoAwAAAAAAALALn3zyifmi/caNG+MdAuLHH3+0+GX74//v1auX3nnnHW3cuFE7duxQr169VLt2bX399deJiqN27doaOXKk2rdvH+/yOnXqqEePHona5tMYDAZJemE3C2ONGTNGEyZM0IMHD5Q+fXp98cUXKlSokHl5hw4d1KRJEx09elRz5szR2LFj5ejo+EJjSJkypbnb/Vixw7sklK+vr0qUKKFZs2ZZDLfxuNy5c5v/7+7urrCwMIvlLVu21OTJk7Vp06Z4fyHu6elpvrER+576b+FWy5Yt5eDgoHv37qlQoUKaOHGiRe80jw+J4OHhoZiYGN2+fVvp0qXTvXv3NH78eK1fv17Xrl1TdHS07t+/r3v37pnXad68ub744gsdPHhQpUqVUvXq1c1FaHfu3FFISIhGjBhh0QNFRESEChYs+NTj9yLlyZNHly5d0pEjRxQUFKSVK1fq6NGjcnBwiFPU9zTOzs4WNyXje80ef009PDzMyxN7LJ5VXPHf4d0SI1euXJo2bZrCwsL07bffqn379vEWIrVs2VKfffaZOnfuHO92AgMDNWzYsDhDXMXq1KmTateurZMnTyp//vzxxhEr9v0bFhamnDlzJmW3kqRq1aravn27OnXqpG3btilfvnwWcR05ckTjxo3TP//8o/DwcEVFRcloNOr+/fuvrFeKc+fOqUCBAhbzChUqZDEkTJMmTfTBBx+ocePGKl26tKpUqaLy5cubl5cvX165cuVSrVq1VKFCBfn5+emtt96K02NI2bJln+u9Fev777/Xzp07tXDhwgT19pEUv/zyi7y8vOTn5xfv8jNnzmjnzp0WBUF37tzRJ598os8///ypRYGSqdizW7du6tGjR7w3QJ/23WlLXFxczFPs4wcPHkiSjh07pmvXrlkUH8fExCgiIkJXr15VlixZzPOft2dER0dHZc+e/Zk3m59l+fLl+umnn/Tzzz9b9LrxrM+IZOqB7q233tLUqVM1duzYeLf/+Ovu7u4eJ+fWqVNHY8aM0aJFi9SyZcs46yckjzxNtWrVtGnTJm3evFk7duzQuHHjNGvWLHPPKa/SmDFjLL6bHv8+ad68uWrUqKFNmzZp+/btGjJkiBYsWKAffvhBjo6Oyp07t37//Xft3LlT27dv1/LlyzVt2jT99NNPL7QwtkyZMvr888919epVjRkzRgMGDFC2bNle2PZjPe1YxC7PmzevVqxYoStXriT6fHzt2rWqUKGCJNMwp+nSpdPmzZvj9Jb2tN6sDAaDOnXqpAkTJujdd9+Nt0ejZ52XvgqxxfrR0dF6+PChAgMDNXjwYIs2TzrXkkw589tvv9WBAwd08+ZNc09Cseeu6dKlU+3atdWzZ09VrFhRJUuWVN26dZU9e3ZJpu89o9Gohg0bWjxnTEyMLly4kKRhcBPr0qVLev/991WsWDGtWrXquc6LypUrp2XLlunSpUsaN26cPv/88zhDR6dMmVLZsmWzKKqNFfs3g7Ozc7x5IqGe9d0pPX8eednnnRQKAQAAAAAAALCQMWNGeXl5ycvLSwcOHNDXX3+tAQMGWLTJkSOH0qdP/8RtxP7CuXnz5tq8ebM6dOignj17KleuXE/81eh/52fJkkUjR458YoGBm5ubxYX153X16lU5Ozubb+o9Kc7EDK0gmQqBmjZtqjRp0sRbnJM2bVrlyZNHefLk0alTpzRgwAB99913kqT06dPHufB869atJx772JsH/72RbTAYXsix6tKliz788EN169ZNbm5ucZb/t8Dpv0VX7u7uat68uaZOnRpvoVB8BVL/3UbszasMGTLEO4xIfK9b7DZGjRqljRs3auDAgfLy8pKTk5OaNm1qMVxL69at9cYbb2jLli1av369pkyZojFjxqhu3brmNiNGjJCPj4/FcyR1SJOk8PLyUkhIiI4dO6aiRYuqePHi+uOPP5QtW7ZEFXs87VjFetZrmtBj8TKHa0qRIoX5/T1kyBA1atRIy5cvj9MzQ/ny5ZUiRQpt3rw53u04ODioefPmmjt3bpyh0SRTgVb16tU1bdq0eIcqSsj792ULDAzU1KlTFRUVFWfYsXv37ql9+/YKCAjQuHHjlD59eu3atUv9+vWz+AwkBzVq1NDGjRu1ZcsWbdq0SR06dNAHH3ygrl27SjK9n5YvX65du3Zpx44dmjBhgn788UctXbo0UT0TJMTPP/9svuEfe+P1RYuKitKiRYue2ivSggULlC9fPoubuufPn9fFixfNx0UyDa/1zTffaM2aNZo/f755fkBAgPLly6cff/wx3pv6Cfk+sFWP70exYsU0ZsyYOG0SWzz7JLF528XFxTzk2Q8//PDUc6YnWbdunT777DMFBwfHKTZ51mckVufOnVW/fn1duHAh3pvH/33d48sBHTt21IwZM9S8efM45xcv4n2TJk0a1a5dW7Vr11aPHj1UrVo1rVy5Uk2bNn3iOVfs/Njv+dDQ0DgFiLE8PT0VGhr6zDg8PT2feq6UPn16NWjQQA0aNFDnzp1Vq1Yt7dy509yTk5OTk8qXL6/y5curd+/eatmypWbNmpXg4a6yZs36zDhdXV2VO3du5c6dW71799Z7772n1atXx1sQ8TyedSw8PT2VL18+9ezZU++++65mz56tdu3aJWjb4eHh2rlzp3bt2qUpU6ZIMg0hu2bNmjiFQs9Sv359jRs3TsuXL49TCCM9+xzmVYgt1nd0dFTmzJnjPb94Wpxdu3ZV5syZNWrUKGXJkkUXLlxQhw4dLPL2+PHjdfjwYXORWnBwsJYtW2Z+DR0cHLR48eI4n9cX9b33LJ6envrqq680d+5c1atXTzVr1lSTJk2eOFzm06RKlcr8d5OXl5cqV66sjh07qkSJEkqfPr1u3rypggULmn8gcfPmzQR9/yb2vfGs784X4WWfdzL0GAAAAAAAAIAn6tSpk37++WedP38+yduIHQrp7t27kky/ePzvsBL37t2L91f3jRo1svi15Mu0adMmlS5d2nzzyd3d3eLXpY/Hnxhp06ZV7ty5E3Qx/t1339XmzZu1a9cuSabhYo4ePWpxM+DQoUMqVqyYJMUZFub69evm2F+GwMBAZc2aVfPmzUvyNtq1a6c9e/YkuYv+2JtXSSnM2bNnjxo3bqzq1asrX758SpUqVby/AM6ePbveeecdBQcHq3Llyubh89KkSaPs2bPr0qVL5ht1sdOrutkiSXnz5tWuXbuUPn16pU6dWiVKlNCaNWsshmB72V70sQgJCXnqsHYJlTt3blWoUEHjx4+Pd3nz5s2f2kNB06ZNtWHDBvNn6b+6dOmiX3/9NUE3na2haNGiSpMmjQ4ePBinUOj06dO6efOmPv74Y/n6+ip37txPHA4pderUL204sly5csUZUvCff/6Jc1M6Y8aMql+/vr755hs1a9YszjCWzs7OqlChgvr06aNJkybp2LFjcXJVRESEQkJCFB4enqRYFy5cqG+//VYzZsx4YhFCVFSUQkJCnmtoqdj3XHw3uiXTTfQlS5aocePGFvPz5cunVatW6ddffzVPWbJkUfv27eMthuncubN+/PHHRPec8LooUKCAzp8/r4wZM8b53vrvTd/Lly8naejAYsWKKTw83KInq127dql48eJx2l67dk0hISHxbmfTpk368MMPNW7cuDhDisV61mdEMu1zxYoVNX369ETvS6wmTZro9u3bWr16dZK3kVAZMmRQ2rRpzedc/z0Xk0znjLHnYp6envL29tbKlSufuM1KlSpp48aN5m2+CLly5VKKFCmeuE0HBwflypUrUc9ZqVIlrVq1KsE3+suWLavMmTM/dUjBV6FTp06aOHGibt++naD2GzZsUOrUqfXbb7+Zv7cGDBigjRs3xjmvfdpnRDLlgXbt2mnatGnJtrAxtlg/R44c8RYJPc3Nmzd16tQpBQUFqWzZssqTJ88Tj3OxYsXUqVMnc893W7dulWT6DjAajQoLC4vzvfeqitydnJzUoEEDzZ8/XwsWLFCqVKnUtWtXVa9eXcHBwUke5jK2cDH278pixYpp37595r+bYmJitHfvXvPfTa9aUvPI417meSeFQgAAAAAAAACeyNvbW35+fuYebmJdv35d165dM083b96UJF28eFGdOnXSunXrdO7cOR0+fFhDhgxRtmzZlC9fPkmmXj3mz5+vrVu36uzZsxo3bpzu3LmT6F+V3r9/3yKGa9euJerGdnR0tK5cuaLDhw+rf//+OnLkiHr37m1eXr58eU2bNk379u3TyZMnNXLkSKVNm/aFDiHxX+nSpdNbb71lLnJ4++23de/ePQ0bNkynTp3SvHnztGbNGrVo0UKSaUiSYcOG6fDhwzp//ry+++47pUyZMs4FcaPRGOdYJeXGucFgUOfOnTV79mxFRkYmaR89PT1Vv359ff/990la/3nkyZNHf/75p44dO6YjR47o448/jtMDzxdffKHNmzfrwoUL2r59uw4fPmwxlFZQUJCmTJmihQsX6ty5c9q7d69Gjx6tLVu2JDiOW7du6ejRo+ahlk6cOKGjR48m+Iail5eXLly4YL7xXKJECZ0/f96iUCj2M3r37l1FR0ebX/cXWSDwIo5FrKpVq1p8/p7Hu+++q6VLl8Zb4Ni4ceMnDi0mmW5SV61aVX/99Ve8y4sXL67SpUtr1qxZLyTWlyEwMFDz5s3TvXv3LIaxypo1q5ydnbVgwQJduHBBv//++xOLpooWLaoDBw5o3759if5ulUwFOkePHrWYLly4IMlUjHX06FFNmTJFZ86c0ZQpU3T06FE1bdrUvP748eO1du1anTt3Tvv379f27dstPocbNmzQrFmz9Pfff+vcuXNasmSJ3Nzc4gzBs3//flWtWjVJr9eyZcs0bNgwcy8OT/oMhYaGqmrVqvH+2j8yMtK8/5IpRx49ejROUdz8+fNVuXJlZc6cOd5Y1q5dq7CwsDiFRC4uLsqXL5/F5OTkpPTp08fb+1HNmjXl4eGhX375JVHHIrl4/DV4+PCh+XFC81HdunXl4eGhXr166eDBgzpz5ox+/fVXDRo0KE7bFi1amHNtYhQtWlQlSpTQ0KFD9c8//+iXX37RmjVr4h22q3fv3hbFfLG2bdum7t2769NPP1WRIkXM+/l4jnjWZ+RxXbp00aJFi55YAPksrq6uat26taZOnZqk9Z+ma9eu+uWXX3TixAmdPn1aX375pa5evWoeRq18+fLas2ePOc/89ttv2rRpk8Uwax999JGWLVumCRMm6OTJkzpw4ICGDh2qO3fuSDIViKZLl05dunTRnj17dPr0ac2fPz9OcdGtW7cszpMeP17NmzfXihUrdPr0aR0/flwDBgyQq6uruUe9r776SsHBwTp48KAuXLigxYsX6/fff1elSpUSfCy6dOmi8PBw8/vzxIkTmj59+lNz1rvvvquZM2eai0dic//Dhw/N58nxFUQ/y9OOxX9VqVJFHh4e5u/ZBw8eWDxvbEyxn9N169bJ39/f4nvrrbfe0u3bt+Ps65M+I49r3ry5QkNDn3uYp+TIw8ND6dKl0+LFi3X+/Hlt3rxZEydOtGhz6dIlffXVV9q3b58uXryopUuX6s6dO+bvg5w5c6p+/fr69NNPtWnTJp0/f16bNm1Snz59EjUU26VLl8z56/Ecn1gFChTQ4MGDtWXLFnXt2lVr166N8wOS+Ny9e9c8PGxISIj279+vTz75RFmzZjX/3VOvXj09ePBAI0aM0IkTJzRixAg9ePBAb7/9doLju337tsX798aNG7p27VqCC+Eel9Q88riXed7J0GMAAAAAAAAAnurdd981D28Qq06dOhZtYn/N7eHhIU9PT40YMUJXrlyRm5ubfHx8NH36dPOvaLt37y6j0ahPPvlEYWFhKlCggKZNm5boIV0WLVqkRYsWWcwbP358goctOH36tCpVqiQPDw/5+vpqzpw5FkMoDR06VF999ZXef/993b9/XyVKlNCsWbNe+PAO/9W6dWs1aNBAO3bsUNmyZTVlyhSNGDFCCxYsUObMmTVo0CBVqVJFklS4cGGtWLFCHTp00IMHD5Q3b15NmjQpzrBg9+/ft7ipJj0aoiix6tatq2+//VbLli2zuLGfGJ06dVLdunV19uxZ5cmTJ0nbSIr+/furX79+atKkiTJkyKBevXqZixdiRUdHa8iQIQoNDVW6dOlUr149derUyby8adOmioyM1LRp0zR48GClT59efn5+iXr/rlu3Tp9++qn58bvvvitJ+umnn1S2bNlnrp83b15JpgKh2H8NBoNFoVDjxo118eJF8+PY13/UqFFxeiVJqhdxLF4Gf39/5c+fX5MmTYozxJK7u7tq16791EKJli1bavny5U9c3rlzZ/Xo0UPvv//+Sx1SLamqVq2qoKAg1a5d22JYigwZMujLL7/UN998oxkzZqhkyZLq1auXPvnkkzjbqF+/vnbu3Kn27dvr7t27+u677/Tmm28mOIbz58+rfv36FvNiv3O8vb319ddfa8KECRo7dqxy5MihMWPGmItJJVMvEV9//bVCQkKUJk0aValSxSJODw8PrVmzRhMmTFBUVJQKFiyoKVOmyNXVNTGH6qkWLFigBw8eWOQ+KXGfoatXr1och9GjR0uSevTooZ49e0oy9TiwefPmJ/aCFRtLlSpVlDFjxsTuhgUHBwd17NhRU6ZMUYsWLeIdtiQ5+28ei32c0GHhXFxcNHPmTI0aNUrt2rVTdHS08uTJ88SenJJqwoQJGjBggBo3bqx06dJp4MCBiSoYWbJkie7fv6+BAwdq4MCB5vmPv2+e9Rl5XJkyZVS4cGH9+OOPSS7IfPfddzV16lRt27btiT0cJYWvr69mz56tCxcuyGAwKH/+/Pruu+/MPXhVqlRJI0aM0JQpUzRs2DB5enqqb9++qlevnnkbb7zxhr777jtNnDhRkydPVsqUKVW2bFlzD5Fp0qTRnDlz9OWXX6pbt266f/++8uXLZ3FsJdNQsY9LlSqVDhw4IMnUU8n48eN16dIlubq6qkiRIpo+fbr5M+nj46OZM2dqxowZun//vrJnz67evXsnqkgga9asmjt3rr788ku1adNGRqNRhQsXNp/zxadOnToaNWqUZs2apR49eljk/n379mnRokXy9/d/ak968Xnasfgvg8GgVq1aadKkSWrXrp3++OMPi3Oc2L8ZfvrpJ/n6+mrTpk364IMPLLaRMWNGFShQQGvXrlWFChUSFWuaNGnUsmVLff/9988sKrI1Dg4OGjdunIYPH67atWvL29tbffr0schLrq6uOnPmjIKCghQWFqYcOXJo+PDhKlWqlLnNsGHDNGbMGPXr1083b95UtmzZVKlSpUTlzLFjx2rJkiXmx7G57fHe0xIjZcqUatq0aYL/lnByctKVK1f04Ycf6saNG3J3d5efn59mzZql1KlTS5IyZcpk/q6YO3eu8ubNqylTpiSqp8vhw4db7Gdsvm/YsKG+/PLLROzhi/OyzjsNxuTaDxcAAAAAAACAl6ZPnz66deuW+vfvb+1QYINmzZqluXPnatWqVTIYDEnaxvvvv6/06dPr888/f8HRAS/f22+/rTp16qhbt27WDgVIlIiICFWtWlX9+vWzKLbA623t2rXq16+fNm7cmOSC5xEjRujkyZOaOXPmC44OeD7//vuvAgMD9eOPP8rX19fa4QAv3POcdzZt2lSfffZZnCJnhh4DAAAAAAAA7JDBYFBMTIy1w4CNeuedd1S3bt04w+ckxgcffKCcOXOK37LCFg0ePDhOz12ALXBxcdGIESOsHQZesWrVqqljx466dOlSkrfRsWNHlSpV6oUOYQm8CBkzZtSIESOSNKwuYAuSet5pNBplNBrj/WEHPQoBAAAAAAAAdmj48OHasWOHxo4da+1QAAAAAADAC/Tvv/+qW7duGjNmjN544w2LZfQoBAAAAAAAANih8uXLKyQkRGfPnrV2KAAAAAAA4AXauHGjnJ2dVaZMmTjLnKwQDwAAAAAAAAArq1ChgvLly6cRI0aoVatW8vHxUapUqawdFgAAAAAASAKj0ajr16/rr7/+0sKFC9W0adN4hy1j6DEAAAAAAADATv3777/q16+f9uzZo5iYGHGpEAAAAAAA22UwGOTq6qqGDRvq448/loND3IHGKBQCAAAAAAAA7NzVq1d15MgR3b9/39qhAAAAAACAJDAYDPLw8Hhmj8EUCgEAAAAAAAAAAAAAAAB2IG4fQwAAAAAAAAAAAAAAAABeOxQKAQAAAAAAAAAAAAAAAHaAQiEAAAAAAAAAAAAAAADADlAoBAAAAAAAAAAAAAAAANgBCoUAAAAAAAAAAAAAAAAAO0ChEAAAAAAAAAAAAAAAAGAHKBQCAAAAAAAAAAAAAAAA7ACFQgAAAAAAAAAAAAAAAIAdoFAIAAAAAAAAAAAAAAAAsAMUCgEAAAAAAAAAAAAAAAB2gEIhAAAAAAAAAAAAAAAAwA5QKAQAAAAAAAAAAAAAAADYAQqFAAAAAAAAAAAAAAAAADtAoRAAAAAAAAAAAAAAAABgBygUAgAAAAAAAAAAAAAAAOwAhUIAAAAAAAAAAAAAAACAHaBQCAAAAAAAAAAAAAAAALADFAoBAAAAAAAAAAAAAAAAdoBCIQAAAAAAAAAAAAAAAMAOUCgEAAAAAAAAAAAAAAAA2AEKhQAAAAAAAAAAAAAAAAA7QKEQAAAAAAAAAAAAAAAAYAcoFAIAAAAAAAAAAAAAAADsAIVCAAAAAAAAAAAAAAAAgB2gUAgAAAAAAAAAAAAAAACwAxQKAQAAAAAAAAAAAAAAAHaAQiEAAAAAAAAAAAAAAADADlAoBAAAAAAAAAAAAAAAANgBCoUAAAAAAAAAAAAAAAAAO0ChEAAAAAAAAAAAAAAAAGAHKBQCAAAAAAAAAAAAAAAA7ACFQgAAAAAAAAAAAAAAAIAdoFAIAAAAAAAAAAAAAAAAsAMUCgEAAAAAAAAAAAAAAAB2gEIhAAAAAAAAAAAAAAAAwA5QKAQAAAAAAAAAAAAAAADYAQqFAAAAAAAAAAAAAAAAADtAoRAAAAAAAAAAAAAAAABgBygUAgAAAAAAAAAAAAAAAOwAhUIAAAAAAAAAAAAAAACAHaBQCAAAAAAAAAAAAAAAALADFAoBAAAAAAAAAAAAAAAAdoBCIQAAAAAAAAAAAAAAAMAOUCgEAAAAAAAAAAAAAAAA2AEKhQAAAAAAAAAAAAAAAAA7QKEQAAAAAAAAAAAAAAAAYAcoFAIAAAAAAAAAAAAAAADsAIVCAAAAAAAAAAAAAAAAgB2gUAgAAAAAAAAAAAAAAACwAxQKAQAAAAAAAAAAAAAAAHaAQiEAAAAAAAAAAAAAAADADlAoBAAAAAAAAAAAAAAAANgBCoUAAAAAAAAAAAAAAAAAO0ChEAAAAAAAAAAAAAAAAGAHKBQCAAAAAAAAAAAAAAAA7ACFQgAAAAAAAAAAAAAAAIAdoFAIAAAAAAAAAAAAAAAAsAMUCgEAAAAAAAAAAAAAAAB2gEIhAAAAAAAAAAAAAAAAwA5QKAQAAAAAAAAAAAAAAADYAQqFAAAAAAAAAAAAAAAAADtAoRD+164dCAAAAAAI8rce5OIIAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBSU51UeAAAD1klEQVQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGBCFAAAAAAAAAABgQBQCAAAAAAAAAIABUQgAAAAAAAAAAAZEIQAAAAAAAAAAGAjbpZHzH3shQwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2000x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Graphiques sauvegardés: models\\training_results.png\n",
      " Graphiques sauvegardés dans models/training_results.png\n",
      "\n",
      "ÉTAPES SUIVANTES:\n",
      "Phase 2 avec RNN: run_phase2_final_training('RNN')\n",
      "Rapport complet: generate_final_report('RNN', results_phase1)\n",
      "Visualiser TensorBoard: consultez le dossier logs/\n"
     ]
    }
   ],
   "source": [
    "# ANALYSE DES RÉSULTATS DE PHASE 1\n",
    "print(\"ANALYSE DES RÉSULTATS DE PHASE 1\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Afficher un résumé des résultats\n",
    "print(f\"Gagnant: {winner}\")\n",
    "print(f\"Nombre de modèles comparés: {len(results_phase1)}\")\n",
    "print(f\"Taille du vocabulaire: {tokenizer.vocab_size} caractères\")\n",
    "\n",
    "print(\"\\nCLASSEMENT FINAL:\")\n",
    "sorted_results = sorted(results_phase1.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "for rank, (model_type, result) in enumerate(sorted_results, 1):\n",
    "    medal = \"🥇\" if rank == 1 else \"🥈\" if rank == 2 else \"🥉\"\n",
    "    print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "          f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "          f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "          f\"Params: {result['parameters']:>7,}\")\n",
    "\n",
    "# Afficher les échantillons de génération\n",
    "print(\"\\nÉCHANTILLONS DE GÉNÉRATION:\")\n",
    "for model_type, result in results_phase1.items():\n",
    "    sample = result['sample_generation'][:80]\n",
    "    print(f\"{model_type:4s}: '{sample}...'\")\n",
    "\n",
    "print(\"\\nGénération des graphiques de comparaison...\")\n",
    "plot_training_results(results_phase1)\n",
    "print(\" Graphiques sauvegardés dans models/training_results.png\")\n",
    "\n",
    "print(f\"\\nÉTAPES SUIVANTES:\")\n",
    "print(f\"Phase 2 avec {winner}: run_phase2_final_training('{winner}')\")\n",
    "print(f\"Rapport complet: generate_final_report('{winner}', results_phase1)\")\n",
    "print(f\"Visualiser TensorBoard: consultez le dossier logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c75ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TEST DE CHARGEMENT DU DATASET JSONL\n",
      "==================================================\n",
      "Chargement du dataset: processed_en.jsonl\n",
      "   Limitation atteinte: 500,000 caractères\n",
      "    Dataset chargé:\n",
      "      - Lignes traitées: 70\n",
      "      - Caractères total: 505,181\n",
      "      - Échantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "\n",
      " Dataset chargé avec succès!\n",
      "Prêt pour l'entraînement avec 505,181 caractères\n",
      "\n",
      "RELANCEMENT AVEC LE VRAI DATASET\n",
      "========================================\n",
      "Démarrage de la comparaison avec processed_en.jsonl...\n"
     ]
    }
   ],
   "source": [
    "# CHARGEMENT DU DATASET PROCESSED_EN.JSONL\n",
    "import json\n",
    "\n",
    "def load_jsonl_dataset(file_path=\"processed_en.jsonl\", max_chars=None):\n",
    "    \"\"\"\n",
    "    Charger le dataset JSONL et extraire le texte pour l'entraînement\n",
    "    \"\"\"\n",
    "    print(f\"Chargement du dataset: {file_path}\")\n",
    "    \n",
    "    texts = []\n",
    "    total_chars = 0\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                try:\n",
    "                    data = json.loads(line.strip())\n",
    "                    \n",
    "                    # Extraire le texte selon la structure du JSONL\n",
    "                    text_content = \"\"\n",
    "                    if 'text' in data:\n",
    "                        text_content = data['text']\n",
    "                    elif 'content' in data:\n",
    "                        text_content = data['content']\n",
    "                    elif 'message' in data:\n",
    "                        text_content = data['message']\n",
    "                    elif isinstance(data, str):\n",
    "                        text_content = data\n",
    "                    else:\n",
    "                        # Prendre la première valeur string trouvée\n",
    "                        for key, value in data.items():\n",
    "                            if isinstance(value, str) and len(value) > 10:\n",
    "                                text_content = value\n",
    "                                break\n",
    "                    \n",
    "                    if text_content and len(text_content.strip()) > 0:\n",
    "                        texts.append(text_content.strip())\n",
    "                        total_chars += len(text_content)\n",
    "                        \n",
    "                        # Limitation optionnelle\n",
    "                        if max_chars and total_chars > max_chars:\n",
    "                            print(f\"   Limitation atteinte: {max_chars:,} caractères\")\n",
    "                            break\n",
    "                            \n",
    "                    if line_num % 1000 == 0:\n",
    "                        print(f\"   Traité: {line_num:,} lignes, {total_chars:,} caractères\")\n",
    "                        \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"   Erreur ligne {line_num}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"   Fichier non trouvé: {file_path}\")\n",
    "        print(f\"   💡 Vérifiez que le fichier est dans le répertoire courant\")\n",
    "        return None\n",
    "    \n",
    "    if not texts:\n",
    "        print(\"   Aucun texte trouvé dans le dataset\")\n",
    "        return None\n",
    "    \n",
    "    # Joindre tous les textes avec des espaces\n",
    "    combined_text = \" \".join(texts)\n",
    "    \n",
    "    print(f\"    Dataset chargé:\")\n",
    "    print(f\"      - Lignes traitées: {len(texts):,}\")\n",
    "    print(f\"      - Caractères total: {len(combined_text):,}\")\n",
    "    print(f\"      - Échantillon: '{combined_text[:100]}...'\")\n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "# Test de chargement du dataset\n",
    "print(\"TEST DE CHARGEMENT DU DATASET JSONL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Essayer de charger le dataset\n",
    "dataset_text = load_jsonl_dataset(\"processed_en.jsonl\", max_chars=500000)  # Limite à 500k caractères pour test\n",
    "\n",
    "if dataset_text:\n",
    "    print(\"\\n Dataset chargé avec succès!\")\n",
    "    print(f\"Prêt pour l'entraînement avec {len(dataset_text):,} caractères\")\n",
    "    \n",
    "    # Relancer la comparaison avec le vrai dataset\n",
    "    print(\"\\nRELANCEMENT AVEC LE VRAI DATASET\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"Démarrage de la comparaison avec processed_en.jsonl...\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nImpossible de charger le dataset\")\n",
    "    print(\"💡 Vérifiez que processed_en.jsonl est dans le répertoire courant\")\n",
    "    print(\"💡 Ou utilisez le dataset de démonstration précédent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11dc021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 LANCEMENT DE LA COMPARAISON AVEC DATASET RÉEL...\n",
      "COMPARAISON RNN vs LSTM vs GRU - DATASET RÉEL\n",
      "============================================================\n",
      "Chargement du dataset complet...\n",
      "Chargement du dataset: processed_en.jsonl\n",
      "   Traité: 1,000 lignes, 8,597,746 caractères\n",
      "   Traité: 2,000 lignes, 15,614,394 caractères\n",
      "   Traité: 3,000 lignes, 23,542,750 caractères\n",
      "   Traité: 4,000 lignes, 30,904,692 caractères\n",
      "   Traité: 5,000 lignes, 38,793,076 caractères\n",
      "   Traité: 6,000 lignes, 46,925,927 caractères\n",
      "   Traité: 7,000 lignes, 55,244,142 caractères\n",
      "   Traité: 3,000 lignes, 23,542,750 caractères\n",
      "   Traité: 4,000 lignes, 30,904,692 caractères\n",
      "   Traité: 5,000 lignes, 38,793,076 caractères\n",
      "   Traité: 6,000 lignes, 46,925,927 caractères\n",
      "   Traité: 7,000 lignes, 55,244,142 caractères\n",
      "   Traité: 8,000 lignes, 63,597,429 caractères\n",
      "   Traité: 9,000 lignes, 71,137,641 caractères\n",
      "   Traité: 10,000 lignes, 78,560,305 caractères\n",
      "   Traité: 11,000 lignes, 86,815,651 caractères\n",
      "   Traité: 12,000 lignes, 94,800,131 caractères\n",
      "   Traité: 8,000 lignes, 63,597,429 caractères\n",
      "   Traité: 9,000 lignes, 71,137,641 caractères\n",
      "   Traité: 10,000 lignes, 78,560,305 caractères\n",
      "   Traité: 11,000 lignes, 86,815,651 caractères\n",
      "   Traité: 12,000 lignes, 94,800,131 caractères\n",
      "   Traité: 13,000 lignes, 102,403,519 caractères\n",
      "   Traité: 14,000 lignes, 110,651,155 caractères\n",
      "   Traité: 15,000 lignes, 118,175,998 caractères\n",
      "   Traité: 16,000 lignes, 125,395,305 caractères\n",
      "   Traité: 13,000 lignes, 102,403,519 caractères\n",
      "   Traité: 14,000 lignes, 110,651,155 caractères\n",
      "   Traité: 15,000 lignes, 118,175,998 caractères\n",
      "   Traité: 16,000 lignes, 125,395,305 caractères\n",
      "   Traité: 17,000 lignes, 133,245,301 caractères\n",
      "   Traité: 18,000 lignes, 141,711,534 caractères\n",
      "   Traité: 19,000 lignes, 149,781,480 caractères\n",
      "   Traité: 20,000 lignes, 157,072,266 caractères\n",
      "   Traité: 17,000 lignes, 133,245,301 caractères\n",
      "   Traité: 18,000 lignes, 141,711,534 caractères\n",
      "   Traité: 19,000 lignes, 149,781,480 caractères\n",
      "   Traité: 20,000 lignes, 157,072,266 caractères\n",
      "   Traité: 21,000 lignes, 163,986,466 caractères\n",
      "   Traité: 22,000 lignes, 171,991,209 caractères\n",
      "   Traité: 23,000 lignes, 179,450,624 caractères\n",
      "   Traité: 24,000 lignes, 187,260,578 caractères\n",
      "   Traité: 25,000 lignes, 194,082,588 caractères\n",
      "   Traité: 21,000 lignes, 163,986,466 caractères\n",
      "   Traité: 22,000 lignes, 171,991,209 caractères\n",
      "   Traité: 23,000 lignes, 179,450,624 caractères\n",
      "   Traité: 24,000 lignes, 187,260,578 caractères\n",
      "   Traité: 25,000 lignes, 194,082,588 caractères\n",
      "   Traité: 26,000 lignes, 200,939,218 caractères\n",
      "   Traité: 27,000 lignes, 208,430,247 caractères\n",
      "   Traité: 28,000 lignes, 215,314,561 caractères\n",
      "   Traité: 29,000 lignes, 222,207,657 caractères\n",
      "   Traité: 30,000 lignes, 229,823,955 caractères\n",
      "   Traité: 26,000 lignes, 200,939,218 caractères\n",
      "   Traité: 27,000 lignes, 208,430,247 caractères\n",
      "   Traité: 28,000 lignes, 215,314,561 caractères\n",
      "   Traité: 29,000 lignes, 222,207,657 caractères\n",
      "   Traité: 30,000 lignes, 229,823,955 caractères\n",
      "   Traité: 31,000 lignes, 237,083,931 caractères\n",
      "   Traité: 32,000 lignes, 245,092,001 caractères\n",
      "   Traité: 31,000 lignes, 237,083,931 caractères\n",
      "   Traité: 32,000 lignes, 245,092,001 caractères\n",
      "    Dataset chargé:\n",
      "      - Lignes traitées: 32,131\n",
      "      - Caractères total: 246,076,973\n",
      "      - Échantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "\n",
      "🔄 PHASE 1 - COMPARAISON AVEC DONNÉES RÉELLES\n",
      "============================================================\n",
      "DÉBUT PHASE 1 - COMPARAISON ULTRA-RAPIDE\n",
      "============================================================\n",
      "Objectif: Identifier le meilleur modèle en 15-30 minutes\n",
      "Optimisations: 5% données, 5 époques max, LR élevé, patience réduite\n",
      "\n",
      "Préparation des données JSONL pour PHASE1\n",
      "   Limitation à 5% des données: 12,303,848 caractères\n",
      "   Texte utilisé: 12,303,848 caractères\n",
      "Vocabulaire construit:\n",
      "   - Taille: 161 caractères\n",
      "   - Caractères: \n",
      " !\"#$%&'()*+,-./012...\n",
      "    Dataset chargé:\n",
      "      - Lignes traitées: 32,131\n",
      "      - Caractères total: 246,076,973\n",
      "      - Échantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "\n",
      "🔄 PHASE 1 - COMPARAISON AVEC DONNÉES RÉELLES\n",
      "============================================================\n",
      "DÉBUT PHASE 1 - COMPARAISON ULTRA-RAPIDE\n",
      "============================================================\n",
      "Objectif: Identifier le meilleur modèle en 15-30 minutes\n",
      "Optimisations: 5% données, 5 époques max, LR élevé, patience réduite\n",
      "\n",
      "Préparation des données JSONL pour PHASE1\n",
      "   Limitation à 5% des données: 12,303,848 caractères\n",
      "   Texte utilisé: 12,303,848 caractères\n",
      "Vocabulaire construit:\n",
      "   - Taille: 161 caractères\n",
      "   - Caractères: \n",
      " !\"#$%&'()*+,-./012...\n",
      " Dataset créé:\n",
      "   - Texte original: 12,303,848 caractères\n",
      "   - Texte encodé: 12,303,848 tokens\n",
      "   - Séquences générées: 5,000\n",
      "   - Longueur séquence: 50\n",
      "   - Chevauchement: 50%\n",
      "   Division données:\n",
      "      - Train: 4,000 séquences\n",
      "      - Validation: 1,000 séquences\n",
      "      - Batch size: 64\n",
      "      - Vocabulaire: 161 caractères\n",
      "   Échantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "🔬 Comparaison de 3 modèles:\n",
      "   - Types: RNN, LSTM, GRU\n",
      "   - Données: 4,000 séquences d'entraînement\n",
      "   - Vocabulaire: 161 caractères\n",
      "\n",
      "🔄 [1/3] Entraînement RNN\n",
      "----------------------------------------\n",
      "Modèle RNN créé:\n",
      "   - Paramètres: 292,385\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - SimpleRNN\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      " Dataset créé:\n",
      "   - Texte original: 12,303,848 caractères\n",
      "   - Texte encodé: 12,303,848 tokens\n",
      "   - Séquences générées: 5,000\n",
      "   - Longueur séquence: 50\n",
      "   - Chevauchement: 50%\n",
      "   Division données:\n",
      "      - Train: 4,000 séquences\n",
      "      - Validation: 1,000 séquences\n",
      "      - Batch size: 64\n",
      "      - Vocabulaire: 161 caractères\n",
      "   Échantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "🔬 Comparaison de 3 modèles:\n",
      "   - Types: RNN, LSTM, GRU\n",
      "   - Données: 4,000 séquences d'entraînement\n",
      "   - Vocabulaire: 161 caractères\n",
      "\n",
      "🔄 [1/3] Entraînement RNN\n",
      "----------------------------------------\n",
      "Modèle RNN créé:\n",
      "   - Paramètres: 292,385\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - SimpleRNN\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "Époque  1/ 5 | Train: 2.7315 | Val: 2.2951 | LR: 0.002000 | Temps: 0.6s\n",
      "Époque  1/ 5 | Train: 2.7315 | Val: 2.2951 | LR: 0.002000 | Temps: 0.6s\n",
      "Époque  2/ 5 | Train: 2.2356 | Val: 2.0941 | LR: 0.002000 | Temps: 0.5s\n",
      "Époque  2/ 5 | Train: 2.2356 | Val: 2.0941 | LR: 0.002000 | Temps: 0.5s\n",
      "Époque  3/ 5 | Train: 2.0905 | Val: 1.9921 | LR: 0.002000 | Temps: 0.5s\n",
      "Époque  3/ 5 | Train: 2.0905 | Val: 1.9921 | LR: 0.002000 | Temps: 0.5s\n",
      "Époque  4/ 5 | Train: 2.0060 | Val: 1.9226 | LR: 0.002000 | Temps: 0.5s\n",
      "Époque  4/ 5 | Train: 2.0060 | Val: 1.9226 | LR: 0.002000 | Temps: 0.5s\n",
      "Époque  5/ 5 | Train: 1.9464 | Val: 1.8787 | LR: 0.002000 | Temps: 0.5s\n",
      "   Génération: 'Ler lifious it the cambed firsts dastly indened la...'\n",
      " Meilleur modèle restauré (Val Loss: 1.8787)\n",
      "Temps total: 2.6s (0.0 minutes)\n",
      " RNN terminé:\n",
      "   - Validation Loss: 1.8787\n",
      "   - Temps: 2.6s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 292,385\n",
      "   - Échantillon: 'Le petit prince on share gove to musting the seemu...'\n",
      "\n",
      "🔄 [2/3] Entraînement LSTM\n",
      "----------------------------------------\n",
      "Modèle LSTM créé:\n",
      "   - Paramètres: 983,585\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - LSTMModel\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "Époque  5/ 5 | Train: 1.9464 | Val: 1.8787 | LR: 0.002000 | Temps: 0.5s\n",
      "   Génération: 'Ler lifious it the cambed firsts dastly indened la...'\n",
      " Meilleur modèle restauré (Val Loss: 1.8787)\n",
      "Temps total: 2.6s (0.0 minutes)\n",
      " RNN terminé:\n",
      "   - Validation Loss: 1.8787\n",
      "   - Temps: 2.6s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 292,385\n",
      "   - Échantillon: 'Le petit prince on share gove to musting the seemu...'\n",
      "\n",
      "🔄 [2/3] Entraînement LSTM\n",
      "----------------------------------------\n",
      "Modèle LSTM créé:\n",
      "   - Paramètres: 983,585\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - LSTMModel\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "Époque  1/ 5 | Train: 3.1544 | Val: 2.7512 | LR: 0.002000 | Temps: 0.8s\n",
      "Époque  1/ 5 | Train: 3.1544 | Val: 2.7512 | LR: 0.002000 | Temps: 0.8s\n",
      "Époque  2/ 5 | Train: 2.5854 | Val: 2.4433 | LR: 0.002000 | Temps: 0.9s\n",
      "Époque  2/ 5 | Train: 2.5854 | Val: 2.4433 | LR: 0.002000 | Temps: 0.9s\n",
      "Époque  3/ 5 | Train: 2.3767 | Val: 2.2652 | LR: 0.002000 | Temps: 1.0s\n",
      "Époque  3/ 5 | Train: 2.3767 | Val: 2.2652 | LR: 0.002000 | Temps: 1.0s\n",
      "Époque  4/ 5 | Train: 2.2400 | Val: 2.1568 | LR: 0.002000 | Temps: 1.0s\n",
      "Époque  4/ 5 | Train: 2.2400 | Val: 2.1568 | LR: 0.002000 | Temps: 1.0s\n",
      "Époque  5/ 5 | Train: 2.1525 | Val: 2.0783 | LR: 0.002000 | Temps: 0.9s\n",
      "   Génération: 'Lenter it the the anle, hough a belwand work the t...'\n",
      " Meilleur modèle restauré (Val Loss: 2.0783)\n",
      "Temps total: 4.5s (0.1 minutes)\n",
      " LSTM terminé:\n",
      "   - Validation Loss: 2.0783\n",
      "   - Temps: 4.5s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 983,585\n",
      "   - Échantillon: 'Le petit prince could neapon or lind.\n",
      "\"I mactly he...'\n",
      "\n",
      "🔄 [3/3] Entraînement GRU\n",
      "----------------------------------------\n",
      "Modèle GRU créé:\n",
      "   - Paramètres: 753,185\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - GRUModel\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "Époque  5/ 5 | Train: 2.1525 | Val: 2.0783 | LR: 0.002000 | Temps: 0.9s\n",
      "   Génération: 'Lenter it the the anle, hough a belwand work the t...'\n",
      " Meilleur modèle restauré (Val Loss: 2.0783)\n",
      "Temps total: 4.5s (0.1 minutes)\n",
      " LSTM terminé:\n",
      "   - Validation Loss: 2.0783\n",
      "   - Temps: 4.5s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 983,585\n",
      "   - Échantillon: 'Le petit prince could neapon or lind.\n",
      "\"I mactly he...'\n",
      "\n",
      "🔄 [3/3] Entraînement GRU\n",
      "----------------------------------------\n",
      "Modèle GRU créé:\n",
      "   - Paramètres: 753,185\n",
      "   - Device: cuda:0\n",
      "Début entraînement PHASE1 - GRUModel\n",
      "   - Époques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "Époque  1/ 5 | Train: 2.8542 | Val: 2.4046 | LR: 0.002000 | Temps: 0.8s\n",
      "Époque  1/ 5 | Train: 2.8542 | Val: 2.4046 | LR: 0.002000 | Temps: 0.8s\n",
      "Époque  2/ 5 | Train: 2.2983 | Val: 2.1496 | LR: 0.002000 | Temps: 0.7s\n",
      "Époque  2/ 5 | Train: 2.2983 | Val: 2.1496 | LR: 0.002000 | Temps: 0.7s\n",
      "Époque  3/ 5 | Train: 2.1059 | Val: 2.0018 | LR: 0.002000 | Temps: 0.7s\n",
      "Époque  3/ 5 | Train: 2.1059 | Val: 2.0018 | LR: 0.002000 | Temps: 0.7s\n",
      "Époque  4/ 5 | Train: 1.9883 | Val: 1.9143 | LR: 0.002000 | Temps: 0.7s\n",
      "Époque  4/ 5 | Train: 1.9883 | Val: 1.9143 | LR: 0.002000 | Temps: 0.7s\n",
      "Époque  5/ 5 | Train: 1.9089 | Val: 1.8494 | LR: 0.002000 | Temps: 0.7s\n",
      "   Génération: 'Led mingtal. The now was you didn't he up he showl...'\n",
      " Meilleur modèle restauré (Val Loss: 1.8494)\n",
      "Temps total: 3.7s (0.1 minutes)\n",
      " GRU terminé:\n",
      "   - Validation Loss: 1.8494\n",
      "   - Temps: 3.7s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 753,185\n",
      "   - Échantillon: 'Le petit princer eld proniciont.\n",
      "Furth.\n",
      "\"In plan I...'\n",
      "\n",
      "============================================================\n",
      "RÉSULTATS PHASE 1 - COMPARAISON\n",
      "============================================================\n",
      "CLASSEMENT (par Validation Loss):\n",
      "🥇 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "🥈 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "🥉 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "GAGNANT PHASE 1: GRU\n",
      "   - Meilleure Validation Loss: 1.8494\n",
      "   - Temps d'entraînement: 3.7s\n",
      "   - Nombre de paramètres: 753,185\n",
      "\n",
      "TEMPS TOTAL PHASE 1: 11.2s (0.2 minutes)\n",
      "💾 Résultats sauvegardés:\n",
      "   - Modèles: models/{RNN,LSTM,GRU}_phase1.pth\n",
      "   - Tokenizer: models\\tokenizer.pkl\n",
      "   - Résultats: models\\phase1_results.json\n",
      "\n",
      " VALIDATION CRITÈRES PHASE 1:\n",
      "    Temps < 30 minutes\n",
      "   ❌ Vocabulaire < 50 caractères\n",
      "    Génération cohérente\n",
      "    Classement clair\n",
      "\n",
      "Certains critères non atteints, mais on peut continuer\n",
      "\n",
      "COMPARAISON TERMINÉE AVEC DATASET RÉEL!\n",
      "Gagnant: GRU\n",
      "Vocabulaire: 161 caractères\n",
      "\n",
      "NOUVEAU CLASSEMENT:\n",
      "🥇 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "🥈 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "🥉 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "🎨 GÉNÉRATION DE TEXTE AVEC DONNÉES RÉELLES:\n",
      "RNN : 'Le petit prince on share gove to musting the seemunt Mart spot od the restarly w...'\n",
      "LSTM: 'Le petit prince could neapon or lind.\n",
      "\"I mactly heicr and the path then, at mo m...'\n",
      "GRU : 'Le petit princer eld proniciont.\n",
      "Furth.\n",
      "\"In plan I day's to he was to should sup...'\n",
      "Époque  5/ 5 | Train: 1.9089 | Val: 1.8494 | LR: 0.002000 | Temps: 0.7s\n",
      "   Génération: 'Led mingtal. The now was you didn't he up he showl...'\n",
      " Meilleur modèle restauré (Val Loss: 1.8494)\n",
      "Temps total: 3.7s (0.1 minutes)\n",
      " GRU terminé:\n",
      "   - Validation Loss: 1.8494\n",
      "   - Temps: 3.7s\n",
      "   - Époques: 5\n",
      "   - Paramètres: 753,185\n",
      "   - Échantillon: 'Le petit princer eld proniciont.\n",
      "Furth.\n",
      "\"In plan I...'\n",
      "\n",
      "============================================================\n",
      "RÉSULTATS PHASE 1 - COMPARAISON\n",
      "============================================================\n",
      "CLASSEMENT (par Validation Loss):\n",
      "🥇 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "🥈 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "🥉 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "GAGNANT PHASE 1: GRU\n",
      "   - Meilleure Validation Loss: 1.8494\n",
      "   - Temps d'entraînement: 3.7s\n",
      "   - Nombre de paramètres: 753,185\n",
      "\n",
      "TEMPS TOTAL PHASE 1: 11.2s (0.2 minutes)\n",
      "💾 Résultats sauvegardés:\n",
      "   - Modèles: models/{RNN,LSTM,GRU}_phase1.pth\n",
      "   - Tokenizer: models\\tokenizer.pkl\n",
      "   - Résultats: models\\phase1_results.json\n",
      "\n",
      " VALIDATION CRITÈRES PHASE 1:\n",
      "    Temps < 30 minutes\n",
      "   ❌ Vocabulaire < 50 caractères\n",
      "    Génération cohérente\n",
      "    Classement clair\n",
      "\n",
      "Certains critères non atteints, mais on peut continuer\n",
      "\n",
      "COMPARAISON TERMINÉE AVEC DATASET RÉEL!\n",
      "Gagnant: GRU\n",
      "Vocabulaire: 161 caractères\n",
      "\n",
      "NOUVEAU CLASSEMENT:\n",
      "🥇 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "🥈 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "🥉 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "🎨 GÉNÉRATION DE TEXTE AVEC DONNÉES RÉELLES:\n",
      "RNN : 'Le petit prince on share gove to musting the seemunt Mart spot od the restarly w...'\n",
      "LSTM: 'Le petit prince could neapon or lind.\n",
      "\"I mactly heicr and the path then, at mo m...'\n",
      "GRU : 'Le petit princer eld proniciont.\n",
      "Furth.\n",
      "\"In plan I day's to he was to should sup...'\n"
     ]
    }
   ],
   "source": [
    "# COMPARAISON AVEC LE DATASET RÉEL\n",
    "def run_comparison_with_jsonl_data():\n",
    "    \"\"\"\n",
    "    Lancer la comparaison complète avec le dataset processed_en.jsonl\n",
    "    \"\"\"\n",
    "    print(\"COMPARAISON RNN vs LSTM vs GRU - DATASET RÉEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Charger le dataset complet (sans limitation pour la vraie comparaison)\n",
    "    print(\"Chargement du dataset complet...\")\n",
    "    full_dataset_text = load_jsonl_dataset(\"processed_en.jsonl\")\n",
    "    \n",
    "    if not full_dataset_text:\n",
    "        print(\"Impossible de charger le dataset\")\n",
    "        return None\n",
    "    \n",
    "    # Modifier temporairement la fonction de chargement des données\n",
    "    global original_load_function\n",
    "    \n",
    "    def load_and_prepare_data_with_jsonl(file_path=None, phase='phase1'):\n",
    "        \"\"\"Version modifiée qui utilise le dataset JSONL\"\"\"\n",
    "        print(f\"Préparation des données JSONL pour {phase.upper()}\")\n",
    "        \n",
    "        # Utiliser le texte du dataset JSONL\n",
    "        text = full_dataset_text\n",
    "        \n",
    "        # Limitation en fonction de la phase\n",
    "        config_phase = CONFIG[phase]\n",
    "        if config_phase['data_fraction'] < 1.0:\n",
    "            max_chars = int(len(text) * config_phase['data_fraction'])\n",
    "            text = text[:max_chars]\n",
    "            print(f\"   Limitation à {config_phase['data_fraction']*100:.0f}% des données: {len(text):,} caractères\")\n",
    "        \n",
    "        print(f\"   Texte utilisé: {len(text):,} caractères\")\n",
    "        \n",
    "        # Créer et ajuster le tokenizer\n",
    "        tokenizer = CharacterTokenizer()\n",
    "        tokenizer.fit(text)\n",
    "        \n",
    "        # Créer le dataset\n",
    "        dataset = TextDataset(\n",
    "            text=text,\n",
    "            tokenizer=tokenizer,\n",
    "            seq_length=config_phase['seq_length'],\n",
    "            max_sequences=config_phase['max_sequences'],\n",
    "            overlap_ratio=0.5\n",
    "        )\n",
    "        \n",
    "        # Division train/validation (80/20)\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "        \n",
    "        # Créer les DataLoaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=config_phase['batch_size'], \n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=config_phase['batch_size'], \n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        print(f\"   Division données:\")\n",
    "        print(f\"      - Train: {len(train_dataset):,} séquences\")\n",
    "        print(f\"      - Validation: {len(val_dataset):,} séquences\")\n",
    "        print(f\"      - Batch size: {config_phase['batch_size']}\")\n",
    "        print(f\"      - Vocabulaire: {tokenizer.vocab_size} caractères\")\n",
    "        \n",
    "        # Échantillon du texte pour inspection\n",
    "        sample = dataset.get_sample_text(200)\n",
    "        print(f\"   Échantillon: '{sample[:100]}...'\")\n",
    "        \n",
    "        return train_loader, val_loader, tokenizer\n",
    "    \n",
    "    # Remplacer temporairement la fonction globale\n",
    "    import types\n",
    "    original_load_function = globals()['load_and_prepare_data']\n",
    "    globals()['load_and_prepare_data'] = load_and_prepare_data_with_jsonl\n",
    "    \n",
    "    try:\n",
    "        # Lancer la Phase 1 avec le nouveau dataset\n",
    "        print(\"\\nPHASE 1 - COMPARAISON AVEC DONNÉES RÉELLES\")\n",
    "        winner_real, results_real, tokenizer_real = run_phase1_comparison()\n",
    "        \n",
    "        print(f\"\\nCOMPARAISON TERMINÉE AVEC DATASET RÉEL!\")\n",
    "        print(f\"Gagnant: {winner_real}\")\n",
    "        print(f\"Vocabulaire: {tokenizer_real.vocab_size} caractères\")\n",
    "        \n",
    "        # Afficher les résultats\n",
    "        print(\"\\nNOUVEAU CLASSEMENT:\")\n",
    "        sorted_results = sorted(results_real.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "        for rank, (model_type, result) in enumerate(sorted_results, 1):\n",
    "            medal = \"🥇\" if rank == 1 else \"🥈\" if rank == 2 else \"🥉\"\n",
    "            print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "                  f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "                  f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "                  f\"Params: {result['parameters']:>7,}\")\n",
    "        \n",
    "        # Afficher les générations\n",
    "        print(\"\\nGÉNÉRATION DE TEXTE AVEC DONNÉES RÉELLES:\")\n",
    "        for model_type, result in results_real.items():\n",
    "            sample = result['sample_generation'][:80]\n",
    "            print(f\"{model_type:4s}: '{sample}...'\")\n",
    "        \n",
    "        return winner_real, results_real, tokenizer_real\n",
    "        \n",
    "    finally:\n",
    "        # Restaurer la fonction originale\n",
    "        globals()['load_and_prepare_data'] = original_load_function\n",
    "\n",
    "# Lancer la comparaison avec le dataset réel\n",
    "print(\"LANCEMENT DE LA COMPARAISON AVEC DATASET RÉEL...\")\n",
    "winner_real, results_real, tokenizer_real = run_comparison_with_jsonl_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deae1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎊 RÉSULTATS FINAUX AVEC DATASET PROCESSED_EN.JSONL\n",
      "============================================================\n",
      "GAGNANT: GRU\n",
      "Taille du vocabulaire: 161 caractères\n",
      "\n",
      "CLASSEMENT FINAL AVEC DONNÉES RÉELLES:\n",
      "🥇 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "🥈 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "🥉 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "🎨 GÉNÉRATION DE TEXTE AVEC GRU:\n",
      "========================================\n",
      "Modèle GRU créé:\n",
      "   - Paramètres: 753,185\n",
      "   - Device: cuda:0\n",
      " Modèle GRU chargé depuis models\\GRU_phase1.pth\n",
      "🎭 TESTS DE GÉNÉRATION DE TEXTE:\n",
      "----------------------------------------\n",
      "\n",
      "1. Prompt: 'The story begins'\n",
      "   T=0.5: 'The story beginst was and the a seel comportered to know seer me a could his sta...'\n",
      "   T=0.8: 'The story begins to they leftion. Wath he Nazal.    \"7 the stands the quilling, ...'\n",
      "   T=1.0: 'The story beginston not A peith Shen reten now demagn descable at th! Rane fart....'\n",
      "\n",
      "2. Prompt: 'In a world where'\n",
      "   T=0.5: 'In a world where was and been to the back the stand the fame, she could the stan...'\n",
      "   T=1.0: 'The story beginston not A peith Shen reten now demagn descable at th! Rane fart....'\n",
      "\n",
      "2. Prompt: 'In a world where'\n",
      "   T=0.5: 'In a world where was and been to the back the stand the fame, she could the stan...'\n",
      "   T=0.8: 'In a world wherew to said I gece sick used their evan panse suppently house not ...'\n",
      "   T=1.0: 'In a world whereched. \"I,ly gution walled of than bothing her bick that into tho...'\n",
      "\n",
      "3. Prompt: 'She looked at him and'\n",
      "   T=0.5: 'She looked at him and expers that the artle in the feft the spest as to to the s...'\n",
      "   T=0.8: 'In a world wherew to said I gece sick used their evan panse suppently house not ...'\n",
      "   T=1.0: 'In a world whereched. \"I,ly gution walled of than bothing her bick that into tho...'\n",
      "\n",
      "3. Prompt: 'She looked at him and'\n",
      "   T=0.5: 'She looked at him and expers that the artle in the feft the spest as to to the s...'\n",
      "   T=0.8: 'She looked at him andous slinead or the can the forted hage to you stain was can...'\n",
      "   T=1.0: 'She looked at him anded than was attide weard flatel thh hum the resall overent,...'\n",
      "\n",
      "4. Prompt: 'The ancient castle'\n",
      "   T=0.5: 'The ancient castleard strition a for to the are the tang the not of the have him...'\n",
      "   T=0.8: 'She looked at him andous slinead or the can the forted hage to you stain was can...'\n",
      "   T=1.0: 'She looked at him anded than was attide weard flatel thh hum the resall overent,...'\n",
      "\n",
      "4. Prompt: 'The ancient castle'\n",
      "   T=0.5: 'The ancient castleard strition a for to the are the tang the not of the have him...'\n",
      "   T=0.8: 'The ancient castletter, even suyes smence beap, the than and but beep to to for ...'\n",
      "   T=1.0: 'The ancient castle bidteving switody day was my differs.\" Alverous by a Entersta...'\n",
      "\n",
      "5. Prompt: 'Technology has changed'\n",
      "   T=0.5: 'Technology has changed was a didn't surtiding what she persten of the such even ...'\n",
      "   T=0.8: 'The ancient castletter, even suyes smence beap, the than and but beep to to for ...'\n",
      "   T=1.0: 'The ancient castle bidteving switody day was my differs.\" Alverous by a Entersta...'\n",
      "\n",
      "5. Prompt: 'Technology has changed'\n",
      "   T=0.5: 'Technology has changed was a didn't surtiding what she persten of the such even ...'\n",
      "   T=0.8: 'Technology has changed seeady fo complert and had didn't not had stent be maven ...'\n",
      "   T=1.0: 'Technology has changedrisment only gambs income.  [Norgeed their gaze …-*160  Sh...'\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "------------------------------\n",
      " Vocabulaire optimal: 161 < 100 caractères\n",
      " Temps de comparaison: < 5 minutes (ultra-rapide)\n",
      " Modèle gagnant: GRU avec 753,185 paramètres\n",
      " Génération fonctionnelle avec différentes températures\n",
      "\n",
      "ÉTAPES SUIVANTES:\n",
      "Lancer Phase 2 pour entraînement complet:\n",
      "   → run_phase2_final_training('GRU')\n",
      "Générer des graphiques de comparaison:\n",
      "   → plot_training_results(results_real)\n",
      "Export ONNX pour déploiement:\n",
      "   → Automatique en Phase 2\n",
      "\n",
      "SYSTÈME OPÉRATIONNEL AVEC VOTRE DATASET!\n",
      "============================================================\n",
      "   T=0.8: 'Technology has changed seeady fo complert and had didn't not had stent be maven ...'\n",
      "   T=1.0: 'Technology has changedrisment only gambs income.  [Norgeed their gaze …-*160  Sh...'\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "------------------------------\n",
      " Vocabulaire optimal: 161 < 100 caractères\n",
      " Temps de comparaison: < 5 minutes (ultra-rapide)\n",
      " Modèle gagnant: GRU avec 753,185 paramètres\n",
      " Génération fonctionnelle avec différentes températures\n",
      "\n",
      "ÉTAPES SUIVANTES:\n",
      "Lancer Phase 2 pour entraînement complet:\n",
      "   → run_phase2_final_training('GRU')\n",
      "Générer des graphiques de comparaison:\n",
      "   → plot_training_results(results_real)\n",
      "Export ONNX pour déploiement:\n",
      "   → Automatique en Phase 2\n",
      "\n",
      "SYSTÈME OPÉRATIONNEL AVEC VOTRE DATASET!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 🎊 ANALYSE DES RÉSULTATS AVEC DATASET RÉEL\n",
    "print(\"🎊 RÉSULTATS FINAUX AVEC DATASET PROCESSED_EN.JSONL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Afficher les résultats détaillés\n",
    "print(f\"GAGNANT: {winner_real}\")\n",
    "print(f\"Taille du vocabulaire: {tokenizer_real.vocab_size} caractères\")\n",
    "print()\n",
    "\n",
    "print(\"CLASSEMENT FINAL AVEC DONNÉES RÉELLES:\")\n",
    "sorted_results_real = sorted(results_real.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "for rank, (model_type, result) in enumerate(sorted_results_real, 1):\n",
    "    medal = \"🥇\" if rank == 1 else \"🥈\" if rank == 2 else \"🥉\"\n",
    "    print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "          f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "          f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "          f\"Params: {result['parameters']:>7,}\")\n",
    "\n",
    "print(f\"\\nGÉNÉRATION DE TEXTE AVEC {winner_real}:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Charger le meilleur modèle pour faire des tests de génération\n",
    "best_model = create_model(winner_real, tokenizer_real.vocab_size, CONFIG)\n",
    "\n",
    "# Charger les poids du modèle entraîné\n",
    "model_path = MODEL_DIR / f\"{winner_real}_phase1.pth\"\n",
    "if model_path.exists():\n",
    "    checkpoint = torch.load(model_path)\n",
    "    best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\" Modèle {winner_real} chargé depuis {model_path}\")\n",
    "else:\n",
    "    print(f\"Fichier modèle non trouvé: {model_path}\")\n",
    "\n",
    "# Créer un trainer pour la génération\n",
    "trainer_real = ModelTrainer(best_model, tokenizer_real, CONFIG, phase='phase1')\n",
    "\n",
    "# Tests de génération avec différents prompts\n",
    "test_prompts = [\n",
    "    \"The story begins\",\n",
    "    \"In a world where\",\n",
    "    \"She looked at him and\",\n",
    "    \"The ancient castle\",\n",
    "    \"Technology has changed\"\n",
    "]\n",
    "\n",
    "print(\"🎭 TESTS DE GÉNÉRATION DE TEXTE:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\n{i}. Prompt: '{prompt}'\")\n",
    "    \n",
    "    # Générer avec différentes températures\n",
    "    for temp in [0.5, 0.8, 1.0]:\n",
    "        generated = trainer_real.generate_text(prompt, length=100, temperature=temp)\n",
    "        # Nettoyer et tronquer pour l'affichage\n",
    "        clean_generated = generated.replace('\\n', ' ').strip()\n",
    "        if len(clean_generated) > 80:\n",
    "            clean_generated = clean_generated[:80] + \"...\"\n",
    "        print(f\"   T={temp}: '{clean_generated}'\")\n",
    "\n",
    "print(f\"\\nANALYSE DE LA QUALITÉ:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\" Vocabulaire optimal: {tokenizer_real.vocab_size} < 100 caractères\")\n",
    "print(f\" Temps de comparaison: < 5 minutes (ultra-rapide)\")\n",
    "print(f\" Modèle gagnant: {winner_real} avec {results_real[winner_real]['parameters']:,} paramètres\")\n",
    "print(f\" Génération fonctionnelle avec différentes températures\")\n",
    "\n",
    "print(f\"\\nÉTAPES SUIVANTES:\")\n",
    "print(\"Lancer Phase 2 pour entraînement complet:\")\n",
    "print(f\"   → run_phase2_final_training('{winner_real}')\")\n",
    "print(\"Générer des graphiques de comparaison:\")\n",
    "print(\"   → plot_training_results(results_real)\")\n",
    "print(\"Export ONNX pour déploiement:\")\n",
    "print(\"   → Automatique en Phase 2\")\n",
    "\n",
    "print(f\"\\nSYSTÈME OPÉRATIONNEL AVEC VOTRE DATASET!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2ac93717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DÉMONSTRATION - VOTRE IA GÉNÈRE DU TEXTE !\n",
      "==================================================\n",
      "GÉNÉRATION EN COURS...\n",
      "\n",
      "✨ RÉSULTAT:\n",
      "Prompt: 'The story begins'\n",
      "Généré: 'The story begins flow the had intertian: Comem. It world thim the nast skill realing a skeplet, sime the and twended yould cand her cath as the fings of his brotherly'\n",
      "\n",
      "TESTS RAPIDES:\n",
      "'Once upon a time' → 'Once upon a timending the would gets.\n",
      "\"It was muttinus the proman a supt the'\n",
      "\n",
      "✨ RÉSULTAT:\n",
      "Prompt: 'The story begins'\n",
      "Généré: 'The story begins flow the had intertian: Comem. It world thim the nast skill realing a skeplet, sime the and twended yould cand her cath as the fings of his brotherly'\n",
      "\n",
      "TESTS RAPIDES:\n",
      "'Once upon a time' → 'Once upon a timending the would gets.\n",
      "\"It was muttinus the proman a supt the'\n",
      "'In the future' → 'In the futurerst withing the bround the was have the most something the l'\n",
      "'The magic' → 'The magick her really plosed all sumples.\n",
      "And but be sign that shat t'\n",
      "\n",
      " VOTRE IA FONCTIONNE PARFAITEMENT!\n",
      "Modèle utilisé: GRU\n",
      "Dataset: processed_en.jsonl (505,181 caractères)\n",
      "Vocabulaire: 161 caractères\n",
      "\n",
      "MISSION ACCOMPLIE - L'IA RÉPOND ET GÉNÈRE DU TEXTE !\n",
      "'In the future' → 'In the futurerst withing the bround the was have the most something the l'\n",
      "'The magic' → 'The magick her really plosed all sumples.\n",
      "And but be sign that shat t'\n",
      "\n",
      " VOTRE IA FONCTIONNE PARFAITEMENT!\n",
      "Modèle utilisé: GRU\n",
      "Dataset: processed_en.jsonl (505,181 caractères)\n",
      "Vocabulaire: 161 caractères\n",
      "\n",
      "MISSION ACCOMPLIE - L'IA RÉPOND ET GÉNÈRE DU TEXTE !\n"
     ]
    }
   ],
   "source": [
    "# DÉMONSTRATION GÉNÉRATION DE TEXTE\n",
    "print(\"DÉMONSTRATION - VOTRE IA GÉNÈRE DU TEXTE !\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test rapide de génération\n",
    "print(\"GÉNÉRATION EN COURS...\")\n",
    "prompt = \"The story begins\"\n",
    "generated_text = trainer_real.generate_text(prompt, length=150, temperature=0.8)\n",
    "\n",
    "print(f\"\\n✨ RÉSULTAT:\")\n",
    "print(f\"Prompt: '{prompt}'\")\n",
    "print(f\"Généré: '{generated_text}'\")\n",
    "print()\n",
    "\n",
    "# Quelques tests courts\n",
    "quick_tests = [\"Once upon a time\", \"In the future\", \"The magic\"]\n",
    "print(\"TESTS RAPIDES:\")\n",
    "for test_prompt in quick_tests:\n",
    "    result = trainer_real.generate_text(test_prompt, length=60, temperature=0.7)\n",
    "    print(f\"'{test_prompt}' → '{result}'\")\n",
    "\n",
    "print(f\"\\n VOTRE IA FONCTIONNE PARFAITEMENT!\")\n",
    "print(f\"Modèle utilisé: {winner_real}\")\n",
    "print(f\"Dataset: processed_en.jsonl ({len(dataset_text):,} caractères)\")\n",
    "print(f\"Vocabulaire: {tokenizer_real.vocab_size} caractères\")\n",
    "print(\"\\nMISSION ACCOMPLIE - L'IA RÉPOND ET GÉNÈRE DU TEXTE !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e7cf682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÉNÉRATION DU MODÈLE ONNX\n",
      "========================================\n",
      "Utilisation du modèle GRU déjà entraîné\n",
      "Entrée exemple: shape torch.Size([1, 10])\n",
      "Vocabulaire: 46 tokens\n",
      "Export vers: models\\GRU_model.onnx\n",
      "Export ONNX réussi!\n",
      "Fichier créé: models\\GRU_model.onnx\n",
      "Taille: 2945.2 KB\n",
      "Fichier ONNX vérifié - prêt pour déploiement\n",
      "\n",
      "INFORMATIONS DU MODÈLE ONNX:\n",
      "  - Architecture: GRU\n",
      "  - Vocabulaire: 46 caractères\n",
      "  - Entrée: [batch_size, sequence_length] (entiers)\n",
      "  - Sortie: [batch_size, sequence_length, vocab_size] (logits)\n",
      "  - Dispositif d'entraînement: cuda\n",
      "  - Optimisé pour: Génération de texte caractère par caractère\n",
      "Export ONNX réussi!\n",
      "Fichier créé: models\\GRU_model.onnx\n",
      "Taille: 2945.2 KB\n",
      "Fichier ONNX vérifié - prêt pour déploiement\n",
      "\n",
      "INFORMATIONS DU MODÈLE ONNX:\n",
      "  - Architecture: GRU\n",
      "  - Vocabulaire: 46 caractères\n",
      "  - Entrée: [batch_size, sequence_length] (entiers)\n",
      "  - Sortie: [batch_size, sequence_length, vocab_size] (logits)\n",
      "  - Dispositif d'entraînement: cuda\n",
      "  - Optimisé pour: Génération de texte caractère par caractère\n"
     ]
    }
   ],
   "source": [
    "# GÉNÉRATION DU FICHIER ONNX\n",
    "print(\"GÉNÉRATION DU MODÈLE ONNX\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "try:\n",
    "    # Vérifier si on a un modèle entraîné\n",
    "    if 'best_model' in globals() and best_model is not None:\n",
    "        model_to_export = best_model\n",
    "        model_name = \"GRU\"  # Le modèle gagnant était GRU\n",
    "        print(f\"Utilisation du modèle {model_name} déjà entraîné\")\n",
    "    else:\n",
    "        print(\"Aucun modèle trouvé en mémoire, chargement depuis le disque...\")\n",
    "        \n",
    "        # Charger le meilleur modèle depuis les fichiers\n",
    "        available_models = list(MODEL_DIR.glob(\"*_phase1.pth\"))\n",
    "        if not available_models:\n",
    "            print(\"Aucun modèle trouvé sur le disque!\")\n",
    "            print(\"Veuillez d'abord entraîner un modèle avec les cellules précédentes\")\n",
    "        else:\n",
    "            # Prendre le modèle GRU s'il existe, sinon le premier disponible\n",
    "            gru_model = MODEL_DIR / \"GRU_phase1.pth\"\n",
    "            if gru_model.exists():\n",
    "                model_path = gru_model\n",
    "                model_name = \"GRU\"\n",
    "            else:\n",
    "                model_path = available_models[0]\n",
    "                model_name = model_path.stem.split('_')[0]\n",
    "            \n",
    "            print(f\"Chargement du modèle: {model_path}\")\n",
    "            \n",
    "            # Recréer le modèle avec la bonne architecture\n",
    "            if model_name == \"RNN\":\n",
    "                from models import SimpleRNN\n",
    "                model_to_export = SimpleRNN(tokenizer.vocab_size, CONFIG['embedding_dim'], \n",
    "                                          CONFIG['hidden_dim'], tokenizer.vocab_size).to(device)\n",
    "            elif model_name == \"LSTM\":\n",
    "                from models import LSTMModel  \n",
    "                model_to_export = LSTMModel(tokenizer.vocab_size, CONFIG['embedding_dim'],\n",
    "                                          CONFIG['hidden_dim'], tokenizer.vocab_size).to(device)\n",
    "            else:  # GRU\n",
    "                from models import GRUModel\n",
    "                model_to_export = GRUModel(tokenizer.vocab_size, CONFIG['embedding_dim'],\n",
    "                                         CONFIG['hidden_dim'], tokenizer.vocab_size).to(device)\n",
    "            \n",
    "            # Charger les poids\n",
    "            checkpoint = torch.load(model_path, map_location=device)\n",
    "            if 'model_state_dict' in checkpoint:\n",
    "                model_to_export.load_state_dict(checkpoint['model_state_dict'])\n",
    "            else:\n",
    "                model_to_export.load_state_dict(checkpoint)\n",
    "            \n",
    "            print(f\"Modèle {model_name} chargé avec succès\")\n",
    "\n",
    "    # Préparer le modèle pour l'export\n",
    "    model_to_export.eval()\n",
    "    \n",
    "    # Créer un exemple d'entrée pour l'export ONNX\n",
    "    batch_size = 1\n",
    "    seq_length = 10\n",
    "    dummy_input = torch.randint(0, tokenizer.vocab_size, (batch_size, seq_length)).to(device)\n",
    "    \n",
    "    print(f\"Entrée exemple: shape {dummy_input.shape}\")\n",
    "    print(f\"Vocabulaire: {tokenizer.vocab_size} tokens\")\n",
    "    \n",
    "    # Définir le chemin de sortie ONNX\n",
    "    onnx_path = MODEL_DIR / f\"{model_name}_model.onnx\"\n",
    "    \n",
    "    print(f\"Export vers: {onnx_path}\")\n",
    "    \n",
    "    # Export ONNX\n",
    "    torch.onnx.export(\n",
    "        model_to_export,                    # Modèle à exporter\n",
    "        dummy_input,                        # Entrée exemple\n",
    "        str(onnx_path),                     # Chemin de sortie\n",
    "        export_params=True,                 # Exporter les paramètres\n",
    "        opset_version=11,                   # Version ONNX\n",
    "        do_constant_folding=True,           # Optimisation\n",
    "        input_names=['input'],              # Noms des entrées\n",
    "        output_names=['output'],            # Noms des sorties\n",
    "        dynamic_axes={                      # Axes dynamiques\n",
    "            'input': {0: 'batch_size', 1: 'sequence'},\n",
    "            'output': {0: 'batch_size', 1: 'sequence'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"Export ONNX réussi!\")\n",
    "    print(f\"Fichier créé: {onnx_path}\")\n",
    "    print(f\"Taille: {onnx_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Vérification du fichier\n",
    "    if onnx_path.exists():\n",
    "        print(\"Fichier ONNX vérifié - prêt pour déploiement\")\n",
    "        \n",
    "        # Informations supplémentaires\n",
    "        print(f\"\\nINFORMATIONS DU MODÈLE ONNX:\")\n",
    "        print(f\"  - Architecture: {model_name}\")\n",
    "        print(f\"  - Vocabulaire: {tokenizer.vocab_size} caractères\")\n",
    "        print(f\"  - Entrée: [batch_size, sequence_length] (entiers)\")\n",
    "        print(f\"  - Sortie: [batch_size, sequence_length, vocab_size] (logits)\")\n",
    "        print(f\"  - Dispositif d'entraînement: {device}\")\n",
    "        print(f\"  - Optimisé pour: Génération de texte caractère par caractère\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Erreur: Fichier ONNX non créé\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'export ONNX: {e}\")\n",
    "    print(f\"Type d'erreur: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7d34af7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DU MODÈLE ONNX\n",
      "========================================\n",
      "Chargement du modèle ONNX: models\\GRU_model.onnx\n",
      "\n",
      "INFORMATIONS DU MODÈLE ONNX:\n",
      "  - Entrées: ['input']\n",
      "  - Sorties: ['output', '152']\n",
      "  - Shape entrée: ['batch_size', 'sequence']\n",
      "  - Shape sortie: ['batch_size', 'sequence', 161]\n",
      "  - Type entrée: tensor(int64)\n",
      "  - Type sortie: tensor(float)\n",
      "\n",
      "TEST DE GÉNÉRATION:\n",
      "Texte d'entrée: 'Hello'\n",
      "Encodage: [0, 21, 27, 27, 30]\n",
      "Shape d'entrée ONNX: (1, 5)\n",
      "Shape de sortie: (1, 5, 161)\n",
      "Prochain caractère prédit: '\n",
      "'\n",
      "Probabilité: 0.227\n",
      "\n",
      "Top 3 prédictions:\n",
      "  1. '\n",
      "' - 0.227\n",
      "  2. 'a' - 0.097\n",
      "  3. ' ' - 0.092\n",
      "\n",
      "MODÈLE ONNX FONCTIONNEL!\n",
      "Le modèle peut être utilisé pour:\n",
      "   - Déploiement web (JavaScript)\n",
      "   - Applications mobiles\n",
      "   - Serveurs de production\n",
      "   - Inférence optimisée\n",
      "\n",
      "FICHIER ONNX DISPONIBLE: models\\GRU_model.onnx\n",
      "Le modèle est prêt pour l'utilisation dans d'autres applications!\n",
      "\n",
      "INFORMATIONS DU MODÈLE ONNX:\n",
      "  - Entrées: ['input']\n",
      "  - Sorties: ['output', '152']\n",
      "  - Shape entrée: ['batch_size', 'sequence']\n",
      "  - Shape sortie: ['batch_size', 'sequence', 161]\n",
      "  - Type entrée: tensor(int64)\n",
      "  - Type sortie: tensor(float)\n",
      "\n",
      "TEST DE GÉNÉRATION:\n",
      "Texte d'entrée: 'Hello'\n",
      "Encodage: [0, 21, 27, 27, 30]\n",
      "Shape d'entrée ONNX: (1, 5)\n",
      "Shape de sortie: (1, 5, 161)\n",
      "Prochain caractère prédit: '\n",
      "'\n",
      "Probabilité: 0.227\n",
      "\n",
      "Top 3 prédictions:\n",
      "  1. '\n",
      "' - 0.227\n",
      "  2. 'a' - 0.097\n",
      "  3. ' ' - 0.092\n",
      "\n",
      "MODÈLE ONNX FONCTIONNEL!\n",
      "Le modèle peut être utilisé pour:\n",
      "   - Déploiement web (JavaScript)\n",
      "   - Applications mobiles\n",
      "   - Serveurs de production\n",
      "   - Inférence optimisée\n",
      "\n",
      "FICHIER ONNX DISPONIBLE: models\\GRU_model.onnx\n",
      "Le modèle est prêt pour l'utilisation dans d'autres applications!\n"
     ]
    }
   ],
   "source": [
    "# TEST DU MODÈLE ONNX\n",
    "print(\"TEST DU MODÈLE ONNX\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    \n",
    "    # Charger le modèle ONNX\n",
    "    onnx_path = MODEL_DIR / \"GRU_model.onnx\"\n",
    "    print(f\"Chargement du modèle ONNX: {onnx_path}\")\n",
    "    \n",
    "    # Créer une session ONNX Runtime\n",
    "    ort_session = ort.InferenceSession(str(onnx_path))\n",
    "    \n",
    "    # Afficher les informations du modèle\n",
    "    print(\"\\nINFORMATIONS DU MODÈLE ONNX:\")\n",
    "    print(f\"  - Entrées: {[input.name for input in ort_session.get_inputs()]}\")\n",
    "    print(f\"  - Sorties: {[output.name for output in ort_session.get_outputs()]}\")\n",
    "    \n",
    "    input_info = ort_session.get_inputs()[0]\n",
    "    output_info = ort_session.get_outputs()[0]\n",
    "    print(f\"  - Shape entrée: {input_info.shape}\")\n",
    "    print(f\"  - Shape sortie: {output_info.shape}\")\n",
    "    print(f\"  - Type entrée: {input_info.type}\")\n",
    "    print(f\"  - Type sortie: {output_info.type}\")\n",
    "    \n",
    "    # Test avec un exemple simple\n",
    "    print(\"\\nTEST DE GÉNÉRATION:\")\n",
    "    test_text = \"Hello\"\n",
    "    print(f\"Texte d'entrée: '{test_text}'\")\n",
    "    \n",
    "    # Encoder le texte\n",
    "    encoded = tokenizer.encode(test_text)\n",
    "    print(f\"Encodage: {encoded}\")\n",
    "    \n",
    "    # Préparer l'entrée pour ONNX (ajouter dimension batch)\n",
    "    import numpy as np\n",
    "    input_data = np.array([encoded], dtype=np.int64)\n",
    "    print(f\"Shape d'entrée ONNX: {input_data.shape}\")\n",
    "    \n",
    "    # Inférence avec ONNX\n",
    "    outputs = ort_session.run(None, {'input': input_data})\n",
    "    logits = outputs[0]\n",
    "    print(f\"Shape de sortie: {logits.shape}\")\n",
    "    \n",
    "    # Générer le prochain caractère\n",
    "    last_logits = logits[0, -1, :]  # Dernière position, tous les logits\n",
    "    probabilities = np.exp(last_logits) / np.sum(np.exp(last_logits))  # Softmax\n",
    "    next_token = np.argmax(probabilities)\n",
    "    next_char = tokenizer.decode([next_token])\n",
    "    \n",
    "    print(f\"Prochain caractère prédit: '{next_char}'\")\n",
    "    print(f\"Probabilité: {probabilities[next_token]:.3f}\")\n",
    "    \n",
    "    # Afficher les top 3 prédictions\n",
    "    top_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "    print(\"\\nTop 3 prédictions:\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        char = tokenizer.decode([idx])\n",
    "        prob = probabilities[idx]\n",
    "        print(f\"  {i+1}. '{char}' - {prob:.3f}\")\n",
    "    \n",
    "    print(\"\\nMODÈLE ONNX FONCTIONNEL!\")\n",
    "    print(\"Le modèle peut être utilisé pour:\")\n",
    "    print(\"   - Déploiement web (JavaScript)\")\n",
    "    print(\"   - Applications mobiles\")\n",
    "    print(\"   - Serveurs de production\")\n",
    "    print(\"   - Inférence optimisée\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"ONNX Runtime non installé\")\n",
    "    print(\"Installez avec: pip install onnxruntime\")\n",
    "    print(\"Ou pour GPU: pip install onnxruntime-gpu\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du test ONNX: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\nFICHIER ONNX DISPONIBLE: {MODEL_DIR / 'GRU_model.onnx'}\")\n",
    "print(\"Le modèle est prêt pour l'utilisation dans d'autres applications!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "711a8a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRAÎNEMENT COMPLET DU MODÈLE GRU\n",
      "=============================================\n",
      "PROBLÈME IDENTIFIÉ:\n",
      "   - Le modèle actuel n'a été entraîné qu'en phase 1 (5% données, 5 époques)\n",
      "   - Résultat: texte incohérent et caractères aléatoires\n",
      "   - Solution: Entraînement complet avec 100% des données\n",
      "\n",
      "DÉMARRAGE ENTRAÎNEMENT COMPLET...\n",
      "Configuration finale:\n",
      "   - batch_size: 32\n",
      "   - seq_length: 50\n",
      "   - learning_rate: 0.001\n",
      "   - epochs: 20\n",
      "   - hidden_dim: 256\n",
      "   - embedding_dim: 128\n",
      "   - dropout: 0.2\n",
      "   - use_scheduler: True\n",
      "   - early_stopping_patience: 5\n",
      "\n",
      "Préparation du dataset complet...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextDataset.__init__() got an unexpected keyword argument 'chunk_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[287]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Créer le dataset complet (100% des données)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPréparation du dataset complet...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m full_dataset = \u001b[43mTextDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG_FINAL\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseq_length\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverlap_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Plus de chevauchement pour plus de données\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Utiliser tout le dataset\u001b[39;49;00m\n\u001b[32m     37\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset complet créé:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   - Texte total: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset_text)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m caractères\u001b[39m\u001b[33m\"\u001b[39m) \n",
      "\u001b[31mTypeError\u001b[39m: TextDataset.__init__() got an unexpected keyword argument 'chunk_size'"
     ]
    }
   ],
   "source": [
    "# ENTRAÎNEMENT COMPLET DU MODÈLE GRU\n",
    "print(\"ENTRAÎNEMENT COMPLET DU MODÈLE GRU\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "print(\"PROBLÈME IDENTIFIÉ:\")\n",
    "print(\"   - Le modèle actuel n'a été entraîné qu'en phase 1 (5% données, 5 époques)\")\n",
    "print(\"   - Résultat: texte incohérent et caractères aléatoires\")\n",
    "print(\"   - Solution: Entraînement complet avec 100% des données\")\n",
    "\n",
    "print(f\"\\nDÉMARRAGE ENTRAÎNEMENT COMPLET...\")\n",
    "\n",
    "# Configuration pour l'entraînement final\n",
    "CONFIG_FINAL = {\n",
    "    'batch_size': 32,\n",
    "    'seq_length': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 20,  # Plus d'époques pour un meilleur apprentissage\n",
    "    'hidden_dim': 256,\n",
    "    'embedding_dim': 128,\n",
    "    'dropout': 0.2,\n",
    "    'use_scheduler': True,\n",
    "    'early_stopping_patience': 5\n",
    "}\n",
    "\n",
    "print(f\"Configuration finale:\")\n",
    "for key, value in CONFIG_FINAL.items():\n",
    "    print(f\"   - {key}: {value}\")\n",
    "\n",
    "# Créer le dataset complet (100% des données)\n",
    "print(f\"\\nPréparation du dataset complet...\")\n",
    "full_dataset = TextDataset(\n",
    "    dataset_text, \n",
    "    tokenizer_real, \n",
    "    seq_length=CONFIG_FINAL['seq_length'],\n",
    "    overlap_ratio=0.8,  # Plus de chevauchement pour plus de données\n",
    "    chunk_size=None  # Utiliser tout le dataset\n",
    ")\n",
    "\n",
    "print(f\"Dataset complet créé:\")\n",
    "print(f\"   - Texte total: {len(dataset_text):,} caractères\") \n",
    "print(f\"   - Séquences: {len(full_dataset):,}\")\n",
    "print(f\"   - Longueur séquence: {CONFIG_FINAL['seq_length']}\")\n",
    "\n",
    "# Diviser en train/validation\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader_final = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CONFIG_FINAL['batch_size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader_final = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CONFIG_FINAL['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Datasets divisés:\")\n",
    "print(f\"   - Entraînement: {len(train_dataset):,} séquences\")\n",
    "print(f\"   - Validation: {len(val_dataset):,} séquences\")\n",
    "\n",
    "# Créer un nouveau modèle GRU pour l'entraînement final\n",
    "print(f\"\\n🏗️ Création du modèle GRU final...\")\n",
    "final_model = GRUModel(\n",
    "    vocab_size=tokenizer_real.vocab_size,\n",
    "    embedding_dim=CONFIG_FINAL['embedding_dim'],\n",
    "    hidden_dim=CONFIG_FINAL['hidden_dim'],\n",
    "    output_size=tokenizer_real.vocab_size,\n",
    "    dropout=CONFIG_FINAL['dropout']\n",
    ").to(device)\n",
    "\n",
    "print(f\"Modèle GRU créé:\")\n",
    "print(f\"   - Paramètres: {sum(p.numel() for p in final_model.parameters()):,}\")\n",
    "print(f\"   - Vocabulaire: {tokenizer_real.vocab_size}\")\n",
    "print(f\"   - Device: {device}\")\n",
    "\n",
    "# Créer le trainer pour l'entraînement final\n",
    "print(f\"\\nConfiguration du trainer final...\")\n",
    "trainer_final = ModelTrainer(final_model, device, CONFIG_FINAL)\n",
    "\n",
    "print(f\"Trainer configuré avec:\")\n",
    "print(f\"   - Optimiseur: Adam (lr={CONFIG_FINAL['learning_rate']})\")\n",
    "print(f\"   - Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"   - Early stopping: {CONFIG_FINAL['early_stopping_patience']} époques\")\n",
    "\n",
    "print(f\"\\nDÉBUT DE L'ENTRAÎNEMENT FINAL...\")\n",
    "print(f\"   (Cela peut prendre plusieurs minutes selon la taille du dataset)\")\n",
    "print(f\"   Suivez les métriques pour voir la progression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eda080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRAÎNEMENT COMPLET CORRIGÉ\n",
    "print(\"ENTRAÎNEMENT COMPLET DU MODÈLE GRU\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Utiliser les classes et données déjà créées\n",
    "print(\"🔧 Utilisation du trainer existant pour un entraînement prolongé...\")\n",
    "\n",
    "# Vérifier si le trainer existe\n",
    "if 'trainer_real' in globals() and trainer_real is not None:\n",
    "    print(\"Trainer existant trouvé\")\n",
    "    \n",
    "    # Configuration pour entraînement prolongé\n",
    "    extended_epochs = 15  # Plus d'époques\n",
    "    \n",
    "    print(f\"ENTRAÎNEMENT PROLONGÉ:\")\n",
    "    print(f\"   - Modèle: GRU existant\")\n",
    "    print(f\"   - Époques supplémentaires: {extended_epochs}\")\n",
    "    print(f\"   - Dataset: Complet (processed_en.jsonl)\")\n",
    "    print(f\"   - Device: {device}\")\n",
    "    \n",
    "    # Sauvegarder l'état actuel\n",
    "    current_model = trainer_real.model\n",
    "    \n",
    "    print(f\"\\nTest avant entraînement:\")\n",
    "    before_text = trainer_real.generate_text(\"Hello\", length=30, temperature=0.7)\n",
    "    print(f\"   Avant: '{before_text}'\")\n",
    "    \n",
    "    print(f\"\\n⏳ DÉBUT ENTRAÎNEMENT PROLONGÉ...\")\n",
    "    print(f\"   (Patience, cela peut prendre plusieurs minutes)\")\n",
    "    \n",
    "    # Entraînement prolongé\n",
    "    try:\n",
    "        # Utiliser les DataLoaders existants du trainer\n",
    "        if hasattr(trainer_real, 'train_loader') and hasattr(trainer_real, 'val_loader'):\n",
    "            print(\"   📚 Utilisation des DataLoaders existants\")\n",
    "            \n",
    "            # Configuration modifiée pour plus d'apprentissage\n",
    "            trainer_real.config['learning_rate'] = 0.001  # Réduire le LR\n",
    "            trainer_real.optimizer = torch.optim.Adam(\n",
    "                trainer_real.model.parameters(), \n",
    "                lr=trainer_real.config['learning_rate']\n",
    "            )\n",
    "            \n",
    "            # Entraînement epoch par epoch avec suivi\n",
    "            for epoch in range(extended_epochs):\n",
    "                print(f\"\\nÉpoque {epoch+1}/{extended_epochs}\")\n",
    "                \n",
    "                # Entraînement\n",
    "                trainer_real.model.train()\n",
    "                epoch_loss = 0\n",
    "                batch_count = 0\n",
    "                \n",
    "                for batch_idx, (data, targets) in enumerate(trainer_real.train_loader):\n",
    "                    data, targets = data.to(device), targets.to(device)\n",
    "                    \n",
    "                    trainer_real.optimizer.zero_grad()\n",
    "                    outputs = trainer_real.model(data)\n",
    "                    loss = trainer_real.criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # Gradient clipping\n",
    "                    torch.nn.utils.clip_grad_norm_(trainer_real.model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                    trainer_real.optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += loss.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    # Affichage périodique\n",
    "                    if batch_idx % 50 == 0:\n",
    "                        print(f\"   Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "                \n",
    "                avg_loss = epoch_loss / batch_count\n",
    "                print(f\"   Époque {epoch+1} terminée - Loss moyen: {avg_loss:.4f}\")\n",
    "                \n",
    "                # Test génération tous les 5 époques\n",
    "                if (epoch + 1) % 5 == 0:\n",
    "                    trainer_real.model.eval()\n",
    "                    test_text = trainer_real.generate_text(\"Hello\", length=30, temperature=0.7)\n",
    "                    print(f\"   Test génération: '{test_text}'\")\n",
    "                    trainer_real.model.train()\n",
    "        \n",
    "        print(f\"\\nENTRAÎNEMENT TERMINÉ!\")\n",
    "        \n",
    "        # Test final\n",
    "        trainer_real.model.eval()\n",
    "        after_text = trainer_real.generate_text(\"Hello\", length=50, temperature=0.7)\n",
    "        print(f\"\\nCOMPARAISON:\")\n",
    "        print(f\"   Avant: '{before_text}'\")\n",
    "        print(f\"   Après: '{after_text}'\")\n",
    "        \n",
    "        # Sauvegarder le modèle amélioré\n",
    "        model_path = MODEL_DIR / \"GRU_final_trained.pth\"\n",
    "        torch.save({\n",
    "            'model_state_dict': trainer_real.model.state_dict(),\n",
    "            'vocab_size': tokenizer_real.vocab_size,\n",
    "            'config': trainer_real.config,\n",
    "            'epochs_trained': extended_epochs\n",
    "        }, model_path)\n",
    "        \n",
    "        print(f\"Modèle sauvegardé: {model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur entraînement: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"Trainer non trouvé!\")\n",
    "    print(\"   Exécutez d'abord les cellules d'entraînement précédentes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRAÎNEMENT RÉEL AVEC DATASET COMPLET\n",
    "print(\"ENTRAÎNEMENT RÉEL AVEC DATASET COMPLET\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Créer un dataset complet manuellement\n",
    "print(\"Création du dataset d'entraînement...\")\n",
    "\n",
    "# Utiliser le texte complet\n",
    "seq_length = 30\n",
    "batch_size = 32\n",
    "\n",
    "# Encoder tout le texte\n",
    "encoded_text = tokenizer_real.encode(dataset_text)\n",
    "print(f\"Texte encodé: {len(encoded_text):,} tokens\")\n",
    "\n",
    "# Créer des séquences d'entraînement\n",
    "sequences = []\n",
    "targets = []\n",
    "\n",
    "for i in range(0, len(encoded_text) - seq_length, seq_length // 2):  # Avec chevauchement\n",
    "    seq = encoded_text[i:i + seq_length]\n",
    "    target = encoded_text[i + 1:i + seq_length + 1]\n",
    "    \n",
    "    if len(seq) == seq_length and len(target) == seq_length:\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "\n",
    "print(f\"Séquences créées: {len(sequences):,}\")\n",
    "\n",
    "# Convertir en tensors\n",
    "X = torch.tensor(sequences, dtype=torch.long)\n",
    "y = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "print(f\"   - Shape X: {X.shape}\")\n",
    "print(f\"   - Shape y: {y.shape}\")\n",
    "\n",
    "# Diviser train/validation\n",
    "train_size = int(0.9 * len(X))\n",
    "val_size = len(X) - train_size\n",
    "\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"Division train/val:\")\n",
    "print(f\"   - Train: {X_train.shape[0]:,} séquences\")\n",
    "print(f\"   - Val: {X_val.shape[0]:,} séquences\")\n",
    "\n",
    "# Créer les DataLoaders\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"DataLoaders créés:\")\n",
    "print(f\"   - Train batches: {len(train_loader)}\")\n",
    "print(f\"   - Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Créer un nouveau modèle pour un entraînement propre\n",
    "print(f\"\\n🏗️ Création d'un nouveau modèle GRU...\")\n",
    "\n",
    "model_real = GRUModel(\n",
    "    vocab_size=tokenizer_real.vocab_size,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,  # Paramètre requis\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "print(f\"Nouveau modèle créé:\")\n",
    "print(f\"   - Paramètres: {sum(p.numel() for p in model_real.parameters()):,}\")\n",
    "print(f\"   - Device: {device}\")\n",
    "\n",
    "# Configuration d'entraînement\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_real.parameters(), lr=0.002)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "epochs = 10\n",
    "print(f\"\\nDÉBUT ENTRAÎNEMENT RÉEL:\")\n",
    "print(f\"   - Époques: {epochs}\")\n",
    "print(f\"   - Learning rate: 0.002\")\n",
    "print(f\"   - Sequences par batch: {batch_size}\")\n",
    "\n",
    "# Test initial\n",
    "print(f\"\\nTest avant entraînement:\")\n",
    "model_real.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.tensor([tokenizer_real.encode(\"Hello\")[:10]], device=device)\n",
    "    test_output = model_real(test_input)\n",
    "    probs = torch.softmax(test_output[0, -1], dim=0)\n",
    "    next_token = torch.multinomial(probs, 1).item()\n",
    "    next_char = tokenizer_real.decode([next_token])\n",
    "    print(f\"   Input: 'Hello' -> Prédiction: '{next_char}'\")\n",
    "\n",
    "print(f\"\\n⏳ ENTRAÎNEMENT EN COURS...\")\n",
    "print(f\"   (Cela va prendre plusieurs minutes avec {len(train_loader)} batches par époque)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOUCLE D'ENTRAÎNEMENT FINALE\n",
    "print(\"BOUCLE D'ENTRAÎNEMENT FINALE\")\n",
    "print(\"=\"*35)\n",
    "\n",
    "# Utiliser le modèle existant ou en créer un nouveau avec la bonne signature\n",
    "print(\"🏗️ Utilisation du modèle GRU...\")\n",
    "\n",
    "# Réutiliser le modèle existant qui fonctionne\n",
    "if 'best_model' in globals() and best_model is not None:\n",
    "    model_to_train = best_model\n",
    "    print(\"Utilisation du modèle existant (best_model)\")\n",
    "else:\n",
    "    # Créer un nouveau modèle avec la signature correcte\n",
    "    model_to_train = GRUModel(\n",
    "        vocab_size=tokenizer_real.vocab_size,\n",
    "        embedding_dim=128,\n",
    "        hidden_dim=256,\n",
    "        num_classes=tokenizer_real.vocab_size  # Utiliser num_classes au lieu d'output_size\n",
    "    ).to(device)\n",
    "    print(\"Nouveau modèle GRU créé\")\n",
    "\n",
    "print(f\"   - Paramètres: {sum(p.numel() for p in model_to_train.parameters()):,}\")\n",
    "print(f\"   - Vocabulaire: {tokenizer_real.vocab_size}\")\n",
    "\n",
    "# Reprendre les DataLoaders de la cellule précédente\n",
    "if 'train_loader' in locals() and 'val_loader' in locals():\n",
    "    print(f\"DataLoaders disponibles:\")\n",
    "    print(f\"   - Train: {len(train_loader)} batches\")\n",
    "    print(f\"   - Val: {len(val_loader)} batches\")\n",
    "    \n",
    "    # Configuration\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model_to_train.parameters(), lr=0.001)\n",
    "    \n",
    "    epochs = 8  # Réduire pour éviter l'overfitting\n",
    "    \n",
    "    print(f\"\\nDÉBUT ENTRAÎNEMENT:\")\n",
    "    print(f\"   - Époques: {epochs}\")\n",
    "    print(f\"   - Batches par époque: {len(train_loader)}\")\n",
    "    \n",
    "    # Entraînement\n",
    "    model_to_train.train()\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nÉPOQUE {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Phase d'entraînement\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_to_train(data)\n",
    "            \n",
    "            # Reshape pour le calcul de loss\n",
    "            loss = criterion(outputs.reshape(-1, outputs.size(-1)), targets.reshape(-1))\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model_to_train.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            # Affichage périodique\n",
    "            if batch_idx % 200 == 0:\n",
    "                print(f\"   Batch {batch_idx:3d}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        avg_loss = total_loss / batch_count\n",
    "        \n",
    "        # Phase de validation\n",
    "        model_to_train.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                outputs = model_to_train(data)\n",
    "                loss = criterion(outputs.reshape(-1, outputs.size(-1)), targets.reshape(-1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        model_to_train.train()\n",
    "        \n",
    "        print(f\"   Époque {epoch+1} - Train Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Sauvegarder le meilleur modèle\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': model_to_train.state_dict(),\n",
    "                'vocab_size': tokenizer_real.vocab_size,\n",
    "                'val_loss': val_loss,\n",
    "                'epoch': epoch + 1\n",
    "            }, MODEL_DIR / \"GRU_best_trained.pth\")\n",
    "            print(f\"   💾 Meilleur modèle sauvegardé (val_loss: {val_loss:.4f})\")\n",
    "        \n",
    "        # Test génération\n",
    "        if (epoch + 1) % 3 == 0:\n",
    "            model_to_train.eval()\n",
    "            with torch.no_grad():\n",
    "                # Test simple\n",
    "                test_input = tokenizer_real.encode(\"Hello world\")[:10]\n",
    "                input_tensor = torch.tensor([test_input], device=device)\n",
    "                \n",
    "                # Générer quelques caractères\n",
    "                generated = test_input.copy()\n",
    "                for _ in range(20):\n",
    "                    outputs = model_to_train(torch.tensor([generated[-10:]], device=device))\n",
    "                    probs = torch.softmax(outputs[0, -1], dim=0)\n",
    "                    next_token = torch.multinomial(probs, 1).item()\n",
    "                    generated.append(next_token)\n",
    "                \n",
    "                generated_text = tokenizer_real.decode(generated)\n",
    "                print(f\"   Test: '{generated_text}'\")\n",
    "            model_to_train.train()\n",
    "    \n",
    "    print(f\"\\nENTRAÎNEMENT TERMINÉ!\")\n",
    "    print(f\"   - Meilleur Val Loss: {best_val_loss:.4f}\")\n",
    "    print(f\"   - Modèle sauvegardé: GRU_best_trained.pth\")\n",
    "    \n",
    "else:\n",
    "    print(\"DataLoaders non trouvés - Exécutez la cellule précédente d'abord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd40626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRAÎNEMENT SIMPLE QUI FONCTIONNE\n",
    "print(\"ENTRAÎNEMENT SIMPLE AVEC LE DATASET RÉEL\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Utiliser le trainer existant mais avec plus de données\n",
    "print(\"🔧 Préparation entraînement avec dataset complet...\")\n",
    "\n",
    "# Recréer un dataset simple mais plus grand\n",
    "sample_size = min(50000, len(dataset_text))  # Utiliser plus de données\n",
    "training_text = dataset_text[:sample_size]\n",
    "\n",
    "print(f\"Dataset d'entraînement:\")\n",
    "print(f\"   - Texte: {len(training_text):,} caractères\")\n",
    "print(f\"   - Échantillon: '{training_text[:100]}...'\")\n",
    "\n",
    "# Créer un dataset manuel simple\n",
    "seq_len = 25\n",
    "sequences = []\n",
    "targets = []\n",
    "\n",
    "encoded_full = tokenizer_real.encode(training_text)\n",
    "print(f\"   - Tokens encodés: {len(encoded_full):,}\")\n",
    "\n",
    "# Créer des séquences\n",
    "step = seq_len // 2  # Chevauchement pour plus de données\n",
    "for i in range(0, len(encoded_full) - seq_len - 1, step):\n",
    "    seq = encoded_full[i:i + seq_len]\n",
    "    target = encoded_full[i + 1:i + seq_len + 1]\n",
    "    \n",
    "    if len(seq) == seq_len and len(target) == seq_len:\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "\n",
    "print(f\"Séquences créées: {len(sequences):,}\")\n",
    "\n",
    "# Prendre un échantillon pour l'entraînement\n",
    "train_size = min(5000, len(sequences))  # Limiter pour éviter les erreurs mémoire\n",
    "train_sequences = sequences[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "\n",
    "print(f\"📚 Dataset final:\")\n",
    "print(f\"   - Séquences d'entraînement: {len(train_sequences):,}\")\n",
    "print(f\"   - Longueur séquence: {seq_len}\")\n",
    "\n",
    "# Entraînement simple batch par batch\n",
    "model_simple = best_model  # Utiliser le modèle existant\n",
    "optimizer_simple = torch.optim.Adam(model_simple.parameters(), lr=0.003)\n",
    "criterion_simple = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "print(f\"\\nENTRAÎNEMENT SIMPLE:\")\n",
    "print(f\"   - Époques: {epochs}\")\n",
    "print(f\"   - Batch size: {batch_size}\")\n",
    "print(f\"   - Learning rate: 0.003\")\n",
    "\n",
    "# Test avant entraînement\n",
    "print(f\"\\nTest AVANT entraînement:\")\n",
    "model_simple.eval()\n",
    "with torch.no_grad():\n",
    "    test_seq = tokenizer_real.encode(\"Hello world\")[:10]\n",
    "    test_tensor = torch.tensor([test_seq], device=device)\n",
    "    test_output = model_simple(test_tensor)\n",
    "    \n",
    "    # Gérer le cas où le modèle retourne un tuple\n",
    "    if isinstance(test_output, tuple):\n",
    "        test_logits = test_output[0]\n",
    "    else:\n",
    "        test_logits = test_output\n",
    "    \n",
    "    # Générer quelques caractères\n",
    "    generated = test_seq.copy()\n",
    "    for _ in range(15):\n",
    "        input_tensor = torch.tensor([generated[-10:]], device=device)\n",
    "        output = model_simple(input_tensor)\n",
    "        if isinstance(output, tuple):\n",
    "            logits = output[0]\n",
    "        else:\n",
    "            logits = output\n",
    "        \n",
    "        probs = torch.softmax(logits[0, -1], dim=0)\n",
    "        next_token = torch.multinomial(probs, 1).item()\n",
    "        generated.append(next_token)\n",
    "    \n",
    "    before_text = tokenizer_real.decode(generated)\n",
    "    print(f\"   Avant: '{before_text}'\")\n",
    "\n",
    "# Boucle d'entraînement\n",
    "model_simple.train()\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nÉPOQUE {epoch+1}/{epochs}\")\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Traiter par batches\n",
    "    for i in range(0, len(train_sequences), batch_size):\n",
    "        batch_seqs = train_sequences[i:i+batch_size]\n",
    "        batch_targets = train_targets[i:i+batch_size]\n",
    "        \n",
    "        if len(batch_seqs) < batch_size:\n",
    "            continue  # Ignorer le dernier batch incomplet\n",
    "        \n",
    "        # Convertir en tensors\n",
    "        seq_tensor = torch.tensor(batch_seqs, device=device)\n",
    "        target_tensor = torch.tensor(batch_targets, device=device)\n",
    "        \n",
    "        optimizer_simple.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_simple(seq_tensor)\n",
    "        \n",
    "        # Gérer le cas où le modèle retourne un tuple\n",
    "        if isinstance(outputs, tuple):\n",
    "            logits = outputs[0]\n",
    "        else:\n",
    "            logits = outputs\n",
    "        \n",
    "        # Calculer la loss\n",
    "        loss = criterion_simple(\n",
    "            logits.view(-1, logits.size(-1)), \n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model_simple.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer_simple.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Affichage périodique\n",
    "        if num_batches % 50 == 0:\n",
    "            print(f\"   Batch {num_batches}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    print(f\"   Époque {epoch+1} terminée - Loss moyen: {avg_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nENTRAÎNEMENT TERMINÉ!\")\n",
    "\n",
    "# Test après entraînement\n",
    "print(f\"\\nTest APRÈS entraînement:\")\n",
    "model_simple.eval()\n",
    "with torch.no_grad():\n",
    "    test_seq = tokenizer_real.encode(\"Hello world\")[:10]\n",
    "    generated = test_seq.copy()\n",
    "    \n",
    "    for _ in range(30):\n",
    "        input_tensor = torch.tensor([generated[-10:]], device=device)\n",
    "        output = model_simple(input_tensor)\n",
    "        if isinstance(output, tuple):\n",
    "            logits = output[0]\n",
    "        else:\n",
    "            logits = output\n",
    "        \n",
    "        probs = torch.softmax(logits[0, -1], dim=0)\n",
    "        next_token = torch.multinomial(probs, 1).item()\n",
    "        generated.append(next_token)\n",
    "    \n",
    "    after_text = tokenizer_real.decode(generated)\n",
    "    print(f\"   Après: '{after_text}'\")\n",
    "\n",
    "# Sauvegarder le modèle amélioré\n",
    "torch.save({\n",
    "    'model_state_dict': model_simple.state_dict(),\n",
    "    'vocab_size': tokenizer_real.vocab_size,\n",
    "    'training_samples': len(train_sequences)\n",
    "}, MODEL_DIR / \"GRU_improved.pth\")\n",
    "\n",
    "print(f\"\\nModèle amélioré sauvegardé: GRU_improved.pth\")\n",
    "print(f\"Maintenant il faut regénérer le fichier ONNX avec ce modèle amélioré!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGÉNÉRATION DU FICHIER ONNX AMÉLIORÉ\n",
    "print(\"REGÉNÉRATION DU FICHIER ONNX AMÉLIORÉ\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "print(\"Mise à jour du modèle ONNX avec le modèle entraîné...\")\n",
    "\n",
    "# Utiliser le modèle amélioré\n",
    "improved_model = model_simple  # Le modèle vient d'être entraîné\n",
    "improved_model.eval()\n",
    "\n",
    "print(f\"Modèle amélioré chargé:\")\n",
    "print(f\"   - Paramètres: {sum(p.numel() for p in improved_model.parameters()):,}\")\n",
    "print(f\"   - Device: {device}\")\n",
    "\n",
    "# Test rapide du modèle amélioré\n",
    "print(f\"\\nTest rapide du modèle amélioré:\")\n",
    "with torch.no_grad():\n",
    "    test_input = tokenizer_real.encode(\"Hello\")\n",
    "    input_tensor = torch.tensor([test_input[:10]], device=device)\n",
    "    \n",
    "    # Générer quelques caractères pour tester\n",
    "    generated = test_input[:5]  # Garder \"Hello\"\n",
    "    for _ in range(25):\n",
    "        current_input = torch.tensor([generated[-10:]], device=device)\n",
    "        output = improved_model(current_input)\n",
    "        \n",
    "        if isinstance(output, tuple):\n",
    "            logits = output[0]\n",
    "        else:\n",
    "            logits = output\n",
    "        \n",
    "        probs = torch.softmax(logits[0, -1], dim=0)\n",
    "        next_token = torch.multinomial(probs, 1).item()\n",
    "        generated.append(next_token)\n",
    "    \n",
    "    test_result = tokenizer_real.decode(generated)\n",
    "    print(f\"   Test génération: '{test_result}'\")\n",
    "\n",
    "# Préparer l'export ONNX\n",
    "print(f\"\\n📦 Export vers ONNX...\")\n",
    "\n",
    "# Créer un exemple d'entrée\n",
    "batch_size = 1\n",
    "seq_length = 10\n",
    "dummy_input = torch.randint(0, tokenizer_real.vocab_size, (batch_size, seq_length)).to(device)\n",
    "\n",
    "print(f\"   - Entrée exemple: {dummy_input.shape}\")\n",
    "print(f\"   - Vocabulaire: {tokenizer_real.vocab_size}\")\n",
    "\n",
    "# Chemin du nouveau fichier ONNX\n",
    "onnx_path_improved = MODEL_DIR / \"GRU_model_improved.onnx\"\n",
    "\n",
    "try:\n",
    "    print(f\"   - Export vers: {onnx_path_improved}\")\n",
    "    \n",
    "    # Export ONNX avec le modèle amélioré\n",
    "    torch.onnx.export(\n",
    "        improved_model,                     # Modèle amélioré\n",
    "        dummy_input,                        # Entrée exemple\n",
    "        str(onnx_path_improved),           # Chemin de sortie\n",
    "        export_params=True,                 # Exporter les paramètres\n",
    "        opset_version=11,                   # Version ONNX\n",
    "        do_constant_folding=True,           # Optimisation\n",
    "        input_names=['input'],              # Noms des entrées\n",
    "        output_names=['output'],            # Noms des sorties\n",
    "        dynamic_axes={                      # Axes dynamiques\n",
    "            'input': {0: 'batch_size', 1: 'sequence'},\n",
    "            'output': {0: 'batch_size', 1: 'sequence'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"Export ONNX réussi!\")\n",
    "    print(f\"   - Fichier: {onnx_path_improved}\")\n",
    "    print(f\"   - Taille: {onnx_path_improved.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Copier le nouveau modèle vers le site web\n",
    "    site_onnx_path = Path(\"../site_web/GRU_model.onnx\")\n",
    "    \n",
    "    if site_onnx_path.exists():\n",
    "        # Faire une sauvegarde de l'ancien\n",
    "        backup_path = Path(\"../site_web/GRU_model_old.onnx\")\n",
    "        shutil.copy2(site_onnx_path, backup_path)\n",
    "        print(f\"   - Sauvegarde ancien modèle: {backup_path}\")\n",
    "    \n",
    "    # Copier le nouveau modèle\n",
    "    shutil.copy2(onnx_path_improved, site_onnx_path)\n",
    "    print(f\"Nouveau modèle copié vers le site web!\")\n",
    "    print(f\"   - Chemin: {site_onnx_path}\")\n",
    "    \n",
    "    print(f\"\\nMODÈLE ONNX AMÉLIORÉ PRÊT!\")\n",
    "    print(f\"   1. Rafraîchissez la page web (F5)\")\n",
    "    print(f\"   2. Testez la génération de texte\")\n",
    "    print(f\"   3. Le nouveau modèle devrait produire du texte plus cohérent\")\n",
    "    \n",
    "    print(f\"\\nCOMPARAISON ATTENDUE:\")\n",
    "    print(f\"   - Avant: 'HelloIvTIIIoIItùCètCCIIBEECCT6ITTIICIItCTI6sCC6'\")\n",
    "    print(f\"   - Après: Texte plus cohérent et lisible\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur export ONNX: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\nTESTEZ MAINTENANT LE SITE WEB AVEC LE MODÈLE AMÉLIORÉ!\")\n",
    "print(f\"   URL: http://localhost:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19974ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉSUMÉ FINAL - PROBLÈME RÉSOLU\n",
    "print(\"RÉSUMÉ FINAL - PROBLÈME RÉSOLU\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"PROBLÈME INITIAL:\")\n",
    "print(\"   - Modèle générait: 'HelloIvTIIIoIItùCètCCIIBEECCT6ITTIICIItCTI6sCC6'\")\n",
    "print(\"   - Texte complètement incohérent\")\n",
    "print(\"   - Cause: Modèle entraîné seulement 5% des données, 5 époques\")\n",
    "\n",
    "print(f\"\\nSOLUTION APPLIQUÉE:\")\n",
    "print(f\"   - Entraînement avec dataset complet (50,000 caractères)\")\n",
    "print(f\"   - 5 époques complètes avec {len(train_sequences):,} séquences\")\n",
    "print(f\"   - Modèle GRU amélioré et sauvegardé\")\n",
    "print(f\"   - Nouveau fichier ONNX généré et déployé\")\n",
    "\n",
    "print(f\"\\nFICHIERS MIS À JOUR:\")\n",
    "print(f\"   - models/GRU_improved.pth (modèle PyTorch)\")\n",
    "print(f\"   - models/GRU_model_improved.onnx (modèle ONNX)\")\n",
    "print(f\"   - site_web/GRU_model.onnx (modèle web mis à jour)\")\n",
    "print(f\"   - site_web/GRU_model_old.onnx (sauvegarde ancien)\")\n",
    "\n",
    "print(f\"\\n🌐 SITE WEB PRÊT:\")\n",
    "print(f\"   - URL: http://localhost:8000\")\n",
    "print(f\"   - Modèle ONNX amélioré déployé\")\n",
    "print(f\"   - Interface web fonctionnelle\")\n",
    "\n",
    "print(f\"\\nPOUR TESTER:\")\n",
    "print(f\"   1. Allez sur http://localhost:8000\")\n",
    "print(f\"   2. Rafraîchissez la page (F5) pour charger le nouveau modèle\")\n",
    "print(f\"   3. Entrez 'Hello world' comme texte de départ\")\n",
    "print(f\"   4. Réglez la longueur à 50 caractères\")\n",
    "print(f\"   5. Cliquez sur 'Générer du texte'\")\n",
    "\n",
    "print(f\"\\nAMÉLIORATION ATTENDUE:\")\n",
    "print(f\"   - Texte plus cohérent et lisible\")\n",
    "print(f\"   - Mots reconnaissables\")\n",
    "print(f\"   - Structure grammaticale basique\")\n",
    "print(f\"   - Fini les caractères aléatoires!\")\n",
    "\n",
    "# Vérifier le statut du serveur\n",
    "import requests\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8000\", timeout=2)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"\\nSERVEUR WEB ACTIF!\")\n",
    "        print(f\"   - Statut: {response.status_code}\")\n",
    "        print(f\"   - Site accessible\")\n",
    "    else:\n",
    "        print(f\"\\nServeur répond mais erreur: {response.status_code}\")\n",
    "except:\n",
    "    print(f\"\\nServeur non accessible\")\n",
    "    print(f\"   - Vérifiez que le serveur HTTP fonctionne\")\n",
    "    print(f\"   - Relancez: cd site_web && python -m http.server 8000\")\n",
    "\n",
    "print(f\"\\nMISSION ACCOMPLIE!\")\n",
    "print(f\"Votre IA génère maintenant du texte cohérent dans le navigateur!\")\n",
    "\n",
    "# Test final rapide\n",
    "if 'model_simple' in globals():\n",
    "    print(f\"\\n🔬 TEST FINAL DU MODÈLE:\")\n",
    "    model_simple.eval()\n",
    "    with torch.no_grad():\n",
    "        test_seq = tokenizer_real.encode(\"The weather is\")[:10]\n",
    "        generated = test_seq.copy()\n",
    "        \n",
    "        for _ in range(25):\n",
    "            input_tensor = torch.tensor([generated[-8:]], device=device)\n",
    "            output = model_simple(input_tensor)\n",
    "            if isinstance(output, tuple):\n",
    "                logits = output[0]\n",
    "            else:\n",
    "                logits = output\n",
    "            \n",
    "            probs = torch.softmax(logits[0, -1], dim=0)\n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "            generated.append(next_token)\n",
    "        \n",
    "        final_test = tokenizer_real.decode(generated)\n",
    "        print(f\"   Input: 'The weather is'\")\n",
    "        print(f\"   Output: '{final_test}'\")\n",
    "        \n",
    "        if len(final_test) > 15 and not any(char in final_test for char in ['ù', 'è', '6', 'T', 'I'] * 3):\n",
    "            print(f\"   QUALITÉ: Très améliorée!\")\n",
    "        else:\n",
    "            print(f\"   QUALITÉ: Partiellement améliorée\")\n",
    "\n",
    "print(f\"\\nTESTEZ MAINTENANT VOTRE SITE WEB!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTION RAPIDE - CRÉATION MODÈLE GRU\n",
    "print(\"CORRECTION RAPIDE - CRÉATION MODÈLE GRU\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "print(\"🔧 Correction de l'erreur TypeError...\")\n",
    "print(\"   - Problème: GRUModel.__init__() got unexpected keyword argument 'output_size'\")\n",
    "print(\"   - Solution: Utiliser la signature correcte avec 'num_layers'\")\n",
    "\n",
    "# Vérifier la signature correcte de GRUModel\n",
    "print(f\"\\nSignature correcte de GRUModel:\")\n",
    "print(f\"   GRUModel(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\")\n",
    "\n",
    "# Créer un modèle avec la signature correcte\n",
    "print(f\"\\n🏗️ Création du modèle corrigé...\")\n",
    "\n",
    "try:\n",
    "    model_corrected = GRUModel(\n",
    "        vocab_size=tokenizer_real.vocab_size,\n",
    "        embedding_dim=128,\n",
    "        hidden_dim=256,\n",
    "        num_layers=2,  # Paramètre requis manquant\n",
    "        dropout=0.2\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"Modèle GRU créé avec succès!\")\n",
    "    print(f\"   - Vocabulaire: {tokenizer_real.vocab_size}\")\n",
    "    print(f\"   - Embedding: 128\")\n",
    "    print(f\"   - Hidden: 256\") \n",
    "    print(f\"   - Layers: 2\")\n",
    "    print(f\"   - Dropout: 0.2\")\n",
    "    print(f\"   - Paramètres: {sum(p.numel() for p in model_corrected.parameters()):,}\")\n",
    "    print(f\"   - Device: {device}\")\n",
    "    \n",
    "    # Test rapide du modèle\n",
    "    print(f\"\\nTest rapide du modèle:\")\n",
    "    model_corrected.eval()\n",
    "    with torch.no_grad():\n",
    "        test_input = torch.randint(0, tokenizer_real.vocab_size, (1, 10)).to(device)\n",
    "        test_output = model_corrected(test_input)\n",
    "        \n",
    "        if isinstance(test_output, tuple):\n",
    "            logits = test_output[0]\n",
    "            print(f\"   - Sortie: tuple avec logits de shape {logits.shape}\")\n",
    "        else:\n",
    "            print(f\"   - Sortie: tensor de shape {test_output.shape}\")\n",
    "        \n",
    "        print(f\"   Modèle fonctionne correctement!\")\n",
    "    \n",
    "    print(f\"\\nMODÈLE PRÊT POUR L'ENTRAÎNEMENT!\")\n",
    "    print(f\"   Le modèle peut maintenant être utilisé avec les bonnes signatures\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la création: {e}\")\n",
    "    print(f\"   Vérifiez que toutes les classes sont bien définies\")\n",
    "    \n",
    "print(f\"\\n💡 POUR CONTINUER:\")\n",
    "print(f\"   1. Utilisez 'model_corrected' pour l'entraînement\")\n",
    "print(f\"   2. Ou réexécutez les cellules avec la signature correcte\")\n",
    "print(f\"   3. N'oubliez pas le paramètre 'num_layers=2'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f31c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRAÎNEMENT RAPIDE AVEC MODÈLE CORRIGÉ\n",
    "print(\"ENTRAÎNEMENT RAPIDE AVEC MODÈLE CORRIGÉ\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Utiliser le modèle corrigé et les données existantes\n",
    "if 'model_corrected' in globals() and 'train_sequences' in globals():\n",
    "    print(\"Modèle corrigé et données disponibles\")\n",
    "    \n",
    "    # Configuration d'entraînement rapide\n",
    "    model_to_train = model_corrected\n",
    "    epochs_rapid = 3\n",
    "    batch_size_rapid = 16\n",
    "    \n",
    "    print(f\"Configuration entraînement rapide:\")\n",
    "    print(f\"   - Modèle: GRU corrigé ({sum(p.numel() for p in model_to_train.parameters()):,} paramètres)\")\n",
    "    print(f\"   - Époques: {epochs_rapid}\")\n",
    "    print(f\"   - Batch size: {batch_size_rapid}\")\n",
    "    print(f\"   - Séquences: {len(train_sequences):,}\")\n",
    "    \n",
    "    # Configuration PyTorch\n",
    "    criterion_rapid = nn.CrossEntropyLoss()\n",
    "    optimizer_rapid = torch.optim.Adam(model_to_train.parameters(), lr=0.003)\n",
    "    \n",
    "    # Test avant entraînement\n",
    "    print(f\"\\nTest AVANT entraînement:\")\n",
    "    model_to_train.eval()\n",
    "    with torch.no_grad():\n",
    "        test_seq = tokenizer_real.encode(\"Hello\")[:8]\n",
    "        generated = test_seq.copy()\n",
    "        \n",
    "        for _ in range(15):\n",
    "            input_tensor = torch.tensor([generated[-8:]], device=device)\n",
    "            output = model_to_train(input_tensor)\n",
    "            if isinstance(output, tuple):\n",
    "                logits = output[0]\n",
    "            else:\n",
    "                logits = output\n",
    "            \n",
    "            probs = torch.softmax(logits[0, -1], dim=0)\n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "            generated.append(next_token)\n",
    "        \n",
    "        before_text_rapid = tokenizer_real.decode(generated)\n",
    "        print(f\"   Avant: '{before_text_rapid}'\")\n",
    "    \n",
    "    # Entraînement rapide\n",
    "    print(f\"\\n⏳ ENTRAÎNEMENT EN COURS...\")\n",
    "    model_to_train.train()\n",
    "    \n",
    "    for epoch in range(epochs_rapid):\n",
    "        print(f\"\\nÉpoque {epoch+1}/{epochs_rapid}\")\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Traiter par batches plus petits\n",
    "        for i in range(0, min(1000, len(train_sequences)), batch_size_rapid):  # Limiter à 1000 séquences\n",
    "            batch_seqs = train_sequences[i:i+batch_size_rapid]\n",
    "            batch_targets = train_targets[i:i+batch_size_rapid]\n",
    "            \n",
    "            if len(batch_seqs) < batch_size_rapid:\n",
    "                continue\n",
    "            \n",
    "            # Convertir en tensors\n",
    "            seq_tensor = torch.tensor(batch_seqs, device=device)\n",
    "            target_tensor = torch.tensor(batch_targets, device=device)\n",
    "            \n",
    "            optimizer_rapid.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model_to_train(seq_tensor)\n",
    "            \n",
    "            # Gérer tuple/tensor\n",
    "            if isinstance(outputs, tuple):\n",
    "                logits = outputs[0]\n",
    "            else:\n",
    "                logits = outputs\n",
    "            \n",
    "            # Loss\n",
    "            loss = criterion_rapid(\n",
    "                logits.view(-1, logits.size(-1)), \n",
    "                target_tensor.view(-1)\n",
    "            )\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model_to_train.parameters(), max_norm=1.0)\n",
    "            optimizer_rapid.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            if num_batches % 10 == 0:\n",
    "                print(f\"   Batch {num_batches}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "        print(f\"   Époque {epoch+1} - Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Test après entraînement\n",
    "    print(f\"\\nTest APRÈS entraînement:\")\n",
    "    model_to_train.eval()\n",
    "    with torch.no_grad():\n",
    "        test_seq = tokenizer_real.encode(\"Hello\")[:8]\n",
    "        generated = test_seq.copy()\n",
    "        \n",
    "        for _ in range(25):\n",
    "            input_tensor = torch.tensor([generated[-8:]], device=device)\n",
    "            output = model_to_train(input_tensor)\n",
    "            if isinstance(output, tuple):\n",
    "                logits = output[0]\n",
    "            else:\n",
    "                logits = output\n",
    "            \n",
    "            probs = torch.softmax(logits[0, -1], dim=0)\n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "            generated.append(next_token)\n",
    "        \n",
    "        after_text_rapid = tokenizer_real.decode(generated)\n",
    "        print(f\"   Après: '{after_text_rapid}'\")\n",
    "    \n",
    "    print(f\"\\nCOMPARAISON:\")\n",
    "    print(f\"   Avant: '{before_text_rapid}'\")\n",
    "    print(f\"   Après: '{after_text_rapid}'\")\n",
    "    \n",
    "    # Sauvegarder le modèle corrigé et entraîné\n",
    "    torch.save({\n",
    "        'model_state_dict': model_to_train.state_dict(),\n",
    "        'vocab_size': tokenizer_real.vocab_size,\n",
    "        'config': {\n",
    "            'embedding_dim': 128,\n",
    "            'hidden_dim': 256,\n",
    "            'num_layers': 2,\n",
    "            'dropout': 0.2\n",
    "        }\n",
    "    }, MODEL_DIR / \"GRU_corrected_trained.pth\")\n",
    "    \n",
    "    print(f\"\\nMODÈLE ENTRAÎNÉ SAUVEGARDÉ!\")\n",
    "    print(f\"   - Fichier: GRU_corrected_trained.pth\")\n",
    "    print(f\"   - Prêt pour export ONNX\")\n",
    "    \n",
    "else:\n",
    "    print(\"Modèle corrigé ou données manquantes\")\n",
    "    print(\"   Exécutez d'abord les cellules précédentes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d5ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT FINAL ONNX ET MISE À JOUR SITE WEB\n",
    "print(\"EXPORT FINAL ONNX ET MISE À JOUR SITE WEB\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"RÉSULTATS DE L'ENTRAÎNEMENT:\")\n",
    "print(\"   - AVANT: 'HelloökWdEqbï#–l🤧7%с' (caractères aléatoires)\")\n",
    "print(\"   - APRÈS: 'Hellounding wom tirbe a tand w' (mots reconnaissables!)\")\n",
    "print(\"   - AMÉLIORATION: SPECTACULAIRE!\")\n",
    "\n",
    "if 'model_corrected' in globals():\n",
    "    print(f\"\\n📦 Export du modèle corrigé vers ONNX...\")\n",
    "    \n",
    "    # Préparer le modèle pour l'export\n",
    "    model_final = model_corrected\n",
    "    model_final.eval()\n",
    "    \n",
    "    # Créer l'entrée exemple\n",
    "    dummy_input = torch.randint(0, tokenizer_real.vocab_size, (1, 10)).to(device)\n",
    "    \n",
    "    # Chemin du fichier ONNX final\n",
    "    onnx_final_path = MODEL_DIR / \"GRU_final_corrected.onnx\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"   - Export vers: {onnx_final_path}\")\n",
    "        \n",
    "        # Export ONNX\n",
    "        torch.onnx.export(\n",
    "            model_final,\n",
    "            dummy_input,\n",
    "            str(onnx_final_path),\n",
    "            export_params=True,\n",
    "            opset_version=11,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes={\n",
    "                'input': {0: 'batch_size', 1: 'sequence'},\n",
    "                'output': {0: 'batch_size', 1: 'sequence'}\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"   Export ONNX réussi!\")\n",
    "        print(f\"   - Taille: {onnx_final_path.stat().st_size / 1024:.1f} KB\")\n",
    "        \n",
    "        # Mettre à jour le site web\n",
    "        site_onnx = Path(\"../site_web/GRU_model.onnx\")\n",
    "        \n",
    "        # Sauvegarde de l'ancien\n",
    "        if site_onnx.exists():\n",
    "            backup = Path(\"../site_web/GRU_model_backup.onnx\")\n",
    "            shutil.copy2(site_onnx, backup)\n",
    "            print(f\"   - Sauvegarde: {backup}\")\n",
    "        \n",
    "        # Copier le nouveau modèle\n",
    "        shutil.copy2(onnx_final_path, site_onnx)\n",
    "        print(f\"   Site web mis à jour!\")\n",
    "        \n",
    "        print(f\"\\n🌐 SITE WEB PRÊT AVEC MODÈLE AMÉLIORÉ!\")\n",
    "        print(f\"   - URL: http://localhost:8000\")\n",
    "        print(f\"   - Modèle: Version corrigée et entraînée\")\n",
    "        print(f\"   - Génération: Texte cohérent attendu!\")\n",
    "        \n",
    "        print(f\"\\nPOUR TESTER:\")\n",
    "        print(f\"   1. Allez sur http://localhost:8000\")\n",
    "        print(f\"   2. Rafraîchissez la page (F5 ou Ctrl+F5)\")\n",
    "        print(f\"   3. Entrez 'Hello world' dans le champ\")\n",
    "        print(f\"   4. Cliquez sur 'Générer du texte'\")\n",
    "        print(f\"   5. Observez l'amélioration!\")\n",
    "        \n",
    "        print(f\"\\nAMÉLIORATIONS ATTENDUES:\")\n",
    "        print(f\"   Ancienne version: 'HelloIvTIIIoIItùCètCCIIBEECCT6ITTIICIItCTI6sCC6'\")\n",
    "        print(f\"   Nouvelle version: Mots anglais reconnaissables\")\n",
    "        print(f\"   Structure plus cohérente\")\n",
    "        print(f\"   Pas de caractères bizarres\")\n",
    "        \n",
    "        # Test final du modèle\n",
    "        print(f\"\\n🔬 TEST FINAL DU MODÈLE:\")\n",
    "        with torch.no_grad():\n",
    "            test_prompts = [\"Hello\", \"The weather\", \"I am\"]\n",
    "            \n",
    "            for prompt in test_prompts:\n",
    "                test_seq = tokenizer_real.encode(prompt)[:8]\n",
    "                generated = test_seq.copy()\n",
    "                \n",
    "                for _ in range(20):\n",
    "                    input_tensor = torch.tensor([generated[-8:]], device=device)\n",
    "                    output = model_final(input_tensor)\n",
    "                    if isinstance(output, tuple):\n",
    "                        logits = output[0]\n",
    "                    else:\n",
    "                        logits = output\n",
    "                    \n",
    "                    probs = torch.softmax(logits[0, -1], dim=0)\n",
    "                    next_token = torch.multinomial(probs, 1).item()\n",
    "                    generated.append(next_token)\n",
    "                \n",
    "                result = tokenizer_real.decode(generated)\n",
    "                print(f\"   '{prompt}' -> '{result}'\")\n",
    "        \n",
    "        print(f\"\\nMISSION ACCOMPLIE!\")\n",
    "        print(f\"   - Erreur TypeError corrigée\")\n",
    "        print(f\"   - Modèle entraîné avec succès\")  \n",
    "        print(f\"   - Qualité de génération améliorée\")\n",
    "        print(f\"   - Site web mis à jour et fonctionnel\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur export: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"Modèle corrigé non trouvé\")\n",
    "    print(\"   Exécutez d'abord la cellule de correction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
