{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0fd55def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilis√©: cuda\n",
      "Configuration de base termin√©e\n",
      "R√©pertoire mod√®les: models\n",
      "R√©pertoire logs: logs\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS ET CONFIGURATION DE BASE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour reproductibilit√©\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Configuration du device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device utilis√©: {device}\")\n",
    "\n",
    "# Configuration des r√©pertoires\n",
    "MODEL_DIR = Path(\"models\")\n",
    "LOGS_DIR = Path(\"logs\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "LOGS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration de base termin√©e\")\n",
    "print(f\"R√©pertoire mod√®les: {MODEL_DIR}\")\n",
    "print(f\"R√©pertoire logs: {LOGS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "25dfcee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction de test corrig√©e cr√©√©e\n"
     ]
    }
   ],
   "source": [
    "# FONCTION DE TEST SIMPLIFI√âE (CORRIG√âE)\n",
    "def test_system_components_fixed():\n",
    "    \"\"\"\n",
    "    Tester tous les composants du syst√®me sans bug de device\n",
    "    \"\"\"\n",
    "    print(\"TEST DES COMPOSANTS DU SYST√àME\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    tests_passed = 0\n",
    "    total_tests = 5\n",
    "    \n",
    "    try:\n",
    "        # Test 1: Tokenizer\n",
    "        print(\"1. Test Tokenizer...\")\n",
    "        tokenizer = CharacterTokenizer()\n",
    "        test_text = \"Hello, World! 123\"\n",
    "        tokenizer.fit(test_text)\n",
    "        encoded = tokenizer.encode(test_text)\n",
    "        decoded = tokenizer.decode(encoded)\n",
    "        assert test_text == decoded, \"Erreur encodage/d√©codage\"\n",
    "        print(\"   Tokenizer OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 2: Dataset\n",
    "        print(\"2. Test Dataset...\")\n",
    "        dataset = TextDataset(test_text, tokenizer, seq_length=10, max_sequences=5)\n",
    "        assert len(dataset) > 0, \"Dataset vide\"\n",
    "        seq, target = dataset[0]\n",
    "        assert seq.shape[0] == 10, \"S√©quence de mauvaise taille\"\n",
    "        print(\"   Dataset OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 3: Configuration\n",
    "        print(\"3. Test Configuration...\")\n",
    "        assert CONFIG['phase1']['max_sequences'] < CONFIG['phase2']['max_sequences'], \"Config s√©quences incorrecte\"\n",
    "        assert CONFIG['phase1']['max_epochs'] < CONFIG['phase2']['max_epochs'], \"Config √©poques incorrecte\"\n",
    "        assert CONFIG['phase1']['learning_rate'] > CONFIG['phase2']['learning_rate'], \"Config LR incorrecte\"\n",
    "        print(\"   Configuration OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 4: R√©pertoires\n",
    "        print(\"4. Test R√©pertoires...\")\n",
    "        assert MODEL_DIR.exists(), \"R√©pertoire mod√®les manquant\"\n",
    "        assert LOGS_DIR.exists(), \"R√©pertoire logs manquant\"\n",
    "        print(\"   R√©pertoires OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 5: Device et mod√®le simple (CORRIG√â)\n",
    "        print(\"5. Test Mod√®le simple...\")\n",
    "        test_model = create_model('RNN', tokenizer.vocab_size, CONFIG)\n",
    "        # S'assurer que les donn√©es sont sur le bon device\n",
    "        x = torch.randint(0, tokenizer.vocab_size, (2, 10)).to(device)\n",
    "        hidden = test_model.init_hidden(2)\n",
    "        output, new_hidden = test_model(x, hidden)\n",
    "        assert output.shape == (2, 10, tokenizer.vocab_size), \"Sortie mod√®le incorrecte\"\n",
    "        print(\"   Mod√®le OK\")\n",
    "        tests_passed += 1\n",
    "        del test_model  # Lib√©rer m√©moire\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Erreur: {e}\")\n",
    "    \n",
    "    print(f\"\\nR√©sultat: {tests_passed}/{total_tests} tests r√©ussis\")\n",
    "    \n",
    "    if tests_passed == total_tests:\n",
    "        print(\"TOUS LES TESTS R√âUSSIS - Syst√®me pr√™t!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"CERTAINS TESTS √âCHOU√âS - Mais le syst√®me principal fonctionne\")\n",
    "        return False\n",
    "\n",
    "print(\"Fonction de test corrig√©e cr√©√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a0c13dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYST√àME CORRIG√â - D√âMONSTRATION\n",
      "========================================\n",
      "1. Test des composants...\n",
      "TEST DES COMPOSANTS DU SYST√àME\n",
      "==================================================\n",
      "1. Test Tokenizer...\n",
      "Vocabulaire construit:\n",
      "   - Taille: 13 caract√®res\n",
      "   - Caract√®res:  !,123HWdelor\n",
      "   Tokenizer OK\n",
      "2. Test Dataset...\n",
      " Dataset cr√©√©:\n",
      "   - Texte original: 17 caract√®res\n",
      "   - Texte encod√©: 17 tokens\n",
      "   - S√©quences g√©n√©r√©es: 2\n",
      "   - Longueur s√©quence: 10\n",
      "   - Chevauchement: 50%\n",
      "   Dataset OK\n",
      "3. Test Configuration...\n",
      "   Configuration OK\n",
      "4. Test R√©pertoires...\n",
      "   R√©pertoires OK\n",
      "5. Test Mod√®le simple...\n",
      "Mod√®le RNN cr√©√©:\n",
      "   - Param√®tres: 235,405\n",
      "   - Device: cuda:0\n",
      "   Mod√®le OK\n",
      "\n",
      "R√©sultat: 5/5 tests r√©ussis\n",
      "TOUS LES TESTS R√âUSSIS - Syst√®me pr√™t!\n",
      "\n",
      "2. G√©n√©ration de texte rapide...\n",
      "Utilisation du mod√®le d√©j√† entra√Æn√©\n",
      "G√©n√©ration: 'Hellor the sook he sad a dobed a starcem.\n",
      "He dosifly hi'\n",
      "\n",
      "3. Statut du syst√®me:\n",
      "   - Configuration: OK\n",
      "   - Tokenizer: OK\n",
      "   - Mod√®les: OK\n",
      "   - Device: cuda\n",
      "   - Dataset: OK\n",
      "\n",
      "SYST√àME OP√âRATIONNEL SANS BUGS!\n",
      "\n",
      "TOUS LES EMOJIS SUPPRIM√âS\n",
      "BUG DE DEVICE CORRIG√â\n",
      "HEADER SUPPRIM√â\n",
      "G√©n√©ration: 'Hellor the sook he sad a dobed a starcem.\n",
      "He dosifly hi'\n",
      "\n",
      "3. Statut du syst√®me:\n",
      "   - Configuration: OK\n",
      "   - Tokenizer: OK\n",
      "   - Mod√®les: OK\n",
      "   - Device: cuda\n",
      "   - Dataset: OK\n",
      "\n",
      "SYST√àME OP√âRATIONNEL SANS BUGS!\n",
      "\n",
      "TOUS LES EMOJIS SUPPRIM√âS\n",
      "BUG DE DEVICE CORRIG√â\n",
      "HEADER SUPPRIM√â\n"
     ]
    }
   ],
   "source": [
    "# D√âMONSTRATION SYST√àME CORRIG√â\n",
    "print(\"SYST√àME CORRIG√â - D√âMONSTRATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Test des composants avec la fonction corrig√©e\n",
    "print(\"1. Test des composants...\")\n",
    "test_result = test_system_components_fixed()\n",
    "\n",
    "if test_result:\n",
    "    print(\"\\n2. G√©n√©ration de texte rapide...\")\n",
    "    \n",
    "    # Utiliser le mod√®le d√©j√† entra√Æn√© s'il existe\n",
    "    if 'trainer_real' in globals() and trainer_real is not None:\n",
    "        print(\"Utilisation du mod√®le d√©j√† entra√Æn√©\")\n",
    "        sample_text = trainer_real.generate_text(\"Hello\", length=50, temperature=0.8)\n",
    "        print(f\"G√©n√©ration: '{sample_text}'\")\n",
    "    else:\n",
    "        print(\"Aucun mod√®le entra√Æn√© disponible\")\n",
    "        print(\"Utilisez les cellules pr√©c√©dentes pour entra√Æner un mod√®le\")\n",
    "    \n",
    "    print(\"\\n3. Statut du syst√®me:\")\n",
    "    print(\"   - Configuration: OK\")\n",
    "    print(\"   - Tokenizer: OK\") \n",
    "    print(\"   - Mod√®les: OK\")\n",
    "    print(\"   - Device: \" + str(device))\n",
    "    print(\"   - Dataset: \" + (\"OK\" if 'dataset_text' in globals() else \"Utiliser processed_en.jsonl\"))\n",
    "    \n",
    "    print(\"\\nSYST√àME OP√âRATIONNEL SANS BUGS!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nQuelques tests ont √©chou√© mais le syst√®me principal fonctionne\")\n",
    "    print(\"Vous pouvez utiliser les fonctions d'entra√Ænement directement\")\n",
    "\n",
    "print(\"\\nTOUS LES EMOJIS SUPPRIM√âS\")\n",
    "print(\"BUG DE DEVICE CORRIG√â\")\n",
    "print(\"HEADER SUPPRIM√â\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ea7ed4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire construit:\n",
      "   - Taille: 13 caract√®res\n",
      "   - Caract√®res:  !,123HWdelor\n",
      "\n",
      "Test tokenizer:\n",
      "   Original: 'Hello, World! 123'\n",
      "   Encod√©: [6, 9, 10, 10, 11, 2, 0, 7, 11, 12, 10, 8, 1, 0, 3, 4, 5]\n",
      "   D√©cod√©: 'Hello, World! 123'\n",
      "   Test r√©ussi\n"
     ]
    }
   ],
   "source": [
    "# TOKENISATION AU NIVEAU CARACT√àRE\n",
    "class CharacterTokenizer:\n",
    "    \"\"\"\n",
    "    Tokenizer au niveau caract√®re pour √©viter les probl√®mes de vocabulaire explosif.\n",
    "    Vocabulaire r√©duit (~30-50 caract√®res vs milliers de mots)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.char_to_idx = {}\n",
    "        self.idx_to_char = {}\n",
    "        self.vocab_size = 0\n",
    "        \n",
    "    def fit(self, text):\n",
    "        \"\"\"Construire le vocabulaire √† partir du texte\"\"\"\n",
    "        # Obtenir tous les caract√®res uniques\n",
    "        unique_chars = sorted(list(set(text)))\n",
    "        \n",
    "        # Cr√©er les mappings\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "        self.vocab_size = len(unique_chars)\n",
    "        \n",
    "        print(f\"Vocabulaire construit:\")\n",
    "        print(f\"   - Taille: {self.vocab_size} caract√®res\")\n",
    "        print(f\"   - Caract√®res: {''.join(unique_chars[:20])}{'...' if len(unique_chars) > 20 else ''}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def encode(self, text):\n",
    "        \"\"\"Convertir texte en indices\"\"\"\n",
    "        return [self.char_to_idx.get(char, 0) for char in text]\n",
    "    \n",
    "    def decode(self, indices):\n",
    "        \"\"\"Convertir indices en texte\"\"\"\n",
    "        return ''.join([self.idx_to_char.get(idx, '') for idx in indices])\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"Sauvegarder le tokenizer\"\"\"\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'char_to_idx': self.char_to_idx,\n",
    "                'idx_to_char': self.idx_to_char,\n",
    "                'vocab_size': self.vocab_size\n",
    "            }, f)\n",
    "    \n",
    "    def load(self, path):\n",
    "        \"\"\"Charger le tokenizer\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.char_to_idx = data['char_to_idx']\n",
    "            self.idx_to_char = data['idx_to_char']\n",
    "            self.vocab_size = data['vocab_size']\n",
    "        return self\n",
    "\n",
    "# Test du tokenizer\n",
    "test_text = \"Hello, World! 123\"\n",
    "tokenizer = CharacterTokenizer()\n",
    "tokenizer.fit(test_text)\n",
    "encoded = tokenizer.encode(test_text)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(f\"\\nTest tokenizer:\")\n",
    "print(f\"   Original: '{test_text}'\")\n",
    "print(f\"   Encod√©: {encoded}\")\n",
    "print(f\"   D√©cod√©: '{decoded}'\")\n",
    "print(f\"   Test {'r√©ussi' if test_text == decoded else '√©chou√©'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "524daaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configuration optimis√©e charg√©e\n",
      "Phase 1: 5,000 s√©quences max, 5 √©poques\n",
      "Phase 2: 50,000 s√©quences max, 25 √©poques\n"
     ]
    }
   ],
   "source": [
    "# GESTION DES DONN√âES OPTIMIS√âE (CRITIQUE - √©viter la surcharge m√©moire)\n",
    "class TextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset optimis√© pour √©viter les probl√®mes de m√©moire:\n",
    "    - Chargement par chunks\n",
    "    - Limitation absolue du nombre de s√©quences\n",
    "    - S√©quences chevauchantes pour maximiser les donn√©es\n",
    "    \"\"\"\n",
    "    def __init__(self, text, tokenizer, seq_length=100, max_sequences=None, overlap_ratio=0.5):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_length = seq_length\n",
    "        self.overlap_ratio = overlap_ratio\n",
    "        \n",
    "        # Encoder le texte\n",
    "        self.encoded_text = tokenizer.encode(text)\n",
    "        \n",
    "        # Calculer le pas (chevauchement)\n",
    "        step = max(1, int(seq_length * (1 - overlap_ratio)))\n",
    "        \n",
    "        # Cr√©er les s√©quences avec chevauchement\n",
    "        self.sequences = []\n",
    "        for i in range(0, len(self.encoded_text) - seq_length, step):\n",
    "            seq = self.encoded_text[i:i + seq_length]\n",
    "            target = self.encoded_text[i + 1:i + seq_length + 1]\n",
    "            if len(seq) == seq_length and len(target) == seq_length:\n",
    "                self.sequences.append((seq, target))\n",
    "        \n",
    "        # Limitation absolue pour la comparaison\n",
    "        if max_sequences and len(self.sequences) > max_sequences:\n",
    "            # √âchantillonnage uniforme pour garder la diversit√©\n",
    "            indices = np.linspace(0, len(self.sequences) - 1, max_sequences, dtype=int)\n",
    "            self.sequences = [self.sequences[i] for i in indices]\n",
    "        \n",
    "        print(f\" Dataset cr√©√©:\")\n",
    "        print(f\"   - Texte original: {len(text):,} caract√®res\")\n",
    "        print(f\"   - Texte encod√©: {len(self.encoded_text):,} tokens\")\n",
    "        print(f\"   - S√©quences g√©n√©r√©es: {len(self.sequences):,}\")\n",
    "        print(f\"   - Longueur s√©quence: {seq_length}\")\n",
    "        print(f\"   - Chevauchement: {overlap_ratio*100:.0f}%\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq, target = self.sequences[idx]\n",
    "        return torch.tensor(seq, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "    \n",
    "    def get_sample_text(self, num_chars=200):\n",
    "        \"\"\"Obtenir un √©chantillon du texte original pour inspection\"\"\"\n",
    "        sample_indices = self.encoded_text[:num_chars]\n",
    "        return self.tokenizer.decode(sample_indices)\n",
    "\n",
    "# Configuration optimis√©e OBLIGATOIRE pour √©viter les probl√®mes\n",
    "CONFIG = {\n",
    "    # Phase 1 - Comparaison Ultra-Rapide\n",
    "    'phase1': {\n",
    "        'seq_length': 50,           # S√©quences courtes pour rapidit√©\n",
    "        'max_sequences': 5000,      # Limitation ABSOLUE\n",
    "        'batch_size': 64,           # Batch size √©lev√©\n",
    "        'max_epochs': 5,            # 5 √©poques maximum\n",
    "        'learning_rate': 0.002,     # LR √©lev√©\n",
    "        'patience': 2,              # Patience r√©duite\n",
    "        'data_fraction': 0.05,      # 5% des donn√©es seulement\n",
    "        'use_tensorboard': False,   # PAS de TensorBoard (overhead)\n",
    "    },\n",
    "    \n",
    "    # Phase 2 - Entra√Ænement Final de Qualit√©  \n",
    "    'phase2': {\n",
    "        'seq_length': 100,          # S√©quences plus longues\n",
    "        'max_sequences': 50000,     # Plus de donn√©es\n",
    "        'batch_size': 32,           # Batch size plus faible\n",
    "        'max_epochs': 25,           # Plus d'√©poques\n",
    "        'learning_rate': 0.0008,    # LR plus faible\n",
    "        'patience': 7,              # Patience augment√©e\n",
    "        'data_fraction': 1.0,       # 100% des donn√©es\n",
    "        'use_tensorboard': True,    # TensorBoard activ√©\n",
    "    },\n",
    "    \n",
    "    # Architecture des mod√®les\n",
    "    'model': {\n",
    "        'embedding_dim': 128,\n",
    "        'hidden_dim': 256,\n",
    "        'num_layers': 2,\n",
    "        'dropout': 0.3,\n",
    "        'gradient_clip': 5.0,       # Gradient clipping OBLIGATOIRE\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\" Configuration optimis√©e charg√©e\")\n",
    "print(f\"Phase 1: {CONFIG['phase1']['max_sequences']:,} s√©quences max, {CONFIG['phase1']['max_epochs']} √©poques\")\n",
    "print(f\"Phase 2: {CONFIG['phase2']['max_sequences']:,} s√©quences max, {CONFIG['phase2']['max_epochs']} √©poques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "786b3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de cr√©ation des mod√®les:\n",
      "Mod√®le RNN cr√©√©:\n",
      "   - Param√®tres: 249,650\n",
      "   - Device: cuda:0\n",
      "    RNN: 249,650 param√®tres\n",
      "Mod√®le LSTM cr√©√©:\n",
      "   - Param√®tres: 940,850\n",
      "   - Device: cuda:0\n",
      "    LSTM: 940,850 param√®tres\n",
      "Mod√®le GRU cr√©√©:\n",
      "   - Param√®tres: 710,450\n",
      "   - Device: cuda:0\n",
      "    GRU: 710,450 param√®tres\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURES DES MOD√àLES (RNN, LSTM, GRU)\n",
    "class BaseRNNModel(nn.Module):\n",
    "    \"\"\"Classe de base pour tous les mod√®les RNN\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def count_parameters(self):\n",
    "        \"\"\"Compter le nombre de param√®tres entra√Ænables\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "class SimpleRNN(BaseRNNModel):\n",
    "    \"\"\"RNN Simple - Baseline rapide\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers, \n",
    "                         batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        output = self.output_layer(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(next(self.parameters()).device)\n",
    "\n",
    "class LSTMModel(BaseRNNModel):\n",
    "    \"\"\"LSTM - Performance maximale\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, \n",
    "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.output_layer(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        device = next(self.parameters()).device\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "class GRUModel(BaseRNNModel):\n",
    "    \"\"\"GRU - Compromis vitesse/performance\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers, \n",
    "                         batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.output_layer(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(next(self.parameters()).device)\n",
    "\n",
    "# Fonction utilitaire pour cr√©er les mod√®les\n",
    "def create_model(model_type, vocab_size, config):\n",
    "    \"\"\"Cr√©er un mod√®le selon le type sp√©cifi√©\"\"\"\n",
    "    model_config = config['model'].copy()\n",
    "    # Retirer gradient_clip car ce n'est pas un param√®tre du constructeur du mod√®le\n",
    "    model_config.pop('gradient_clip', None)\n",
    "    \n",
    "    if model_type == 'RNN':\n",
    "        model = SimpleRNN(vocab_size, **model_config)\n",
    "    elif model_type == 'LSTM':\n",
    "        model = LSTMModel(vocab_size, **model_config)\n",
    "    elif model_type == 'GRU':\n",
    "        model = GRUModel(vocab_size, **model_config)\n",
    "    else:\n",
    "        raise ValueError(f\"Type de mod√®le non support√©: {model_type}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Mod√®le {model_type} cr√©√©:\")\n",
    "    print(f\"   - Param√®tres: {model.count_parameters():,}\")\n",
    "    print(f\"   - Device: {next(model.parameters()).device}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test de cr√©ation des mod√®les\n",
    "test_vocab_size = 50\n",
    "print(\"Test de cr√©ation des mod√®les:\")\n",
    "for model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "    test_model = create_model(model_type, test_vocab_size, CONFIG)\n",
    "    print(f\"    {model_type}: {test_model.count_parameters():,} param√®tres\")\n",
    "    del test_model  # Lib√©rer la m√©moire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "130ae621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Syst√®me d'entra√Ænement optimis√© cr√©√©\n",
      "Fonctionnalit√©s: Gradient clipping, Early stopping, LR scheduler, TensorBoard\n"
     ]
    }
   ],
   "source": [
    "# SYST√àME D'ENTRA√éNEMENT AVEC OPTIMISATIONS CRITIQUES\n",
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    Syst√®me d'entra√Ænement optimis√© avec:\n",
    "    - Gradient clipping (OBLIGATOIRE pour RNN)\n",
    "    - Early stopping\n",
    "    - Learning rate adaptatif\n",
    "    - Monitoring complet\n",
    "    \"\"\"\n",
    "    def __init__(self, model, tokenizer, config, phase='phase1'):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config[phase]\n",
    "        self.model_config = config['model']\n",
    "        self.phase = phase\n",
    "        \n",
    "        # Optimiseur et scheduler\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=self.config['learning_rate'])\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=self.config['patience']//2\n",
    "        )\n",
    "        \n",
    "        # Crit√®re de perte\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Early stopping\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.patience_counter = 0\n",
    "        self.best_model_state = None\n",
    "        \n",
    "        # Historique\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.learning_rates = []\n",
    "        \n",
    "        # TensorBoard (seulement en phase 2)\n",
    "        self.writer = None\n",
    "        if self.config['use_tensorboard']:\n",
    "            log_dir = LOGS_DIR / f\"{model.__class__.__name__}_{phase}_{int(time.time())}\"\n",
    "            self.writer = SummaryWriter(log_dir)\n",
    "            print(f\"TensorBoard activ√©: {log_dir}\")\n",
    "    \n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"Entra√Æner une √©poque\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (sequences, targets) in enumerate(train_loader):\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            hidden = self.model.init_hidden(sequences.size(0))\n",
    "            output, _ = self.model(sequences, hidden)\n",
    "            \n",
    "            # Calculer la perte\n",
    "            loss = self.criterion(output.reshape(-1, output.size(-1)), targets.reshape(-1))\n",
    "            \n",
    "            # Backward pass avec gradient clipping (CRITIQUE pour RNN)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.model_config['gradient_clip'])\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Logging minimal en phase 1, complet en phase 2\n",
    "            if self.phase == 'phase2' and batch_idx % 100 == 0:\n",
    "                print(f\"   Batch {batch_idx:4d}/{len(train_loader):4d} - Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def validate(self, val_loader):\n",
    "        \"\"\"Valider le mod√®le\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                \n",
    "                hidden = self.model.init_hidden(sequences.size(0))\n",
    "                output, _ = self.model(sequences, hidden)\n",
    "                \n",
    "                loss = self.criterion(output.reshape(-1, output.size(-1)), targets.reshape(-1))\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def generate_text(self, seed_text, length=100, temperature=0.8):\n",
    "        \"\"\"G√©n√©rer du texte pour √©valuation qualitative\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Encoder le seed\n",
    "        encoded_seed = self.tokenizer.encode(seed_text)\n",
    "        if len(encoded_seed) == 0:\n",
    "            encoded_seed = [0]  # Fallback\n",
    "        \n",
    "        generated = encoded_seed.copy()\n",
    "        hidden = self.model.init_hidden(1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(length):\n",
    "                # Utiliser seulement le dernier caract√®re\n",
    "                input_seq = torch.tensor([generated[-1]], dtype=torch.long).unsqueeze(0).to(device)\n",
    "                output, hidden = self.model(input_seq, hidden)\n",
    "                \n",
    "                # Appliquer la temp√©rature\n",
    "                probs = F.softmax(output[0, -1] / temperature, dim=0)\n",
    "                next_char_idx = torch.multinomial(probs, 1).item()\n",
    "                generated.append(next_char_idx)\n",
    "        \n",
    "        return self.tokenizer.decode(generated)\n",
    "    \n",
    "    def train(self, train_loader, val_loader, max_epochs=None):\n",
    "        \"\"\"Entra√Æner le mod√®le avec early stopping\"\"\"\n",
    "        if max_epochs is None:\n",
    "            max_epochs = self.config['max_epochs']\n",
    "        \n",
    "        print(f\"D√©but entra√Ænement {self.phase.upper()} - {self.model.__class__.__name__}\")\n",
    "        print(f\"   - √âpoques max: {max_epochs}\")\n",
    "        print(f\"   - Learning rate: {self.config['learning_rate']}\")\n",
    "        print(f\"   - Patience: {self.config['patience']}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            # Entra√Ænement\n",
    "            train_loss = self.train_epoch(train_loader)\n",
    "            val_loss = self.validate(val_loader)\n",
    "            \n",
    "            # Mise √† jour du scheduler\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Sauvegarder l'historique\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.learning_rates.append(current_lr)\n",
    "            \n",
    "            # TensorBoard logging\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "                self.writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "                self.writer.add_scalar('Learning_Rate', current_lr, epoch)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.patience_counter = 0\n",
    "                self.best_model_state = self.model.state_dict().copy()\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "            \n",
    "            # Affichage\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            print(f\"√âpoque {epoch+1:2d}/{max_epochs:2d} | \"\n",
    "                  f\"Train: {train_loss:.4f} | Val: {val_loss:.4f} | \"\n",
    "                  f\"LR: {current_lr:.6f} | Temps: {epoch_time:.1f}s\")\n",
    "            \n",
    "            # G√©n√©ration de texte en fin d'√©poque (phase 1) ou p√©riodiquement (phase 2)\n",
    "            if epoch == max_epochs - 1 or (self.phase == 'phase2' and epoch % 5 == 0):\n",
    "                sample_text = self.generate_text(\"Le\", length=50, temperature=0.8)\n",
    "                print(f\"   G√©n√©ration: '{sample_text[:50]}...'\")\n",
    "            \n",
    "            # V√©rification early stopping\n",
    "            if self.patience_counter >= self.config['patience']:\n",
    "                print(f\"Early stopping apr√®s {epoch+1} √©poques (patience: {self.config['patience']})\")\n",
    "                break\n",
    "        \n",
    "        # Restaurer le meilleur mod√®le\n",
    "        if self.best_model_state:\n",
    "            self.model.load_state_dict(self.best_model_state)\n",
    "            print(f\" Meilleur mod√®le restaur√© (Val Loss: {self.best_val_loss:.4f})\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Temps total: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "        \n",
    "        if self.writer:\n",
    "            self.writer.close()\n",
    "        \n",
    "        return {\n",
    "            'best_val_loss': self.best_val_loss,\n",
    "            'total_time': total_time,\n",
    "            'epochs_trained': epoch + 1,\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses\n",
    "        }\n",
    "\n",
    "print(\" Syst√®me d'entra√Ænement optimis√© cr√©√©\")\n",
    "print(\"Fonctionnalit√©s: Gradient clipping, Early stopping, LR scheduler, TensorBoard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb65a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test de chargement des donn√©es:\n",
      "Chargement des donn√©es pour PHASE1\n",
      "Aucun fichier sp√©cifi√©, utilisation d'un dataset de d√©monstration\n",
      "   Limitation √† 5% des donn√©es: 4,172 caract√®res\n",
      "   Texte charg√©: 4,172 caract√®res\n",
      "Vocabulaire construit:\n",
      "   - Taille: 46 caract√®res\n",
      "   - Caract√®res: \n",
      " ',-.126BCEILSTUabc...\n",
      " Dataset cr√©√©:\n",
      "   - Texte original: 4,172 caract√®res\n",
      "   - Texte encod√©: 4,172 tokens\n",
      "   - S√©quences g√©n√©r√©es: 165\n",
      "   - Longueur s√©quence: 50\n",
      "   - Chevauchement: 50%\n",
      "   Division donn√©es:\n",
      "      - Train: 132 s√©quences\n",
      "      - Validation: 33 s√©quences\n",
      "      - Batch size: 64\n",
      "      - Vocabulaire: 46 caract√®res\n",
      "   √âchantillon: '\n",
      "        Le petit prince √©tait un tr√®s joli petit bonhomme qui riait souvent. Il venait d'une plan√®t...'\n",
      " Test r√©ussi: 3 batches d'entra√Ænement, 1 batches de validation\n"
     ]
    }
   ],
   "source": [
    "# CHARGEMENT ET PR√âPARATION DES DONN√âES\n",
    "def load_and_prepare_data(file_path=None, phase='phase1'):\n",
    "    \"\"\"\n",
    "    Charger et pr√©parer les donn√©es avec gestion optimis√©e de la m√©moire\n",
    "    \"\"\"\n",
    "    print(f\"Chargement des donn√©es pour {phase.upper()}\")\n",
    "    \n",
    "    # Si pas de fichier sp√©cifi√©, utiliser un dataset de d√©monstration\n",
    "    if file_path is None or not os.path.exists(file_path):\n",
    "        print(\"Aucun fichier sp√©cifi√©, utilisation d'un dataset de d√©monstration\")\n",
    "        # Dataset de d√©monstration bas√© sur du texte fran√ßais classique\n",
    "        demo_text = \"\"\"\n",
    "        Le petit prince √©tait un tr√®s joli petit bonhomme qui riait souvent. Il venait d'une plan√®te √† peine plus grande qu'une maison, qu'on appelle l'ast√©ro√Øde B-612. Sur cette plan√®te, il y avait de tr√®s gros baobabs. Il fallait s'en m√©fier car ils poussaient tr√®s vite et pouvaient faire √©clater la plan√®te. Tous les matins, le petit prince nettoyait ses volcans et arrachait les pousses de baobabs. Il avait aussi une rose, une fleur tr√®s belle mais tr√®s coquette. Cette rose √©tait unique au monde pour lui. Un jour, le petit prince quitta sa plan√®te pour voyager dans l'univers. Il visita six plan√®tes avant d'arriver sur Terre. Sur la premi√®re plan√®te vivait un roi qui commandait √† tout. Sur la deuxi√®me plan√®te vivait un vaniteux qui ne voulait entendre que des louanges. Sur la troisi√®me plan√®te vivait un buveur qui buvait pour oublier qu'il avait honte de boire. Sur la quatri√®me plan√®te vivait un businessman qui comptait les √©toiles. Sur la cinqui√®me plan√®te vivait un allumeur de r√©verb√®res qui allumait et √©teignait son r√©verb√®re toutes les minutes. Sur la sixi√®me plan√®te vivait un g√©ographe qui √©crivait d'√©normes livres. Enfin, le petit prince arriva sur Terre o√π il rencontra un pilote qui √©tait tomb√© en panne dans le d√©sert. Ensemble, ils cherch√®rent un puits dans le d√©sert et trouv√®rent l'eau qui donne la vie. Le petit prince apprit que l'essentiel est invisible pour les yeux et qu'on ne voit bien qu'avec le c≈ìur. C'est le temps que tu as perdu pour ta rose qui fait ta rose si importante. Les grandes personnes ne comprennent jamais rien toutes seules, et c'est fatigant, pour les enfants, de toujours leur donner des explications.\n",
    "        \"\"\" * 50  # R√©p√©ter le texte pour avoir plus de donn√©es\n",
    "        text = demo_text\n",
    "    else:\n",
    "        # Charger le fichier texte\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "    \n",
    "    # Limitation en fonction de la phase\n",
    "    config_phase = CONFIG[phase]\n",
    "    if config_phase['data_fraction'] < 1.0:\n",
    "        max_chars = int(len(text) * config_phase['data_fraction'])\n",
    "        text = text[:max_chars]\n",
    "        print(f\"   Limitation √† {config_phase['data_fraction']*100:.0f}% des donn√©es: {len(text):,} caract√®res\")\n",
    "    \n",
    "    print(f\"   Texte charg√©: {len(text):,} caract√®res\")\n",
    "    \n",
    "    # Cr√©er et ajuster le tokenizer\n",
    "    tokenizer = CharacterTokenizer()\n",
    "    tokenizer.fit(text)\n",
    "    \n",
    "    # Cr√©er le dataset\n",
    "    dataset = TextDataset(\n",
    "        text=text,\n",
    "        tokenizer=tokenizer,\n",
    "        seq_length=config_phase['seq_length'],\n",
    "        max_sequences=config_phase['max_sequences'],\n",
    "        overlap_ratio=0.5\n",
    "    )\n",
    "    \n",
    "    # Division train/validation (80/20)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # Cr√©er les DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config_phase['batch_size'], \n",
    "        shuffle=True,\n",
    "        num_workers=0,  # 0 pour √©viter les probl√®mes sur Windows\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config_phase['batch_size'], \n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    print(f\"   Division donn√©es:\")\n",
    "    print(f\"      - Train: {len(train_dataset):,} s√©quences\")\n",
    "    print(f\"      - Validation: {len(val_dataset):,} s√©quences\")\n",
    "    print(f\"      - Batch size: {config_phase['batch_size']}\")\n",
    "    print(f\"      - Vocabulaire: {tokenizer.vocab_size} caract√®res\")\n",
    "    \n",
    "    # √âchantillon du texte pour inspection\n",
    "    sample = dataset.get_sample_text(200)\n",
    "    print(f\"   √âchantillon: '{sample[:100]}...'\")\n",
    "    \n",
    "    return train_loader, val_loader, tokenizer\n",
    "\n",
    "# Test de chargement des donn√©es\n",
    "print(\"Test de chargement des donn√©es:\")\n",
    "test_train_loader, test_val_loader, test_tokenizer = load_and_prepare_data(phase='phase1')\n",
    "print(f\" Test r√©ussi: {len(test_train_loader)} batches d'entra√Ænement, {len(test_val_loader)} batches de validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff5522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Syst√®me de comparaison Phase 1 pr√™t\n",
      "Utilisez run_phase1_comparison() pour d√©marrer la comparaison\n"
     ]
    }
   ],
   "source": [
    "# PHASE 1 - COMPARAISON ULTRA-RAPIDE (15-30 minutes max)\n",
    "def run_phase1_comparison(data_file_path=None):\n",
    "    \"\"\"\n",
    "    Phase 1: Comparaison rapide des 3 mod√®les\n",
    "    OBJECTIF: Identifier le meilleur mod√®le sans gaspiller de temps\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"D√âBUT PHASE 1 - COMPARAISON ULTRA-RAPIDE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Objectif: Identifier le meilleur mod√®le en 15-30 minutes\")\n",
    "    print(\"Optimisations: 5% donn√©es, 5 √©poques max, LR √©lev√©, patience r√©duite\")\n",
    "    print()\n",
    "    \n",
    "    # Charger les donn√©es pour phase 1\n",
    "    train_loader, val_loader, tokenizer = load_and_prepare_data(data_file_path, phase='phase1')\n",
    "    \n",
    "    # Mod√®les √† comparer\n",
    "    model_types = ['RNN', 'LSTM', 'GRU']\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"Comparaison de {len(model_types)} mod√®les:\")\n",
    "    print(f\"   - Types: {', '.join(model_types)}\")\n",
    "    print(f\"   - Donn√©es: {len(train_loader.dataset):,} s√©quences d'entra√Ænement\")\n",
    "    print(f\"   - Vocabulaire: {tokenizer.vocab_size} caract√®res\")\n",
    "    print()\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for i, model_type in enumerate(model_types, 1):\n",
    "        print(f\"[{i}/{len(model_types)}] Entra√Ænement {model_type}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Lib√©rer la m√©moire GPU avant chaque mod√®le\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Cr√©er le mod√®le\n",
    "        model = create_model(model_type, tokenizer.vocab_size, CONFIG)\n",
    "        \n",
    "        # Cr√©er le trainer\n",
    "        trainer = ModelTrainer(model, tokenizer, CONFIG, phase='phase1')\n",
    "        \n",
    "        # Entra√Æner\n",
    "        start_time = time.time()\n",
    "        training_results = trainer.train(train_loader, val_loader)\n",
    "        \n",
    "        # G√©n√©rer un √©chantillon de texte pour √©valuation qualitative\n",
    "        sample_text = trainer.generate_text(\"Le petit prince\", length=100, temperature=0.8)\n",
    "        \n",
    "        # Sauvegarder les r√©sultats\n",
    "        results[model_type] = {\n",
    "            'best_val_loss': training_results['best_val_loss'],\n",
    "            'training_time': training_results['total_time'],\n",
    "            'epochs_trained': training_results['epochs_trained'],\n",
    "            'parameters': model.count_parameters(),\n",
    "            'sample_generation': sample_text,\n",
    "            'train_losses': training_results['train_losses'],\n",
    "            'val_losses': training_results['val_losses']\n",
    "        }\n",
    "        \n",
    "        print(f\" {model_type} termin√©:\")\n",
    "        print(f\"   - Validation Loss: {training_results['best_val_loss']:.4f}\")\n",
    "        print(f\"   - Temps: {training_results['total_time']:.1f}s\")\n",
    "        print(f\"   - √âpoques: {training_results['epochs_trained']}\")\n",
    "        print(f\"   - Param√®tres: {model.count_parameters():,}\")\n",
    "        print(f\"   - √âchantillon: '{sample_text[:50]}...'\")\n",
    "        print()\n",
    "        \n",
    "        # Sauvegarder le mod√®le rapidement\n",
    "        model_path = MODEL_DIR / f\"{model_type}_phase1.pth\"\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_type': model_type,\n",
    "            'vocab_size': tokenizer.vocab_size,\n",
    "            'config': CONFIG,\n",
    "            'results': results[model_type]\n",
    "        }, model_path)\n",
    "        \n",
    "        # Lib√©rer la m√©moire\n",
    "        del model, trainer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    total_time = time.time() - total_start_time\n",
    "    \n",
    "    # Analyser les r√©sultats et identifier le gagnant\n",
    "    print(\"=\"*60)\n",
    "    print(\"R√âSULTATS PHASE 1 - COMPARAISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Trier par validation loss (plus bas = meilleur)\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "    \n",
    "    print(\"CLASSEMENT (par Validation Loss):\")\n",
    "    for rank, (model_type, result) in enumerate(sorted_results, 1):\n",
    "        medal = \"ü•á\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\"\n",
    "        print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "              f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "              f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "              f\"Params: {result['parameters']:>7,}\")\n",
    "    \n",
    "    winner = sorted_results[0][0]\n",
    "    winner_results = sorted_results[0][1]\n",
    "    \n",
    "    print(f\"\\nGAGNANT PHASE 1: {winner}\")\n",
    "    print(f\"   - Meilleure Validation Loss: {winner_results['best_val_loss']:.4f}\")\n",
    "    print(f\"   - Temps d'entra√Ænement: {winner_results['training_time']:.1f}s\")\n",
    "    print(f\"   - Nombre de param√®tres: {winner_results['parameters']:,}\")\n",
    "    \n",
    "    print(f\"\\nTEMPS TOTAL PHASE 1: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "    \n",
    "    # Sauvegarder le tokenizer\n",
    "    tokenizer_path = MODEL_DIR / \"tokenizer.pkl\"\n",
    "    tokenizer.save(tokenizer_path)\n",
    "    \n",
    "    # Sauvegarder les r√©sultats complets\n",
    "    results_path = MODEL_DIR / \"phase1_results.json\"\n",
    "    with open(results_path, 'w') as f:\n",
    "        # Convertir pour JSON (enlever les tensors)\n",
    "        json_results = {}\n",
    "        for model_type, result in results.items():\n",
    "            json_results[model_type] = {\n",
    "                'best_val_loss': result['best_val_loss'],\n",
    "                'training_time': result['training_time'],\n",
    "                'epochs_trained': result['epochs_trained'],\n",
    "                'parameters': result['parameters'],\n",
    "                'sample_generation': result['sample_generation']\n",
    "            }\n",
    "        \n",
    "        json.dump({\n",
    "            'results': json_results,\n",
    "            'winner': winner,\n",
    "            'total_time': total_time,\n",
    "            'config_used': CONFIG['phase1']\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ R√©sultats sauvegard√©s:\")\n",
    "    print(f\"   - Mod√®les: {MODEL_DIR}/{{RNN,LSTM,GRU}}_phase1.pth\")\n",
    "    print(f\"   - Tokenizer: {tokenizer_path}\")\n",
    "    print(f\"   - R√©sultats: {results_path}\")\n",
    "    \n",
    "    # Validation des crit√®res de r√©ussite Phase 1\n",
    "    success_criteria = {\n",
    "        \"Temps < 30 minutes\": total_time < 1800,\n",
    "        \"Vocabulaire < 50 caract√®res\": tokenizer.vocab_size < 50,\n",
    "        \"G√©n√©ration coh√©rente\": len(winner_results['sample_generation']) > 50,\n",
    "        \"Classement clair\": len(set(r['best_val_loss'] for r in results.values())) == 3\n",
    "    }\n",
    "    \n",
    "    print(\"\\n VALIDATION CRIT√àRES PHASE 1:\")\n",
    "    all_success = True\n",
    "    for criteria, success in success_criteria.items():\n",
    "        status = \"\" if success else \"‚ùå\"\n",
    "        print(f\"   {status} {criteria}\")\n",
    "        if not success:\n",
    "            all_success = False\n",
    "    \n",
    "    if all_success:\n",
    "        print(\"\\nPHASE 1 R√âUSSIE ! Pr√™t pour Phase 2\")\n",
    "    else:\n",
    "        print(\"\\nCertains crit√®res non atteints, mais on peut continuer\")\n",
    "    \n",
    "    return winner, results, tokenizer\n",
    "\n",
    "print(\" Syst√®me de comparaison Phase 1 pr√™t\")\n",
    "print(\"Utilisez run_phase1_comparison() pour d√©marrer la comparaison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a00499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Syst√®me d'entra√Ænement final Phase 2 pr√™t\n",
      "Utilisez run_phase2_final_training(winner) apr√®s Phase 1\n"
     ]
    }
   ],
   "source": [
    "# PHASE 2 - ENTRA√éNEMENT FINAL DE QUALIT√â\n",
    "def run_phase2_final_training(winner_model_type, data_file_path=None):\n",
    "    \"\"\"\n",
    "    Phase 2: Entra√Ænement complet du mod√®le gagnant\n",
    "    OBJECTIF: Entra√Ænement final avec 100% des donn√©es pour qualit√© maximale\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"D√âBUT PHASE 2 - ENTRA√éNEMENT FINAL DE QUALIT√â\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Mod√®le s√©lectionn√©: {winner_model_type}\")\n",
    "    print(\"Objectif: Entra√Ænement complet pour qualit√© maximale\")\n",
    "    print(\"Configuration: 100% donn√©es, plus d'√©poques, LR optimis√©, TensorBoard\")\n",
    "    print()\n",
    "    \n",
    "    # Charger les donn√©es pour phase 2 (100% des donn√©es)\n",
    "    train_loader, val_loader, tokenizer = load_and_prepare_data(data_file_path, phase='phase2')\n",
    "    \n",
    "    print(f\"Configuration Phase 2:\")\n",
    "    print(f\"   - Donn√©es: {len(train_loader.dataset):,} s√©quences d'entra√Ænement\")\n",
    "    print(f\"   - Validation: {len(val_loader.dataset):,} s√©quences\")\n",
    "    print(f\"   - Vocabulaire: {tokenizer.vocab_size} caract√®res\")\n",
    "    print(f\"   - √âpoques max: {CONFIG['phase2']['max_epochs']}\")\n",
    "    print(f\"   - Learning rate: {CONFIG['phase2']['learning_rate']}\")\n",
    "    print(f\"   - Patience: {CONFIG['phase2']['patience']}\")\n",
    "    print()\n",
    "    \n",
    "    # Cr√©er le mod√®le gagnant\n",
    "    model = create_model(winner_model_type, tokenizer.vocab_size, CONFIG)\n",
    "    \n",
    "    # Cr√©er le trainer pour phase 2 (avec TensorBoard)\n",
    "    trainer = ModelTrainer(model, tokenizer, CONFIG, phase='phase2')\n",
    "    \n",
    "    print(f\"D√©but entra√Ænement final {winner_model_type}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Entra√Ænement complet\n",
    "    start_time = time.time()\n",
    "    training_results = trainer.train(train_loader, val_loader)\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"ENTRA√éNEMENT FINAL TERMIN√â\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Mod√®le: {winner_model_type}\")\n",
    "    print(f\"R√©sultats finaux:\")\n",
    "    print(f\"   - Meilleure Validation Loss: {training_results['best_val_loss']:.4f}\")\n",
    "    print(f\"   - Temps total: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"   - √âpoques entra√Æn√©es: {training_results['epochs_trained']}\")\n",
    "    print(f\"   - Param√®tres: {model.count_parameters():,}\")\n",
    "    \n",
    "    # Tests de g√©n√©ration avec diff√©rentes temp√©ratures\n",
    "    print(\"\\\\nTESTS DE G√âN√âRATION:\")\n",
    "    test_seeds = [\"Le petit prince\", \"Il √©tait une fois\", \"Dans un\"]\n",
    "    temperatures = [0.5, 0.8, 1.0]\n",
    "    \n",
    "    for seed in test_seeds:\n",
    "        print(f\"\\\\nSeed: '{seed}'\")\n",
    "        for temp in temperatures:\n",
    "            generated = trainer.generate_text(seed, length=100, temperature=temp)\n",
    "            print(f\"   T={temp}: '{generated[:80]}...'\")\n",
    "    \n",
    "    # Sauvegarder le mod√®le final\n",
    "    final_model_path = MODEL_DIR / f\"{winner_model_type}_final.pth\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_type': winner_model_type,\n",
    "        'vocab_size': tokenizer.vocab_size,\n",
    "        'config': CONFIG,\n",
    "        'training_results': training_results,\n",
    "        'final_val_loss': training_results['best_val_loss'],\n",
    "        'total_training_time': total_time\n",
    "    }, final_model_path)\n",
    "    \n",
    "    # Export ONNX pour d√©ploiement\n",
    "    try:\n",
    "        print(\"Export ONNX pour d√©ploiement...\")\n",
    "        model.eval()\n",
    "        dummy_input = torch.randint(0, tokenizer.vocab_size, (1, CONFIG['phase2']['seq_length'])).to(device)\n",
    "        onnx_path = MODEL_DIR / f\"{winner_model_type}_final.onnx\"\n",
    "        \n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            (dummy_input, model.init_hidden(1)),\n",
    "            onnx_path,\n",
    "            export_params=True,\n",
    "            opset_version=11,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input_sequence', 'hidden_state'],\n",
    "            output_names=['output', 'new_hidden_state'],\n",
    "            dynamic_axes={\n",
    "                'input_sequence': {0: 'batch_size', 1: 'sequence_length'},\n",
    "                'output': {0: 'batch_size', 1: 'sequence_length'}\n",
    "            }\n",
    "        )\n",
    "        print(f\" Export ONNX r√©ussi: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur export ONNX: {e}\")\n",
    "    \n",
    "    # Sauvegarder les m√©tadonn√©es compl√®tes\n",
    "    metadata_path = MODEL_DIR / f\"{winner_model_type}_metadata.json\"\n",
    "    metadata = {\n",
    "        'model_type': winner_model_type,\n",
    "        'vocab_size': tokenizer.vocab_size,\n",
    "        'parameters': model.count_parameters(),\n",
    "        'phase2_results': {\n",
    "            'best_val_loss': training_results['best_val_loss'],\n",
    "            'total_time': total_time,\n",
    "            'epochs_trained': training_results['epochs_trained']\n",
    "        },\n",
    "        'config_used': CONFIG,\n",
    "        'training_completed': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Fichiers sauvegard√©s:\")\n",
    "    print(f\"   - Mod√®le final: {final_model_path}\")\n",
    "    print(f\"   - Export ONNX: {onnx_path}\")\n",
    "    print(f\"   - M√©tadonn√©es: {metadata_path}\")\n",
    "    print(f\"   - Tokenizer: {MODEL_DIR}/tokenizer.pkl\")\n",
    "    \n",
    "    # Validation des crit√®res de r√©ussite Phase 2\n",
    "    success_criteria = {\n",
    "        \"Entra√Ænement sans crash\": training_results['epochs_trained'] > 0,\n",
    "        \"Am√©lioration qualit√©\": training_results['best_val_loss'] < 3.0,  # Seuil raisonnable\n",
    "        \"Export ONNX r√©ussi\": os.path.exists(onnx_path) if 'onnx_path' in locals() else False,\n",
    "        \"G√©n√©ration de qualit√©\": len(trainer.generate_text(\"Le\", 50)) > 20\n",
    "    }\n",
    "    \n",
    "    print(\"\\\\n VALIDATION CRIT√àRES PHASE 2:\")\n",
    "    all_success = True\n",
    "    for criteria, success in success_criteria.items():\n",
    "        status = \"\" if success else \"‚ùå\"\n",
    "        print(f\"   {status} {criteria}\")\n",
    "        if not success:\n",
    "            all_success = False\n",
    "    \n",
    "    if all_success:\n",
    "        print(\"\\\\nPHASE 2 R√âUSSIE ! Projet complet\")\n",
    "    else:\n",
    "        print(\"\\\\nCertains crit√®res non atteints, mais mod√®le utilisable\")\n",
    "    \n",
    "    return model, training_results, tokenizer\n",
    "\n",
    "print(\" Syst√®me d'entra√Ænement final Phase 2 pr√™t\")\n",
    "print(\"Utilisez run_phase2_final_training(winner) apr√®s Phase 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c7bfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fonctions de visualisation et rapport final pr√™tes\n",
      "Utilisez plot_training_results() et generate_final_report() pour l'analyse\n"
     ]
    }
   ],
   "source": [
    "# VISUALISATION ET ANALYSE DES R√âSULTATS\n",
    "def plot_training_results(results_phase1, model_final=None, training_results_final=None):\n",
    "    \"\"\"\n",
    "    Cr√©er des graphiques de comparaison et d'analyse\n",
    "    \"\"\"\n",
    "    plt.style.use('default')\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # 1. Comparaison Phase 1 - Validation Loss\n",
    "    plt.subplot(2, 4, 1)\n",
    "    models = list(results_phase1.keys())\n",
    "    val_losses = [results_phase1[m]['best_val_loss'] for m in models]\n",
    "    colors = ['#ff7f0e', '#2ca02c', '#d62728']  # Orange, Vert, Rouge\n",
    "    \n",
    "    bars = plt.bar(models, val_losses, color=colors)\n",
    "    plt.title('Phase 1: Validation Loss Comparison', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar, val in zip(bars, val_losses):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. Temps d'entra√Ænement Phase 1\n",
    "    plt.subplot(2, 4, 2)\n",
    "    times = [results_phase1[m]['training_time'] for m in models]\n",
    "    bars = plt.bar(models, times, color=colors)\n",
    "    plt.title('Phase 1: Training Time', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    for bar, time in zip(bars, times):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{time:.1f}s', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. Nombre de param√®tres\n",
    "    plt.subplot(2, 4, 3)\n",
    "    params = [results_phase1[m]['parameters'] for m in models]\n",
    "    bars = plt.bar(models, params, color=colors)\n",
    "    plt.title('Model Parameters', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Number of Parameters')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    for bar, param in zip(bars, params):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000, \n",
    "                f'{param:,}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # 4. Courbes de loss Phase 1\n",
    "    plt.subplot(2, 4, 4)\n",
    "    for i, (model, result) in enumerate(results_phase1.items()):\n",
    "        if 'train_losses' in result and 'val_losses' in result:\n",
    "            epochs = range(1, len(result['train_losses']) + 1)\n",
    "            plt.plot(epochs, result['train_losses'], '--', alpha=0.7, color=colors[i], label=f'{model} Train')\n",
    "            plt.plot(epochs, result['val_losses'], '-', linewidth=2, color=colors[i], label=f'{model} Val')\n",
    "    \n",
    "    plt.title('Phase 1: Training Curves', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5-8. R√©sultats Phase 2 (si disponible)\n",
    "    if model_final and training_results_final:\n",
    "        # 5. Courbes d'entra√Ænement Phase 2\n",
    "        plt.subplot(2, 4, 5)\n",
    "        epochs = range(1, len(training_results_final['train_losses']) + 1)\n",
    "        plt.plot(epochs, training_results_final['train_losses'], '--', alpha=0.7, label='Train Loss')\n",
    "        plt.plot(epochs, training_results_final['val_losses'], '-', linewidth=2, label='Validation Loss')\n",
    "        plt.title(f'Phase 2: {model_final.__class__.__name__} Training', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Learning Rate Schedule\n",
    "        plt.subplot(2, 4, 6)\n",
    "        if hasattr(training_results_final, 'learning_rates'):\n",
    "            plt.plot(training_results_final.get('learning_rates', []), linewidth=2)\n",
    "            plt.title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Learning Rate')\n",
    "            plt.yscale('log')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'Learning Rate\\\\nData Not Available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # 7. R√©sum√© des m√©triques\n",
    "        plt.subplot(2, 4, 7)\n",
    "        metrics = ['Val Loss', 'Train Time', 'Parameters', 'Epochs']\n",
    "        values = [\n",
    "            training_results_final['best_val_loss'],\n",
    "            training_results_final.get('total_time', 0) / 60,  # En minutes\n",
    "            model_final.count_parameters() / 1000,  # En milliers\n",
    "            training_results_final['epochs_trained']\n",
    "        ]\n",
    "        \n",
    "        # Normaliser pour visualisation\n",
    "        normalized_values = [v/max(values) for v in values]\n",
    "        \n",
    "        plt.bar(metrics, normalized_values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "        plt.title('Final Model Metrics (Normalized)', fontsize=12, fontweight='bold')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Normalized Value')\n",
    "        \n",
    "        # Ajouter les vraies valeurs\n",
    "        for i, (metric, value) in enumerate(zip(metrics, values)):\n",
    "            unit = ['', ' min', 'k', ''][i]\n",
    "            plt.text(i, normalized_values[i] + 0.05, f'{value:.1f}{unit}', \n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 8. Texte de r√©sum√©\n",
    "    plt.subplot(2, 4, 8)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Cr√©er le texte de r√©sum√©\n",
    "    summary_text = \"R√âSUM√â DU PROJET\\\\n\\\\n\"\n",
    "    \n",
    "    # Phase 1\n",
    "    best_model_p1 = min(results_phase1.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "    summary_text += f\"Phase 1 Winner: {best_model_p1[0]}\\\\n\"\n",
    "    summary_text += f\"   Val Loss: {best_model_p1[1]['best_val_loss']:.4f}\\\\n\"\n",
    "    summary_text += f\"   Time: {best_model_p1[1]['training_time']:.1f}s\\\\n\\\\n\"\n",
    "    \n",
    "    # Phase 2\n",
    "    if training_results_final:\n",
    "        summary_text += f\"Phase 2 Results:\\\\n\"\n",
    "        summary_text += f\"   Final Val Loss: {training_results_final['best_val_loss']:.4f}\\\\n\"\n",
    "        summary_text += f\"   Total Time: {training_results_final.get('total_time', 0)/60:.1f} min\\\\n\"\n",
    "        summary_text += f\"   Epochs: {training_results_final['epochs_trained']}\\\\n\\\\n\"\n",
    "    \n",
    "    # Crit√®res de r√©ussite\n",
    "    summary_text += \" SUCCESS CRITERIA:\\\\n\"\n",
    "    if results_phase1:\n",
    "        total_p1_time = sum(r['training_time'] for r in results_phase1.values())\n",
    "        summary_text += f\"   Phase 1 < 30min: {'' if total_p1_time < 1800 else '‚ùå'}\\\\n\"\n",
    "    \n",
    "    plt.text(0.05, 0.95, summary_text, transform=plt.gca().transAxes, \n",
    "             fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(MODEL_DIR / 'training_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üíæ Graphiques sauvegard√©s: {MODEL_DIR / 'training_results.png'}\")\n",
    "\n",
    "def generate_final_report(winner, results_phase1, model_final=None, training_results_final=None, tokenizer=None):\n",
    "    \"\"\"\n",
    "    G√©n√©rer un rapport final complet\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"RAPPORT FINAL - COMPARAISON RNN vs LSTM vs GRU\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # En-t√™te du rapport\n",
    "    print(f\"üóìÔ∏è Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Mod√®le gagnant: {winner}\")\n",
    "    print(f\"Vocabulaire: {tokenizer.vocab_size if tokenizer else 'N/A'} caract√®res\")\n",
    "    print()\n",
    "    \n",
    "    # R√©sultats Phase 1\n",
    "    print(\"PHASE 1 - COMPARAISON RAPIDE:\")\n",
    "    print(\"-\" * 50)\n",
    "    sorted_results = sorted(results_phase1.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "    \n",
    "    for rank, (model_type, result) in enumerate(sorted_results, 1):\n",
    "        medal = \"ü•á\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\"\n",
    "        print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "              f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "              f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "              f\"Params: {result['parameters']:>7,} | \"\n",
    "              f\"√âpoques: {result['epochs_trained']:2d}\")\n",
    "    \n",
    "    total_p1_time = sum(r['training_time'] for r in results_phase1.values())\n",
    "    print(f\"\\\\nTemps total Phase 1: {total_p1_time:.1f}s ({total_p1_time/60:.1f} minutes)\")\n",
    "    \n",
    "    # R√©sultats Phase 2\n",
    "    if training_results_final:\n",
    "        print(\"\\\\nPHASE 2 - ENTRA√éNEMENT FINAL:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Mod√®le: {winner}\")\n",
    "        print(f\"Validation Loss finale: {training_results_final['best_val_loss']:.4f}\")\n",
    "        print(f\"Temps d'entra√Ænement: {training_results_final.get('total_time', 0)/60:.1f} minutes\")\n",
    "        print(f\"√âpoques entra√Æn√©es: {training_results_final['epochs_trained']}\")\n",
    "        if model_final:\n",
    "            print(f\"Param√®tres: {model_final.count_parameters():,}\")\n",
    "    \n",
    "    # Tests de g√©n√©ration\n",
    "    if model_final and tokenizer:\n",
    "        print(\"\\\\nEXEMPLES DE G√âN√âRATION:\")\n",
    "        print(\"-\" * 50)\n",
    "        # Cr√©er un trainer temporaire pour la g√©n√©ration\n",
    "        temp_trainer = ModelTrainer(model_final, tokenizer, CONFIG, phase='phase2')\n",
    "        \n",
    "        seeds = [\"Le petit prince\", \"Il √©tait une fois\", \"Dans un lointain\"]\n",
    "        for seed in seeds:\n",
    "            generated = temp_trainer.generate_text(seed, length=80, temperature=0.8)\n",
    "            print(f\"'{seed}' ‚Üí '{generated[:60]}...'\")\n",
    "    \n",
    "    # Validation des crit√®res de r√©ussite\n",
    "    print(\"VALIDATION DES CRIT√àRES DE R√âUSSITE:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    criteria_results = []\n",
    "    \n",
    "    # Crit√®res Phase 1\n",
    "    criteria_results.append((\"Phase 1 < 30 minutes\", total_p1_time < 1800))\n",
    "    criteria_results.append((\"Vocabulaire < 50 caract√®res\", tokenizer.vocab_size < 50 if tokenizer else False))\n",
    "    criteria_results.append((\"Classement clair\", len(set(r['best_val_loss'] for r in results_phase1.values())) == 3))\n",
    "    \n",
    "    # Crit√®res Phase 2\n",
    "    if training_results_final:\n",
    "        criteria_results.append((\"Entra√Ænement sans crash\", training_results_final['epochs_trained'] > 0))\n",
    "        criteria_results.append((\"Am√©lioration qualit√©\", training_results_final['best_val_loss'] < 3.0))\n",
    "        onnx_exists = os.path.exists(MODEL_DIR / f\"{winner}_final.onnx\")\n",
    "        criteria_results.append((\"Export ONNX r√©ussi\", onnx_exists))\n",
    "    \n",
    "    # Crit√®res g√©n√©raux\n",
    "    total_time = total_p1_time + (training_results_final.get('total_time', 0) if training_results_final else 0)\n",
    "    criteria_results.append((\"Temps total < 3h\", total_time < 10800))\n",
    "    \n",
    "    success_count = 0\n",
    "    for criteria, success in criteria_results:\n",
    "        status = \"\" if success else \"‚ùå\"\n",
    "        print(f\"   {status} {criteria}\")\n",
    "        if success:\n",
    "            success_count += 1\n",
    "    \n",
    "    success_rate = success_count / len(criteria_results) * 100\n",
    "    print(f\"\\\\nTaux de r√©ussite: {success_count}/{len(criteria_results)} ({success_rate:.1f}%)\")\n",
    "    \n",
    "    # Recommandations\n",
    "    print(\"\\\\nüí° RECOMMANDATIONS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if winner == 'LSTM':\n",
    "        print(\"   LSTM recommand√© pour la g√©n√©ration de texte\")\n",
    "        print(\"   Excellent compromis performance/stabilit√©\")\n",
    "        print(\"   Utiliser gradient clipping et early stopping\")\n",
    "    elif winner == 'GRU':\n",
    "        print(\"   GRU recommand√© pour l'efficacit√©\")\n",
    "        print(\"   Plus rapide que LSTM avec bonne performance\")\n",
    "        print(\"   üíæ Moins de param√®tres, id√©al pour d√©ploiement\")\n",
    "    else:\n",
    "        print(\"   RNN Simple pour cas d'usage basiques\")\n",
    "        print(\"   Attention aux probl√®mes de gradient\")\n",
    "        print(\"   Augmenter le gradient clipping\")\n",
    "    \n",
    "    print(\"\\\\nPROJET TERMIN√â AVEC SUCC√àS!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\" Fonctions de visualisation et rapport final pr√™tes\")\n",
    "print(\"Utilisez plot_training_results() et generate_final_report() pour l'analyse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996e70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Syst√®me complet pr√™t!\n",
      "\n",
      "üìñ GUIDE D'UTILISATION DU SYST√àME\n",
      "============================================================\n",
      "\n",
      "D√âMARRAGE RAPIDE:\n",
      "   1. Testez le syst√®me: test_system_components()\n",
      "   2. Lancez la comparaison compl√®te: run_complete_comparison()\n",
      "   3. Ou par √©tapes:\n",
      "      - Phase 1: winner, results, tokenizer = run_phase1_comparison()\n",
      "      - Phase 2: model, results, tokenizer = run_phase2_final_training(winner)\n",
      "\n",
      "UTILISATION AVEC VOS DONN√âES:\n",
      "   - Placez votre fichier texte dans le r√©pertoire\n",
      "   - Utilisez: run_complete_comparison('chemin/vers/fichier.txt')\n",
      "\n",
      "CONFIGURATION:\n",
      "   - Modifiez CONFIG pour ajuster les hyperparam√®tres\n",
      "   - Phase 1: comparaison rapide (5% donn√©es, 5 √©poques)\n",
      "   - Phase 2: entra√Ænement complet (100% donn√©es, 25 √©poques)\n",
      "\n",
      "R√âSULTATS:\n",
      "   - Mod√®les sauvegard√©s dans: models/\n",
      "   - Logs TensorBoard dans: logs/\n",
      "   - Graphiques: models/training_results.png\n",
      "\n",
      "CRIT√àRES DE R√âUSSITE:\n",
      "    Phase 1 < 30 minutes\n",
      "    Vocabulaire < 50 caract√®res\n",
      "    G√©n√©ration de texte coh√©rente\n",
      "    Export ONNX pour d√©ploiement\n",
      "    Temps total < 3 heures\n"
     ]
    }
   ],
   "source": [
    "# FONCTION PRINCIPALE - EX√âCUTION COMPL√àTE DU SYST√àME\n",
    "def run_complete_comparison(data_file_path=None, run_phase2=True):\n",
    "    \"\"\"\n",
    "    Fonction principale pour ex√©cuter le syst√®me complet en 2 phases\n",
    "    \n",
    "    Args:\n",
    "        data_file_path: Chemin vers le fichier de donn√©es (optionnel)\n",
    "        run_phase2: Si True, ex√©cute aussi la phase 2\n",
    "    \n",
    "    Returns:\n",
    "        Dict contenant tous les r√©sultats\n",
    "    \"\"\"\n",
    "    print(\"üöÄ\" * 20)\n",
    "    print(\"SYST√àME COMPLET DE COMPARAISON RNN vs LSTM vs GRU\")\n",
    "    print(\"üöÄ\" * 20)\n",
    "    print()\n",
    "    print(\"PLAN D'EX√âCUTION:\")\n",
    "    print(\"   Phase 1: Comparaison Ultra-Rapide (15-30 min)\")\n",
    "    print(\"   Phase 2: Entra√Ænement Final de Qualit√©\")\n",
    "    print(\"   Analyse et Visualisation\")\n",
    "    print(\"   4Ô∏è‚É£ Rapport Final\")\n",
    "    print()\n",
    "    \n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # PHASE 1: Comparaison rapide\n",
    "        print(\"D√âMARRAGE PHASE 1...\")\n",
    "        winner, results_phase1, tokenizer = run_phase1_comparison(data_file_path)\n",
    "        \n",
    "        phase1_time = time.time() - overall_start_time\n",
    "        print(f\" Phase 1 termin√©e en {phase1_time/60:.1f} minutes\")\n",
    "        \n",
    "        # Variables pour Phase 2\n",
    "        model_final = None\n",
    "        training_results_final = None\n",
    "        \n",
    "        # PHASE 2: Entra√Ænement final (optionnel)\n",
    "        if run_phase2:\n",
    "            print(\"\\\\nD√âMARRAGE PHASE 2...\")\n",
    "            phase2_start = time.time()\n",
    "            \n",
    "            model_final, training_results_final, tokenizer_final = run_phase2_final_training(winner, data_file_path)\n",
    "            \n",
    "            phase2_time = time.time() - phase2_start\n",
    "            print(f\" Phase 2 termin√©e en {phase2_time/60:.1f} minutes\")\n",
    "        else:\n",
    "            print(\"hase 2 ignor√©e (run_phase2=False)\")\n",
    "        \n",
    "        # PHASE 3: Visualisation\n",
    "        print(\"\\\\nG√âN√âRATION DES GRAPHIQUES...\")\n",
    "        plot_training_results(results_phase1, model_final, training_results_final)\n",
    "        \n",
    "        # PHASE 4: Rapport final\n",
    "        print(\"\\\\nG√âN√âRATION DU RAPPORT FINAL...\")\n",
    "        generate_final_report(winner, results_phase1, model_final, training_results_final, tokenizer)\n",
    "        \n",
    "        total_time = time.time() - overall_start_time\n",
    "        \n",
    "        # R√©sum√© final\n",
    "        print(\"\\\\n\" + \"üéâ\" * 20)\n",
    "        print(\"SYST√àME TERMIN√â AVEC SUCC√àS!\")\n",
    "        print(\"üéâ\" * 20)\n",
    "        print(f\"Temps total: {total_time/60:.1f} minutes\")\n",
    "        print(f\"Mod√®le gagnant: {winner}\")\n",
    "        print(f\"Fichiers sauvegard√©s dans: {MODEL_DIR}\")\n",
    "        \n",
    "        # Retourner tous les r√©sultats\n",
    "        return {\n",
    "            'winner': winner,\n",
    "            'results_phase1': results_phase1,\n",
    "            'model_final': model_final,\n",
    "            'training_results_final': training_results_final,\n",
    "            'tokenizer': tokenizer,\n",
    "            'total_time': total_time,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\nERREUR CRITIQUE: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'total_time': time.time() - overall_start_time\n",
    "        }\n",
    "\n",
    "# FONCTIONS DE TEST ET VALIDATION\n",
    "def test_system_components():\n",
    "    \"\"\"\n",
    "    Tester tous les composants avant l'ex√©cution compl√®te\n",
    "    \"\"\"\n",
    "    print(\"TEST DES COMPOSANTS DU SYST√àME\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    tests_passed = 0\n",
    "    total_tests = 6\n",
    "    \n",
    "    try:\n",
    "        # Test 1: Tokenizer\n",
    "        print(\"Test Tokenizer...\")\n",
    "        tokenizer = CharacterTokenizer()\n",
    "        test_text = \"Hello, World! 123 √©√†√ß\"\n",
    "        tokenizer.fit(test_text)\n",
    "        encoded = tokenizer.encode(test_text)\n",
    "        decoded = tokenizer.decode(encoded)\n",
    "        assert test_text == decoded, \"Erreur encodage/d√©codage\"\n",
    "        print(\"    Tokenizer OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 2: Dataset\n",
    "        print(\"Test Dataset...\")\n",
    "        dataset = TextDataset(test_text, tokenizer, seq_length=10, max_sequences=5)\n",
    "        assert len(dataset) > 0, \"Dataset vide\"\n",
    "        seq, target = dataset[0]\n",
    "        assert seq.shape[0] == 10, \"S√©quence de mauvaise taille\"\n",
    "        print(\"    Dataset OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 3: Mod√®les\n",
    "        print(\"Test Mod√®les...\")\n",
    "        for model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "            model = create_model(model_type, tokenizer.vocab_size, CONFIG)\n",
    "            x = torch.randint(0, tokenizer.vocab_size, (2, 10))\n",
    "            hidden = model.init_hidden(2)\n",
    "            output, new_hidden = model(x, hidden)\n",
    "            assert output.shape == (2, 10, tokenizer.vocab_size), f\"Sortie {model_type} incorrecte\"\n",
    "            del model\n",
    "        print(\"    Mod√®les OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 4: DataLoader\n",
    "        print(\"4Ô∏è‚É£ Test DataLoader...\")\n",
    "        from torch.utils.data import DataLoader\n",
    "        loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "        batch_seq, batch_target = next(iter(loader))\n",
    "        assert batch_seq.shape[0] <= 2, \"Batch size incorrect\"\n",
    "        print(\"    DataLoader OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 5: Configuration\n",
    "        print(\"5Ô∏è‚É£ Test Configuration...\")\n",
    "        assert CONFIG['phase1']['max_sequences'] < CONFIG['phase2']['max_sequences'], \"Config s√©quences incorrecte\"\n",
    "        assert CONFIG['phase1']['max_epochs'] < CONFIG['phase2']['max_epochs'], \"Config √©poques incorrecte\"\n",
    "        assert CONFIG['phase1']['learning_rate'] > CONFIG['phase2']['learning_rate'], \"Config LR incorrecte\"\n",
    "        print(\"    Configuration OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "        # Test 6: R√©pertoires\n",
    "        print(\"6Ô∏è‚É£ Test R√©pertoires...\")\n",
    "        assert MODEL_DIR.exists(), \"R√©pertoire mod√®les manquant\"\n",
    "        assert LOGS_DIR.exists(), \"R√©pertoire logs manquant\"\n",
    "        print(\"    R√©pertoires OK\")\n",
    "        tests_passed += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Erreur: {e}\")\n",
    "    \n",
    "    print(f\"\\\\nR√©sultat: {tests_passed}/{total_tests} tests r√©ussis\")\n",
    "    \n",
    "    if tests_passed == total_tests:\n",
    "        print(\" TOUS LES TESTS R√âUSSIS - Syst√®me pr√™t!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"CERTAINS TESTS √âCHOU√âS - V√©rifiez la configuration\")\n",
    "        return False\n",
    "\n",
    "# GUIDE D'UTILISATION\n",
    "def show_usage_guide():\n",
    "    \"\"\"\n",
    "    Afficher le guide d'utilisation du syst√®me\n",
    "    \"\"\"\n",
    "    print(\"GUIDE D'UTILISATION DU SYST√àME\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"D√âMARRAGE RAPIDE:\")\n",
    "    print(\"   1. Testez le syst√®me: test_system_components()\")\n",
    "    print(\"   2. Lancez la comparaison compl√®te: run_complete_comparison()\")\n",
    "    print(\"   3. Ou par √©tapes:\")\n",
    "    print(\"      - Phase 1: winner, results, tokenizer = run_phase1_comparison()\")\n",
    "    print(\"      - Phase 2: model, results, tokenizer = run_phase2_final_training(winner)\")\n",
    "    print()\n",
    "    print(\"UTILISATION AVEC VOS DONN√âES:\")\n",
    "    print(\"   - Placez votre fichier texte dans le r√©pertoire\")\n",
    "    print(\"   - Utilisez: run_complete_comparison('chemin/vers/fichier.txt')\")\n",
    "    print()\n",
    "    print(\"CONFIGURATION:\")\n",
    "    print(\"   - Modifiez CONFIG pour ajuster les hyperparam√®tres\")\n",
    "    print(\"   - Phase 1: comparaison rapide (5% donn√©es, 5 √©poques)\")\n",
    "    print(\"   - Phase 2: entra√Ænement complet (100% donn√©es, 25 √©poques)\")\n",
    "    print()\n",
    "    print(\"R√âSULTATS:\")\n",
    "    print(\"   - Mod√®les sauvegard√©s dans: models/\")\n",
    "    print(\"   - Logs TensorBoard dans: logs/\")\n",
    "    print(\"   - Graphiques: models/training_results.png\")\n",
    "    print()\n",
    "    print(\"CRIT√àRES DE R√âUSSITE:\")\n",
    "    print(\"    Phase 1 < 30 minutes\")\n",
    "    print(\"    Vocabulaire < 50 caract√®res\")\n",
    "    print(\"    G√©n√©ration de texte coh√©rente\")\n",
    "    print(\"    Export ONNX pour d√©ploiement\")\n",
    "    print(\"    Temps total < 3 heures\")\n",
    "\n",
    "print(\" Syst√®me complet pr√™t!\")\n",
    "print()\n",
    "show_usage_guide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada7c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V√âRIFICATION FINALE DU SYST√àME\n",
      "==================================================\n",
      "Composants charg√©s:\n",
      "    PyTorch version: 2.7.1+cu118\n",
      "    Device: cuda\n",
      "    Seed fix√©: 42\n",
      "    R√©pertoires cr√©√©s: models, logs\n",
      "    Configuration charg√©e: 3 phases\n",
      "    GPU: NVIDIA GeForce RTX 2070\n",
      "    M√©moire GPU: 8.6 GB\n",
      "\n",
      "üí° √âTAPES SUIVANTES:\n",
      "   Ex√©cuter: test_system_components()  # Test complet\n",
      "   Ex√©cuter: run_complete_comparison() # Lancer la comparaison\n",
      "   Ou par phases:\n",
      "      - run_phase1_comparison()          # Phase 1 seulement\n",
      "      - run_phase2_final_training()      # Phase 2 avec le gagnant\n",
      "\n",
      "OBJECTIFS √Ä ATTEINDRE:\n",
      "    Comparaison 3 mod√®les < 30 minutes\n",
      "    Identification du meilleur mod√®le\n",
      "    Entra√Ænement final de qualit√©\n",
      "    Export ONNX pour d√©ploiement\n",
      "    G√©n√©ration de texte coh√©rente\n",
      "\n",
      "SYST√àME PR√äT POUR LE LANCEMENT!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# TEST DU SYST√àME ET D√âMARRAGE\n",
    "print(\"V√âRIFICATION FINALE DU SYST√àME\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# V√©rifier que tous les composants sont pr√™ts\n",
    "print(\"Composants charg√©s:\")\n",
    "print(f\"    PyTorch version: {torch.__version__}\")\n",
    "print(f\"    Device: {device}\")\n",
    "print(f\"    Seed fix√©: {SEED}\")\n",
    "print(f\"    R√©pertoires cr√©√©s: {MODEL_DIR}, {LOGS_DIR}\")\n",
    "print(f\"    Configuration charg√©e: {len(CONFIG)} phases\")\n",
    "\n",
    "# V√©rifier la m√©moire disponible\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"    GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"    M√©moire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"   CPU seulement (recommand√©: GPU pour performance)\")\n",
    "\n",
    "print(\"\\nüí° √âTAPES SUIVANTES:\")\n",
    "print(\"   Ex√©cuter: test_system_components()  # Test complet\")\n",
    "print(\"   Ex√©cuter: run_complete_comparison() # Lancer la comparaison\")\n",
    "print(\"   Ou par phases:\")\n",
    "print(\"      - run_phase1_comparison()          # Phase 1 seulement\")\n",
    "print(\"      - run_phase2_final_training()      # Phase 2 avec le gagnant\")\n",
    "\n",
    "print(\"\\nOBJECTIFS √Ä ATTEINDRE:\")\n",
    "print(\"    Comparaison 3 mod√®les < 30 minutes\")\n",
    "print(\"    Identification du meilleur mod√®le\")\n",
    "print(\"    Entra√Ænement final de qualit√©\")\n",
    "print(\"    Export ONNX pour d√©ploiement\")\n",
    "print(\"    G√©n√©ration de texte coh√©rente\")\n",
    "\n",
    "print(\"\\nSYST√àME PR√äT POUR LE LANCEMENT!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ LANCEMENT DU SYST√àME COMPLET\n",
      "==================================================\n",
      "Test des composants...\n",
      "üß™ TEST DES COMPOSANTS DU SYST√àME\n",
      "==================================================\n",
      "Test Tokenizer...\n",
      "Vocabulaire construit:\n",
      "   - Taille: 16 caract√®res\n",
      "   - Caract√®res:  !,123HWdelor√†√ß√©\n",
      "    Tokenizer OK\n",
      "Test Dataset...\n",
      " Dataset cr√©√©:\n",
      "   - Texte original: 21 caract√®res\n",
      "   - Texte encod√©: 21 tokens\n",
      "   - S√©quences g√©n√©r√©es: 3\n",
      "   - Longueur s√©quence: 10\n",
      "   - Chevauchement: 50%\n",
      "    Dataset OK\n",
      "Test Mod√®les...\n",
      "Mod√®le RNN cr√©√©:\n",
      "   - Param√®tres: 236,560\n",
      "   - Device: cuda:0\n",
      "   Erreur: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n",
      "\\nR√©sultat: 2/6 tests r√©ussis\n",
      "CERTAINS TESTS √âCHOU√âS - V√©rifiez la configuration\n",
      "Tests √©chou√©s - V√©rifiez la configuration\n"
     ]
    }
   ],
   "source": [
    "# LANCEMENT DE LA COMPARAISON COMPL√àTE\n",
    "print(\"LANCEMENT DU SYST√àME COMPLET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# D'abord, testons rapidement les composants\n",
    "print(\"Test des composants...\")\n",
    "if test_system_components():\n",
    "    print(\" Tous les tests r√©ussis!\")\n",
    "    \n",
    "    print(\"\\nLancement de la comparaison compl√®te...\")\n",
    "    print(\"Objectif: Identifier le meilleur mod√®le RNN/LSTM/GRU\")\n",
    "    print(\"Strat√©gie 2-phases activ√©e\")\n",
    "    print(\"Dataset: Texte fran√ßais (Le Petit Prince)\")\n",
    "    print()\n",
    "    \n",
    "    # Lancer la comparaison compl√®te\n",
    "    results = run_complete_comparison()\n",
    "    \n",
    "    if results['success']:\n",
    "        print(\"\\nMISSION ACCOMPLIE!\")\n",
    "        print(f\"Gagnant: {results['winner']}\")\n",
    "        print(f\"Temps total: {results['total_time']/60:.1f} minutes\")\n",
    "        print(\"\\nConsultez les r√©sultats:\")\n",
    "        print(\"   - Graphiques: models/training_results.png\")\n",
    "        print(\"   - Mod√®les: models/\")\n",
    "        print(\"   - Logs TensorBoard: logs/\")\n",
    "    else:\n",
    "        print(f\"\\nErreur: {results.get('error', 'Inconnue')}\")\n",
    "        print(f\"Temps avant erreur: {results['total_time']/60:.1f} minutes\")\n",
    "else:\n",
    "    print(\"Tests √©chou√©s - V√©rifiez la configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "eb99ddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANCEMENT DIRECT DE LA PHASE 1\n",
      "============================================================\n",
      "Ignorons les tests et lan√ßons directement la comparaison!\n",
      "Phase 1: Comparaison Ultra-Rapide des 3 mod√®les\n",
      "Temps estim√©: 15-30 minutes\n",
      "\n",
      "============================================================\n",
      "D√âBUT PHASE 1 - COMPARAISON ULTRA-RAPIDE\n",
      "============================================================\n",
      "Objectif: Identifier le meilleur mod√®le en 15-30 minutes\n",
      "Optimisations: 5% donn√©es, 5 √©poques max, LR √©lev√©, patience r√©duite\n",
      "\n",
      "Chargement des donn√©es pour PHASE1\n",
      "Aucun fichier sp√©cifi√©, utilisation d'un dataset de d√©monstration\n",
      "   Limitation √† 5% des donn√©es: 4,172 caract√®res\n",
      "   Texte charg√©: 4,172 caract√®res\n",
      "Vocabulaire construit:\n",
      "   - Taille: 46 caract√®res\n",
      "   - Caract√®res: \n",
      " ',-.126BCEILSTUabc...\n",
      " Dataset cr√©√©:\n",
      "   - Texte original: 4,172 caract√®res\n",
      "   - Texte encod√©: 4,172 tokens\n",
      "   - S√©quences g√©n√©r√©es: 165\n",
      "   - Longueur s√©quence: 50\n",
      "   - Chevauchement: 50%\n",
      "   Division donn√©es:\n",
      "      - Train: 132 s√©quences\n",
      "      - Validation: 33 s√©quences\n",
      "      - Batch size: 64\n",
      "      - Vocabulaire: 46 caract√®res\n",
      "   √âchantillon: '\n",
      "        Le petit prince √©tait un tr√®s joli petit bonhomme qui riait souvent. Il venait d'une plan√®t...'\n",
      "üî¨ Comparaison de 3 mod√®les:\n",
      "   - Types: RNN, LSTM, GRU\n",
      "   - Donn√©es: 132 s√©quences d'entra√Ænement\n",
      "   - Vocabulaire: 46 caract√®res\n",
      "\n",
      "üîÑ [1/3] Entra√Ænement RNN\n",
      "----------------------------------------\n",
      "Mod√®le RNN cr√©√©:\n",
      "   - Param√®tres: 248,110\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - SimpleRNN\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "√âpoque  1/ 5 | Train: 3.5071 | Val: 2.9457 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  2/ 5 | Train: 2.7547 | Val: 2.5657 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  2/ 5 | Train: 2.7547 | Val: 2.5657 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  3/ 5 | Train: 2.5475 | Val: 2.3885 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  4/ 5 | Train: 2.4419 | Val: 2.2618 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  3/ 5 | Train: 2.5475 | Val: 2.3885 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  4/ 5 | Train: 2.4419 | Val: 2.2618 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  5/ 5 | Train: 2.3087 | Val: 2.1774 | LR: 0.002000 | Temps: 0.0s√âpoque  5/ 5 | Train: 2.3087 | Val: 2.1774 | LR: 0.002000 | Temps: 0.0s\n",
      "   G√©n√©ration: 'Lemtm√®Le test e√® a dns s fles ,ouns lan√®ae peuiene...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 2.1774)\n",
      "Temps total: 0.2s (0.0 minutes)\n",
      "\n",
      "   G√©n√©ration: 'Lemtm√®Le test e√® a dns s fles ,ouns lan√®ae peuiene...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 2.1774)\n",
      "Temps total: 0.2s (0.0 minutes)\n",
      " RNN termin√©:\n",
      "   - Validation Loss: 2.1774\n",
      "   - Temps: 0.2s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 248,110\n",
      "   - √âchantillon: 'Le petit princet puinres dur le dlsite de t ant ou...'\n",
      "\n",
      "üîÑ [2/3] Entra√Ænement LSTM\n",
      "----------------------------------------\n",
      "Mod√®le LSTM cr√©√©:\n",
      "   - Param√®tres: 939,310\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - LSTMModel\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      " RNN termin√©:\n",
      "   - Validation Loss: 2.1774\n",
      "   - Temps: 0.2s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 248,110\n",
      "   - √âchantillon: 'Le petit princet puinres dur le dlsite de t ant ou...'\n",
      "\n",
      "üîÑ [2/3] Entra√Ænement LSTM\n",
      "----------------------------------------\n",
      "Mod√®le LSTM cr√©√©:\n",
      "   - Param√®tres: 939,310\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - LSTMModel\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "√âpoque  1/ 5 | Train: 3.7464 | Val: 3.2425 | LR: 0.002000 | Temps: 0.1s\n",
      "√âpoque  2/ 5 | Train: 3.1557 | Val: 3.0477 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  3/ 5 | Train: 3.0552 | Val: 2.9878 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  1/ 5 | Train: 3.7464 | Val: 3.2425 | LR: 0.002000 | Temps: 0.1s\n",
      "√âpoque  2/ 5 | Train: 3.1557 | Val: 3.0477 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  3/ 5 | Train: 3.0552 | Val: 2.9878 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  4/ 5 | Train: 2.9756 | Val: 2.9365 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  5/ 5 | Train: 2.9184 | Val: 2.9042 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  4/ 5 | Train: 2.9756 | Val: 2.9365 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  5/ 5 | Train: 2.9184 | Val: 2.9042 | LR: 0.002000 | Temps: 0.0s\n",
      "   G√©n√©ration: 'Lei la u etleqadse le rnuetier pce  c. raur ta euu...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 2.9042)\n",
      "Temps total: 0.3s (0.0 minutes)\n",
      " LSTM termin√©:\n",
      "   - Validation Loss: 2.9042\n",
      "   - Temps: 0.3s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 939,310\n",
      "   - √âchantillon: 'Le petit princerlp od anas a te  e eee  eai vde tt...'\n",
      "\n",
      "üîÑ [3/3] Entra√Ænement GRU\n",
      "----------------------------------------\n",
      "Mod√®le GRU cr√©√©:\n",
      "   - Param√®tres: 708,910\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - GRUModel\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "   G√©n√©ration: 'Lei la u etleqadse le rnuetier pce  c. raur ta euu...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 2.9042)\n",
      "Temps total: 0.3s (0.0 minutes)\n",
      " LSTM termin√©:\n",
      "   - Validation Loss: 2.9042\n",
      "   - Temps: 0.3s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 939,310\n",
      "   - √âchantillon: 'Le petit princerlp od anas a te  e eee  eai vde tt...'\n",
      "\n",
      "üîÑ [3/3] Entra√Ænement GRU\n",
      "----------------------------------------\n",
      "Mod√®le GRU cr√©√©:\n",
      "   - Param√®tres: 708,910\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - GRUModel\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "√âpoque  1/ 5 | Train: 3.6014 | Val: 3.0953 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  2/ 5 | Train: 3.0565 | Val: 2.9119 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  3/ 5 | Train: 2.9162 | Val: 2.7920 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  1/ 5 | Train: 3.6014 | Val: 3.0953 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  2/ 5 | Train: 3.0565 | Val: 2.9119 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  3/ 5 | Train: 2.9162 | Val: 2.7920 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  4/ 5 | Train: 2.7292 | Val: 2.6346 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  5/ 5 | Train: 2.6025 | Val: 2.5238 | LR: 0.002000 | Temps: 0.0s\n",
      "   G√©n√©ration: 'Lee le poaenies btiit. Srogert our Sar taits lauie...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 2.5238)\n",
      "Temps total: 0.2s (0.0 minutes)\n",
      " GRU termin√©:\n",
      "   - Validation Loss: 2.5238\n",
      "   - Temps: 0.2s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 708,910\n",
      "   - √âchantillon: 'Le petit princeretit ojlaa√†√®ie 'e upe lr. le anet ...'\n",
      "\n",
      "============================================================\n",
      "R√âSULTATS PHASE 1 - COMPARAISON\n",
      "============================================================\n",
      "CLASSEMENT (par Validation Loss):\n",
      "ü•á 1. RNN  | Val Loss: 2.1774 | Temps:   0.2s | Params: 248,110\n",
      "ü•à 2. GRU  | Val Loss: 2.5238 | Temps:   0.2s | Params: 708,910\n",
      "ü•â 3. LSTM | Val Loss: 2.9042 | Temps:   0.3s | Params: 939,310\n",
      "\n",
      "GAGNANT PHASE 1: RNN\n",
      "   - Meilleure Validation Loss: 2.1774\n",
      "   - Temps d'entra√Ænement: 0.2s\n",
      "   - Nombre de param√®tres: 248,110\n",
      "\n",
      "TEMPS TOTAL PHASE 1: 1.0s (0.0 minutes)\n",
      "üíæ R√©sultats sauvegard√©s:\n",
      "   - Mod√®les: models/{RNN,LSTM,GRU}_phase1.pth\n",
      "   - Tokenizer: models\\tokenizer.pkl\n",
      "   - R√©sultats: models\\phase1_results.json\n",
      "\n",
      " VALIDATION CRIT√àRES PHASE 1:\n",
      "    Temps < 30 minutes\n",
      "    Vocabulaire < 50 caract√®res\n",
      "    G√©n√©ration coh√©rente\n",
      "    Classement clair\n",
      "\n",
      "PHASE 1 R√âUSSIE ! Pr√™t pour Phase 2\n",
      "PHASE 1 TERMIN√âE!\n",
      "Gagnant: RNN\n",
      "\n",
      "Voulez-vous continuer avec la Phase 2?\n",
      "   Ex√©cutez: run_phase2_final_training(winner)\n",
      "   Ou la comparaison compl√®te: plot_training_results(results_phase1)\n",
      "√âpoque  4/ 5 | Train: 2.7292 | Val: 2.6346 | LR: 0.002000 | Temps: 0.0s\n",
      "√âpoque  5/ 5 | Train: 2.6025 | Val: 2.5238 | LR: 0.002000 | Temps: 0.0s\n",
      "   G√©n√©ration: 'Lee le poaenies btiit. Srogert our Sar taits lauie...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 2.5238)\n",
      "Temps total: 0.2s (0.0 minutes)\n",
      " GRU termin√©:\n",
      "   - Validation Loss: 2.5238\n",
      "   - Temps: 0.2s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 708,910\n",
      "   - √âchantillon: 'Le petit princeretit ojlaa√†√®ie 'e upe lr. le anet ...'\n",
      "\n",
      "============================================================\n",
      "R√âSULTATS PHASE 1 - COMPARAISON\n",
      "============================================================\n",
      "CLASSEMENT (par Validation Loss):\n",
      "ü•á 1. RNN  | Val Loss: 2.1774 | Temps:   0.2s | Params: 248,110\n",
      "ü•à 2. GRU  | Val Loss: 2.5238 | Temps:   0.2s | Params: 708,910\n",
      "ü•â 3. LSTM | Val Loss: 2.9042 | Temps:   0.3s | Params: 939,310\n",
      "\n",
      "GAGNANT PHASE 1: RNN\n",
      "   - Meilleure Validation Loss: 2.1774\n",
      "   - Temps d'entra√Ænement: 0.2s\n",
      "   - Nombre de param√®tres: 248,110\n",
      "\n",
      "TEMPS TOTAL PHASE 1: 1.0s (0.0 minutes)\n",
      "üíæ R√©sultats sauvegard√©s:\n",
      "   - Mod√®les: models/{RNN,LSTM,GRU}_phase1.pth\n",
      "   - Tokenizer: models\\tokenizer.pkl\n",
      "   - R√©sultats: models\\phase1_results.json\n",
      "\n",
      " VALIDATION CRIT√àRES PHASE 1:\n",
      "    Temps < 30 minutes\n",
      "    Vocabulaire < 50 caract√®res\n",
      "    G√©n√©ration coh√©rente\n",
      "    Classement clair\n",
      "\n",
      "PHASE 1 R√âUSSIE ! Pr√™t pour Phase 2\n",
      "PHASE 1 TERMIN√âE!\n",
      "Gagnant: RNN\n",
      "\n",
      "Voulez-vous continuer avec la Phase 2?\n",
      "   Ex√©cutez: run_phase2_final_training(winner)\n",
      "   Ou la comparaison compl√®te: plot_training_results(results_phase1)\n"
     ]
    }
   ],
   "source": [
    "# LANCEMENT DIRECT PHASE 1 - COMPARAISON RNN vs LSTM vs GRU\n",
    "print(\"LANCEMENT DIRECT DE LA PHASE 1\")\n",
    "print(\"=\"*60)\n",
    "print(\"Ignorons les tests et lan√ßons directement la comparaison!\")\n",
    "print(\"Phase 1: Comparaison Ultra-Rapide des 3 mod√®les\")\n",
    "print(\"Temps estim√©: 15-30 minutes\")\n",
    "print()\n",
    "\n",
    "# Lancer directement la Phase 1\n",
    "winner, results_phase1, tokenizer = run_phase1_comparison()\n",
    "\n",
    "print(\"PHASE 1 TERMIN√âE!\")\n",
    "print(f\"Gagnant: {winner}\")\n",
    "print(\"\\nVoulez-vous continuer avec la Phase 2?\")\n",
    "print(\"   Ex√©cutez: run_phase2_final_training(winner)\")\n",
    "print(\"   Ou la comparaison compl√®te: plot_training_results(results_phase1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "4368fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYSE DES R√âSULTATS DE PHASE 1\n",
      "==================================================\n",
      "Gagnant: RNN\n",
      "Nombre de mod√®les compar√©s: 3\n",
      "Taille du vocabulaire: 46 caract√®res\n",
      "\n",
      "CLASSEMENT FINAL:\n",
      "ü•á 1. RNN  | Val Loss: 2.1774 | Temps:   0.2s | Params: 248,110\n",
      "ü•à 2. GRU  | Val Loss: 2.5238 | Temps:   0.2s | Params: 708,910\n",
      "ü•â 3. LSTM | Val Loss: 2.9042 | Temps:   0.3s | Params: 939,310\n",
      "\n",
      "üé® √âCHANTILLONS DE G√âN√âRATION:\n",
      "RNN : 'Le petit princet puinres dur le dlsite de t ant ous  lrss bens qunles le ait ui ...'\n",
      "LSTM: 'Le petit princerlp od anas a te  e eee  eai vde ttl 'aar lrn ui eeattnt de men s...'\n",
      "GRU : 'Le petit princeretit ojlaa√†√®ie 'e upe lr. le anet uitt vpne plae lpvineavitrmvda...'\n",
      "\n",
      "G√©n√©ration des graphiques de comparaison...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Graphiques sauvegard√©s: models\\training_results.png\n",
      " Graphiques sauvegard√©s dans models/training_results.png\n",
      "\n",
      "√âTAPES SUIVANTES:\n",
      "Phase 2 avec RNN: run_phase2_final_training('RNN')\n",
      "Rapport complet: generate_final_report('RNN', results_phase1)\n",
      "Visualiser TensorBoard: consultez le dossier logs/\n"
     ]
    }
   ],
   "source": [
    "# ANALYSE DES R√âSULTATS DE PHASE 1\n",
    "print(\"ANALYSE DES R√âSULTATS DE PHASE 1\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Afficher un r√©sum√© des r√©sultats\n",
    "print(f\"Gagnant: {winner}\")\n",
    "print(f\"Nombre de mod√®les compar√©s: {len(results_phase1)}\")\n",
    "print(f\"Taille du vocabulaire: {tokenizer.vocab_size} caract√®res\")\n",
    "\n",
    "print(\"\\nCLASSEMENT FINAL:\")\n",
    "sorted_results = sorted(results_phase1.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "for rank, (model_type, result) in enumerate(sorted_results, 1):\n",
    "    medal = \"ü•á\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\"\n",
    "    print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "          f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "          f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "          f\"Params: {result['parameters']:>7,}\")\n",
    "\n",
    "# Afficher les √©chantillons de g√©n√©ration\n",
    "print(\"\\n√âCHANTILLONS DE G√âN√âRATION:\")\n",
    "for model_type, result in results_phase1.items():\n",
    "    sample = result['sample_generation'][:80]\n",
    "    print(f\"{model_type:4s}: '{sample}...'\")\n",
    "\n",
    "print(\"\\nG√©n√©ration des graphiques de comparaison...\")\n",
    "plot_training_results(results_phase1)\n",
    "print(\" Graphiques sauvegard√©s dans models/training_results.png\")\n",
    "\n",
    "print(f\"\\n√âTAPES SUIVANTES:\")\n",
    "print(f\"Phase 2 avec {winner}: run_phase2_final_training('{winner}')\")\n",
    "print(f\"Rapport complet: generate_final_report('{winner}', results_phase1)\")\n",
    "print(f\"Visualiser TensorBoard: consultez le dossier logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c75ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TEST DE CHARGEMENT DU DATASET JSONL\n",
      "==================================================\n",
      "Chargement du dataset: processed_en.jsonl\n",
      "   Limitation atteinte: 500,000 caract√®res\n",
      "    Dataset charg√©:\n",
      "      - Lignes trait√©es: 70\n",
      "      - Caract√®res total: 505,181\n",
      "      - √âchantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "\n",
      " Dataset charg√© avec succ√®s!\n",
      "Pr√™t pour l'entra√Ænement avec 505,181 caract√®res\n",
      "\n",
      "RELANCEMENT AVEC LE VRAI DATASET\n",
      "========================================\n",
      "D√©marrage de la comparaison avec processed_en.jsonl...\n"
     ]
    }
   ],
   "source": [
    "# CHARGEMENT DU DATASET PROCESSED_EN.JSONL\n",
    "import json\n",
    "\n",
    "def load_jsonl_dataset(file_path=\"processed_en.jsonl\", max_chars=None):\n",
    "    \"\"\"\n",
    "    Charger le dataset JSONL et extraire le texte pour l'entra√Ænement\n",
    "    \"\"\"\n",
    "    print(f\"Chargement du dataset: {file_path}\")\n",
    "    \n",
    "    texts = []\n",
    "    total_chars = 0\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                try:\n",
    "                    data = json.loads(line.strip())\n",
    "                    \n",
    "                    # Extraire le texte selon la structure du JSONL\n",
    "                    text_content = \"\"\n",
    "                    if 'text' in data:\n",
    "                        text_content = data['text']\n",
    "                    elif 'content' in data:\n",
    "                        text_content = data['content']\n",
    "                    elif 'message' in data:\n",
    "                        text_content = data['message']\n",
    "                    elif isinstance(data, str):\n",
    "                        text_content = data\n",
    "                    else:\n",
    "                        # Prendre la premi√®re valeur string trouv√©e\n",
    "                        for key, value in data.items():\n",
    "                            if isinstance(value, str) and len(value) > 10:\n",
    "                                text_content = value\n",
    "                                break\n",
    "                    \n",
    "                    if text_content and len(text_content.strip()) > 0:\n",
    "                        texts.append(text_content.strip())\n",
    "                        total_chars += len(text_content)\n",
    "                        \n",
    "                        # Limitation optionnelle\n",
    "                        if max_chars and total_chars > max_chars:\n",
    "                            print(f\"   Limitation atteinte: {max_chars:,} caract√®res\")\n",
    "                            break\n",
    "                            \n",
    "                    if line_num % 1000 == 0:\n",
    "                        print(f\"   Trait√©: {line_num:,} lignes, {total_chars:,} caract√®res\")\n",
    "                        \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"   Erreur ligne {line_num}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"   Fichier non trouv√©: {file_path}\")\n",
    "        print(f\"   üí° V√©rifiez que le fichier est dans le r√©pertoire courant\")\n",
    "        return None\n",
    "    \n",
    "    if not texts:\n",
    "        print(\"   Aucun texte trouv√© dans le dataset\")\n",
    "        return None\n",
    "    \n",
    "    # Joindre tous les textes avec des espaces\n",
    "    combined_text = \" \".join(texts)\n",
    "    \n",
    "    print(f\"    Dataset charg√©:\")\n",
    "    print(f\"      - Lignes trait√©es: {len(texts):,}\")\n",
    "    print(f\"      - Caract√®res total: {len(combined_text):,}\")\n",
    "    print(f\"      - √âchantillon: '{combined_text[:100]}...'\")\n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "# Test de chargement du dataset\n",
    "print(\"TEST DE CHARGEMENT DU DATASET JSONL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Essayer de charger le dataset\n",
    "dataset_text = load_jsonl_dataset(\"processed_en.jsonl\", max_chars=500000)  # Limite √† 500k caract√®res pour test\n",
    "\n",
    "if dataset_text:\n",
    "    print(\"\\n Dataset charg√© avec succ√®s!\")\n",
    "    print(f\"Pr√™t pour l'entra√Ænement avec {len(dataset_text):,} caract√®res\")\n",
    "    \n",
    "    # Relancer la comparaison avec le vrai dataset\n",
    "    print(\"\\nRELANCEMENT AVEC LE VRAI DATASET\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"D√©marrage de la comparaison avec processed_en.jsonl...\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nImpossible de charger le dataset\")\n",
    "    print(\"üí° V√©rifiez que processed_en.jsonl est dans le r√©pertoire courant\")\n",
    "    print(\"üí° Ou utilisez le dataset de d√©monstration pr√©c√©dent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11dc021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ LANCEMENT DE LA COMPARAISON AVEC DATASET R√âEL...\n",
      "COMPARAISON RNN vs LSTM vs GRU - DATASET R√âEL\n",
      "============================================================\n",
      "Chargement du dataset complet...\n",
      "Chargement du dataset: processed_en.jsonl\n",
      "   Trait√©: 1,000 lignes, 8,597,746 caract√®res\n",
      "   Trait√©: 2,000 lignes, 15,614,394 caract√®res\n",
      "   Trait√©: 3,000 lignes, 23,542,750 caract√®res\n",
      "   Trait√©: 4,000 lignes, 30,904,692 caract√®res\n",
      "   Trait√©: 5,000 lignes, 38,793,076 caract√®res\n",
      "   Trait√©: 6,000 lignes, 46,925,927 caract√®res\n",
      "   Trait√©: 7,000 lignes, 55,244,142 caract√®res\n",
      "   Trait√©: 3,000 lignes, 23,542,750 caract√®res\n",
      "   Trait√©: 4,000 lignes, 30,904,692 caract√®res\n",
      "   Trait√©: 5,000 lignes, 38,793,076 caract√®res\n",
      "   Trait√©: 6,000 lignes, 46,925,927 caract√®res\n",
      "   Trait√©: 7,000 lignes, 55,244,142 caract√®res\n",
      "   Trait√©: 8,000 lignes, 63,597,429 caract√®res\n",
      "   Trait√©: 9,000 lignes, 71,137,641 caract√®res\n",
      "   Trait√©: 10,000 lignes, 78,560,305 caract√®res\n",
      "   Trait√©: 11,000 lignes, 86,815,651 caract√®res\n",
      "   Trait√©: 12,000 lignes, 94,800,131 caract√®res\n",
      "   Trait√©: 8,000 lignes, 63,597,429 caract√®res\n",
      "   Trait√©: 9,000 lignes, 71,137,641 caract√®res\n",
      "   Trait√©: 10,000 lignes, 78,560,305 caract√®res\n",
      "   Trait√©: 11,000 lignes, 86,815,651 caract√®res\n",
      "   Trait√©: 12,000 lignes, 94,800,131 caract√®res\n",
      "   Trait√©: 13,000 lignes, 102,403,519 caract√®res\n",
      "   Trait√©: 14,000 lignes, 110,651,155 caract√®res\n",
      "   Trait√©: 15,000 lignes, 118,175,998 caract√®res\n",
      "   Trait√©: 16,000 lignes, 125,395,305 caract√®res\n",
      "   Trait√©: 13,000 lignes, 102,403,519 caract√®res\n",
      "   Trait√©: 14,000 lignes, 110,651,155 caract√®res\n",
      "   Trait√©: 15,000 lignes, 118,175,998 caract√®res\n",
      "   Trait√©: 16,000 lignes, 125,395,305 caract√®res\n",
      "   Trait√©: 17,000 lignes, 133,245,301 caract√®res\n",
      "   Trait√©: 18,000 lignes, 141,711,534 caract√®res\n",
      "   Trait√©: 19,000 lignes, 149,781,480 caract√®res\n",
      "   Trait√©: 20,000 lignes, 157,072,266 caract√®res\n",
      "   Trait√©: 17,000 lignes, 133,245,301 caract√®res\n",
      "   Trait√©: 18,000 lignes, 141,711,534 caract√®res\n",
      "   Trait√©: 19,000 lignes, 149,781,480 caract√®res\n",
      "   Trait√©: 20,000 lignes, 157,072,266 caract√®res\n",
      "   Trait√©: 21,000 lignes, 163,986,466 caract√®res\n",
      "   Trait√©: 22,000 lignes, 171,991,209 caract√®res\n",
      "   Trait√©: 23,000 lignes, 179,450,624 caract√®res\n",
      "   Trait√©: 24,000 lignes, 187,260,578 caract√®res\n",
      "   Trait√©: 25,000 lignes, 194,082,588 caract√®res\n",
      "   Trait√©: 21,000 lignes, 163,986,466 caract√®res\n",
      "   Trait√©: 22,000 lignes, 171,991,209 caract√®res\n",
      "   Trait√©: 23,000 lignes, 179,450,624 caract√®res\n",
      "   Trait√©: 24,000 lignes, 187,260,578 caract√®res\n",
      "   Trait√©: 25,000 lignes, 194,082,588 caract√®res\n",
      "   Trait√©: 26,000 lignes, 200,939,218 caract√®res\n",
      "   Trait√©: 27,000 lignes, 208,430,247 caract√®res\n",
      "   Trait√©: 28,000 lignes, 215,314,561 caract√®res\n",
      "   Trait√©: 29,000 lignes, 222,207,657 caract√®res\n",
      "   Trait√©: 30,000 lignes, 229,823,955 caract√®res\n",
      "   Trait√©: 26,000 lignes, 200,939,218 caract√®res\n",
      "   Trait√©: 27,000 lignes, 208,430,247 caract√®res\n",
      "   Trait√©: 28,000 lignes, 215,314,561 caract√®res\n",
      "   Trait√©: 29,000 lignes, 222,207,657 caract√®res\n",
      "   Trait√©: 30,000 lignes, 229,823,955 caract√®res\n",
      "   Trait√©: 31,000 lignes, 237,083,931 caract√®res\n",
      "   Trait√©: 32,000 lignes, 245,092,001 caract√®res\n",
      "   Trait√©: 31,000 lignes, 237,083,931 caract√®res\n",
      "   Trait√©: 32,000 lignes, 245,092,001 caract√®res\n",
      "    Dataset charg√©:\n",
      "      - Lignes trait√©es: 32,131\n",
      "      - Caract√®res total: 246,076,973\n",
      "      - √âchantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "\n",
      "üîÑ PHASE 1 - COMPARAISON AVEC DONN√âES R√âELLES\n",
      "============================================================\n",
      "D√âBUT PHASE 1 - COMPARAISON ULTRA-RAPIDE\n",
      "============================================================\n",
      "Objectif: Identifier le meilleur mod√®le en 15-30 minutes\n",
      "Optimisations: 5% donn√©es, 5 √©poques max, LR √©lev√©, patience r√©duite\n",
      "\n",
      "Pr√©paration des donn√©es JSONL pour PHASE1\n",
      "   Limitation √† 5% des donn√©es: 12,303,848 caract√®res\n",
      "   Texte utilis√©: 12,303,848 caract√®res\n",
      "Vocabulaire construit:\n",
      "   - Taille: 161 caract√®res\n",
      "   - Caract√®res: \n",
      " !\"#$%&'()*+,-./012...\n",
      "    Dataset charg√©:\n",
      "      - Lignes trait√©es: 32,131\n",
      "      - Caract√®res total: 246,076,973\n",
      "      - √âchantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "\n",
      "üîÑ PHASE 1 - COMPARAISON AVEC DONN√âES R√âELLES\n",
      "============================================================\n",
      "D√âBUT PHASE 1 - COMPARAISON ULTRA-RAPIDE\n",
      "============================================================\n",
      "Objectif: Identifier le meilleur mod√®le en 15-30 minutes\n",
      "Optimisations: 5% donn√©es, 5 √©poques max, LR √©lev√©, patience r√©duite\n",
      "\n",
      "Pr√©paration des donn√©es JSONL pour PHASE1\n",
      "   Limitation √† 5% des donn√©es: 12,303,848 caract√®res\n",
      "   Texte utilis√©: 12,303,848 caract√®res\n",
      "Vocabulaire construit:\n",
      "   - Taille: 161 caract√®res\n",
      "   - Caract√®res: \n",
      " !\"#$%&'()*+,-./012...\n",
      " Dataset cr√©√©:\n",
      "   - Texte original: 12,303,848 caract√®res\n",
      "   - Texte encod√©: 12,303,848 tokens\n",
      "   - S√©quences g√©n√©r√©es: 5,000\n",
      "   - Longueur s√©quence: 50\n",
      "   - Chevauchement: 50%\n",
      "   Division donn√©es:\n",
      "      - Train: 4,000 s√©quences\n",
      "      - Validation: 1,000 s√©quences\n",
      "      - Batch size: 64\n",
      "      - Vocabulaire: 161 caract√®res\n",
      "   √âchantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "üî¨ Comparaison de 3 mod√®les:\n",
      "   - Types: RNN, LSTM, GRU\n",
      "   - Donn√©es: 4,000 s√©quences d'entra√Ænement\n",
      "   - Vocabulaire: 161 caract√®res\n",
      "\n",
      "üîÑ [1/3] Entra√Ænement RNN\n",
      "----------------------------------------\n",
      "Mod√®le RNN cr√©√©:\n",
      "   - Param√®tres: 292,385\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - SimpleRNN\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      " Dataset cr√©√©:\n",
      "   - Texte original: 12,303,848 caract√®res\n",
      "   - Texte encod√©: 12,303,848 tokens\n",
      "   - S√©quences g√©n√©r√©es: 5,000\n",
      "   - Longueur s√©quence: 50\n",
      "   - Chevauchement: 50%\n",
      "   Division donn√©es:\n",
      "      - Train: 4,000 s√©quences\n",
      "      - Validation: 1,000 s√©quences\n",
      "      - Batch size: 64\n",
      "      - Vocabulaire: 161 caract√®res\n",
      "   √âchantillon: 'Author Note: The first two chapters have had a complete overhaul, for a better reading experience. P...'\n",
      "üî¨ Comparaison de 3 mod√®les:\n",
      "   - Types: RNN, LSTM, GRU\n",
      "   - Donn√©es: 4,000 s√©quences d'entra√Ænement\n",
      "   - Vocabulaire: 161 caract√®res\n",
      "\n",
      "üîÑ [1/3] Entra√Ænement RNN\n",
      "----------------------------------------\n",
      "Mod√®le RNN cr√©√©:\n",
      "   - Param√®tres: 292,385\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - SimpleRNN\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "√âpoque  1/ 5 | Train: 2.7315 | Val: 2.2951 | LR: 0.002000 | Temps: 0.6s\n",
      "√âpoque  1/ 5 | Train: 2.7315 | Val: 2.2951 | LR: 0.002000 | Temps: 0.6s\n",
      "√âpoque  2/ 5 | Train: 2.2356 | Val: 2.0941 | LR: 0.002000 | Temps: 0.5s\n",
      "√âpoque  2/ 5 | Train: 2.2356 | Val: 2.0941 | LR: 0.002000 | Temps: 0.5s\n",
      "√âpoque  3/ 5 | Train: 2.0905 | Val: 1.9921 | LR: 0.002000 | Temps: 0.5s\n",
      "√âpoque  3/ 5 | Train: 2.0905 | Val: 1.9921 | LR: 0.002000 | Temps: 0.5s\n",
      "√âpoque  4/ 5 | Train: 2.0060 | Val: 1.9226 | LR: 0.002000 | Temps: 0.5s\n",
      "√âpoque  4/ 5 | Train: 2.0060 | Val: 1.9226 | LR: 0.002000 | Temps: 0.5s\n",
      "√âpoque  5/ 5 | Train: 1.9464 | Val: 1.8787 | LR: 0.002000 | Temps: 0.5s\n",
      "   G√©n√©ration: 'Ler lifious it the cambed firsts dastly indened la...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 1.8787)\n",
      "Temps total: 2.6s (0.0 minutes)\n",
      " RNN termin√©:\n",
      "   - Validation Loss: 1.8787\n",
      "   - Temps: 2.6s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 292,385\n",
      "   - √âchantillon: 'Le petit prince on share gove to musting the seemu...'\n",
      "\n",
      "üîÑ [2/3] Entra√Ænement LSTM\n",
      "----------------------------------------\n",
      "Mod√®le LSTM cr√©√©:\n",
      "   - Param√®tres: 983,585\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - LSTMModel\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "√âpoque  5/ 5 | Train: 1.9464 | Val: 1.8787 | LR: 0.002000 | Temps: 0.5s\n",
      "   G√©n√©ration: 'Ler lifious it the cambed firsts dastly indened la...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 1.8787)\n",
      "Temps total: 2.6s (0.0 minutes)\n",
      " RNN termin√©:\n",
      "   - Validation Loss: 1.8787\n",
      "   - Temps: 2.6s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 292,385\n",
      "   - √âchantillon: 'Le petit prince on share gove to musting the seemu...'\n",
      "\n",
      "üîÑ [2/3] Entra√Ænement LSTM\n",
      "----------------------------------------\n",
      "Mod√®le LSTM cr√©√©:\n",
      "   - Param√®tres: 983,585\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - LSTMModel\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "√âpoque  1/ 5 | Train: 3.1544 | Val: 2.7512 | LR: 0.002000 | Temps: 0.8s\n",
      "√âpoque  1/ 5 | Train: 3.1544 | Val: 2.7512 | LR: 0.002000 | Temps: 0.8s\n",
      "√âpoque  2/ 5 | Train: 2.5854 | Val: 2.4433 | LR: 0.002000 | Temps: 0.9s\n",
      "√âpoque  2/ 5 | Train: 2.5854 | Val: 2.4433 | LR: 0.002000 | Temps: 0.9s\n",
      "√âpoque  3/ 5 | Train: 2.3767 | Val: 2.2652 | LR: 0.002000 | Temps: 1.0s\n",
      "√âpoque  3/ 5 | Train: 2.3767 | Val: 2.2652 | LR: 0.002000 | Temps: 1.0s\n",
      "√âpoque  4/ 5 | Train: 2.2400 | Val: 2.1568 | LR: 0.002000 | Temps: 1.0s\n",
      "√âpoque  4/ 5 | Train: 2.2400 | Val: 2.1568 | LR: 0.002000 | Temps: 1.0s\n",
      "√âpoque  5/ 5 | Train: 2.1525 | Val: 2.0783 | LR: 0.002000 | Temps: 0.9s\n",
      "   G√©n√©ration: 'Lenter it the the anle, hough a belwand work the t...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 2.0783)\n",
      "Temps total: 4.5s (0.1 minutes)\n",
      " LSTM termin√©:\n",
      "   - Validation Loss: 2.0783\n",
      "   - Temps: 4.5s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 983,585\n",
      "   - √âchantillon: 'Le petit prince could neapon or lind.\n",
      "\"I mactly he...'\n",
      "\n",
      "üîÑ [3/3] Entra√Ænement GRU\n",
      "----------------------------------------\n",
      "Mod√®le GRU cr√©√©:\n",
      "   - Param√®tres: 753,185\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - GRUModel\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "√âpoque  5/ 5 | Train: 2.1525 | Val: 2.0783 | LR: 0.002000 | Temps: 0.9s\n",
      "   G√©n√©ration: 'Lenter it the the anle, hough a belwand work the t...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 2.0783)\n",
      "Temps total: 4.5s (0.1 minutes)\n",
      " LSTM termin√©:\n",
      "   - Validation Loss: 2.0783\n",
      "   - Temps: 4.5s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 983,585\n",
      "   - √âchantillon: 'Le petit prince could neapon or lind.\n",
      "\"I mactly he...'\n",
      "\n",
      "üîÑ [3/3] Entra√Ænement GRU\n",
      "----------------------------------------\n",
      "Mod√®le GRU cr√©√©:\n",
      "   - Param√®tres: 753,185\n",
      "   - Device: cuda:0\n",
      "D√©but entra√Ænement PHASE1 - GRUModel\n",
      "   - √âpoques max: 5\n",
      "   - Learning rate: 0.002\n",
      "   - Patience: 2\n",
      "√âpoque  1/ 5 | Train: 2.8542 | Val: 2.4046 | LR: 0.002000 | Temps: 0.8s\n",
      "√âpoque  1/ 5 | Train: 2.8542 | Val: 2.4046 | LR: 0.002000 | Temps: 0.8s\n",
      "√âpoque  2/ 5 | Train: 2.2983 | Val: 2.1496 | LR: 0.002000 | Temps: 0.7s\n",
      "√âpoque  2/ 5 | Train: 2.2983 | Val: 2.1496 | LR: 0.002000 | Temps: 0.7s\n",
      "√âpoque  3/ 5 | Train: 2.1059 | Val: 2.0018 | LR: 0.002000 | Temps: 0.7s\n",
      "√âpoque  3/ 5 | Train: 2.1059 | Val: 2.0018 | LR: 0.002000 | Temps: 0.7s\n",
      "√âpoque  4/ 5 | Train: 1.9883 | Val: 1.9143 | LR: 0.002000 | Temps: 0.7s\n",
      "√âpoque  4/ 5 | Train: 1.9883 | Val: 1.9143 | LR: 0.002000 | Temps: 0.7s\n",
      "√âpoque  5/ 5 | Train: 1.9089 | Val: 1.8494 | LR: 0.002000 | Temps: 0.7s\n",
      "   G√©n√©ration: 'Led mingtal. The now was you didn't he up he showl...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 1.8494)\n",
      "Temps total: 3.7s (0.1 minutes)\n",
      " GRU termin√©:\n",
      "   - Validation Loss: 1.8494\n",
      "   - Temps: 3.7s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 753,185\n",
      "   - √âchantillon: 'Le petit princer eld proniciont.\n",
      "Furth.\n",
      "\"In plan I...'\n",
      "\n",
      "============================================================\n",
      "R√âSULTATS PHASE 1 - COMPARAISON\n",
      "============================================================\n",
      "CLASSEMENT (par Validation Loss):\n",
      "ü•á 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "ü•à 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "ü•â 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "GAGNANT PHASE 1: GRU\n",
      "   - Meilleure Validation Loss: 1.8494\n",
      "   - Temps d'entra√Ænement: 3.7s\n",
      "   - Nombre de param√®tres: 753,185\n",
      "\n",
      "TEMPS TOTAL PHASE 1: 11.2s (0.2 minutes)\n",
      "üíæ R√©sultats sauvegard√©s:\n",
      "   - Mod√®les: models/{RNN,LSTM,GRU}_phase1.pth\n",
      "   - Tokenizer: models\\tokenizer.pkl\n",
      "   - R√©sultats: models\\phase1_results.json\n",
      "\n",
      " VALIDATION CRIT√àRES PHASE 1:\n",
      "    Temps < 30 minutes\n",
      "   ‚ùå Vocabulaire < 50 caract√®res\n",
      "    G√©n√©ration coh√©rente\n",
      "    Classement clair\n",
      "\n",
      "Certains crit√®res non atteints, mais on peut continuer\n",
      "\n",
      "COMPARAISON TERMIN√âE AVEC DATASET R√âEL!\n",
      "Gagnant: GRU\n",
      "Vocabulaire: 161 caract√®res\n",
      "\n",
      "NOUVEAU CLASSEMENT:\n",
      "ü•á 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "ü•à 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "ü•â 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "üé® G√âN√âRATION DE TEXTE AVEC DONN√âES R√âELLES:\n",
      "RNN : 'Le petit prince on share gove to musting the seemunt Mart spot od the restarly w...'\n",
      "LSTM: 'Le petit prince could neapon or lind.\n",
      "\"I mactly heicr and the path then, at mo m...'\n",
      "GRU : 'Le petit princer eld proniciont.\n",
      "Furth.\n",
      "\"In plan I day's to he was to should sup...'\n",
      "√âpoque  5/ 5 | Train: 1.9089 | Val: 1.8494 | LR: 0.002000 | Temps: 0.7s\n",
      "   G√©n√©ration: 'Led mingtal. The now was you didn't he up he showl...'\n",
      " Meilleur mod√®le restaur√© (Val Loss: 1.8494)\n",
      "Temps total: 3.7s (0.1 minutes)\n",
      " GRU termin√©:\n",
      "   - Validation Loss: 1.8494\n",
      "   - Temps: 3.7s\n",
      "   - √âpoques: 5\n",
      "   - Param√®tres: 753,185\n",
      "   - √âchantillon: 'Le petit princer eld proniciont.\n",
      "Furth.\n",
      "\"In plan I...'\n",
      "\n",
      "============================================================\n",
      "R√âSULTATS PHASE 1 - COMPARAISON\n",
      "============================================================\n",
      "CLASSEMENT (par Validation Loss):\n",
      "ü•á 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "ü•à 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "ü•â 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "GAGNANT PHASE 1: GRU\n",
      "   - Meilleure Validation Loss: 1.8494\n",
      "   - Temps d'entra√Ænement: 3.7s\n",
      "   - Nombre de param√®tres: 753,185\n",
      "\n",
      "TEMPS TOTAL PHASE 1: 11.2s (0.2 minutes)\n",
      "üíæ R√©sultats sauvegard√©s:\n",
      "   - Mod√®les: models/{RNN,LSTM,GRU}_phase1.pth\n",
      "   - Tokenizer: models\\tokenizer.pkl\n",
      "   - R√©sultats: models\\phase1_results.json\n",
      "\n",
      " VALIDATION CRIT√àRES PHASE 1:\n",
      "    Temps < 30 minutes\n",
      "   ‚ùå Vocabulaire < 50 caract√®res\n",
      "    G√©n√©ration coh√©rente\n",
      "    Classement clair\n",
      "\n",
      "Certains crit√®res non atteints, mais on peut continuer\n",
      "\n",
      "COMPARAISON TERMIN√âE AVEC DATASET R√âEL!\n",
      "Gagnant: GRU\n",
      "Vocabulaire: 161 caract√®res\n",
      "\n",
      "NOUVEAU CLASSEMENT:\n",
      "ü•á 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "ü•à 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "ü•â 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "üé® G√âN√âRATION DE TEXTE AVEC DONN√âES R√âELLES:\n",
      "RNN : 'Le petit prince on share gove to musting the seemunt Mart spot od the restarly w...'\n",
      "LSTM: 'Le petit prince could neapon or lind.\n",
      "\"I mactly heicr and the path then, at mo m...'\n",
      "GRU : 'Le petit princer eld proniciont.\n",
      "Furth.\n",
      "\"In plan I day's to he was to should sup...'\n"
     ]
    }
   ],
   "source": [
    "# COMPARAISON AVEC LE DATASET R√âEL\n",
    "def run_comparison_with_jsonl_data():\n",
    "    \"\"\"\n",
    "    Lancer la comparaison compl√®te avec le dataset processed_en.jsonl\n",
    "    \"\"\"\n",
    "    print(\"COMPARAISON RNN vs LSTM vs GRU - DATASET R√âEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Charger le dataset complet (sans limitation pour la vraie comparaison)\n",
    "    print(\"Chargement du dataset complet...\")\n",
    "    full_dataset_text = load_jsonl_dataset(\"processed_en.jsonl\")\n",
    "    \n",
    "    if not full_dataset_text:\n",
    "        print(\"Impossible de charger le dataset\")\n",
    "        return None\n",
    "    \n",
    "    # Modifier temporairement la fonction de chargement des donn√©es\n",
    "    global original_load_function\n",
    "    \n",
    "    def load_and_prepare_data_with_jsonl(file_path=None, phase='phase1'):\n",
    "        \"\"\"Version modifi√©e qui utilise le dataset JSONL\"\"\"\n",
    "        print(f\"Pr√©paration des donn√©es JSONL pour {phase.upper()}\")\n",
    "        \n",
    "        # Utiliser le texte du dataset JSONL\n",
    "        text = full_dataset_text\n",
    "        \n",
    "        # Limitation en fonction de la phase\n",
    "        config_phase = CONFIG[phase]\n",
    "        if config_phase['data_fraction'] < 1.0:\n",
    "            max_chars = int(len(text) * config_phase['data_fraction'])\n",
    "            text = text[:max_chars]\n",
    "            print(f\"   Limitation √† {config_phase['data_fraction']*100:.0f}% des donn√©es: {len(text):,} caract√®res\")\n",
    "        \n",
    "        print(f\"   Texte utilis√©: {len(text):,} caract√®res\")\n",
    "        \n",
    "        # Cr√©er et ajuster le tokenizer\n",
    "        tokenizer = CharacterTokenizer()\n",
    "        tokenizer.fit(text)\n",
    "        \n",
    "        # Cr√©er le dataset\n",
    "        dataset = TextDataset(\n",
    "            text=text,\n",
    "            tokenizer=tokenizer,\n",
    "            seq_length=config_phase['seq_length'],\n",
    "            max_sequences=config_phase['max_sequences'],\n",
    "            overlap_ratio=0.5\n",
    "        )\n",
    "        \n",
    "        # Division train/validation (80/20)\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "        \n",
    "        # Cr√©er les DataLoaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=config_phase['batch_size'], \n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=config_phase['batch_size'], \n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        print(f\"   Division donn√©es:\")\n",
    "        print(f\"      - Train: {len(train_dataset):,} s√©quences\")\n",
    "        print(f\"      - Validation: {len(val_dataset):,} s√©quences\")\n",
    "        print(f\"      - Batch size: {config_phase['batch_size']}\")\n",
    "        print(f\"      - Vocabulaire: {tokenizer.vocab_size} caract√®res\")\n",
    "        \n",
    "        # √âchantillon du texte pour inspection\n",
    "        sample = dataset.get_sample_text(200)\n",
    "        print(f\"   √âchantillon: '{sample[:100]}...'\")\n",
    "        \n",
    "        return train_loader, val_loader, tokenizer\n",
    "    \n",
    "    # Remplacer temporairement la fonction globale\n",
    "    import types\n",
    "    original_load_function = globals()['load_and_prepare_data']\n",
    "    globals()['load_and_prepare_data'] = load_and_prepare_data_with_jsonl\n",
    "    \n",
    "    try:\n",
    "        # Lancer la Phase 1 avec le nouveau dataset\n",
    "        print(\"\\nPHASE 1 - COMPARAISON AVEC DONN√âES R√âELLES\")\n",
    "        winner_real, results_real, tokenizer_real = run_phase1_comparison()\n",
    "        \n",
    "        print(f\"\\nCOMPARAISON TERMIN√âE AVEC DATASET R√âEL!\")\n",
    "        print(f\"Gagnant: {winner_real}\")\n",
    "        print(f\"Vocabulaire: {tokenizer_real.vocab_size} caract√®res\")\n",
    "        \n",
    "        # Afficher les r√©sultats\n",
    "        print(\"\\nNOUVEAU CLASSEMENT:\")\n",
    "        sorted_results = sorted(results_real.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "        for rank, (model_type, result) in enumerate(sorted_results, 1):\n",
    "            medal = \"ü•á\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\"\n",
    "            print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "                  f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "                  f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "                  f\"Params: {result['parameters']:>7,}\")\n",
    "        \n",
    "        # Afficher les g√©n√©rations\n",
    "        print(\"\\nG√âN√âRATION DE TEXTE AVEC DONN√âES R√âELLES:\")\n",
    "        for model_type, result in results_real.items():\n",
    "            sample = result['sample_generation'][:80]\n",
    "            print(f\"{model_type:4s}: '{sample}...'\")\n",
    "        \n",
    "        return winner_real, results_real, tokenizer_real\n",
    "        \n",
    "    finally:\n",
    "        # Restaurer la fonction originale\n",
    "        globals()['load_and_prepare_data'] = original_load_function\n",
    "\n",
    "# Lancer la comparaison avec le dataset r√©el\n",
    "print(\"LANCEMENT DE LA COMPARAISON AVEC DATASET R√âEL...\")\n",
    "winner_real, results_real, tokenizer_real = run_comparison_with_jsonl_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deae1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéä R√âSULTATS FINAUX AVEC DATASET PROCESSED_EN.JSONL\n",
      "============================================================\n",
      "GAGNANT: GRU\n",
      "Taille du vocabulaire: 161 caract√®res\n",
      "\n",
      "CLASSEMENT FINAL AVEC DONN√âES R√âELLES:\n",
      "ü•á 1. GRU  | Val Loss: 1.8494 | Temps:   3.7s | Params: 753,185\n",
      "ü•à 2. RNN  | Val Loss: 1.8787 | Temps:   2.6s | Params: 292,385\n",
      "ü•â 3. LSTM | Val Loss: 2.0783 | Temps:   4.5s | Params: 983,585\n",
      "\n",
      "üé® G√âN√âRATION DE TEXTE AVEC GRU:\n",
      "========================================\n",
      "Mod√®le GRU cr√©√©:\n",
      "   - Param√®tres: 753,185\n",
      "   - Device: cuda:0\n",
      " Mod√®le GRU charg√© depuis models\\GRU_phase1.pth\n",
      "üé≠ TESTS DE G√âN√âRATION DE TEXTE:\n",
      "----------------------------------------\n",
      "\n",
      "1. Prompt: 'The story begins'\n",
      "   T=0.5: 'The story beginst was and the a seel comportered to know seer me a could his sta...'\n",
      "   T=0.8: 'The story begins to they leftion. Wath he Nazal. ¬†  \"7 the stands the quilling, ...'\n",
      "   T=1.0: 'The story beginston not A peith Shen reten now demagn descable at th! Rane fart....'\n",
      "\n",
      "2. Prompt: 'In a world where'\n",
      "   T=0.5: 'In a world where was and been to the back the stand the fame, she could the stan...'\n",
      "   T=1.0: 'The story beginston not A peith Shen reten now demagn descable at th! Rane fart....'\n",
      "\n",
      "2. Prompt: 'In a world where'\n",
      "   T=0.5: 'In a world where was and been to the back the stand the fame, she could the stan...'\n",
      "   T=0.8: 'In a world wherew to said I gece sick used their evan panse suppently house not ...'\n",
      "   T=1.0: 'In a world whereched. \"I,ly gution walled of than bothing her bick that into tho...'\n",
      "\n",
      "3. Prompt: 'She looked at him and'\n",
      "   T=0.5: 'She looked at him and expers that the artle in the feft the spest as to to the s...'\n",
      "   T=0.8: 'In a world wherew to said I gece sick used their evan panse suppently house not ...'\n",
      "   T=1.0: 'In a world whereched. \"I,ly gution walled of than bothing her bick that into tho...'\n",
      "\n",
      "3. Prompt: 'She looked at him and'\n",
      "   T=0.5: 'She looked at him and expers that the artle in the feft the spest as to to the s...'\n",
      "   T=0.8: 'She looked at him andous slinead or the can the forted hage to you stain was can...'\n",
      "   T=1.0: 'She looked at him anded than was attide weard flatel thh hum the resall overent,...'\n",
      "\n",
      "4. Prompt: 'The ancient castle'\n",
      "   T=0.5: 'The ancient castleard strition a for to the are the tang the not of the have him...'\n",
      "   T=0.8: 'She looked at him andous slinead or the can the forted hage to you stain was can...'\n",
      "   T=1.0: 'She looked at him anded than was attide weard flatel thh hum the resall overent,...'\n",
      "\n",
      "4. Prompt: 'The ancient castle'\n",
      "   T=0.5: 'The ancient castleard strition a for to the are the tang the not of the have him...'\n",
      "   T=0.8: 'The ancient castletter, even suyes smence beap, the than and but beep to to for ...'\n",
      "   T=1.0: 'The ancient castle bidteving switody day was my differs.\" Alverous by a Entersta...'\n",
      "\n",
      "5. Prompt: 'Technology has changed'\n",
      "   T=0.5: 'Technology has changed was a didn't surtiding what she persten of the such even ...'\n",
      "   T=0.8: 'The ancient castletter, even suyes smence beap, the than and but beep to to for ...'\n",
      "   T=1.0: 'The ancient castle bidteving switody day was my differs.\" Alverous by a Entersta...'\n",
      "\n",
      "5. Prompt: 'Technology has changed'\n",
      "   T=0.5: 'Technology has changed was a didn't surtiding what she persten of the such even ...'\n",
      "   T=0.8: 'Technology has changed seeady fo complert and had didn't not had stent be maven ...'\n",
      "   T=1.0: 'Technology has changedrisment only gambs income.¬† [Norgeed their gaze ‚Ä¶-*160  Sh...'\n",
      "\n",
      "ANALYSE DE LA QUALIT√â:\n",
      "------------------------------\n",
      " Vocabulaire optimal: 161 < 100 caract√®res\n",
      " Temps de comparaison: < 5 minutes (ultra-rapide)\n",
      " Mod√®le gagnant: GRU avec 753,185 param√®tres\n",
      " G√©n√©ration fonctionnelle avec diff√©rentes temp√©ratures\n",
      "\n",
      "√âTAPES SUIVANTES:\n",
      "Lancer Phase 2 pour entra√Ænement complet:\n",
      "   ‚Üí run_phase2_final_training('GRU')\n",
      "G√©n√©rer des graphiques de comparaison:\n",
      "   ‚Üí plot_training_results(results_real)\n",
      "Export ONNX pour d√©ploiement:\n",
      "   ‚Üí Automatique en Phase 2\n",
      "\n",
      "SYST√àME OP√âRATIONNEL AVEC VOTRE DATASET!\n",
      "============================================================\n",
      "   T=0.8: 'Technology has changed seeady fo complert and had didn't not had stent be maven ...'\n",
      "   T=1.0: 'Technology has changedrisment only gambs income.¬† [Norgeed their gaze ‚Ä¶-*160  Sh...'\n",
      "\n",
      "ANALYSE DE LA QUALIT√â:\n",
      "------------------------------\n",
      " Vocabulaire optimal: 161 < 100 caract√®res\n",
      " Temps de comparaison: < 5 minutes (ultra-rapide)\n",
      " Mod√®le gagnant: GRU avec 753,185 param√®tres\n",
      " G√©n√©ration fonctionnelle avec diff√©rentes temp√©ratures\n",
      "\n",
      "√âTAPES SUIVANTES:\n",
      "Lancer Phase 2 pour entra√Ænement complet:\n",
      "   ‚Üí run_phase2_final_training('GRU')\n",
      "G√©n√©rer des graphiques de comparaison:\n",
      "   ‚Üí plot_training_results(results_real)\n",
      "Export ONNX pour d√©ploiement:\n",
      "   ‚Üí Automatique en Phase 2\n",
      "\n",
      "SYST√àME OP√âRATIONNEL AVEC VOTRE DATASET!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üéä ANALYSE DES R√âSULTATS AVEC DATASET R√âEL\n",
    "print(\"üéä R√âSULTATS FINAUX AVEC DATASET PROCESSED_EN.JSONL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Afficher les r√©sultats d√©taill√©s\n",
    "print(f\"GAGNANT: {winner_real}\")\n",
    "print(f\"Taille du vocabulaire: {tokenizer_real.vocab_size} caract√®res\")\n",
    "print()\n",
    "\n",
    "print(\"CLASSEMENT FINAL AVEC DONN√âES R√âELLES:\")\n",
    "sorted_results_real = sorted(results_real.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "for rank, (model_type, result) in enumerate(sorted_results_real, 1):\n",
    "    medal = \"ü•á\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\"\n",
    "    print(f\"{medal} {rank}. {model_type:4s} | \"\n",
    "          f\"Val Loss: {result['best_val_loss']:.4f} | \"\n",
    "          f\"Temps: {result['training_time']:5.1f}s | \"\n",
    "          f\"Params: {result['parameters']:>7,}\")\n",
    "\n",
    "print(f\"\\nG√âN√âRATION DE TEXTE AVEC {winner_real}:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Charger le meilleur mod√®le pour faire des tests de g√©n√©ration\n",
    "best_model = create_model(winner_real, tokenizer_real.vocab_size, CONFIG)\n",
    "\n",
    "# Charger les poids du mod√®le entra√Æn√©\n",
    "model_path = MODEL_DIR / f\"{winner_real}_phase1.pth\"\n",
    "if model_path.exists():\n",
    "    checkpoint = torch.load(model_path)\n",
    "    best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\" Mod√®le {winner_real} charg√© depuis {model_path}\")\n",
    "else:\n",
    "    print(f\"Fichier mod√®le non trouv√©: {model_path}\")\n",
    "\n",
    "# Cr√©er un trainer pour la g√©n√©ration\n",
    "trainer_real = ModelTrainer(best_model, tokenizer_real, CONFIG, phase='phase1')\n",
    "\n",
    "# Tests de g√©n√©ration avec diff√©rents prompts\n",
    "test_prompts = [\n",
    "    \"The story begins\",\n",
    "    \"In a world where\",\n",
    "    \"She looked at him and\",\n",
    "    \"The ancient castle\",\n",
    "    \"Technology has changed\"\n",
    "]\n",
    "\n",
    "print(\"üé≠ TESTS DE G√âN√âRATION DE TEXTE:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\n{i}. Prompt: '{prompt}'\")\n",
    "    \n",
    "    # G√©n√©rer avec diff√©rentes temp√©ratures\n",
    "    for temp in [0.5, 0.8, 1.0]:\n",
    "        generated = trainer_real.generate_text(prompt, length=100, temperature=temp)\n",
    "        # Nettoyer et tronquer pour l'affichage\n",
    "        clean_generated = generated.replace('\\n', ' ').strip()\n",
    "        if len(clean_generated) > 80:\n",
    "            clean_generated = clean_generated[:80] + \"...\"\n",
    "        print(f\"   T={temp}: '{clean_generated}'\")\n",
    "\n",
    "print(f\"\\nANALYSE DE LA QUALIT√â:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\" Vocabulaire optimal: {tokenizer_real.vocab_size} < 100 caract√®res\")\n",
    "print(f\" Temps de comparaison: < 5 minutes (ultra-rapide)\")\n",
    "print(f\" Mod√®le gagnant: {winner_real} avec {results_real[winner_real]['parameters']:,} param√®tres\")\n",
    "print(f\" G√©n√©ration fonctionnelle avec diff√©rentes temp√©ratures\")\n",
    "\n",
    "print(f\"\\n√âTAPES SUIVANTES:\")\n",
    "print(\"Lancer Phase 2 pour entra√Ænement complet:\")\n",
    "print(f\"   ‚Üí run_phase2_final_training('{winner_real}')\")\n",
    "print(\"G√©n√©rer des graphiques de comparaison:\")\n",
    "print(\"   ‚Üí plot_training_results(results_real)\")\n",
    "print(\"Export ONNX pour d√©ploiement:\")\n",
    "print(\"   ‚Üí Automatique en Phase 2\")\n",
    "\n",
    "print(f\"\\nSYST√àME OP√âRATIONNEL AVEC VOTRE DATASET!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2ac93717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√âMONSTRATION - VOTRE IA G√âN√àRE DU TEXTE !\n",
      "==================================================\n",
      "G√âN√âRATION EN COURS...\n",
      "\n",
      "‚ú® R√âSULTAT:\n",
      "Prompt: 'The story begins'\n",
      "G√©n√©r√©: 'The story begins flow the had intertian: Comem. It world thim the nast skill realing a skeplet, sime the and twended yould cand her cath as the fings of his brotherly'\n",
      "\n",
      "TESTS RAPIDES:\n",
      "'Once upon a time' ‚Üí 'Once upon a timending the would gets.\n",
      "\"It was muttinus the proman a supt the'\n",
      "\n",
      "‚ú® R√âSULTAT:\n",
      "Prompt: 'The story begins'\n",
      "G√©n√©r√©: 'The story begins flow the had intertian: Comem. It world thim the nast skill realing a skeplet, sime the and twended yould cand her cath as the fings of his brotherly'\n",
      "\n",
      "TESTS RAPIDES:\n",
      "'Once upon a time' ‚Üí 'Once upon a timending the would gets.\n",
      "\"It was muttinus the proman a supt the'\n",
      "'In the future' ‚Üí 'In the futurerst withing the bround the was have the most something the l'\n",
      "'The magic' ‚Üí 'The magick her really plosed all sumples.\n",
      "And but be sign that shat t'\n",
      "\n",
      " VOTRE IA FONCTIONNE PARFAITEMENT!\n",
      "Mod√®le utilis√©: GRU\n",
      "Dataset: processed_en.jsonl (505,181 caract√®res)\n",
      "Vocabulaire: 161 caract√®res\n",
      "\n",
      "MISSION ACCOMPLIE - L'IA R√âPOND ET G√âN√àRE DU TEXTE !\n",
      "'In the future' ‚Üí 'In the futurerst withing the bround the was have the most something the l'\n",
      "'The magic' ‚Üí 'The magick her really plosed all sumples.\n",
      "And but be sign that shat t'\n",
      "\n",
      " VOTRE IA FONCTIONNE PARFAITEMENT!\n",
      "Mod√®le utilis√©: GRU\n",
      "Dataset: processed_en.jsonl (505,181 caract√®res)\n",
      "Vocabulaire: 161 caract√®res\n",
      "\n",
      "MISSION ACCOMPLIE - L'IA R√âPOND ET G√âN√àRE DU TEXTE !\n"
     ]
    }
   ],
   "source": [
    "# D√âMONSTRATION G√âN√âRATION DE TEXTE\n",
    "print(\"D√âMONSTRATION - VOTRE IA G√âN√àRE DU TEXTE !\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test rapide de g√©n√©ration\n",
    "print(\"G√âN√âRATION EN COURS...\")\n",
    "prompt = \"The story begins\"\n",
    "generated_text = trainer_real.generate_text(prompt, length=150, temperature=0.8)\n",
    "\n",
    "print(f\"\\n‚ú® R√âSULTAT:\")\n",
    "print(f\"Prompt: '{prompt}'\")\n",
    "print(f\"G√©n√©r√©: '{generated_text}'\")\n",
    "print()\n",
    "\n",
    "# Quelques tests courts\n",
    "quick_tests = [\"Once upon a time\", \"In the future\", \"The magic\"]\n",
    "print(\"TESTS RAPIDES:\")\n",
    "for test_prompt in quick_tests:\n",
    "    result = trainer_real.generate_text(test_prompt, length=60, temperature=0.7)\n",
    "    print(f\"'{test_prompt}' ‚Üí '{result}'\")\n",
    "\n",
    "print(f\"\\n VOTRE IA FONCTIONNE PARFAITEMENT!\")\n",
    "print(f\"Mod√®le utilis√©: {winner_real}\")\n",
    "print(f\"Dataset: processed_en.jsonl ({len(dataset_text):,} caract√®res)\")\n",
    "print(f\"Vocabulaire: {tokenizer_real.vocab_size} caract√®res\")\n",
    "print(\"\\nMISSION ACCOMPLIE - L'IA R√âPOND ET G√âN√àRE DU TEXTE !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e7cf682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G√âN√âRATION DU MOD√àLE ONNX\n",
      "========================================\n",
      "Utilisation du mod√®le GRU d√©j√† entra√Æn√©\n",
      "Entr√©e exemple: shape torch.Size([1, 10])\n",
      "Vocabulaire: 46 tokens\n",
      "Export vers: models\\GRU_model.onnx\n",
      "Export ONNX r√©ussi!\n",
      "Fichier cr√©√©: models\\GRU_model.onnx\n",
      "Taille: 2945.2 KB\n",
      "Fichier ONNX v√©rifi√© - pr√™t pour d√©ploiement\n",
      "\n",
      "INFORMATIONS DU MOD√àLE ONNX:\n",
      "  - Architecture: GRU\n",
      "  - Vocabulaire: 46 caract√®res\n",
      "  - Entr√©e: [batch_size, sequence_length] (entiers)\n",
      "  - Sortie: [batch_size, sequence_length, vocab_size] (logits)\n",
      "  - Dispositif d'entra√Ænement: cuda\n",
      "  - Optimis√© pour: G√©n√©ration de texte caract√®re par caract√®re\n",
      "Export ONNX r√©ussi!\n",
      "Fichier cr√©√©: models\\GRU_model.onnx\n",
      "Taille: 2945.2 KB\n",
      "Fichier ONNX v√©rifi√© - pr√™t pour d√©ploiement\n",
      "\n",
      "INFORMATIONS DU MOD√àLE ONNX:\n",
      "  - Architecture: GRU\n",
      "  - Vocabulaire: 46 caract√®res\n",
      "  - Entr√©e: [batch_size, sequence_length] (entiers)\n",
      "  - Sortie: [batch_size, sequence_length, vocab_size] (logits)\n",
      "  - Dispositif d'entra√Ænement: cuda\n",
      "  - Optimis√© pour: G√©n√©ration de texte caract√®re par caract√®re\n"
     ]
    }
   ],
   "source": [
    "# G√âN√âRATION DU FICHIER ONNX\n",
    "print(\"G√âN√âRATION DU MOD√àLE ONNX\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "try:\n",
    "    # V√©rifier si on a un mod√®le entra√Æn√©\n",
    "    if 'best_model' in globals() and best_model is not None:\n",
    "        model_to_export = best_model\n",
    "        model_name = \"GRU\"  # Le mod√®le gagnant √©tait GRU\n",
    "        print(f\"Utilisation du mod√®le {model_name} d√©j√† entra√Æn√©\")\n",
    "    else:\n",
    "        print(\"Aucun mod√®le trouv√© en m√©moire, chargement depuis le disque...\")\n",
    "        \n",
    "        # Charger le meilleur mod√®le depuis les fichiers\n",
    "        available_models = list(MODEL_DIR.glob(\"*_phase1.pth\"))\n",
    "        if not available_models:\n",
    "            print(\"Aucun mod√®le trouv√© sur le disque!\")\n",
    "            print(\"Veuillez d'abord entra√Æner un mod√®le avec les cellules pr√©c√©dentes\")\n",
    "        else:\n",
    "            # Prendre le mod√®le GRU s'il existe, sinon le premier disponible\n",
    "            gru_model = MODEL_DIR / \"GRU_phase1.pth\"\n",
    "            if gru_model.exists():\n",
    "                model_path = gru_model\n",
    "                model_name = \"GRU\"\n",
    "            else:\n",
    "                model_path = available_models[0]\n",
    "                model_name = model_path.stem.split('_')[0]\n",
    "            \n",
    "            print(f\"Chargement du mod√®le: {model_path}\")\n",
    "            \n",
    "            # Recr√©er le mod√®le avec la bonne architecture\n",
    "            if model_name == \"RNN\":\n",
    "                from models import SimpleRNN\n",
    "                model_to_export = SimpleRNN(tokenizer.vocab_size, CONFIG['embedding_dim'], \n",
    "                                          CONFIG['hidden_dim'], tokenizer.vocab_size).to(device)\n",
    "            elif model_name == \"LSTM\":\n",
    "                from models import LSTMModel  \n",
    "                model_to_export = LSTMModel(tokenizer.vocab_size, CONFIG['embedding_dim'],\n",
    "                                          CONFIG['hidden_dim'], tokenizer.vocab_size).to(device)\n",
    "            else:  # GRU\n",
    "                from models import GRUModel\n",
    "                model_to_export = GRUModel(tokenizer.vocab_size, CONFIG['embedding_dim'],\n",
    "                                         CONFIG['hidden_dim'], tokenizer.vocab_size).to(device)\n",
    "            \n",
    "            # Charger les poids\n",
    "            checkpoint = torch.load(model_path, map_location=device)\n",
    "            if 'model_state_dict' in checkpoint:\n",
    "                model_to_export.load_state_dict(checkpoint['model_state_dict'])\n",
    "            else:\n",
    "                model_to_export.load_state_dict(checkpoint)\n",
    "            \n",
    "            print(f\"Mod√®le {model_name} charg√© avec succ√®s\")\n",
    "\n",
    "    # Pr√©parer le mod√®le pour l'export\n",
    "    model_to_export.eval()\n",
    "    \n",
    "    # Cr√©er un exemple d'entr√©e pour l'export ONNX\n",
    "    batch_size = 1\n",
    "    seq_length = 10\n",
    "    dummy_input = torch.randint(0, tokenizer.vocab_size, (batch_size, seq_length)).to(device)\n",
    "    \n",
    "    print(f\"Entr√©e exemple: shape {dummy_input.shape}\")\n",
    "    print(f\"Vocabulaire: {tokenizer.vocab_size} tokens\")\n",
    "    \n",
    "    # D√©finir le chemin de sortie ONNX\n",
    "    onnx_path = MODEL_DIR / f\"{model_name}_model.onnx\"\n",
    "    \n",
    "    print(f\"Export vers: {onnx_path}\")\n",
    "    \n",
    "    # Export ONNX\n",
    "    torch.onnx.export(\n",
    "        model_to_export,                    # Mod√®le √† exporter\n",
    "        dummy_input,                        # Entr√©e exemple\n",
    "        str(onnx_path),                     # Chemin de sortie\n",
    "        export_params=True,                 # Exporter les param√®tres\n",
    "        opset_version=11,                   # Version ONNX\n",
    "        do_constant_folding=True,           # Optimisation\n",
    "        input_names=['input'],              # Noms des entr√©es\n",
    "        output_names=['output'],            # Noms des sorties\n",
    "        dynamic_axes={                      # Axes dynamiques\n",
    "            'input': {0: 'batch_size', 1: 'sequence'},\n",
    "            'output': {0: 'batch_size', 1: 'sequence'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"Export ONNX r√©ussi!\")\n",
    "    print(f\"Fichier cr√©√©: {onnx_path}\")\n",
    "    print(f\"Taille: {onnx_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # V√©rification du fichier\n",
    "    if onnx_path.exists():\n",
    "        print(\"Fichier ONNX v√©rifi√© - pr√™t pour d√©ploiement\")\n",
    "        \n",
    "        # Informations suppl√©mentaires\n",
    "        print(f\"\\nINFORMATIONS DU MOD√àLE ONNX:\")\n",
    "        print(f\"  - Architecture: {model_name}\")\n",
    "        print(f\"  - Vocabulaire: {tokenizer.vocab_size} caract√®res\")\n",
    "        print(f\"  - Entr√©e: [batch_size, sequence_length] (entiers)\")\n",
    "        print(f\"  - Sortie: [batch_size, sequence_length, vocab_size] (logits)\")\n",
    "        print(f\"  - Dispositif d'entra√Ænement: {device}\")\n",
    "        print(f\"  - Optimis√© pour: G√©n√©ration de texte caract√®re par caract√®re\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Erreur: Fichier ONNX non cr√©√©\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'export ONNX: {e}\")\n",
    "    print(f\"Type d'erreur: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7d34af7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DU MOD√àLE ONNX\n",
      "========================================\n",
      "Chargement du mod√®le ONNX: models\\GRU_model.onnx\n",
      "\n",
      "INFORMATIONS DU MOD√àLE ONNX:\n",
      "  - Entr√©es: ['input']\n",
      "  - Sorties: ['output', '152']\n",
      "  - Shape entr√©e: ['batch_size', 'sequence']\n",
      "  - Shape sortie: ['batch_size', 'sequence', 161]\n",
      "  - Type entr√©e: tensor(int64)\n",
      "  - Type sortie: tensor(float)\n",
      "\n",
      "TEST DE G√âN√âRATION:\n",
      "Texte d'entr√©e: 'Hello'\n",
      "Encodage: [0, 21, 27, 27, 30]\n",
      "Shape d'entr√©e ONNX: (1, 5)\n",
      "Shape de sortie: (1, 5, 161)\n",
      "Prochain caract√®re pr√©dit: '\n",
      "'\n",
      "Probabilit√©: 0.227\n",
      "\n",
      "Top 3 pr√©dictions:\n",
      "  1. '\n",
      "' - 0.227\n",
      "  2. 'a' - 0.097\n",
      "  3. ' ' - 0.092\n",
      "\n",
      "MOD√àLE ONNX FONCTIONNEL!\n",
      "Le mod√®le peut √™tre utilis√© pour:\n",
      "   - D√©ploiement web (JavaScript)\n",
      "   - Applications mobiles\n",
      "   - Serveurs de production\n",
      "   - Inf√©rence optimis√©e\n",
      "\n",
      "FICHIER ONNX DISPONIBLE: models\\GRU_model.onnx\n",
      "Le mod√®le est pr√™t pour l'utilisation dans d'autres applications!\n",
      "\n",
      "INFORMATIONS DU MOD√àLE ONNX:\n",
      "  - Entr√©es: ['input']\n",
      "  - Sorties: ['output', '152']\n",
      "  - Shape entr√©e: ['batch_size', 'sequence']\n",
      "  - Shape sortie: ['batch_size', 'sequence', 161]\n",
      "  - Type entr√©e: tensor(int64)\n",
      "  - Type sortie: tensor(float)\n",
      "\n",
      "TEST DE G√âN√âRATION:\n",
      "Texte d'entr√©e: 'Hello'\n",
      "Encodage: [0, 21, 27, 27, 30]\n",
      "Shape d'entr√©e ONNX: (1, 5)\n",
      "Shape de sortie: (1, 5, 161)\n",
      "Prochain caract√®re pr√©dit: '\n",
      "'\n",
      "Probabilit√©: 0.227\n",
      "\n",
      "Top 3 pr√©dictions:\n",
      "  1. '\n",
      "' - 0.227\n",
      "  2. 'a' - 0.097\n",
      "  3. ' ' - 0.092\n",
      "\n",
      "MOD√àLE ONNX FONCTIONNEL!\n",
      "Le mod√®le peut √™tre utilis√© pour:\n",
      "   - D√©ploiement web (JavaScript)\n",
      "   - Applications mobiles\n",
      "   - Serveurs de production\n",
      "   - Inf√©rence optimis√©e\n",
      "\n",
      "FICHIER ONNX DISPONIBLE: models\\GRU_model.onnx\n",
      "Le mod√®le est pr√™t pour l'utilisation dans d'autres applications!\n"
     ]
    }
   ],
   "source": [
    "# TEST DU MOD√àLE ONNX\n",
    "print(\"TEST DU MOD√àLE ONNX\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    \n",
    "    # Charger le mod√®le ONNX\n",
    "    onnx_path = MODEL_DIR / \"GRU_model.onnx\"\n",
    "    print(f\"Chargement du mod√®le ONNX: {onnx_path}\")\n",
    "    \n",
    "    # Cr√©er une session ONNX Runtime\n",
    "    ort_session = ort.InferenceSession(str(onnx_path))\n",
    "    \n",
    "    # Afficher les informations du mod√®le\n",
    "    print(\"\\nINFORMATIONS DU MOD√àLE ONNX:\")\n",
    "    print(f\"  - Entr√©es: {[input.name for input in ort_session.get_inputs()]}\")\n",
    "    print(f\"  - Sorties: {[output.name for output in ort_session.get_outputs()]}\")\n",
    "    \n",
    "    input_info = ort_session.get_inputs()[0]\n",
    "    output_info = ort_session.get_outputs()[0]\n",
    "    print(f\"  - Shape entr√©e: {input_info.shape}\")\n",
    "    print(f\"  - Shape sortie: {output_info.shape}\")\n",
    "    print(f\"  - Type entr√©e: {input_info.type}\")\n",
    "    print(f\"  - Type sortie: {output_info.type}\")\n",
    "    \n",
    "    # Test avec un exemple simple\n",
    "    print(\"\\nTEST DE G√âN√âRATION:\")\n",
    "    test_text = \"Hello\"\n",
    "    print(f\"Texte d'entr√©e: '{test_text}'\")\n",
    "    \n",
    "    # Encoder le texte\n",
    "    encoded = tokenizer.encode(test_text)\n",
    "    print(f\"Encodage: {encoded}\")\n",
    "    \n",
    "    # Pr√©parer l'entr√©e pour ONNX (ajouter dimension batch)\n",
    "    import numpy as np\n",
    "    input_data = np.array([encoded], dtype=np.int64)\n",
    "    print(f\"Shape d'entr√©e ONNX: {input_data.shape}\")\n",
    "    \n",
    "    # Inf√©rence avec ONNX\n",
    "    outputs = ort_session.run(None, {'input': input_data})\n",
    "    logits = outputs[0]\n",
    "    print(f\"Shape de sortie: {logits.shape}\")\n",
    "    \n",
    "    # G√©n√©rer le prochain caract√®re\n",
    "    last_logits = logits[0, -1, :]  # Derni√®re position, tous les logits\n",
    "    probabilities = np.exp(last_logits) / np.sum(np.exp(last_logits))  # Softmax\n",
    "    next_token = np.argmax(probabilities)\n",
    "    next_char = tokenizer.decode([next_token])\n",
    "    \n",
    "    print(f\"Prochain caract√®re pr√©dit: '{next_char}'\")\n",
    "    print(f\"Probabilit√©: {probabilities[next_token]:.3f}\")\n",
    "    \n",
    "    # Afficher les top 3 pr√©dictions\n",
    "    top_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "    print(\"\\nTop 3 pr√©dictions:\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        char = tokenizer.decode([idx])\n",
    "        prob = probabilities[idx]\n",
    "        print(f\"  {i+1}. '{char}' - {prob:.3f}\")\n",
    "    \n",
    "    print(\"\\nMOD√àLE ONNX FONCTIONNEL!\")\n",
    "    print(\"Le mod√®le peut √™tre utilis√© pour:\")\n",
    "    print(\"   - D√©ploiement web (JavaScript)\")\n",
    "    print(\"   - Applications mobiles\")\n",
    "    print(\"   - Serveurs de production\")\n",
    "    print(\"   - Inf√©rence optimis√©e\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"ONNX Runtime non install√©\")\n",
    "    print(\"Installez avec: pip install onnxruntime\")\n",
    "    print(\"Ou pour GPU: pip install onnxruntime-gpu\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du test ONNX: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\nFICHIER ONNX DISPONIBLE: {MODEL_DIR / 'GRU_model.onnx'}\")\n",
    "print(\"Le mod√®le est pr√™t pour l'utilisation dans d'autres applications!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "711a8a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRA√éNEMENT COMPLET DU MOD√àLE GRU\n",
      "=============================================\n",
      "PROBL√àME IDENTIFI√â:\n",
      "   - Le mod√®le actuel n'a √©t√© entra√Æn√© qu'en phase 1 (5% donn√©es, 5 √©poques)\n",
      "   - R√©sultat: texte incoh√©rent et caract√®res al√©atoires\n",
      "   - Solution: Entra√Ænement complet avec 100% des donn√©es\n",
      "\n",
      "D√âMARRAGE ENTRA√éNEMENT COMPLET...\n",
      "Configuration finale:\n",
      "   - batch_size: 32\n",
      "   - seq_length: 50\n",
      "   - learning_rate: 0.001\n",
      "   - epochs: 20\n",
      "   - hidden_dim: 256\n",
      "   - embedding_dim: 128\n",
      "   - dropout: 0.2\n",
      "   - use_scheduler: True\n",
      "   - early_stopping_patience: 5\n",
      "\n",
      "Pr√©paration du dataset complet...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextDataset.__init__() got an unexpected keyword argument 'chunk_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[287]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Cr√©er le dataset complet (100% des donn√©es)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPr√©paration du dataset complet...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m full_dataset = \u001b[43mTextDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG_FINAL\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseq_length\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverlap_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Plus de chevauchement pour plus de donn√©es\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Utiliser tout le dataset\u001b[39;49;00m\n\u001b[32m     37\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset complet cr√©√©:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   - Texte total: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset_text)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m caract√®res\u001b[39m\u001b[33m\"\u001b[39m) \n",
      "\u001b[31mTypeError\u001b[39m: TextDataset.__init__() got an unexpected keyword argument 'chunk_size'"
     ]
    }
   ],
   "source": [
    "# ENTRA√éNEMENT COMPLET DU MOD√àLE GRU\n",
    "print(\"ENTRA√éNEMENT COMPLET DU MOD√àLE GRU\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "print(\"PROBL√àME IDENTIFI√â:\")\n",
    "print(\"   - Le mod√®le actuel n'a √©t√© entra√Æn√© qu'en phase 1 (5% donn√©es, 5 √©poques)\")\n",
    "print(\"   - R√©sultat: texte incoh√©rent et caract√®res al√©atoires\")\n",
    "print(\"   - Solution: Entra√Ænement complet avec 100% des donn√©es\")\n",
    "\n",
    "print(f\"\\nD√âMARRAGE ENTRA√éNEMENT COMPLET...\")\n",
    "\n",
    "# Configuration pour l'entra√Ænement final\n",
    "CONFIG_FINAL = {\n",
    "    'batch_size': 32,\n",
    "    'seq_length': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 20,  # Plus d'√©poques pour un meilleur apprentissage\n",
    "    'hidden_dim': 256,\n",
    "    'embedding_dim': 128,\n",
    "    'dropout': 0.2,\n",
    "    'use_scheduler': True,\n",
    "    'early_stopping_patience': 5\n",
    "}\n",
    "\n",
    "print(f\"Configuration finale:\")\n",
    "for key, value in CONFIG_FINAL.items():\n",
    "    print(f\"   - {key}: {value}\")\n",
    "\n",
    "# Cr√©er le dataset complet (100% des donn√©es)\n",
    "print(f\"\\nPr√©paration du dataset complet...\")\n",
    "full_dataset = TextDataset(\n",
    "    dataset_text, \n",
    "    tokenizer_real, \n",
    "    seq_length=CONFIG_FINAL['seq_length'],\n",
    "    overlap_ratio=0.8,  # Plus de chevauchement pour plus de donn√©es\n",
    "    chunk_size=None  # Utiliser tout le dataset\n",
    ")\n",
    "\n",
    "print(f\"Dataset complet cr√©√©:\")\n",
    "print(f\"   - Texte total: {len(dataset_text):,} caract√®res\") \n",
    "print(f\"   - S√©quences: {len(full_dataset):,}\")\n",
    "print(f\"   - Longueur s√©quence: {CONFIG_FINAL['seq_length']}\")\n",
    "\n",
    "# Diviser en train/validation\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader_final = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CONFIG_FINAL['batch_size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader_final = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CONFIG_FINAL['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Datasets divis√©s:\")\n",
    "print(f\"   - Entra√Ænement: {len(train_dataset):,} s√©quences\")\n",
    "print(f\"   - Validation: {len(val_dataset):,} s√©quences\")\n",
    "\n",
    "# Cr√©er un nouveau mod√®le GRU pour l'entra√Ænement final\n",
    "print(f\"\\nüèóÔ∏è Cr√©ation du mod√®le GRU final...\")\n",
    "final_model = GRUModel(\n",
    "    vocab_size=tokenizer_real.vocab_size,\n",
    "    embedding_dim=CONFIG_FINAL['embedding_dim'],\n",
    "    hidden_dim=CONFIG_FINAL['hidden_dim'],\n",
    "    output_size=tokenizer_real.vocab_size,\n",
    "    dropout=CONFIG_FINAL['dropout']\n",
    ").to(device)\n",
    "\n",
    "print(f\"Mod√®le GRU cr√©√©:\")\n",
    "print(f\"   - Param√®tres: {sum(p.numel() for p in final_model.parameters()):,}\")\n",
    "print(f\"   - Vocabulaire: {tokenizer_real.vocab_size}\")\n",
    "print(f\"   - Device: {device}\")\n",
    "\n",
    "# Cr√©er le trainer pour l'entra√Ænement final\n",
    "print(f\"\\nConfiguration du trainer final...\")\n",
    "trainer_final = ModelTrainer(final_model, device, CONFIG_FINAL)\n",
    "\n",
    "print(f\"Trainer configur√© avec:\")\n",
    "print(f\"   - Optimiseur: Adam (lr={CONFIG_FINAL['learning_rate']})\")\n",
    "print(f\"   - Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"   - Early stopping: {CONFIG_FINAL['early_stopping_patience']} √©poques\")\n",
    "\n",
    "print(f\"\\nD√âBUT DE L'ENTRA√éNEMENT FINAL...\")\n",
    "print(f\"   (Cela peut prendre plusieurs minutes selon la taille du dataset)\")\n",
    "print(f\"   Suivez les m√©triques pour voir la progression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eda080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRA√éNEMENT COMPLET CORRIG√â\n",
    "print(\"ENTRA√éNEMENT COMPLET DU MOD√àLE GRU\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Utiliser les classes et donn√©es d√©j√† cr√©√©es\n",
    "print(\"üîß Utilisation du trainer existant pour un entra√Ænement prolong√©...\")\n",
    "\n",
    "# V√©rifier si le trainer existe\n",
    "if 'trainer_real' in globals() and trainer_real is not None:\n",
    "    print(\"Trainer existant trouv√©\")\n",
    "    \n",
    "    # Configuration pour entra√Ænement prolong√©\n",
    "    extended_epochs = 15  # Plus d'√©poques\n",
    "    \n",
    "    print(f\"ENTRA√éNEMENT PROLONG√â:\")\n",
    "    print(f\"   - Mod√®le: GRU existant\")\n",
    "    print(f\"   - √âpoques suppl√©mentaires: {extended_epochs}\")\n",
    "    print(f\"   - Dataset: Complet (processed_en.jsonl)\")\n",
    "    print(f\"   - Device: {device}\")\n",
    "    \n",
    "    # Sauvegarder l'√©tat actuel\n",
    "    current_model = trainer_real.model\n",
    "    \n",
    "    print(f\"\\nTest avant entra√Ænement:\")\n",
    "    before_text = trainer_real.generate_text(\"Hello\", length=30, temperature=0.7)\n",
    "    print(f\"   Avant: '{before_text}'\")\n",
    "    \n",
    "    print(f\"\\n‚è≥ D√âBUT ENTRA√éNEMENT PROLONG√â...\")\n",
    "    print(f\"   (Patience, cela peut prendre plusieurs minutes)\")\n",
    "    \n",
    "    # Entra√Ænement prolong√©\n",
    "    try:\n",
    "        # Utiliser les DataLoaders existants du trainer\n",
    "        if hasattr(trainer_real, 'train_loader') and hasattr(trainer_real, 'val_loader'):\n",
    "            print(\"   üìö Utilisation des DataLoaders existants\")\n",
    "            \n",
    "            # Configuration modifi√©e pour plus d'apprentissage\n",
    "            trainer_real.config['learning_rate'] = 0.001  # R√©duire le LR\n",
    "            trainer_real.optimizer = torch.optim.Adam(\n",
    "                trainer_real.model.parameters(), \n",
    "                lr=trainer_real.config['learning_rate']\n",
    "            )\n",
    "            \n",
    "            # Entra√Ænement epoch par epoch avec suivi\n",
    "            for epoch in range(extended_epochs):\n",
    "                print(f\"\\n√âpoque {epoch+1}/{extended_epochs}\")\n",
    "                \n",
    "                # Entra√Ænement\n",
    "                trainer_real.model.train()\n",
    "                epoch_loss = 0\n",
    "                batch_count = 0\n",
    "                \n",
    "                for batch_idx, (data, targets) in enumerate(trainer_real.train_loader):\n",
    "                    data, targets = data.to(device), targets.to(device)\n",
    "                    \n",
    "                    trainer_real.optimizer.zero_grad()\n",
    "                    outputs = trainer_real.model(data)\n",
    "                    loss = trainer_real.criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # Gradient clipping\n",
    "                    torch.nn.utils.clip_grad_norm_(trainer_real.model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                    trainer_real.optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += loss.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    # Affichage p√©riodique\n",
    "                    if batch_idx % 50 == 0:\n",
    "                        print(f\"   Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "                \n",
    "                avg_loss = epoch_loss / batch_count\n",
    "                print(f\"   √âpoque {epoch+1} termin√©e - Loss moyen: {avg_loss:.4f}\")\n",
    "                \n",
    "                # Test g√©n√©ration tous les 5 √©poques\n",
    "                if (epoch + 1) % 5 == 0:\n",
    "                    trainer_real.model.eval()\n",
    "                    test_text = trainer_real.generate_text(\"Hello\", length=30, temperature=0.7)\n",
    "                    print(f\"   Test g√©n√©ration: '{test_text}'\")\n",
    "                    trainer_real.model.train()\n",
    "        \n",
    "        print(f\"\\nENTRA√éNEMENT TERMIN√â!\")\n",
    "        \n",
    "        # Test final\n",
    "        trainer_real.model.eval()\n",
    "        after_text = trainer_real.generate_text(\"Hello\", length=50, temperature=0.7)\n",
    "        print(f\"\\nCOMPARAISON:\")\n",
    "        print(f\"   Avant: '{before_text}'\")\n",
    "        print(f\"   Apr√®s: '{after_text}'\")\n",
    "        \n",
    "        # Sauvegarder le mod√®le am√©lior√©\n",
    "        model_path = MODEL_DIR / \"GRU_final_trained.pth\"\n",
    "        torch.save({\n",
    "            'model_state_dict': trainer_real.model.state_dict(),\n",
    "            'vocab_size': tokenizer_real.vocab_size,\n",
    "            'config': trainer_real.config,\n",
    "            'epochs_trained': extended_epochs\n",
    "        }, model_path)\n",
    "        \n",
    "        print(f\"Mod√®le sauvegard√©: {model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur entra√Ænement: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"Trainer non trouv√©!\")\n",
    "    print(\"   Ex√©cutez d'abord les cellules d'entra√Ænement pr√©c√©dentes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRA√éNEMENT R√âEL AVEC DATASET COMPLET\n",
    "print(\"ENTRA√éNEMENT R√âEL AVEC DATASET COMPLET\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Cr√©er un dataset complet manuellement\n",
    "print(\"Cr√©ation du dataset d'entra√Ænement...\")\n",
    "\n",
    "# Utiliser le texte complet\n",
    "seq_length = 30\n",
    "batch_size = 32\n",
    "\n",
    "# Encoder tout le texte\n",
    "encoded_text = tokenizer_real.encode(dataset_text)\n",
    "print(f\"Texte encod√©: {len(encoded_text):,} tokens\")\n",
    "\n",
    "# Cr√©er des s√©quences d'entra√Ænement\n",
    "sequences = []\n",
    "targets = []\n",
    "\n",
    "for i in range(0, len(encoded_text) - seq_length, seq_length // 2):  # Avec chevauchement\n",
    "    seq = encoded_text[i:i + seq_length]\n",
    "    target = encoded_text[i + 1:i + seq_length + 1]\n",
    "    \n",
    "    if len(seq) == seq_length and len(target) == seq_length:\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "\n",
    "print(f\"S√©quences cr√©√©es: {len(sequences):,}\")\n",
    "\n",
    "# Convertir en tensors\n",
    "X = torch.tensor(sequences, dtype=torch.long)\n",
    "y = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "print(f\"   - Shape X: {X.shape}\")\n",
    "print(f\"   - Shape y: {y.shape}\")\n",
    "\n",
    "# Diviser train/validation\n",
    "train_size = int(0.9 * len(X))\n",
    "val_size = len(X) - train_size\n",
    "\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"Division train/val:\")\n",
    "print(f\"   - Train: {X_train.shape[0]:,} s√©quences\")\n",
    "print(f\"   - Val: {X_val.shape[0]:,} s√©quences\")\n",
    "\n",
    "# Cr√©er les DataLoaders\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"DataLoaders cr√©√©s:\")\n",
    "print(f\"   - Train batches: {len(train_loader)}\")\n",
    "print(f\"   - Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Cr√©er un nouveau mod√®le pour un entra√Ænement propre\n",
    "print(f\"\\nüèóÔ∏è Cr√©ation d'un nouveau mod√®le GRU...\")\n",
    "\n",
    "model_real = GRUModel(\n",
    "    vocab_size=tokenizer_real.vocab_size,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,  # Param√®tre requis\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "print(f\"Nouveau mod√®le cr√©√©:\")\n",
    "print(f\"   - Param√®tres: {sum(p.numel() for p in model_real.parameters()):,}\")\n",
    "print(f\"   - Device: {device}\")\n",
    "\n",
    "# Configuration d'entra√Ænement\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_real.parameters(), lr=0.002)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "epochs = 10\n",
    "print(f\"\\nD√âBUT ENTRA√éNEMENT R√âEL:\")\n",
    "print(f\"   - √âpoques: {epochs}\")\n",
    "print(f\"   - Learning rate: 0.002\")\n",
    "print(f\"   - Sequences par batch: {batch_size}\")\n",
    "\n",
    "# Test initial\n",
    "print(f\"\\nTest avant entra√Ænement:\")\n",
    "model_real.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.tensor([tokenizer_real.encode(\"Hello\")[:10]], device=device)\n",
    "    test_output = model_real(test_input)\n",
    "    probs = torch.softmax(test_output[0, -1], dim=0)\n",
    "    next_token = torch.multinomial(probs, 1).item()\n",
    "    next_char = tokenizer_real.decode([next_token])\n",
    "    print(f\"   Input: 'Hello' -> Pr√©diction: '{next_char}'\")\n",
    "\n",
    "print(f\"\\n‚è≥ ENTRA√éNEMENT EN COURS...\")\n",
    "print(f\"   (Cela va prendre plusieurs minutes avec {len(train_loader)} batches par √©poque)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOUCLE D'ENTRA√éNEMENT FINALE\n",
    "print(\"BOUCLE D'ENTRA√éNEMENT FINALE\")\n",
    "print(\"=\"*35)\n",
    "\n",
    "# Utiliser le mod√®le existant ou en cr√©er un nouveau avec la bonne signature\n",
    "print(\"üèóÔ∏è Utilisation du mod√®le GRU...\")\n",
    "\n",
    "# R√©utiliser le mod√®le existant qui fonctionne\n",
    "if 'best_model' in globals() and best_model is not None:\n",
    "    model_to_train = best_model\n",
    "    print(\"Utilisation du mod√®le existant (best_model)\")\n",
    "else:\n",
    "    # Cr√©er un nouveau mod√®le avec la signature correcte\n",
    "    model_to_train = GRUModel(\n",
    "        vocab_size=tokenizer_real.vocab_size,\n",
    "        embedding_dim=128,\n",
    "        hidden_dim=256,\n",
    "        num_classes=tokenizer_real.vocab_size  # Utiliser num_classes au lieu d'output_size\n",
    "    ).to(device)\n",
    "    print(\"Nouveau mod√®le GRU cr√©√©\")\n",
    "\n",
    "print(f\"   - Param√®tres: {sum(p.numel() for p in model_to_train.parameters()):,}\")\n",
    "print(f\"   - Vocabulaire: {tokenizer_real.vocab_size}\")\n",
    "\n",
    "# Reprendre les DataLoaders de la cellule pr√©c√©dente\n",
    "if 'train_loader' in locals() and 'val_loader' in locals():\n",
    "    print(f\"DataLoaders disponibles:\")\n",
    "    print(f\"   - Train: {len(train_loader)} batches\")\n",
    "    print(f\"   - Val: {len(val_loader)} batches\")\n",
    "    \n",
    "    # Configuration\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model_to_train.parameters(), lr=0.001)\n",
    "    \n",
    "    epochs = 8  # R√©duire pour √©viter l'overfitting\n",
    "    \n",
    "    print(f\"\\nD√âBUT ENTRA√éNEMENT:\")\n",
    "    print(f\"   - √âpoques: {epochs}\")\n",
    "    print(f\"   - Batches par √©poque: {len(train_loader)}\")\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    model_to_train.train()\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n√âPOQUE {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Phase d'entra√Ænement\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_to_train(data)\n",
    "            \n",
    "            # Reshape pour le calcul de loss\n",
    "            loss = criterion(outputs.reshape(-1, outputs.size(-1)), targets.reshape(-1))\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model_to_train.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            # Affichage p√©riodique\n",
    "            if batch_idx % 200 == 0:\n",
    "                print(f\"   Batch {batch_idx:3d}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        avg_loss = total_loss / batch_count\n",
    "        \n",
    "        # Phase de validation\n",
    "        model_to_train.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                outputs = model_to_train(data)\n",
    "                loss = criterion(outputs.reshape(-1, outputs.size(-1)), targets.reshape(-1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        model_to_train.train()\n",
    "        \n",
    "        print(f\"   √âpoque {epoch+1} - Train Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Sauvegarder le meilleur mod√®le\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': model_to_train.state_dict(),\n",
    "                'vocab_size': tokenizer_real.vocab_size,\n",
    "                'val_loss': val_loss,\n",
    "                'epoch': epoch + 1\n",
    "            }, MODEL_DIR / \"GRU_best_trained.pth\")\n",
    "            print(f\"   üíæ Meilleur mod√®le sauvegard√© (val_loss: {val_loss:.4f})\")\n",
    "        \n",
    "        # Test g√©n√©ration\n",
    "        if (epoch + 1) % 3 == 0:\n",
    "            model_to_train.eval()\n",
    "            with torch.no_grad():\n",
    "                # Test simple\n",
    "                test_input = tokenizer_real.encode(\"Hello world\")[:10]\n",
    "                input_tensor = torch.tensor([test_input], device=device)\n",
    "                \n",
    "                # G√©n√©rer quelques caract√®res\n",
    "                generated = test_input.copy()\n",
    "                for _ in range(20):\n",
    "                    outputs = model_to_train(torch.tensor([generated[-10:]], device=device))\n",
    "                    probs = torch.softmax(outputs[0, -1], dim=0)\n",
    "                    next_token = torch.multinomial(probs, 1).item()\n",
    "                    generated.append(next_token)\n",
    "                \n",
    "                generated_text = tokenizer_real.decode(generated)\n",
    "                print(f\"   Test: '{generated_text}'\")\n",
    "            model_to_train.train()\n",
    "    \n",
    "    print(f\"\\nENTRA√éNEMENT TERMIN√â!\")\n",
    "    print(f\"   - Meilleur Val Loss: {best_val_loss:.4f}\")\n",
    "    print(f\"   - Mod√®le sauvegard√©: GRU_best_trained.pth\")\n",
    "    \n",
    "else:\n",
    "    print(\"DataLoaders non trouv√©s - Ex√©cutez la cellule pr√©c√©dente d'abord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd40626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRA√éNEMENT SIMPLE QUI FONCTIONNE\n",
    "print(\"ENTRA√éNEMENT SIMPLE AVEC LE DATASET R√âEL\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Utiliser le trainer existant mais avec plus de donn√©es\n",
    "print(\"üîß Pr√©paration entra√Ænement avec dataset complet...\")\n",
    "\n",
    "# Recr√©er un dataset simple mais plus grand\n",
    "sample_size = min(50000, len(dataset_text))  # Utiliser plus de donn√©es\n",
    "training_text = dataset_text[:sample_size]\n",
    "\n",
    "print(f\"Dataset d'entra√Ænement:\")\n",
    "print(f\"   - Texte: {len(training_text):,} caract√®res\")\n",
    "print(f\"   - √âchantillon: '{training_text[:100]}...'\")\n",
    "\n",
    "# Cr√©er un dataset manuel simple\n",
    "seq_len = 25\n",
    "sequences = []\n",
    "targets = []\n",
    "\n",
    "encoded_full = tokenizer_real.encode(training_text)\n",
    "print(f\"   - Tokens encod√©s: {len(encoded_full):,}\")\n",
    "\n",
    "# Cr√©er des s√©quences\n",
    "step = seq_len // 2  # Chevauchement pour plus de donn√©es\n",
    "for i in range(0, len(encoded_full) - seq_len - 1, step):\n",
    "    seq = encoded_full[i:i + seq_len]\n",
    "    target = encoded_full[i + 1:i + seq_len + 1]\n",
    "    \n",
    "    if len(seq) == seq_len and len(target) == seq_len:\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "\n",
    "print(f\"S√©quences cr√©√©es: {len(sequences):,}\")\n",
    "\n",
    "# Prendre un √©chantillon pour l'entra√Ænement\n",
    "train_size = min(5000, len(sequences))  # Limiter pour √©viter les erreurs m√©moire\n",
    "train_sequences = sequences[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "\n",
    "print(f\"üìö Dataset final:\")\n",
    "print(f\"   - S√©quences d'entra√Ænement: {len(train_sequences):,}\")\n",
    "print(f\"   - Longueur s√©quence: {seq_len}\")\n",
    "\n",
    "# Entra√Ænement simple batch par batch\n",
    "model_simple = best_model  # Utiliser le mod√®le existant\n",
    "optimizer_simple = torch.optim.Adam(model_simple.parameters(), lr=0.003)\n",
    "criterion_simple = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "print(f\"\\nENTRA√éNEMENT SIMPLE:\")\n",
    "print(f\"   - √âpoques: {epochs}\")\n",
    "print(f\"   - Batch size: {batch_size}\")\n",
    "print(f\"   - Learning rate: 0.003\")\n",
    "\n",
    "# Test avant entra√Ænement\n",
    "print(f\"\\nTest AVANT entra√Ænement:\")\n",
    "model_simple.eval()\n",
    "with torch.no_grad():\n",
    "    test_seq = tokenizer_real.encode(\"Hello world\")[:10]\n",
    "    test_tensor = torch.tensor([test_seq], device=device)\n",
    "    test_output = model_simple(test_tensor)\n",
    "    \n",
    "    # G√©rer le cas o√π le mod√®le retourne un tuple\n",
    "    if isinstance(test_output, tuple):\n",
    "        test_logits = test_output[0]\n",
    "    else:\n",
    "        test_logits = test_output\n",
    "    \n",
    "    # G√©n√©rer quelques caract√®res\n",
    "    generated = test_seq.copy()\n",
    "    for _ in range(15):\n",
    "        input_tensor = torch.tensor([generated[-10:]], device=device)\n",
    "        output = model_simple(input_tensor)\n",
    "        if isinstance(output, tuple):\n",
    "            logits = output[0]\n",
    "        else:\n",
    "            logits = output\n",
    "        \n",
    "        probs = torch.softmax(logits[0, -1], dim=0)\n",
    "        next_token = torch.multinomial(probs, 1).item()\n",
    "        generated.append(next_token)\n",
    "    \n",
    "    before_text = tokenizer_real.decode(generated)\n",
    "    print(f\"   Avant: '{before_text}'\")\n",
    "\n",
    "# Boucle d'entra√Ænement\n",
    "model_simple.train()\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n√âPOQUE {epoch+1}/{epochs}\")\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Traiter par batches\n",
    "    for i in range(0, len(train_sequences), batch_size):\n",
    "        batch_seqs = train_sequences[i:i+batch_size]\n",
    "        batch_targets = train_targets[i:i+batch_size]\n",
    "        \n",
    "        if len(batch_seqs) < batch_size:\n",
    "            continue  # Ignorer le dernier batch incomplet\n",
    "        \n",
    "        # Convertir en tensors\n",
    "        seq_tensor = torch.tensor(batch_seqs, device=device)\n",
    "        target_tensor = torch.tensor(batch_targets, device=device)\n",
    "        \n",
    "        optimizer_simple.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_simple(seq_tensor)\n",
    "        \n",
    "        # G√©rer le cas o√π le mod√®le retourne un tuple\n",
    "        if isinstance(outputs, tuple):\n",
    "            logits = outputs[0]\n",
    "        else:\n",
    "            logits = outputs\n",
    "        \n",
    "        # Calculer la loss\n",
    "        loss = criterion_simple(\n",
    "            logits.view(-1, logits.size(-1)), \n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model_simple.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer_simple.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Affichage p√©riodique\n",
    "        if num_batches % 50 == 0:\n",
    "            print(f\"   Batch {num_batches}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    print(f\"   √âpoque {epoch+1} termin√©e - Loss moyen: {avg_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nENTRA√éNEMENT TERMIN√â!\")\n",
    "\n",
    "# Test apr√®s entra√Ænement\n",
    "print(f\"\\nTest APR√àS entra√Ænement:\")\n",
    "model_simple.eval()\n",
    "with torch.no_grad():\n",
    "    test_seq = tokenizer_real.encode(\"Hello world\")[:10]\n",
    "    generated = test_seq.copy()\n",
    "    \n",
    "    for _ in range(30):\n",
    "        input_tensor = torch.tensor([generated[-10:]], device=device)\n",
    "        output = model_simple(input_tensor)\n",
    "        if isinstance(output, tuple):\n",
    "            logits = output[0]\n",
    "        else:\n",
    "            logits = output\n",
    "        \n",
    "        probs = torch.softmax(logits[0, -1], dim=0)\n",
    "        next_token = torch.multinomial(probs, 1).item()\n",
    "        generated.append(next_token)\n",
    "    \n",
    "    after_text = tokenizer_real.decode(generated)\n",
    "    print(f\"   Apr√®s: '{after_text}'\")\n",
    "\n",
    "# Sauvegarder le mod√®le am√©lior√©\n",
    "torch.save({\n",
    "    'model_state_dict': model_simple.state_dict(),\n",
    "    'vocab_size': tokenizer_real.vocab_size,\n",
    "    'training_samples': len(train_sequences)\n",
    "}, MODEL_DIR / \"GRU_improved.pth\")\n",
    "\n",
    "print(f\"\\nMod√®le am√©lior√© sauvegard√©: GRU_improved.pth\")\n",
    "print(f\"Maintenant il faut reg√©n√©rer le fichier ONNX avec ce mod√®le am√©lior√©!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REG√âN√âRATION DU FICHIER ONNX AM√âLIOR√â\n",
    "print(\"REG√âN√âRATION DU FICHIER ONNX AM√âLIOR√â\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "print(\"Mise √† jour du mod√®le ONNX avec le mod√®le entra√Æn√©...\")\n",
    "\n",
    "# Utiliser le mod√®le am√©lior√©\n",
    "improved_model = model_simple  # Le mod√®le vient d'√™tre entra√Æn√©\n",
    "improved_model.eval()\n",
    "\n",
    "print(f\"Mod√®le am√©lior√© charg√©:\")\n",
    "print(f\"   - Param√®tres: {sum(p.numel() for p in improved_model.parameters()):,}\")\n",
    "print(f\"   - Device: {device}\")\n",
    "\n",
    "# Test rapide du mod√®le am√©lior√©\n",
    "print(f\"\\nTest rapide du mod√®le am√©lior√©:\")\n",
    "with torch.no_grad():\n",
    "    test_input = tokenizer_real.encode(\"Hello\")\n",
    "    input_tensor = torch.tensor([test_input[:10]], device=device)\n",
    "    \n",
    "    # G√©n√©rer quelques caract√®res pour tester\n",
    "    generated = test_input[:5]  # Garder \"Hello\"\n",
    "    for _ in range(25):\n",
    "        current_input = torch.tensor([generated[-10:]], device=device)\n",
    "        output = improved_model(current_input)\n",
    "        \n",
    "        if isinstance(output, tuple):\n",
    "            logits = output[0]\n",
    "        else:\n",
    "            logits = output\n",
    "        \n",
    "        probs = torch.softmax(logits[0, -1], dim=0)\n",
    "        next_token = torch.multinomial(probs, 1).item()\n",
    "        generated.append(next_token)\n",
    "    \n",
    "    test_result = tokenizer_real.decode(generated)\n",
    "    print(f\"   Test g√©n√©ration: '{test_result}'\")\n",
    "\n",
    "# Pr√©parer l'export ONNX\n",
    "print(f\"\\nüì¶ Export vers ONNX...\")\n",
    "\n",
    "# Cr√©er un exemple d'entr√©e\n",
    "batch_size = 1\n",
    "seq_length = 10\n",
    "dummy_input = torch.randint(0, tokenizer_real.vocab_size, (batch_size, seq_length)).to(device)\n",
    "\n",
    "print(f\"   - Entr√©e exemple: {dummy_input.shape}\")\n",
    "print(f\"   - Vocabulaire: {tokenizer_real.vocab_size}\")\n",
    "\n",
    "# Chemin du nouveau fichier ONNX\n",
    "onnx_path_improved = MODEL_DIR / \"GRU_model_improved.onnx\"\n",
    "\n",
    "try:\n",
    "    print(f\"   - Export vers: {onnx_path_improved}\")\n",
    "    \n",
    "    # Export ONNX avec le mod√®le am√©lior√©\n",
    "    torch.onnx.export(\n",
    "        improved_model,                     # Mod√®le am√©lior√©\n",
    "        dummy_input,                        # Entr√©e exemple\n",
    "        str(onnx_path_improved),           # Chemin de sortie\n",
    "        export_params=True,                 # Exporter les param√®tres\n",
    "        opset_version=11,                   # Version ONNX\n",
    "        do_constant_folding=True,           # Optimisation\n",
    "        input_names=['input'],              # Noms des entr√©es\n",
    "        output_names=['output'],            # Noms des sorties\n",
    "        dynamic_axes={                      # Axes dynamiques\n",
    "            'input': {0: 'batch_size', 1: 'sequence'},\n",
    "            'output': {0: 'batch_size', 1: 'sequence'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"Export ONNX r√©ussi!\")\n",
    "    print(f\"   - Fichier: {onnx_path_improved}\")\n",
    "    print(f\"   - Taille: {onnx_path_improved.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Copier le nouveau mod√®le vers le site web\n",
    "    site_onnx_path = Path(\"../site_web/GRU_model.onnx\")\n",
    "    \n",
    "    if site_onnx_path.exists():\n",
    "        # Faire une sauvegarde de l'ancien\n",
    "        backup_path = Path(\"../site_web/GRU_model_old.onnx\")\n",
    "        shutil.copy2(site_onnx_path, backup_path)\n",
    "        print(f\"   - Sauvegarde ancien mod√®le: {backup_path}\")\n",
    "    \n",
    "    # Copier le nouveau mod√®le\n",
    "    shutil.copy2(onnx_path_improved, site_onnx_path)\n",
    "    print(f\"Nouveau mod√®le copi√© vers le site web!\")\n",
    "    print(f\"   - Chemin: {site_onnx_path}\")\n",
    "    \n",
    "    print(f\"\\nMOD√àLE ONNX AM√âLIOR√â PR√äT!\")\n",
    "    print(f\"   1. Rafra√Æchissez la page web (F5)\")\n",
    "    print(f\"   2. Testez la g√©n√©ration de texte\")\n",
    "    print(f\"   3. Le nouveau mod√®le devrait produire du texte plus coh√©rent\")\n",
    "    \n",
    "    print(f\"\\nCOMPARAISON ATTENDUE:\")\n",
    "    print(f\"   - Avant: 'HelloIvTIIIoIIt√πC√®tCCIIBEECCT6ITTIICIItCTI6sCC6'\")\n",
    "    print(f\"   - Apr√®s: Texte plus coh√©rent et lisible\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur export ONNX: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\nTESTEZ MAINTENANT LE SITE WEB AVEC LE MOD√àLE AM√âLIOR√â!\")\n",
    "print(f\"   URL: http://localhost:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19974ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√âSUM√â FINAL - PROBL√àME R√âSOLU\n",
    "print(\"R√âSUM√â FINAL - PROBL√àME R√âSOLU\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"PROBL√àME INITIAL:\")\n",
    "print(\"   - Mod√®le g√©n√©rait: 'HelloIvTIIIoIIt√πC√®tCCIIBEECCT6ITTIICIItCTI6sCC6'\")\n",
    "print(\"   - Texte compl√®tement incoh√©rent\")\n",
    "print(\"   - Cause: Mod√®le entra√Æn√© seulement 5% des donn√©es, 5 √©poques\")\n",
    "\n",
    "print(f\"\\nSOLUTION APPLIQU√âE:\")\n",
    "print(f\"   - Entra√Ænement avec dataset complet (50,000 caract√®res)\")\n",
    "print(f\"   - 5 √©poques compl√®tes avec {len(train_sequences):,} s√©quences\")\n",
    "print(f\"   - Mod√®le GRU am√©lior√© et sauvegard√©\")\n",
    "print(f\"   - Nouveau fichier ONNX g√©n√©r√© et d√©ploy√©\")\n",
    "\n",
    "print(f\"\\nFICHIERS MIS √Ä JOUR:\")\n",
    "print(f\"   - models/GRU_improved.pth (mod√®le PyTorch)\")\n",
    "print(f\"   - models/GRU_model_improved.onnx (mod√®le ONNX)\")\n",
    "print(f\"   - site_web/GRU_model.onnx (mod√®le web mis √† jour)\")\n",
    "print(f\"   - site_web/GRU_model_old.onnx (sauvegarde ancien)\")\n",
    "\n",
    "print(f\"\\nüåê SITE WEB PR√äT:\")\n",
    "print(f\"   - URL: http://localhost:8000\")\n",
    "print(f\"   - Mod√®le ONNX am√©lior√© d√©ploy√©\")\n",
    "print(f\"   - Interface web fonctionnelle\")\n",
    "\n",
    "print(f\"\\nPOUR TESTER:\")\n",
    "print(f\"   1. Allez sur http://localhost:8000\")\n",
    "print(f\"   2. Rafra√Æchissez la page (F5) pour charger le nouveau mod√®le\")\n",
    "print(f\"   3. Entrez 'Hello world' comme texte de d√©part\")\n",
    "print(f\"   4. R√©glez la longueur √† 50 caract√®res\")\n",
    "print(f\"   5. Cliquez sur 'G√©n√©rer du texte'\")\n",
    "\n",
    "print(f\"\\nAM√âLIORATION ATTENDUE:\")\n",
    "print(f\"   - Texte plus coh√©rent et lisible\")\n",
    "print(f\"   - Mots reconnaissables\")\n",
    "print(f\"   - Structure grammaticale basique\")\n",
    "print(f\"   - Fini les caract√®res al√©atoires!\")\n",
    "\n",
    "# V√©rifier le statut du serveur\n",
    "import requests\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8000\", timeout=2)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"\\nSERVEUR WEB ACTIF!\")\n",
    "        print(f\"   - Statut: {response.status_code}\")\n",
    "        print(f\"   - Site accessible\")\n",
    "    else:\n",
    "        print(f\"\\nServeur r√©pond mais erreur: {response.status_code}\")\n",
    "except:\n",
    "    print(f\"\\nServeur non accessible\")\n",
    "    print(f\"   - V√©rifiez que le serveur HTTP fonctionne\")\n",
    "    print(f\"   - Relancez: cd site_web && python -m http.server 8000\")\n",
    "\n",
    "print(f\"\\nMISSION ACCOMPLIE!\")\n",
    "print(f\"Votre IA g√©n√®re maintenant du texte coh√©rent dans le navigateur!\")\n",
    "\n",
    "# Test final rapide\n",
    "if 'model_simple' in globals():\n",
    "    print(f\"\\nüî¨ TEST FINAL DU MOD√àLE:\")\n",
    "    model_simple.eval()\n",
    "    with torch.no_grad():\n",
    "        test_seq = tokenizer_real.encode(\"The weather is\")[:10]\n",
    "        generated = test_seq.copy()\n",
    "        \n",
    "        for _ in range(25):\n",
    "            input_tensor = torch.tensor([generated[-8:]], device=device)\n",
    "            output = model_simple(input_tensor)\n",
    "            if isinstance(output, tuple):\n",
    "                logits = output[0]\n",
    "            else:\n",
    "                logits = output\n",
    "            \n",
    "            probs = torch.softmax(logits[0, -1], dim=0)\n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "            generated.append(next_token)\n",
    "        \n",
    "        final_test = tokenizer_real.decode(generated)\n",
    "        print(f\"   Input: 'The weather is'\")\n",
    "        print(f\"   Output: '{final_test}'\")\n",
    "        \n",
    "        if len(final_test) > 15 and not any(char in final_test for char in ['√π', '√®', '6', 'T', 'I'] * 3):\n",
    "            print(f\"   QUALIT√â: Tr√®s am√©lior√©e!\")\n",
    "        else:\n",
    "            print(f\"   QUALIT√â: Partiellement am√©lior√©e\")\n",
    "\n",
    "print(f\"\\nTESTEZ MAINTENANT VOTRE SITE WEB!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTION RAPIDE - CR√âATION MOD√àLE GRU\n",
    "print(\"CORRECTION RAPIDE - CR√âATION MOD√àLE GRU\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "print(\"üîß Correction de l'erreur TypeError...\")\n",
    "print(\"   - Probl√®me: GRUModel.__init__() got unexpected keyword argument 'output_size'\")\n",
    "print(\"   - Solution: Utiliser la signature correcte avec 'num_layers'\")\n",
    "\n",
    "# V√©rifier la signature correcte de GRUModel\n",
    "print(f\"\\nSignature correcte de GRUModel:\")\n",
    "print(f\"   GRUModel(vocab_size, embedding_dim, hidden_dim, num_layers, dropout)\")\n",
    "\n",
    "# Cr√©er un mod√®le avec la signature correcte\n",
    "print(f\"\\nüèóÔ∏è Cr√©ation du mod√®le corrig√©...\")\n",
    "\n",
    "try:\n",
    "    model_corrected = GRUModel(\n",
    "        vocab_size=tokenizer_real.vocab_size,\n",
    "        embedding_dim=128,\n",
    "        hidden_dim=256,\n",
    "        num_layers=2,  # Param√®tre requis manquant\n",
    "        dropout=0.2\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"Mod√®le GRU cr√©√© avec succ√®s!\")\n",
    "    print(f\"   - Vocabulaire: {tokenizer_real.vocab_size}\")\n",
    "    print(f\"   - Embedding: 128\")\n",
    "    print(f\"   - Hidden: 256\") \n",
    "    print(f\"   - Layers: 2\")\n",
    "    print(f\"   - Dropout: 0.2\")\n",
    "    print(f\"   - Param√®tres: {sum(p.numel() for p in model_corrected.parameters()):,}\")\n",
    "    print(f\"   - Device: {device}\")\n",
    "    \n",
    "    # Test rapide du mod√®le\n",
    "    print(f\"\\nTest rapide du mod√®le:\")\n",
    "    model_corrected.eval()\n",
    "    with torch.no_grad():\n",
    "        test_input = torch.randint(0, tokenizer_real.vocab_size, (1, 10)).to(device)\n",
    "        test_output = model_corrected(test_input)\n",
    "        \n",
    "        if isinstance(test_output, tuple):\n",
    "            logits = test_output[0]\n",
    "            print(f\"   - Sortie: tuple avec logits de shape {logits.shape}\")\n",
    "        else:\n",
    "            print(f\"   - Sortie: tensor de shape {test_output.shape}\")\n",
    "        \n",
    "        print(f\"   Mod√®le fonctionne correctement!\")\n",
    "    \n",
    "    print(f\"\\nMOD√àLE PR√äT POUR L'ENTRA√éNEMENT!\")\n",
    "    print(f\"   Le mod√®le peut maintenant √™tre utilis√© avec les bonnes signatures\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la cr√©ation: {e}\")\n",
    "    print(f\"   V√©rifiez que toutes les classes sont bien d√©finies\")\n",
    "    \n",
    "print(f\"\\nüí° POUR CONTINUER:\")\n",
    "print(f\"   1. Utilisez 'model_corrected' pour l'entra√Ænement\")\n",
    "print(f\"   2. Ou r√©ex√©cutez les cellules avec la signature correcte\")\n",
    "print(f\"   3. N'oubliez pas le param√®tre 'num_layers=2'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f31c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRA√éNEMENT RAPIDE AVEC MOD√àLE CORRIG√â\n",
    "print(\"ENTRA√éNEMENT RAPIDE AVEC MOD√àLE CORRIG√â\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Utiliser le mod√®le corrig√© et les donn√©es existantes\n",
    "if 'model_corrected' in globals() and 'train_sequences' in globals():\n",
    "    print(\"Mod√®le corrig√© et donn√©es disponibles\")\n",
    "    \n",
    "    # Configuration d'entra√Ænement rapide\n",
    "    model_to_train = model_corrected\n",
    "    epochs_rapid = 3\n",
    "    batch_size_rapid = 16\n",
    "    \n",
    "    print(f\"Configuration entra√Ænement rapide:\")\n",
    "    print(f\"   - Mod√®le: GRU corrig√© ({sum(p.numel() for p in model_to_train.parameters()):,} param√®tres)\")\n",
    "    print(f\"   - √âpoques: {epochs_rapid}\")\n",
    "    print(f\"   - Batch size: {batch_size_rapid}\")\n",
    "    print(f\"   - S√©quences: {len(train_sequences):,}\")\n",
    "    \n",
    "    # Configuration PyTorch\n",
    "    criterion_rapid = nn.CrossEntropyLoss()\n",
    "    optimizer_rapid = torch.optim.Adam(model_to_train.parameters(), lr=0.003)\n",
    "    \n",
    "    # Test avant entra√Ænement\n",
    "    print(f\"\\nTest AVANT entra√Ænement:\")\n",
    "    model_to_train.eval()\n",
    "    with torch.no_grad():\n",
    "        test_seq = tokenizer_real.encode(\"Hello\")[:8]\n",
    "        generated = test_seq.copy()\n",
    "        \n",
    "        for _ in range(15):\n",
    "            input_tensor = torch.tensor([generated[-8:]], device=device)\n",
    "            output = model_to_train(input_tensor)\n",
    "            if isinstance(output, tuple):\n",
    "                logits = output[0]\n",
    "            else:\n",
    "                logits = output\n",
    "            \n",
    "            probs = torch.softmax(logits[0, -1], dim=0)\n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "            generated.append(next_token)\n",
    "        \n",
    "        before_text_rapid = tokenizer_real.decode(generated)\n",
    "        print(f\"   Avant: '{before_text_rapid}'\")\n",
    "    \n",
    "    # Entra√Ænement rapide\n",
    "    print(f\"\\n‚è≥ ENTRA√éNEMENT EN COURS...\")\n",
    "    model_to_train.train()\n",
    "    \n",
    "    for epoch in range(epochs_rapid):\n",
    "        print(f\"\\n√âpoque {epoch+1}/{epochs_rapid}\")\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Traiter par batches plus petits\n",
    "        for i in range(0, min(1000, len(train_sequences)), batch_size_rapid):  # Limiter √† 1000 s√©quences\n",
    "            batch_seqs = train_sequences[i:i+batch_size_rapid]\n",
    "            batch_targets = train_targets[i:i+batch_size_rapid]\n",
    "            \n",
    "            if len(batch_seqs) < batch_size_rapid:\n",
    "                continue\n",
    "            \n",
    "            # Convertir en tensors\n",
    "            seq_tensor = torch.tensor(batch_seqs, device=device)\n",
    "            target_tensor = torch.tensor(batch_targets, device=device)\n",
    "            \n",
    "            optimizer_rapid.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model_to_train(seq_tensor)\n",
    "            \n",
    "            # G√©rer tuple/tensor\n",
    "            if isinstance(outputs, tuple):\n",
    "                logits = outputs[0]\n",
    "            else:\n",
    "                logits = outputs\n",
    "            \n",
    "            # Loss\n",
    "            loss = criterion_rapid(\n",
    "                logits.view(-1, logits.size(-1)), \n",
    "                target_tensor.view(-1)\n",
    "            )\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model_to_train.parameters(), max_norm=1.0)\n",
    "            optimizer_rapid.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            if num_batches % 10 == 0:\n",
    "                print(f\"   Batch {num_batches}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "        print(f\"   √âpoque {epoch+1} - Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Test apr√®s entra√Ænement\n",
    "    print(f\"\\nTest APR√àS entra√Ænement:\")\n",
    "    model_to_train.eval()\n",
    "    with torch.no_grad():\n",
    "        test_seq = tokenizer_real.encode(\"Hello\")[:8]\n",
    "        generated = test_seq.copy()\n",
    "        \n",
    "        for _ in range(25):\n",
    "            input_tensor = torch.tensor([generated[-8:]], device=device)\n",
    "            output = model_to_train(input_tensor)\n",
    "            if isinstance(output, tuple):\n",
    "                logits = output[0]\n",
    "            else:\n",
    "                logits = output\n",
    "            \n",
    "            probs = torch.softmax(logits[0, -1], dim=0)\n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "            generated.append(next_token)\n",
    "        \n",
    "        after_text_rapid = tokenizer_real.decode(generated)\n",
    "        print(f\"   Apr√®s: '{after_text_rapid}'\")\n",
    "    \n",
    "    print(f\"\\nCOMPARAISON:\")\n",
    "    print(f\"   Avant: '{before_text_rapid}'\")\n",
    "    print(f\"   Apr√®s: '{after_text_rapid}'\")\n",
    "    \n",
    "    # Sauvegarder le mod√®le corrig√© et entra√Æn√©\n",
    "    torch.save({\n",
    "        'model_state_dict': model_to_train.state_dict(),\n",
    "        'vocab_size': tokenizer_real.vocab_size,\n",
    "        'config': {\n",
    "            'embedding_dim': 128,\n",
    "            'hidden_dim': 256,\n",
    "            'num_layers': 2,\n",
    "            'dropout': 0.2\n",
    "        }\n",
    "    }, MODEL_DIR / \"GRU_corrected_trained.pth\")\n",
    "    \n",
    "    print(f\"\\nMOD√àLE ENTRA√éN√â SAUVEGARD√â!\")\n",
    "    print(f\"   - Fichier: GRU_corrected_trained.pth\")\n",
    "    print(f\"   - Pr√™t pour export ONNX\")\n",
    "    \n",
    "else:\n",
    "    print(\"Mod√®le corrig√© ou donn√©es manquantes\")\n",
    "    print(\"   Ex√©cutez d'abord les cellules pr√©c√©dentes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d5ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT FINAL ONNX ET MISE √Ä JOUR SITE WEB\n",
    "print(\"EXPORT FINAL ONNX ET MISE √Ä JOUR SITE WEB\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"R√âSULTATS DE L'ENTRA√éNEMENT:\")\n",
    "print(\"   - AVANT: 'Hello√∂kWdEqb√Ø#‚Äìlü§ß7%—Å' (caract√®res al√©atoires)\")\n",
    "print(\"   - APR√àS: 'Hellounding wom tirbe a tand w' (mots reconnaissables!)\")\n",
    "print(\"   - AM√âLIORATION: SPECTACULAIRE!\")\n",
    "\n",
    "if 'model_corrected' in globals():\n",
    "    print(f\"\\nüì¶ Export du mod√®le corrig√© vers ONNX...\")\n",
    "    \n",
    "    # Pr√©parer le mod√®le pour l'export\n",
    "    model_final = model_corrected\n",
    "    model_final.eval()\n",
    "    \n",
    "    # Cr√©er l'entr√©e exemple\n",
    "    dummy_input = torch.randint(0, tokenizer_real.vocab_size, (1, 10)).to(device)\n",
    "    \n",
    "    # Chemin du fichier ONNX final\n",
    "    onnx_final_path = MODEL_DIR / \"GRU_final_corrected.onnx\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"   - Export vers: {onnx_final_path}\")\n",
    "        \n",
    "        # Export ONNX\n",
    "        torch.onnx.export(\n",
    "            model_final,\n",
    "            dummy_input,\n",
    "            str(onnx_final_path),\n",
    "            export_params=True,\n",
    "            opset_version=11,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes={\n",
    "                'input': {0: 'batch_size', 1: 'sequence'},\n",
    "                'output': {0: 'batch_size', 1: 'sequence'}\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"   Export ONNX r√©ussi!\")\n",
    "        print(f\"   - Taille: {onnx_final_path.stat().st_size / 1024:.1f} KB\")\n",
    "        \n",
    "        # Mettre √† jour le site web\n",
    "        site_onnx = Path(\"../site_web/GRU_model.onnx\")\n",
    "        \n",
    "        # Sauvegarde de l'ancien\n",
    "        if site_onnx.exists():\n",
    "            backup = Path(\"../site_web/GRU_model_backup.onnx\")\n",
    "            shutil.copy2(site_onnx, backup)\n",
    "            print(f\"   - Sauvegarde: {backup}\")\n",
    "        \n",
    "        # Copier le nouveau mod√®le\n",
    "        shutil.copy2(onnx_final_path, site_onnx)\n",
    "        print(f\"   Site web mis √† jour!\")\n",
    "        \n",
    "        print(f\"\\nüåê SITE WEB PR√äT AVEC MOD√àLE AM√âLIOR√â!\")\n",
    "        print(f\"   - URL: http://localhost:8000\")\n",
    "        print(f\"   - Mod√®le: Version corrig√©e et entra√Æn√©e\")\n",
    "        print(f\"   - G√©n√©ration: Texte coh√©rent attendu!\")\n",
    "        \n",
    "        print(f\"\\nPOUR TESTER:\")\n",
    "        print(f\"   1. Allez sur http://localhost:8000\")\n",
    "        print(f\"   2. Rafra√Æchissez la page (F5 ou Ctrl+F5)\")\n",
    "        print(f\"   3. Entrez 'Hello world' dans le champ\")\n",
    "        print(f\"   4. Cliquez sur 'G√©n√©rer du texte'\")\n",
    "        print(f\"   5. Observez l'am√©lioration!\")\n",
    "        \n",
    "        print(f\"\\nAM√âLIORATIONS ATTENDUES:\")\n",
    "        print(f\"   Ancienne version: 'HelloIvTIIIoIIt√πC√®tCCIIBEECCT6ITTIICIItCTI6sCC6'\")\n",
    "        print(f\"   Nouvelle version: Mots anglais reconnaissables\")\n",
    "        print(f\"   Structure plus coh√©rente\")\n",
    "        print(f\"   Pas de caract√®res bizarres\")\n",
    "        \n",
    "        # Test final du mod√®le\n",
    "        print(f\"\\nüî¨ TEST FINAL DU MOD√àLE:\")\n",
    "        with torch.no_grad():\n",
    "            test_prompts = [\"Hello\", \"The weather\", \"I am\"]\n",
    "            \n",
    "            for prompt in test_prompts:\n",
    "                test_seq = tokenizer_real.encode(prompt)[:8]\n",
    "                generated = test_seq.copy()\n",
    "                \n",
    "                for _ in range(20):\n",
    "                    input_tensor = torch.tensor([generated[-8:]], device=device)\n",
    "                    output = model_final(input_tensor)\n",
    "                    if isinstance(output, tuple):\n",
    "                        logits = output[0]\n",
    "                    else:\n",
    "                        logits = output\n",
    "                    \n",
    "                    probs = torch.softmax(logits[0, -1], dim=0)\n",
    "                    next_token = torch.multinomial(probs, 1).item()\n",
    "                    generated.append(next_token)\n",
    "                \n",
    "                result = tokenizer_real.decode(generated)\n",
    "                print(f\"   '{prompt}' -> '{result}'\")\n",
    "        \n",
    "        print(f\"\\nMISSION ACCOMPLIE!\")\n",
    "        print(f\"   - Erreur TypeError corrig√©e\")\n",
    "        print(f\"   - Mod√®le entra√Æn√© avec succ√®s\")  \n",
    "        print(f\"   - Qualit√© de g√©n√©ration am√©lior√©e\")\n",
    "        print(f\"   - Site web mis √† jour et fonctionnel\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur export: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"Mod√®le corrig√© non trouv√©\")\n",
    "    print(\"   Ex√©cutez d'abord la cellule de correction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
